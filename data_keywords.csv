text,keywords
"magnetic resonance spectroscopic imaging (mrsi) is a powerful molecular imaging modality but has very limited speed, resolution, and snr tradeoffs. construction of a low-dimensional model to effectively reduce the dimensionality of the imaging problem has recently shown great promise in improving these tradeoffs. this paper presents a new approach to model and reconstruct the spectroscopic signals by learning a nonlinear low-dimensional representation of the general mr spectra. specifically, we trained a deep neural network to capture the low-dimensional manifold, where the high-dimensional spectroscopic signals reside. a regularization formulation is proposed to effectively integrate the learned model and physics-based data acquisition model for mrsi reconstruction with the capability to incorporate additional spatiospectral constraints. an efficient numerical algorithm was developed to solve the associated optimization problem involving back-propagating the trained network. simulation and experimental results were obtained to demonstrate the representation power of the learned model and the ability of the proposed formulation in producing snr-enhancing reconstruction from the practical mrsi data.","['constrained magnetic resonance spectroscopic imaging', 'learning nonlinear low', 'dimensional models']"
"existing deep convolutional neural networks (cnns) have found major success in image deraining, but at the expense of an enormous number of parameters. this limits their potential applications, e.g., in mobile devices. in this paper, we propose a lightweight pyramid networt (lpnet) for single-image deraining. instead of designing a complex network structure, we use domain-specific knowledge to simplify the learning process. in particular, we find that by introducing the mature gaussian-laplacian image pyramid decomposition technology to the neural network, the learning problem at each pyramid level is greatly simplified and can be handled by a relatively shallow network with few parameters. we adopt recursive and residual network structures to build the proposed lpnet, which has less than 8k parameters while still achieving the state-of-the-art performance on rain removal. we also discuss the potential value of lpnet for other low- and high-level vision tasks.","['lightweight pyramid networks', 'image deraining']"
"deep learning techniques have been increasingly used to provide more accurate and more accessible diagnosis of thorax diseases on chest radiographs. however, due to the lack of dense annotation of large-scale chest radiograph data, this computer-aided diagnosis task is intrinsically a weakly supervised learning problem and remains challenging. in this paper, we propose a novel deep convolutional neural network called thorax-net to diagnose 14 thorax diseases using chest radiography. thorax-net consists of a classification branch and an attention branch. the classification branch serves as a uniform feature extraction-classification network to free users from the troublesome hand-crafted feature extraction and classifier construction. the attention branch exploits the correlation between class labels and the locations of pathological abnormalities via analyzing the feature maps learned by the classification branch. feeding a chest radiograph to the trained thorax-net, a diagnosis is obtained by averaging and binarizing the outputs of two branches. the proposed thorax-net model has been evaluated against three state-of-the-art deep learning models using the patientwise official split of the chestx-ray14 dataset and against other five deep learning models using the imagewise random data split. our results show that thorax-net achieves an average per-class area under the receiver operating characteristic curve (auc) of 0.7876 and 0.896 in both experiments, respectively, which are higher than the auc values obtained by other deep models when they were all trained with no external data.","['attention regularized deep neural network', 'thoracic diseases', 'chest radiography', 'thorax', 'net', 'classification']"
the original article unfortunately contained a mistake. figure 2b was removed in the article.,"['carotid artery intima media thickness ultrasound images', 'deep learning', 'correction', 'classification']"
"the most common applications of artificial intelligence (ai) in drug treatment have to do with matching patients to their optimal drug or combination of drugs, predicting drug-target or drug-drug interactions, and optimizing treatment protocols. this review outlines some of the recently developed ai methods aiding the drug treatment and administration process. selection of the best drug(s) for a patient typically requires the integration of patient data, such as genetics or proteomics, with drug data, like compound chemical descriptors, to score the therapeutic efficacy of drugs. the prediction of drug interactions often relies on similarity metrics, assuming that drugs with similar structures or targets will have comparable behavior or may interfere with each other. optimizing the dosage schedule for administration of drugs is performed using mathematical models to interpret pharmacokinetic and pharmacodynamic data. the recently developed and powerful models for each of these tasks are addressed, explained, and analyzed here.","['drug treatment', 'artificial intelligence']"
"to compare detection patterns of 80 cephalometric landmarks identified by an automated identification system (ai) based on a recently proposed deep-learning method, the you-only-look-once version 3 (yolov3), with those identified by human examiners.","['part 2', 'cephalometric landmarks', 'automated identification', 'might', 'human', 'better']"
"learning the structures and unknown correlations of a motor imagery electroencephalogram (mi-eeg) signal is important for its classification. it is also a major challenge to obtain good classification accuracy from the increased number of classes and increased variability from different people. in this study, a four-class mi task is investigated.","['novel hybrid deep learning scheme', 'class motor imagery classification', 'four']"
"we present a deep reinforcement learning framework where a machine agent is trained to search for a policy to generate a ground state for the square ice model by exploring the physical environment. after training, the agent is capable of proposing a sequence of local moves to achieve the goal. analysis of the trained policy and the state value function indicates that the ice rule and loop-closing condition are learned without prior knowledge. we test the trained policy as a sampler in the markov chain monte carlo and benchmark against the baseline loop algorithm. this framework can be generalized to other models with topological constraints where generation of constraint-preserving states is difficult.","['deep reinforcement learning', 'ice states', 'generation']"
"to assess the use of deep learning (dl) for computer-assisted glaucoma identification, and the impact of training using images selected by an active learning strategy, which minimizes labelling cost. additionally, this study focuses on the explainability of the glaucoma classifier.","['convolutional neural network', 'colour fundus images', 'transfer learning', 'accurate prediction', 'relies', 'glaucoma', 'active']"
"transcription factor binding sites (tfbss) play an important role in gene expression regulation. many computational methods for tfbs prediction need sufficient labeled data. however, many transcription factors (tfs) lack labeled data in cell types. we propose a novel method, referred to as dann_tf, for tfbs prediction. dann_tf consists of a feature extractor, a label predictor, and a domain classifier. the feature extractor and the domain classifier constitute an adversarial network, which ensures that learned features are common features across different cell types. dann_tf is evaluated on five tfs in five cell types with a total of 25 cell-type tf pairs and compared to a baseline method which does not use adversarial network. for both data augmentation and cross-cell-type prediction, dann_tf performs better than the baseline method on most cell-type tf pairs. dann_tf is further evaluated by an additional 13 tfs in the five cell types with a total of 65 cell-type tf pairs. results show that dann_tf achieves significantly higher auc than the baseline method on 96.9% pairs of the 65 cell-type tf pairs. this is a strong indication that dann_tf can indeed learn common features for cross-cell-type tfbs prediction.","['integrating convolutional neural network', 'adversarial network', 'type prediction', 'binding site', 'tf', 'cross', 'cell']"
"membrane proteins, the most important drug targets, account for around 30% of total proteins encoded by the genome of living organisms. an important role of these proteins is to bind adenosine triphosphate (atp), facilitating crucial biological processes such as metabolism and cell signaling. there are several reports elucidating atp-binding sites within proteins. however, such studies on membrane proteins are limited. our prediction tool, deepatp, combines evolutionary information in the form of position specific scoring matrix and two-dimensional convolutional neural network to predict atp-binding sites in membrane proteins with an mcc of 0.89 and an auc of 99%. compared to recently published atp-binding site predictors and classifiers that use traditional machine learning algorithms, our approach performs significantly better. we suggest this method as a reliable tool for biologists for atp-binding site prediction in membrane proteins.","['dimensional convolutional neural network', 'membrane proteins using', 'binding sites', 'two', 'prediction', 'atp']"
"machine learning (ml) has become a vital part of medical imaging research. ml methods have evolved over the years from manual seeded inputs to automatic initializations. the advancements in the field of ml have led to more intelligent and self-reliant computer-aided diagnosis (cad) systems, as the learning ability of ml methods has been constantly improving. more and more automated methods are emerging with deep feature learning and representations. recent advancements of ml with deeper and extensive representation approaches, commonly known as deep learning (dl) approaches, have made a very significant impact on improving the diagnostics capabilities of the cad systems.","['diagnosis using mammographic data', 'breast cancer detection', 'systematic review']"
"in this paper, we propose a novel deep sparse coding network (scn) capable of efficiently adapting its own regularization parameters for a given application. the network is trained end-to-end with a supervised task-driven learning algorithm via error backpropagation. during training, the network learns both the dictionaries and the regularization parameters of each sparse coding layer so that the reconstructive dictionaries are smoothly transformed into increasingly discriminative representations. in addition, the adaptive regularization also offers the network more flexibility to adjust sparsity levels. furthermore, we have devised a sparse coding layer utilizing a 'skinny' dictionary. integral to computational efficiency, these skinny dictionaries compress the high dimensional sparse codes into lower dimensional structures. the adaptivity and discriminability of our fifteen-layer sparse coding network are demonstrated on five benchmark datasets, namely cifar-10, cifar-100, stl-10, svhn and mnist, most of which are considered difficult for sparse coding models. experimental results show that our architecture overwhelmingly outperforms traditional one-layer sparse coding architectures while using much fewer parameters. moreover, our multilayer architecture exploits the benefits of depth with sparse coding's characteristic ability to operate on smaller datasets. in such data-constrained scenarios, our technique demonstrates highly competitive performance compared to the deep neural networks.","['supervised deep sparse coding networks', 'image classification']"
"deep learning (dl) has emerged as a powerful tool to make accurate predictions from complex data such as image, text, or video. however, its ability to predict phenotypic values from molecular data is less well studied. here, we describe the theoretical foundations of dl and provide a generic code that can be easily modified to suit specific needs. dl comprises a wide variety of algorithms which depend on numerous hyperparameters. careful optimization of hyperparameter values is critical to avoid overfitting. among the dl architectures currently tested in genomic prediction, convolutional neural networks (cnns) seem more promising than multilayer perceptrons (mlps). a limitation of dl is in interpreting the results. this may not be relevant for genomic prediction in plant or animal breeding but can be critical when deciding the genetic risk to a disease. although dl technologies are not ""plug-and-play"", they are easily implemented using keras and tensorflow public software. to illustrate the principles described here, we implemented a keras-based code in github.","['complex trait genomic prediction', 'using deep learning', 'guide']"
"the ovary is a complex endocrine organ that shows significant structural and functional changes in the female reproductive system over recurrent cycles. there are different types of follicles in the ovarian tissue. the reproductive potential of each individual depends on the numbers of these follicles. however, genetic mutations, toxins, and some specific drugs have an effect on follicles. to determine these effects, it is of great importance to count the follicles. the number of follicles in the ovary is usually counted manually by experts, which is a tedious, time-consuming and intense process. in some cases, the experts count the follicles in a subjective way due to their knowledge. in this study, for the first time, a method has been proposed for automatically counting the follicles of ovarian tissue. our method primarily involves filter-based segmentation applied to whole slide histological images, based on a convolutional neural network (cnn). a new method is also proposed to eliminate the noise that occurs after the segmentation process and to determine the boundaries of the follicles. finally, the follicles whose boundaries are determined are classified. to evaluate its performance, the results of the proposed method were compared with those obtained by two different experts and the results of the faster r-cnn model. the number of follicles obtained by the proposed method was very close to the number of follicles counted by the experts. it was also found that the proposed method was much more successful than the faster r-cnn model.","['whole slide histological images based', 'convolutional neural network', 'ovarian follicles', 'new method', 'automatic counting']"
"cardiovascular disease (cvd) has become one of the most serious diseases that threaten human health. over the past decades, over 150 million humans have died of cvds. hence, timely prediction of cvds is especially important. currently, deep learning algorithm-based cvd diagnosis methods are extensively employed, however, most such algorithms can only utilize one-lead ecgs. hence, the potential information in other-lead ecgs was not utilized. to address this issue, we have developed novel methods for diagnosing arrhythmia. in this work, dl-ccanet and tl-ccanet are proposed to extract abstract discriminating features from dual-lead and three-lead ecgs, respectively. then, the linear support vector machine specializing in high-dimensional features is used as the classifier model. on the mit-bih database, a 95.2% overall accuracy is obtained by detecting 15 types of heartbeats using dl-ccanet. on the incart database, overall accuracies of 94.01% (ii and v1 leads), 93.90% (v1 and v5 leads) and 94.07% (ii and v5 leads) are achieved by detecting seven types of heartbeat using dl-ccanet, while tl-ccanet yields a higher overall accuracy of 95.52% using the above three leads. in addition, all of the above experiments are implemented using noisy ecg data. the proposed methods have potential to be applied in the clinic and mobile devices.","['lead ecg classification using dl', 'novel approach', 'tl', 'multi', 'ccanet']"
"in this brief, heterogeneity and noise in big data are shown to increase the generalization error for a traditional learning regime utilized for deep neural networks (deep nns). to reduce this error, while overcoming the issue of vanishing gradients, a direct error-driven learning (edl) scheme is proposed. first, to reduce the impact of heterogeneity and data noise, the concept of a neighborhood is introduced. using this neighborhood, an approximation of generalization error is obtained and an overall error, comprised of learning and the approximate generalization errors, is defined. a novel nn weight-tuning law is obtained through a layer-wise performance measure enabling the direct use of overall error for learning. additional constraints are introduced into the layer-wise performance measure to guide and improve the learning process in the presence of noisy dimensions. the proposed direct edl scheme effectively addresses the issue of heterogeneity and noise while mitigating vanishing gradients and noisy dimensions. a comprehensive simulation study is presented where the proposed approach is shown to mitigate the vanishing gradient problem while improving generalization by 6%.","['deep neural networks', 'driven learning', 'direct error', 'big data', 'applications']"
"as the most commonly occurring form of mental illness worldwide, depression poses significant health and economic burdens to both the individual and community. different types of depression pose different levels of risk. individuals who suffer from mild forms of depression may recover without any assistance or be effectively managed by primary care or family practitioners. however, other forms of depression are far more severe and require advanced care by certified mental health providers. however, identifying cases of depression that require advanced care may be challenging to primary care providers and health care team members whose skill sets run broad rather than deep.","['statewide health information exchange', 'depression using data extracted', 'machine learning approach', 'advanced care', 'patients', 'need', 'identification']"
"the large pose variations and misalignment errors exhibited by person images significantly increase the difficulty of person re-identification (reid). existing works commonly apply extra operations like pose estimation, part segmentation, etc., to alleviate those issues and improve the robustness of pedestrian representations. while boosting the reid accuracy, those operations introduce considerable computational overheads and make the deep models complex and hard to tune. to chase a more efficient solution, we propose a part-guided representation (pgr) composed of pose invariant feature (pif) and local descriptive feature (ldf), respectively. we call pgr ""part-guided"" because it is trained and supervised by local part cues. specifically, pif approximates a pose invariant representation inferred by pose estimation and pose normalization. ldf focuses on discriminative body parts by approximating a representation learned with body region segmentation. in this way, extra pose extraction is only introduced during the training stage to supervise the learning of pgr, but is not required during the testing stage for feature extraction. extensive comparisons with recent works on five widely used datasets demonstrate the competitive accuracy and efficiency of pgr.","['guided representation learning', 'pose', 'person', 'identification']"
"while convolutional neural network (cnn) has been demonstrating powerful ability to learn hierarchical spatial features from medical images, it is still difficult to apply it directly to resting-state functional mri (rs-fmri) and the derived brain functional networks (bfns). we propose a novel cnn framework to simultaneously learn embedded features from bfns for brain disease diagnosis. since bfns can be built by considering both static and dynamic functional connectivity (fc), we first decompose rs-fmri into multiple static bfns with modified independent component analysis. then, the voxel-wise variability in dynamic fc is used to quantify bfn dynamics. a set of paired 3d images representing static/dynamic bfns can be fed into 3d cnns, from which we can hierarchically and simultaneously learn static/dynamic bfn features. as a result, the dynamic bfn features can complement static bfn features and, at the meantime, different bfns can help each other toward a joint and better classification. we validate our method with a publicly accessible, large cohort of rs-fmri dataset in early-stage mild cognitive impairment (emci) diagnosis, which is one of the most challenging problems to the clinicians. by comparing with a conventional method, our method shows significant diagnostic performance improvement by almost 10%. this result demonstrates the effectiveness of deep learning in preclinical alzheimer's disease diagnosis, based on the complex and high-dimensional voxel-wise spatiotemporal patterns of the resting-state brain functional connectomics. the framework provides a new but intuitive way to fully exploit deeply embedded diagnostic features from rs-fmri for a better-individualized diagnosis of various neurological diseases.","['dynamic brain functional networks', 'early mci detection', 'deep learning', 'static']"
"human genes often, through alternative splicing of pre-messenger rnas, produce multiple mrnas and protein isoforms that may have similar or completely different functions. identification of splice sites is, therefore, crucial to understand the gene structure and variants of mrna and protein isoforms produced by the primary rna transcripts. although many computational methods have been developed to detect the splice sites in humans, this is still substantially a challenging problem and further improvement of the computational model is still foreseeable. accordingly, we developed deepdssr (deep donor splice site recognizer), a novel deep learning based architecture, for predicting human donor splice sites. the proposed method, built upon publicly available and highly imbalanced benchmark dataset, is comparable with the leading deep learning based methods for detecting human donor splice sites. performance evaluation metrics show that deepdssr outperformed the existing deep learning based methods. future work will improve the predictive capabilities of our model, and we will build a model for the prediction of acceptor splice sites.","['human donor splice sites recognition', 'deep learning structure', 'deepdssr']"
"learning to estimate 3d geometry in a single frame and optical flow from consecutive frames by watching unlabeled videos via deep convolutional network has made significant progress recently. current state-of-the-art (sota) methods treat the two tasks independently. one important assumption of the existing depth estimation methods is that the scenes contain no moving object. in this paper, we propose to address the two tasks as a whole, i.e. to jointly understand per-pixel 3d geometry and motion. this eliminates the need of static scene assumption and enforces the inherent geometrical consistency during the learning process, yielding significantly improved results for both tasks. we call our method as ""every pixel counts++"" or ""epc++"". various loss terms are formulated to jointly supervise the learning across geometrical cues and effective adaptive training strategy is proposed to achieve better performance. comprehensive experiments were conducted on datasets with different scenes, including driving scenario (kitti 2012 and kitti 2015 datasets), mixed outdoor/indoor scenes (make3d) and synthetic animation (mpi sintel dataset). performance on the five tasks of depth estimation, optical flow estimation, odometry, moving object segmentation and scene flow estimation shows that our approach outperforms other sota methods, demonstrating the effectiveness of each module of our proposed method.","['every pixel counts ++: joint learning', '3d holistic understanding', 'motion', 'geometry']"
"quasi-static ultrasound elastography is an importance imaging technology to assess the conditions of various diseases through reconstructing the tissue strain from radio frequency data. state-of-the-art strain reconstruction techniques suffer from the inexperienced user unfriendliness, high model bias, and low effectiveness-to-efficiency ratio. the three challenges result from the explicitness characteristic (i.e. explicit formulation of the reconstruction model) in these techniques. for these challenges, we are the first to develop an implicit strain reconstruction framework by a deep neural network architecture. however, the classic neural network methods are unsuitable to the strain reconstruction task because they are difficult to impose any direct influence on the intermediate state of the learning process. this may lead the map learned by the neural network to be biased with the desired map. in order to correct the intermediate state of the learning process, our framework proposes the learning-using-privileged-information (lupi) paradigm with causality in the network. it provides the causal privileged information besides the training examples to help the network learning, while makes these privileged information unavailable at the test stage. this improvement can narrow the search region of the map learned by the network, and thus prompts the network to evolve towards the actual ultrasound elastography process. moreover, in order to ensure the causality in lupi, our framework proposes a physically-based data generation strategy to produce the triplets of privileged information, training examples and labels. this data generation process can approximately describes the actual ultrasound elastography process by the numerical simulation based on the tissue biomechanics and ultrasound physics. it thus can build the causal relationship between the privileged information and training examples/labels. it can also address the medical data insufficiency problem. the performance of our framework has been validated on 100 simulation data, 42 phantom data and 4 real clinical data by comparing with the ground truth performed by an ultrasound simulation system and four state-of-the-art methods. the experimental results show that our framework is well agreed (average bias is 0.065 for strain reconstruction) with the ground truth, as well as superior to these state-of-the-art methods. these results can demonstrate the effectiveness of our framework in the strain reconstruction.","['ultrasound elastography using privileged information', 'implicit strain reconstruction', 'learning']"
"lab-on-a-disc (lod) has emerged as a promising candidate for a point-of-care testing (poct) device because it can effectively integrate complex fluid manipulation steps using multiple layers of polymeric substrates. however, it is still highly challenging to design and fabricate temperature measurement and heating system in non-contact with the surface of lod, which is a prerequisite to successful realization of dna amplification especially with a rotatable disc. this study presents a lab-on-a-disc (lod)-based automatic loop-mediated isothermal amplification (lamp) system, where a thermochromic coating (<~420 µm) was used to distantly measure the chamber's temperature and a micro graphite film was integrated into the chamber to remotely absorb laser beam with super high efficiency. we used a deep learning network to more consistently analyze the product of lamp than we could with the naked eye. consequently, both temperature heating and measurement were carried out without a physical contact with the surface of lod. the experimental results show that the proposed approach, which no previous work has attempted, was highly effective in realizing lamp in lod.","['optical temperature control unit', 'mediated isothermal amplification', 'convolutional neural network', 'disc platform', 'colorimetric detection', 'loop', 'lab']"
"unscheduled 30-day readmissions are a hallmark of congestive heart failure (chf) patients that pose significant health risks and escalate care cost. in order to reduce readmissions and curb the cost of care, it is important to initiate targeted intervention programs for patients at risk of readmission. this requires identifying high-risk patients at the time of discharge from hospital. here, using real data from over 7500 chf patients hospitalized between 2012 and 2016 in sweden, we built and tested a deep learning framework to predict 30-day unscheduled readmission. we present a cost-sensitive formulation of long short-term memory (lstm) neural network using expert features and contextual embedding of clinical concepts. this study targets key elements of an electronic health record (ehr) driven prediction model in a single framework: using both expert and machine derived features, incorporating sequential patterns and addressing the class imbalance problem. we evaluate the contribution of each element towards prediction performance (roc-auc, f1-measure) and cost-savings. we show that the model with all key elements achieves higher discrimination ability (auc: 0.77; f1: 0.51; cost: 22% of maximum possible savings) outperforming the reduced models in at least two evaluation metrics. additionally, we present a simple financial analysis to estimate annual savings if targeted interventions are offered to high risk patients.","['readmission prediction using deep learning', 'electronic health records']"
"research on driver status recognition has been actively conducted to reduce fatal crashes caused by the driver's distraction and drowsiness. as in many other research areas, deep-learning-based algorithms are showing excellent performance for driver status recognition. however, despite decades of research in the driver status recognition area, the visual image-based driver monitoring system has not been widely used in the automobile industry. this is because the system requires high-performance processors, as well as has a hierarchical structure in which each procedure is affected by an inaccuracy from the previous procedure. to avoid using a hierarchical structure, we propose a method using mobilenets without the functions of face detection and tracking and show this method is enabled to recognize facial behaviors that indicate the driver's distraction. however, frames per second processed by mobilenets with a raspberry pi, one of the single-board computers, is not enough to recognize the driver status. to alleviate this problem, we propose a lightweight driver monitoring system using a resource sharing device in a vehicle (e.g., a driver's mobile phone). the proposed system is based on multi-task mobilenets (mt-mobilenets), which consists of the mobilenets' base and multi-task classifier. the three softmax regressions of the multi-task classifier help one mobilenets base recognize facial behaviors related to the driver status, such as distraction, fatigue, and drowsiness. the proposed system based on mt-mobilenets improved the accuracy of the driver status recognition with raspberry pi by using one additional device.","['lightweight driver monitoring system based', 'task mobilenets', 'multi']"
"enhancers are short deoxyribonucleic acid fragments that assume an important part in the genetic process of gene expression. due to their possibly distant location relative to the gene that is acted upon, the identification of enhancers is difficult. there are many published works focused on identifying enhancers based on their sequence information, however, the resulting performance still requires improvements. using deep learning methods, this study proposes a model ensemble of classifiers for predicting enhancers based on deep recurrent neural networks. the input features of deep ensemble networks were generated from six types of dinucleotide physicochemical properties, which had outperformed the other features. in summary, our model which used this ensemble approach could identify enhancers with achieved sensitivity of 75.5%, specificity of 76%, accuracy of 75.5%, and mcc of 0.51. for classifying enhancers into strong or weak sequences, our model reached sensitivity of 83.15%, specificity of 45.61%, accuracy of 68.49%, and mcc of 0.312. compared to the benchmark result, our results had higher performance in term of most measurement metrics. the results showed that deep model ensembles hold the potential for improving on the best results achieved to date using shallow machine learning methods.","['identifying enhancers via dinucleotide physicochemical properties', 'deep recurrent neural networks', 'ensemble']"
"ncrna-protein interactions (ncrpis) play an important role in a number of cellular processes, such as post-transcriptional modification, transcriptional regulation, disease progression and development. since experimental methods are expensive and time-consuming to identify the ncrpis, we proposed a computational method, deep mining ncrna-protein interactions (dm-rpis), for identifying the ncrpis. in order to descending dimension and excavating hidden information from k-mer frequency of rna and protein sequences, using the deep stacking auto-encoders networks (dsans) model refined the raw data. three common machine learning algorithms, support vector machine (svm), random forest (rf), and convolution neural network (cnn), were separately trained as individual predictors and then the three individual predictors were integrated together using stacked ensembling strategy. based on the rpi2241 dataset, dm-rpi obtains an accuracy of 0.851, precision of 0.852, sensitivity of 0.873, specificity of 0.826, and mcc of 0.701, which is promising and pioneering for the prediction of ncrpis.","['protein interactions using stacked ensembling strategy', 'predicting ncrna', 'rpis', 'dm']"
"automated polyp detection in colonoscopy videos has been demonstrated to be a promising way for colorectal cancer prevention and diagnosis. traditional manual screening is time consuming, operator dependent, and error prone; hence, automated detection approach is highly demanded in clinical practice. however, automated polyp detection is very challenging due to high intraclass variations in polyp size, color, shape, and texture, and low interclass variations between polyps and hard mimics. in this paper, we propose a novel offline and online three-dimensional (3-d) deep learning integration framework by leveraging the 3-d fully convolutional network (3d-fcn) to tackle this challenging problem. compared with the previous methods employing hand-crafted features or 2-d convolutional neural network, the 3d-fcn is capable of learning more representative spatio-temporal features from colonoscopy videos, and hence has more powerful discrimination capability. more importantly, we propose a novel online learning scheme to deal with the problem of limited training data by harnessing the specific information of an input video in the learning process. we integrate offline and online learning to effectively reduce the number of false positives generated by the offline network and further improve the detection performance. extensive experiments on the dataset of miccai 2015 challenge on polyp detection demonstrated the better performance of our method when compared with other competitors.","['dimensional deep learning', 'automated polyp detection', 'offline three', 'integrating online', 'colonoscopy videos']"
"data center (dc) plays an important role to support services, such as e-commerce and cloud computing. the resulting energy consumption from this growing market has drawn significant attention, and noticeably almost half of the energy cost is used to cool the dc to a particular temperature. it is thus an critical operational challenge to curb the cooling energy cost without sacrificing the thermal safety of a dc. the existing solutions typically follow a two-step approach, in which the system is first modeled based on expert knowledge and, thus, the operational actions are determined with heuristics and/or best practices. these approaches are often hard to generalize and might result in suboptimal performances due to intrinsic model errors for large-scale systems. in this paper, we propose optimizing the dc cooling control via the emerging deep reinforcement learning (drl) framework. compared to the existing approaches, our solution lends itself an end-to-end cooling control algorithm (cca) via an off-policy offline version of the deep deterministic policy gradient (ddpg) algorithm, in which an evaluation network is trained to predict the dc energy cost along with resulting cooling effects, and a policy network is trained to gauge optimized control settings. moreover, we introduce a de-underestimation (due) validation mechanism for the critic network to reduce the potential underestimation of the risk caused by neural approximation. our proposed algorithm is evaluated on an energyplus simulation platform and on a real data trace collected from the national super computing centre (nscc) of singapore. the resulting numerical results show that the proposed cca can achieve up to 11% cooling cost reduction on the simulation platform compared with a manually configured baseline control algorithm. in the trace-based study of conservative nature, the proposed algorithm can achieve about 15% cooling energy savings on the nscc data trace. our pioneering approach can shed new light on the application of drl to optimize and automate dc operations and management, potentially revolutionizing digital infrastructure management with intelligence.","['green data center via deep reinforcement learning', 'transforming cooling optimization']"
deep learning implemented in a collaborative cloud-based platform empowers ophthalmologists in the diagnosis of congenital cataracts.,"['rare disease', 'cybernetic eye']"
"the number of panicles per unit area is a common indicator of rice yield and is of great significance to yield estimation, breeding, and phenotype analysis. traditional counting methods have various drawbacks, such as long delay times and high subjectivity, and they are easily perturbed by noise. to improve the accuracy of rice detection and counting in the field, we developed and implemented a panicle detection and counting system that is based on improved region-based fully convolutional networks, and we use the system to automate rice-phenotype measurements. the field experiments were conducted in target areas to train and test the system and used a rotor light unmanned aerial vehicle equipped with a high-definition rgb camera to collect images. the trained model achieved a precision of 0.868 on a held-out test set, which demonstrates the feasibility of this approach. the algorithm can deal with the irregular edge of the rice panicle, the significantly different appearance between the different varieties and growing periods, the interference due to color overlapping between panicle and leaves, and the variations in illumination intensity and shading effects in the field. the result is more accurate and efficient recognition of rice-panicles, which facilitates rice breeding. overall, the approach of training deep learning models on increasingly large and publicly available image datasets presents a clear path toward smartphone-assisted crop disease diagnosis on a global scale.","['unmanned aerial vehicle platform', 'applying deep learning model', 'rice panicle', 'automated counting', 'images']"
[this corrects the article doi: 10.1038/s41746-019-0099-8,"['deep learning versus human graders', 'classifying diabetic retinopathy severity', 'nationwide screening program', 'author correction', 'erratum']"
"promoter region of protein-coding genes are gradually being well understood, yet no comparable studies exist for the promoter of long non-coding rna (lncrna) genes which has emerged as a global potential regulator in multiple cellular process and different diseases for human. to understand the difference in the transcriptional regulation pattern of these genes, previously, we proposed a machine learning based model to classify the promoter of protein-coding genes and lncrna genes. in this study, we are presenting deepcnpp (deep coding non-coding promoter predictor), an improved model based on deep learning (dl) framework to classify the promoter of lncrna genes and protein-coding genes. we used convolution neural network (cnn) based deep network to classify the promoter of these two broad categories of human genes. our computational model, built upon the sequence information only, was able to classify these two groups of promoters from human at a rate of 83.34% accuracy and outperformed the existing model. further analysis and interpretation of the output from deepcnpp architecture will enable us to understand the difference in transcription regulatory pattern for these two groups of genes.","['human long non', 'deep learning architecture', 'coding rna genes', 'coding genes', 'protein', 'promoter', 'distinguish', 'deepcnpp']"
"this paper addresses the task of nuclei segmentation in high-resolution histopathology images. we propose an automatic end-to-end deep neural network algorithm for segmentation of individual nuclei. a nucleus-boundary model is introduced to predict nuclei and their boundaries simultaneously using a fully convolutional neural network. given a color-normalized image, the model directly outputs an estimated nuclei map and a boundary map. a simple, fast, and parameter-free post-processing procedure is performed on the estimated nuclei map to produce the final segmented nuclei. an overlapped patch extraction and assembling method is also designed for seamless prediction of nuclei in large whole-slide images. we also show the effectiveness of data augmentation methods for nuclei segmentation task. our experiments showed our method outperforms prior state-of-the-art methods. moreover, it is efficient that one 1000×1000 image can be segmented in less than 5 s. this makes it possible to precisely segment the whole-slide image in acceptable time. the source code is available at https://github.com/easycui/nuclei_segmentation . graphical abstract the neural network for nuclei segmentation.","['step contour aware nuclei segmentation', 'deep learning algorithm', 'histopathology images', 'one']"
"a biochemical reaction, bio-event, depicts the relationships between participating entities. current text mining research has been focusing on identifying bio-events from scientific literature. however, rare efforts have been dedicated to normalize bio-events extracted from scientific literature with the entries in the curated reaction databases, which could disambiguate the events and further support interconnecting events into biologically meaningful and complete networks.","['based event normalization', 'reaction databases', 'deep learning', 'curation', 'bionorm']"
"recently, effort has been made to apply deep learning to the detection of mesh saliency. however, one major barrier is to collect a large amount of vertex-level annotation as saliency ground truth for training the neural networks. quite a few pilot studies showed that this task is quite difficult. in this work, we solve this problem by developing a novel network trained in a weakly supervised manner. the training is end-to-end and does not require any saliency ground truth but only the class membership of meshes. our classification-for-saliency cnn (cfs-cnn) employs a multi-view setup and contains a newly designed two-channel structure which integrates view-based features of both classification and saliency. it essentially transfers knowledge from 3d object classification to mesh saliency. our approach significantly outperforms the existing state-of-the-art methods according to extensive experimental results. also, the cfs-cnn can be directly used for scene saliency. we showcase two novel applications based on scene saliency to demonstrate its utility.","['mesh saliency via weakly supervised classification', 'saliency cnn']"
"thoracic diseases are very serious health problems that plague a large number of people. chest x-ray is currently one of the most popular methods to diagnose thoracic diseases, playing an important role in the healthcare workflow. however, reading the chest x-ray images and giving an accurate diagnosis remain challenging tasks for expert radiologists. with the success of deep learning in computer vision, a growing number of deep neural network architectures were applied to chest x-ray image classification. however, most of the previous deep neural network classifiers were based on deterministic architectures which are usually very noise-sensitive and are likely to aggravate the overfitting issue. in this paper, to make a deep architecture more robust to noise and to reduce overfitting, we propose using deep generative classifiers to automatically diagnose thorax diseases from the chest x-ray images. unlike the traditional deterministic classifier, a deep generative classifier has a distribution middle layer in the deep neural network. a sampling layer then draws a random sample from the distribution layer and input it to the following layer for classification. the classifier is generative because the class label is generated from samples of a related distribution. through training the model with a certain amount of randomness, the deep generative classifiers are expected to be robust to noise and can reduce overfitting and then achieve good performances. we implemented our deep generative classifiers based on a number of well-known deterministic neural network architectures, and tested our models on the chest x-ray14 dataset. the results demonstrated the superiority of deep generative classifiers compared with the corresponding deep deterministic classifiers.","['thoracic disease diagnosis', 'deep generative classifiers', 'ray images', 'chest x']"
"deep learning has been recently demonstrated as an effective tool for raster-based sketch simplification. nevertheless, it remains challenging to simplify extremely rough sketches. we found that a simplification network trained with a simple loss, such as pixel loss or discriminator loss, may fail to retain the semantically meaningful details when simplifying a very sketchy and complicated drawing. in this paper, we show that, with a well-designed multi-layer perceptual loss, we are able to obtain aesthetic and neat simplification results preserving semantically important global structures as well as fine details without blurriness and excessive emphasis on local structures. to do so, we design a multi-layer discriminator by fusing all vgg feature layers to differentiate sketches and clean lines. the weights used in layer fusing are automatically learned via an intelligent adjustment mechanism. furthermore, to evaluate our method, we compare our method to state-of-the-art methods through multiple experiments, including visual comparison and intensive user study.","['aware sketch simplification based', 'integrated vgg layers', 'perceptual']"
"multiple object tracking (mot) plays an important role in solving many fundamental problems in video analysis and computer vision. most mot methods employ two steps: object detection and data association. the first step detects objects of interest in every frame of a video, and the second establishes correspondence between the detected objects in different frames to obtain their tracks. object detection has made tremendous progress in the last few years due to deep learning. however, data association for tracking still relies on hand crafted constraints such as appearance, motion, spatial proximity, grouping etc. to compute affinities between the objects in different frames. in this paper, we harness the power of deep learning for data association in tracking by jointly modeling object appearances and their affinities between different frames in an end-to-end fashion. the proposed deep affinity network (dan) learns compact, yet comprehensive features of pre-detected objects at several levels of abstraction, and performs exhaustive pairing permutations of those features in any two frames to infer object affinities. dan also accounts for multiple objects appearing and disappearing between video frames. we exploit the resulting efficient affinity computations to associate objects in the current frame deep into the previous frames for reliable on-line tracking. our technique is evaluated on popular multiple object tracking challenges mot15, mot17 and ua-detrac. comprehensive benchmarking under twelve evaluation metrics demonstrates that our approach is among the best performing techniques on the leader board for these challenges. the open source implementation of our work is available at https://github.com/shijies/sst.git.","['multiple object tracking', 'deep affinity network']"
"hyperspectral remote sensing images (hsis) have great research and application value. at present, deep learning has become an important method for studying image processing. the generative adversarial network (gan) model is a typical network of deep learning developed in recent years and the gan model can also be used to classify hsis. however, there are still some problems in the classification of hsis. on the one hand, due to the existence of different objects with the same spectrum phenomenon, if only according to the original gan model to generate samples from spectral samples, it will produce the wrong detailed characteristic information. on the other hand, the gradient disappears in the original gan model and the scoring ability of a single discriminator limits the quality of the generated samples. in order to solve the above problems, we introduce the scoring mechanism of multi-discriminator collaboration and complete semi-supervised classification on three hyperspectral data sets. compared with the original gan model with a single discriminator, the adjusted criterion is more rigorous and accurate and the generated samples can show more accurate characteristics. aiming at the pattern collapse and diversity deficiency of the original gan generated by single discriminator, this paper proposes a multi-discriminator generative adversarial networks (mdgans) and studies the influence of the number of discriminators on the classification results. the experimental results show that the introduction of multi-discriminator improves the judgment ability of the model, ensures the effect of generating samples, solves the problem of noise in generating spectral samples and can improve the classification effect of hsis. at the same time, the number of discriminators has different effects on different data sets.","['hyperspectral image classification method based', 'discriminator generative adversarial networks', 'multi']"
"memory loss, one of the most dreaded afflictions of the human condition, presents considerable burden on the world's health care system and it is recognized as a major challenge in the elderly. there are only a few neuromodulation treatments for memory dysfunctions. open loop deep brain stimulation is such a treatment for memory improvement, but with limited success and conflicting results. in recent years closed-loop neuroprosthesis systems able to simultaneously record signals during behavioral tasks and generate with the use of internal neural factors the precise timing of stimulation patterns are presented as attractive alternatives and show promise in memory enhancement and restoration. a few such strides have already been made in both animals and humans, but with limited insights into their mechanisms of action. here, i discuss why a deep neuromimetic computing approach linking multiple levels of description, mimicking the dynamics of brain circuits, interfaced with recording and stimulating electrodes could enhance the performance of current memory prosthesis systems, shed light into the neurobiology of learning and memory and accelerate the progress of memory prosthesis research. i propose what the necessary components (nodes, structure, connectivity, learning rules, and physiological responses) of such a deep neuromimetic model should be and what type of data are required to train/test its performance, so it can be used as a true substitute of damaged brain areas capable of restoring/enhancing their missing memory formation capabilities. considerations to neural circuit targeting, tissue interfacing, electrode placement/implantation, and multi-network interactions in complex cognition are also provided.","['deep neuromimetic computing approach', 'memory prosthesis', 'time']"
"in modern manufacturing systems and industries, more and more research efforts have been made in developing effective machine health monitoring systems. among various machine health monitoring approaches, data-driven methods are gaining in popularity due to the development of advanced sensing and data analytic techniques. however, considering the noise, varying length and irregular sampling behind sensory data, this kind of sequential data cannot be fed into classiﬁcation and regression models directly. therefore, previous work focuses on feature extraction/fusion methods requiring expensive human labor and high quality expert knowledge. with the development of deep learning methods in the last few years, which redeﬁne representation learning from raw data, a deep neural network structure named convolutional bi-directional long short-term memory networks (cblstm) has been designed here to address raw sensory data. cblstm ﬁrstly uses cnn to extract local features that are robust and informative from the sequential input. then, bi-directional lstm is introduced to encode temporal information. long short-term memory networks(lstms) are able to capture long-term dependencies and model sequential data, and the bi-directional structure enables the capture of past and future contexts. stacked, fully-connected layers and the linear regression layer are built on top of bi-directional lstms to predict the target value. here, a real-life tool wear test is introduced, and our proposed cblstm is able to predict the actual tool wear based on raw sensory data. the experimental results have shown that our model is able to outperform several state-of-the-art baseline methods.","['monitor machine health', 'directional lstm networks', 'convolutional bi', 'learning']"
"this study aimed to compare one state-of-the-art deep learning method and four classical machine learning methods for classifying mediastinal lymph node metastasis of non-small cell lung cancer (nsclc) from 18f-fdg pet/ct images. another objective was to compare the discriminative power of the recently popular pet/ct texture features with the widely used diagnostic features such as tumor size, ct value, suv, image contrast, and intensity standard deviation. the four classical machine learning methods included random forests, support vector machines, adaptive boosting, and artificial neural network. the deep learning method was the convolutional neural networks (cnn). the five methods were evaluated using 1397 lymph nodes collected from pet/ct images of 168 patients, with corresponding pathology analysis results as gold standard. the comparison was conducted using 10 times 10-fold cross-validation based on the criterion of sensitivity, specificity, accuracy (acc), and area under the roc curve (auc). for each classical method, different input features were compared to select the optimal feature set. based on the optimal feature set, the classical methods were compared with cnn, as well as with human doctors from our institute.","['classifying mediastinal lymph node metastasis', 'small cell lung cancer', 'machine learning methods', 'fdg pet', 'ct images', 'non', 'comparison', '18f']"
"speckle is a major quality degrading factor in optical coherence tomography (oct) images. in this work we propose a new deep learning network for speckle reduction in retinal oct images, termed despecnet. unlike traditional algorithms, the model can learn from training data instead of manually selecting parameters such as noise level. the proposed deep convolutional neural network (cnn) applies strategies including residual learning, shortcut connection, batch normalization and leaky rectified linear units to achieve good despeckling performance. application of the proposed method to the oct images shows great improvement in both visual quality and quantitative indices. the proposed method provides good generalization ability for different types of retinal oct images. it outperforms state-of-the-art methods in suppressing speckles and revealing subtle features while preserving edges.","['retinal optical coherence tomography images', 'speckle reduction', 'based method', 'despecnet', 'cnn']"
"capabilities of inference and prediction are the significant components of visual systems. visual path prediction is an important and challenging task among them, with the goal to infer the future path of a visual object in a static scene. this task is complicated as it needs high-level semantic understandings of both the scenes and underlying motion patterns in video sequences. in practice, cluttered situations have also raised higher demands on the effectiveness and robustness of models. motivated by these observations, we propose a deep learning framework, which simultaneously performs deep feature learning for visual representation in conjunction with spatiotemporal context modeling. after that, a unified path-planning scheme is proposed to make accurate path prediction based on the analytic results returned by the deep context models. the highly effective visual representation and deep context models ensure that our framework makes a deep semantic understanding of the scenes and motion patterns, consequently improving the performance on visual path prediction task. in experiments, we extensively evaluate the model's performance by constructing two large benchmark datasets from the adaptation of video tracking datasets. the qualitative and quantitative experimental results show that our approach outperforms the state-of-the-art approaches and owns a better generalization capability.","['deep learning driven visual path prediction', 'single image']"
"traditional person re-identification (re-id) methods perform poorly under changing illuminations. this situation can be addressed by using dual-cameras that capture visible images in a bright environment and infrared images in a dark environment. yet, this scheme needs to solve the visible-infrared matching issue, which is largely under-studied. matching pedestrians across heterogeneous modalities is extremely challenging because of different visual characteristics. in this paper, we propose a novel framework that employ modality-specific networks to tackle with the heterogeneous matching problem. the proposed framework utilizes the modality-related information and extracts modality-specific representations (msr) by constructing an individual network for each modality. in addition, a cross-modality euclidean constraint is introduced to narrow the gap between different networks. we also integrate the modality-shared layers into modality-specific networks to extract shareable information and use a modality-shared identity loss to facilitate the extraction of modality-invariant features. then a modality-specific discriminant metric is learned for each domain to strengthen the discriminative power of msr. eventually, we use a view classifier to learn view information. the experiments demonstrate that the msr effectively improves the performance of deep networks on vi-reid and remarkably outperforms the state-of-the-art methods.","['specific representations', 'learning modality', 'infrared person', 'visible', 'identification']"
"neighbourhood environment characteristics have been found to be associated with residents' willingness to conduct physical activity (pa). traditional methods to assess perceived neighbourhood environment characteristics are often subjective, costly, and time-consuming, and can be applied only on a small scale. recent developments in deep learning algorithms and the recent availability of street view images enable researchers to assess multiple aspects of neighbourhood environment perceptions more efficiently on a large scale. this study aims to examine the relationship between each of six neighbourhood environment perceptual indicators-namely, wealthy, safe, lively, depressing, boring and beautiful-and residents' time spent on pa in guangzhou, china.","['using street view imagery', 'deep learning techniques', 'physical activity', 'perception', 'neighbourhood', 'linkage', 'guangzhou', 'china']"
"epilepsy is one of the world's most common neurological diseases. early prediction of the incoming seizures has a great influence on epileptic patients' life. in this paper, a novel patient-specific seizure prediction technique based on deep learning and applied to long-term scalp electroencephalogram (eeg) recordings is proposed. the goal is to accurately detect the preictal brain state and differentiate it from the prevailing interictal state as early as possible and make it suitable for real time. the features extraction and classification processes are combined into a single automated system. raw eeg signal without any preprocessing is considered as the input to the system which further reduces the computations. four deep learning models are proposed to extract the most discriminative features which enhance the classification accuracy and prediction time. the proposed approach takes advantage of the convolutional neural network in extracting the significant spatial features from different scalp positions and the recurrent neural network in expecting the incidence of seizures earlier than the current methods. a semi-supervised approach based on transfer learning technique is introduced to improve the optimization problem. a channel selection algorithm is proposed to select the most relevant eeg channels which makes the proposed system good candidate for real-time usage. an effective test method is utilized to ensure robustness. the achieved highest accuracy of 99.6% and lowest false alarm rate of 0.004 h - 1 along with very early seizure prediction time of 1 h make the proposed method the most efficient among the state of the art.","['efficient epileptic seizure prediction based', 'deep learning']"
"predicting novel uses for drugs using their chemical, pharmacological, and indication information contributes to minimizing costs and development periods. most previous prediction methods focused on integrating the similarity and association information of drugs and diseases. however, they tended to construct shallow prediction models to predict drug-associated diseases, which make deeply integrating the information difficult. further, path information between drugs and diseases is important auxiliary information for association prediction, while it is not deeply integrated. we present a deep learning-based method, cgardp, for predicting drug-related candidate disease indications. cgardp establishes a feature matrix by exploiting a variety of biological premises related to drugs and diseases. a novel model based on convolutional neural network (cnn) and gated recurrent unit (gru) is constructed to learn the local and path representations for a drug-disease pair. the cnn-based framework on the left of the model learns the local representation of the drug-disease pair from their feature matrix. as the different paths have discriminative contributions to the drug-disease association prediction, we construct an attention mechanism at the path level to learn the informative paths. in the right part, a gru-based framework learns the path representation based on path information between the drug and the disease. cross-validation results indicate that cgardp performs better than several state-of-the-art methods. further, cgardp retrieves more real drug-disease associations in the top part of the prediction result that are of concern to biologists. case studies on five drugs demonstrate that cgardp can discover potential drug-related disease indications.","['related diseases based', 'gated recurrent unit', 'convolutional neural network', 'inferring drug']"
"parkinson's disease (pd) is characterized by motor symptoms such as rigidity and bradykinesia that prevent normal movement. beta band oscillations (13-30 hz) in neural local field potentials (lfps) have been associated with these motor symptoms. here, three pd patients implanted with a therapeutic deep brain neural stimulator that can also record and wirelessly stream neural data played a neurofeedback game where they modulated their beta band power from sensorimotor cortical areas. patients' beta band power was streamed in real-time to update the position of a cursor that they tried to drive into a cued target. after playing the game for 1-2 hours each, all three patients exhibited above chance-level performance regardless of subcortical stimulation levels. this study, for the first time, demonstrates using an invasive neural recording system for at-home neurofeedback training. future work will investigate chronic neurofeedback training as a potentially therapeutic tool for patients with neurological disorders.","['parkinsonian patients using electrocorticography signals accessed wirelessly', 'fully implanted device', 'neurofeedback control', 'chronic']"
"person re-identification (re-id) aims to match people across non-overlapping camera views in a public space. this is a challenging problem because the people captured in surveillance videos often wear similar clothing. consequently, the differences in their appearance are typically subtle and only detectable at particular locations and scales. in this paper, we propose a deep re-id network (mudeep) that is composed of two novel types of layers - a multi-scale deep learning layer, and a leader-based attention learning layer. specifically, the former learns deep discriminative feature representations at different scales, while the latter utilizes the information from multiple scales to lead and determine the optimal weightings for each scale. the importance of different spatial locations for extracting discriminative features is learned explicitly via our leader-based attention learning layer. extensive experiments are carried out to demonstrate that the proposed mudeep outperforms the state-of-the-art on a number of benchmarks and has a better generalization ability under a domain generalization setting.","['scale attention deep architecture', 'based multi', 'person', 'leader', 'identification']"
"recent years have witnessed the success of deep learning methods in human activity recognition (har). the longstanding shortage of labeled activity data inherently calls for a plethora of semisupervised learning methods, and one of the most challenging and common issues with semisupervised learning is the imbalanced distribution of labeled data over classes. although the problem has long existed in broad real-world har applications, it is rarely explored in the literature. in this paper, we propose a semisupervised deep model for imbalanced activity recognition from multimodal wearable sensory data. we aim to address not only the challenges of multimodal sensor data (e.g., interperson variability and interclass similarity) but also the limited labeled data and class-imbalance issues simultaneously. in particular, we propose a pattern-balanced semisupervised framework to extract and preserve diverse latent patterns of activities. furthermore, we exploit the independence of multi-modalities of sensory data and attentively identify salient regions that are indicative of human activities from inputs by our recurrent convolutional attention networks. our experimental results demonstrate that the proposed model achieves a competitive performance compared to a multitude of state-of-the-art methods, both semisupervised and supervised ones, with 10% labeled training data. the results also show the robustness of our method over imbalanced, small training data sets.","['semisupervised recurrent convolutional attention model', 'human activity recognition']"
"applicator digitization is one of the most critical steps in 3d high-dose-rate brachytherapy (hdrbt) treatment planning. motivated by recent advances in deep-learning, we propose a deep-learning-assisted applicator digitization method for 3d ct image-based hdrbt. this study demonstrates its feasibility and potential in gynecological cancer hdrbt.","['assisted automatic digitization', '3d ct image', 'rate brachytherapy', 'gynecological cancer', 'based high', 'learning', 'dose', 'deep', 'applicators']"
"in this paper, we present a novel deep metric learning method to tackle the multi-label image classification problem. in order to better learn the correlations among images features, as well as labels, we attempt to explore a latent space, where images and labels are embedded via two unique deep neural networks, respectively. to capture the relationships between image features and labels, we aim to learn a two-way deep distance metric over the embedding space from two different views, i.e., the distance between one image and its labels is not only smaller than those distances between the image and its labels' nearest neighbors but also smaller than the distances between the labels and other images corresponding to the labels' nearest neighbors. moreover, a reconstruction module for recovering correct labels is incorporated into the whole framework as a regularization term, such that the label embedding space is more representative. our model can be trained in an end-to-end manner. experimental results on publicly available image data sets corroborate the efficacy of our method compared with the state of the arts.","['reconstruction regularized deep metric learning', 'label image classification', 'multi']"
"ultrasound-guided regional anesthesia (ugra) becomes a standard procedure in surgical operations and pain management, offers the advantages of nerve localization, and provides region of interest anatomical structure visualization. nerve tracking presents a crucial step for practicing ugra and it is useful and important to develop a tool to facilitate this step. however, nerve tracking is a very challenging task that anesthetists can encounter due to the noise, artifacts, and nerve structure variability. deep-learning has shown outstanding performances in computer vision task including tracking. many deep-learning trackers have been proposed, where their performance depends on the application. while no deep-learning study exists for tracking the nerves in ultrasound images, this paper explores thirteen most recent deep-learning trackers for nerve tracking and presents a comparative study for the best deep-learning trackers on different types of nerves in ultrasound images. we evaluate the performance of the trackers in terms of accuracy, consistency, time complexity, and handling different nerve situations, such as disappearance and losing shape information. through the experimentation, certain conclusions were noted on deep learning trackers performance. overall, deep-learning trackers provide good performance and show a comparative performance for tracking different kinds of nerves in ultrasound images.","['deep visual nerve tracking', 'ultrasound images']"
"photoplethysmography (ppg)-based continuous heart rate monitoring is essential in a number of domains, e.g., for healthcare or fitness applications. recently, methods based on time-frequency spectra emerged to address the challenges of motion artefact compensation. however, existing approaches are highly parametrised and optimised for specific scenarios of small, public datasets. we address this fragmentation by contributing research into the robustness and generalisation capabilities of ppg-based heart rate estimation approaches. first, we introduce a novel large-scale dataset (called ppg-dalia), including a wide range of activities performed under close to real-life conditions. second, we extend a state-of-the-art algorithm, significantly improving its performance on several datasets. third, we introduce deep learning to this domain, and investigate various convolutional neural network architectures. our end-to-end learning approach takes the time-frequency spectra of synchronised ppg- and accelerometer-signals as input, and provides the estimated heart rate as output. finally, we compare the novel deep learning approach to classical methods, performing evaluation on four public datasets. we show that on large datasets the deep learning model significantly outperforms other methods: the mean absolute error could be reduced by 31 % on the new dataset ppg-dalia, and by 21 % on the dataset wesad.","['scale heart rate estimation', 'convolutional neural networks', 'deep ppg', 'large']"
"retinal blood vessel extraction is considered to be the indispensable action for the diagnostic purpose of many retinal diseases. in this work, a parallel fully convolved neural network-based architecture is proposed for the retinal blood vessel segmentation. also, the network performance improvement is studied by applying different levels of preprocessed images. the proposed method is experimented on drive (digital retinal images for vessel extraction) and stare (structured analysis of the retina) which are the widely accepted public database for this research area. the proposed work attains high accuracy, sensitivity, and specificity of about 96.37%, 86.53%, and 98.18% respectively. data independence is also proved by testing abnormal stare images with drive trained model. the proposed architecture shows better result in the vessel extraction irrespective of vessel thickness. the obtained results show that the proposed work outperforms most of the existing segmentation methodologies, and it can be implemented as the real time application tool since the entire work is carried out on cpu. the proposed work is executed with low-cost computation; at the same time, it takes less than 2\xa0s per image for vessel extraction.","['fully convolved neural network', 'retinal vessel segmentation', 'parallel architecture']"
"automatically understanding chemical-disease relations (cdrs) is crucial in various areas of biomedical research and health care. supervised machine learning provides a feasible solution to automatically extract relations between biomedical entities from scientific literature, its success, however, heavily depends on large-scale biomedical corpora manually annotated with intensive labor and tremendous investment.","['induced disease relation extraction via attention', 'based distant supervision', 'chemical']"
"we all experience at least occasional lapses in attention but in some neurological conditions, loss of attention is pervasive and debilitating. treating deficits in attention first requires an understanding of the neurobiology of attention, which we now understand to be a set of different cognitive processes. cholinesterase inhibitors are already established as effective attentional enhancers used in the treatment of certain dementias. other stimulant agents such as modafanil, amphetamine and methylphenidate have demonstrated limited success in healthy individuals where attention is already optimal and clinical trials in patients with neurological disease are sparse. dietary and lifestyle changes are gaining increasing prominence, as are experimental treatments such as deep brain stimulation and transcranial magnetic stimulation. as the therapeutic arsenal widens, clinicians will be able to match specific treatments to selective deficits in attention, giving patients a tailored management plan. here we review common diseases that impair attention and emphasise how an understanding of attentional processing within the brain might lead to improved therapeutic strategies.","['neurodegenerative diseases', 'future directions', 'enhancing attention', 'current therapies']"
"attention deficit hyperactivity disorder (adhd) is one of the most prevalent neuropsychiatric disorders in childhood and adolescence and its diagnosis is based on clinical interviews, symptom questionnaires, and neuropsychological testing. much research effort has been undertaken to evaluate the usefulness of neurophysiological (eeg) data to aid this diagnostic process. in the current study, we applied deep learning methods on event-related eeg data to examine whether it is possible to distinguish adhd patients from healthy controls using purely neurophysiological measures. the same was done to distinguish between adhd subtypes. the results show that the applied deep learning model (""eegnet"") was able to distinguish between both adhd subtypes and healthy controls with an accuracy of up to 83%. however, a significant fraction of individuals could not be classified correctly. it is shown that neurophysiological processes indicating attentional selection associated with superior parietal cortical areas were the most important for that. using the applied deep learning method, it was not possible to distinguish adhd subtypes from each other. this is the first study showing that deep learning methods applied to eeg data are able to dissociate between adhd patients and healthy controls. the results show that the applied method reflects a promising means to support clinical diagnosis in adhd. however, more work needs to be done to increase the reliability of the taken approach.","['related eeg differentiates children', 'deep learning based', 'healthy controls', 'event', 'adhd']"
"face alignment aims at localizing multiple facial landmarks for a given facial image, which usually suffers from large variances of diverse facial expressions, aspect ratios and partial occlusions, especially when face images were captured in wild conditions. conventional face alignment methods extract local features and then directly concatenate these features for global shape regression. unlike these methods which cannot explicitly model the correlation of neighbouring landmarks and motivated by the fact that individual landmarks are usually correlated, we propose a deep sharable and structural detectors (dssd) method for face alignment. to achieve this, we firstly develop a structural feature learning method to explicitly exploit the correlation of neighbouring landmarks, which learns to cover semantic information to disambiguate the neighbouring landmarks. moreover, our model selectively learns a subset of sharable latent tasks across neighbouring landmarks under the paradigm of the multi-task learning framework, so that the redundancy information of the overlapped patches can be efficiently removed. to better improve the performance, we extend our dssd to a recurrent dssd (r-dssd) architecture by integrating with the complementary information from multi-scale perspectives. experimental results on the widely used benchmark datasets show that our methods achieve very competitive performance compared to the state-of-the-arts.","['learning deep sharable', 'structural detectors', 'face alignment']"
"body condition scores (bcs) is an important parameter, which is in high correlation with the health status of a dairy cow, metabolic disorder and milk composition during the production period. to evaluate bcs, the traditional methods rely on veterinary experts or skilled staff to look at a cow and touch it. these methods have low efficiency especially on large-scale farms. computer vision methods are widely used but there are some improvements to increase bcs accuracy. in this study, a low cost bcs evaluation method based on deep learning and machine vision is proposed. firstly, the back-view images of the cows are captured by network cameras, resulting in 8972 images that constituted the sample data set. the camera is a common 2d camera, which is cheaper and easier to install compared with 3d cameras. secondly, the key body parts such as tails, pins and rump in the images were labeled manually, the sing shot multi-box detector (ssd) method was used to detect the tail and evaluate the bcs. inspired by densenet and inception-v4, a new ssd was introduced by changing the network connection method of the original ssd. finally, the experiments show that the improved ssd method can achieve 98.46% classification accuracy and 89.63% location accuracy, and it has: (1) faster detection speed with 115 fps; (2) smaller model size with 23.1 mb compared to original ssd and yolo-v3, these are significant advantages for reducing hardware costs.","['improved single shot multibox detector method applied', 'body condition score', 'dairy cows']"
"ultrasound elastography is gaining traction as an accessible and useful diagnostic tool for things such as, cancer detection and differentiation and thyroid disease diagnostics. unfortunately, state-of-the-art shear wave imaging techniques, essential to promote this goal, are limited to high-end ultrasound hardware due to high-power requirements, and are extremely sensitive to patient and sonographer motion, and generally suffer from low frame rates. motivated by research and theory showing that longitudinal wave sound speed carries similar diagnostic abilities to shear wave imaging, we present an alternative approach using single-sided pressure-wave sound speed measurements from channel data.","['sided sound speed inversion', 'deep learning framework', 'medical ultrasound', 'single']"
"with the increasing popularity of social media and smart devices, the face as one of the key biometrics becomes vital for person identification. among those face recognition algorithms, video-based face recognition methods could make use of both temporal and spatial information just as humans do to achieve better classification performance. however, they cannot identify individuals when certain key facial areas, such as eyes or nose, are disguised by heavy makeup or rubber/digital masks. to this end, we propose a novel deep spiking neural network architecture in this paper. it takes dynamic facial movements, the facial muscle changes induced by speaking or other activities, as the sole input. an event-driven continuous spike-timing-dependent plasticity learning rule with adaptive thresholding is applied to train the synaptic weights. the experiments on our proposed video-based disguise face database (makeface db) demonstrate that the proposed learning method performs very well, i.e., it achieves from 95% to 100% correct classification rates under various realistic experimental scenarios.","['based disguise face recognition based', 'deep spiking neural network', 'dynamic facial movements', 'video']"
"non-o157 shiga toxin-producing escherichia coli (stec) serogroups such as o26, o45, o103, o111, o121 and o145 often cause illness to people in the united states and the conventional identification of these ""big-six"" are complex. the label-free hyperspectral microscope imaging (hmi) method, which provides spectral ""fingerprints"" information of bacterial cells, was employed to classify serogroups at the cellular level. in spectral analysis, principal component analysis (pca) method and stacked auto-encoder (sae) method were conducted to extract principal spectral features for classification task. based on these features, multiple classifiers including linear discriminant analysis (lda), support vector machine (svm) and soft-max regression (sr) methods were evaluated. different sizes of datasets were also tested in search for the suitable classification models. among the results, sae-based classification models performed better than pca-based models, achieving classification accuracy of sae-lda (93.5%), sae-svm (94.9%) and sae-sr (94.6%), respectively. in contrast, classification results of pca-based methods such as pca-lda, pca-svm and pca-sr were only 75.5%, 85.7% and 77.1%, respectively. the results also suggested the increasing number of training samples have positive effects on classification models. taking advantage of increasing dataset, the sae-sr classification model finally performed better than others with average accuracy of 94.9% in classifying stec serogroups. specifically, o103 serogroup was classified with the highest accuracy of 97.4%, followed by o111 (96.5%), o26 (95.3%), o121 (95%), o145 (92.9%) and o45 (92.4%), respectively. thus, the hmi technology coupled with sae-sr classification model has the potential for ""big-six"" identification.","['producing escherichia coli', 'o157 shiga toxin', 'identifying non', 'ste']"
"neurodevelopmental spectrum disorders like autism (asd) are diagnosed, on average, beyond age 4 y, after multiple critical periods of brain development close and behavioral intervention becomes less effective. this raises the urgent need for quantitative, noninvasive, and translational biomarkers for their early detection and tracking. we found that both idiopathic (btbr) and genetic (cdkl5- and mecp2-deficient) mouse models of asd display an early, impaired cholinergic neuromodulation as reflected in altered spontaneous pupil fluctuations. abnormalities were already present before the onset of symptoms and were rescued by the selective expression of mecp2 in cholinergic circuits. hence, we trained a neural network (convnetach) to recognize, with 97% accuracy, patterns of these arousal fluctuations in mice with enhanced cholinergic sensitivity (lynx1-deficient). convnetach then successfully detected impairments in all asd mouse models tested except in mecp2-rescued mice. by retraining only the last layers of convnetach with heart rate variation data (a similar proxy of arousal) directly from rett syndrome patients, we generated convnetpatients, a neural network capable of distinguishing them from typically developing subjects. even with small cohorts of rare patients, our approach exhibited significant accuracy before (80% in the first and second year of life) and into regression (88% in stage iii patients). thus, transfer learning across species and modalities establishes spontaneous arousal fluctuations combined with deep learning as a robust noninvasive, quantitative, and sensitive translational biomarker for the rapid and early detection of neurodevelopmental disorders before major symptom onset.","['spontaneous arousal fluctuations detects early cholinergic defects across neurodevelopmental mouse models', 'deep learning', 'patients']"
"magnetic resonance fingerprinting (mrf) is a general framework to quantify multiple mr-sensitive tissue properties with a single acquisition. there have been numerous advances in mrf in the years since its inception. in this work we highlight some of the recent technical developments in mrf, focusing on sequence optimization, modifications for reconstruction and pattern matching, new methods for partial volume analysis, and applications of machine and deep learning. level of evidence: 2 technical efficacy: stage 2 j. magn. reson. imaging 2020;51:993-1007.","['magnetic resonance fingerprinting review part 2', 'technique', 'directions']"
"iot sensor networks have an inherent graph structure that can be used to extract graphical features for improving performance in a variety of prediction tasks. we propose a framework that represents iot sensor network data as a graph, extracts graphical features, and applies feature selection methods to identify the most useful features that are to be used by a classifier for prediction tasks. we show that a set of generic graph-based features can improve performance of sensor network predictions without the need for application-specific and task-specific feature engineering. we apply this approach to three different prediction tasks: activity recognition from motion sensors in a smart home, demographic prediction from gps sensor data in a smart phone, and activity recognition from gps sensor data in a smart phone. our approach produced comparable results with most of the state-of-the-art methods, while maintaining the additional advantage of general applicability to iot sensor networks without using sophisticated and application-specific feature generation techniques or background knowledge. we further investigate the impact of using edge-transition times, categorical features, different sensor window sizes, and normalization in the smart home domain. we also consider deep learning approaches, including the graph convolutional network (gcn), for the elimination of feature engineering in the smart home domain, but our approach provided better performance in most cases. we conclude that the graphical feature-based framework that is based on iot sensor categorization, nodes and edges as features, and feature selection techniques provides superior results when compared to the non-graph-based features.","['improving iot predictions', 'graphical features', 'identification']"
"with the expansion of data, increasing imbalanced data has emerged. when the imbalance ratio (ir) of data is high, most existing imbalanced learning methods decline seriously in classification performance. in this paper, we systematically investigate the highly imbalanced data classification problem, and propose an uncorrelated cost-sensitive multiset learning (ucml) approach for it. specifically, ucml first constructs multiple balanced subsets through random partition, and then employs the multiset feature learning (mfl) to learn discriminant features from the constructed multiset. to enhance the usability of each subset and deal with the non-linearity issue existed in each subset, we further propose a deep metric based ucml (dm-ucml) approach. dm-ucml introduces the generative adversarial network technique into the multiset constructing process, such that each subset can own similar distribution with the original dataset. to cope with the non-linearity issue, dm-ucml integrates deep metric learning with mfl, such that more favorable performance can be achieved. in addition, dm-ucml designs a new discriminant term to enhance the discriminability of learned metrics. experiments on eight traditional highly class-imbalanced datasets and two large-scale datasets indicate that: the proposed approaches outperform state-of-the-art highly imbalanced learning methods and are more robust to high ir.","['highly imbalanced data classification', 'multiset feature learning']"
"due to the popularity of smart devices, traditional one-way teaching methods might not deeply attract school students' attention, especially for the junior high school students, elementary school students, or even younger students, which is a critical issue for educators. therefore, we develop an intelligent interactive education system, which leverages wearable devices (smart watches) to accurately capture hand gestures of school students and respond instantly to teachers so as to increase the interaction and attraction of school students in class. in addition, through multiple physical information of school students from the smart watch, it can find out the crux points of the learning process according to the deep data analysis. in this way, it can provide teachers to make instant adjustments and suggest school students to achieve multi-learning and innovative thinking. the system is mainly composed of three components: (1) smart interactive watch; (2) teacher-side smart application (app); and (3) cloud-based analysis system. specifically, the smart interactive watch is responsible for detecting the physical information and interaction results of school students, and then giving feedback to the teachers. the teacher-side app will provide real-time learning suggestions to adjust the teaching pace to avoid learning disability. the cloud-based analysis system provides intelligent learning advices, academic performance prediction and anomaly learning detection. through field trials, our system has been verified that can potentially enhance teaching and learning processes for both educators and school students.","['smart interactive education system based', 'wearable devices']"
"sarotup (scanner and reporter of target-unrelated peptides) 3.1 is a significant upgrade to the widely used sarotup web server for the rapid identification of target-unrelated peptides (tups) in phage display data. at present, sarotup has gathered a suite of tools for finding potential tups and other purposes. besides the tupscan, the motif-based tool, and three tools based on the bdb database, i.e., mimoscan, mimosearch, and mimoblast, three predictors based on support vector machine, i.e., phd7faster, sabinder and psbinder, are integrated into sarotup. the current version of sarotup contains 27 tup motifs and 823 tup sequences. we also developed the standalone sarotup application with graphical user interface (gui) and command line versions for processing deep sequencing phage display data and distributed it as an open source package, which can perform perfectly locally on almost all systems that support c++ with little or no modification. the web interfaces of sarotup have also been redesigned to be more self-evident and user-friendly. the latest version of sarotup is freely available at http://i.uestc.edu.cn/sarotup3.","['phage display data', 'finding potential target', 'unrelated peptides', 'tools', 'suite', 'sarotup']"
"diabetes is a globally prevalent disease that can cause visible microvascular complications such as diabetic retinopathy and macular edema in the human eye retina, the images of which are today used for manual disease screening and diagnosis. this labor-intensive task could greatly benefit from automatic detection using deep learning technique. here we present a deep learning system that identifies referable diabetic retinopathy comparably or better than presented in the previous studies, although we use only a small fraction of images (<1/4) in training but are aided with higher image resolutions. we also provide novel results for five different screening and clinical grading systems for diabetic retinopathy and macular edema classification, including state-of-the-art results for accurately classifying images according to clinical five-grade diabetic retinopathy and for the first time for the four-grade diabetic macular edema scales. these results suggest, that a deep learning system could increase the cost-effectiveness of screening and diagnosis, while attaining higher than recommended performance, and that the system could be applied in clinical examinations requiring finer grading.","['deep learning fundus image analysis', 'macular edema grading', 'diabetic retinopathy']"
"we present a framework, which we call molecule deep q-networks (moldqn), for molecule optimization by combining domain knowledge of chemistry and state-of-the-art reinforcement learning techniques (double q-learning and randomized value functions). we directly define modifications on molecules, thereby ensuring 100% chemical validity. further, we operate without pre-training on any dataset to avoid possible bias from the choice of that set. moldqn achieves comparable or better performance against several other recently published algorithms for benchmark molecular optimization tasks. however, we also argue that many of these tasks are not representative of real optimization problems in drug discovery. inspired by problems faced during medicinal chemistry lead optimization, we extend our model with multi-objective reinforcement learning, which maximizes drug-likeness while maintaining similarity to the original molecule. we further show the path through chemical space to achieve optimization for a molecule to understand how the model works.","['molecules via deep reinforcement learning', 'optimization']"
"adaptive deep brain stimulation (adbs) is an emerging method to alleviate the side effects and improve the efficacy of conventional open-loop stimulation for movement disorders. however, current adaptive dbs techniques are primarily based on single-feature thresholding, precluding an optimized delivery of stimulation for precise control of motor symptoms. here, we propose to use a machine learning approach for resting-state tremor detection from local field potentials (lfps) recorded from subthalamic nucleus (stn) in 12 parkinson's patients. we compare the performance of state-of-the-art classifiers and lfp-based biomarkers for tremor detection, showing that the high-frequency oscillations and hjorth parameters achieve a high discriminative performance. in addition, using kalman filtering in the feature space, we show that the tremor detection performance significantly improves (f(1,15)=32.16, p<0.0001). the proposed method holds great promise for efficient on-demand delivery of stimulation in parkinson's disease.","['resting tremor detection', 'machine learning', 'kalman filtering', 'parkinson', 'disease']"
"reaction prediction and retrosynthesis are the cornerstones of organic chemistry. rule-based expert systems have been the most widespread approach to computationally solve these two related challenges to date. however, reaction rules often fail because they ignore the molecular context, which leads to reactivity conflicts. herein, we report that deep neural networks can learn to resolve reactivity conflicts and to prioritize the most suitable transformation rules. we show that by training our model on 3.5\u2005million reactions taken from the collective published knowledge of the entire discipline of chemistry, our model exhibits a top10-accuracy of 95\u2009% in retrosynthesis and 97\u2009% for reaction prediction on a validation set of almost 1\u2005million reactions.","['symbolic machine learning', 'reaction prediction', 'retrosynthesis', 'neural']"
"forged documents and counterfeit currency can be better detected with multispectral imaging in multiple color channels instead of the usual red, green and blue. however, multispectral cameras/scanners are expensive. we propose the construction of a low cost scanner designed to capture multispectral images of documents. a standard sheet-feed scanner was modified by disconnecting its internal light source and connecting an external multispectral light source comprising of narrow band light emitting diodes (led). a document was scanned by illuminating the scanner light guide successively with different leds and capturing a scan of the document. the system costs less than a hundred dollars and is portable. it can potentially be used for applications in verification of questioned documents, checks, receipts and bank notes.","['cost document scanner', 'multispectral scanner', 'common low', 'converting']"
we attempted to train and validate a model of deep learning for the preoperative prediction of the response of patients with intermediate-stage hepatocellular carcinoma (hcc) undergoing transarterial chemoembolization (tace).,"['residual convolutional neural network', 'transarterial chemoembolization', 'predicting response', 'hepatocellular carcinoma', 'ct imaging']"
"magnetic resonance fingerprinting (mrf) methods typically rely on dictionary matching to map the temporal mrf signals to quantitative tissue parameters. such approaches suffer from inherent discretization errors, as well as high computational complexity as the dictionary size grows. to alleviate these issues, we propose a hybrid deep magnetic resonance fingerprinting (hydra) approach, referred to as hydra.","['hybrid deep magnetic resonance fingerprinting', 'hydra']"
"as the super-aged society, japan is facing challenges in health care system. as one of measures to cope with challenges, the ministry of health, labor, and welfare started to construct an open medical information platform, named people, in 2016 for personalized medical care, improvement of medical services, and the redistribution of medical resources. the ministry plans to build the platform infrastructure by 2020 and put the platform into full-scale operation by 2025. people collects only medical records, but it should collect lifelogs as well in order to better improve the health, especially for elderly. a lifelog is a record of a person's activity and it has potential to predict the probability a person will suffer a lifestyle-related disease as a result of the person's lifestyle. this prediction could help to maintain the health of the elderly. in addition, constructing a self-recording platform integrated with the medical platform is the best way to collect lifelogs since collecting a large amount of lifelogs for a long time from various people at public or medical agencies is difficult. a self-recording platform is a place where people can post and manage their lifelogs. in return for posting lifelogs, people will receive personalized health advice, which will attract more people.","['support health care', 'integrated information platform', 'recording lifelogs', 'medical records', 'aged society', 'super', 'self', 'japan', 'constructing']"
most brain lesions are characterized by hyperintense signal on flair. we sought to develop an automated deep learning-based method for segmentation of abnormalities on flair and volumetric quantification on clinical brain mris across many pathologic entities and scanning parameters. we evaluated the performance of the algorithm compared with manual segmentation and existing automated methods.,"['clinical brain mr imaging', 'automated flair lesion segmentation', 'convolutional neural network']"
"colorectal cancer (crc) is a leading cause of cancer deaths worldwide. although polypectomy at early stage reduces crc incidence, 90% of the polyps are small and diminutive, where removal of them poses risks to patients that may outweigh the benefits. correctly detecting and predicting polyp type during colonoscopy allows endoscopists to resect and discard the tissue without submitting it for histology, saving time, and costs. nevertheless, human visual observation of early stage polyps varies. therefore, this paper aims at developing a fully automatic algorithm to detect and classify hyperplastic and adenomatous colorectal polyps. adenomatous polyps should be removed, whereas distal diminutive hyperplastic polyps are considered clinically insignificant and may be left in situ . a novel transfer learning application is proposed utilizing features learned from big nonmedical datasets with 1.4-2.5 million images using deep convolutional neural network. the endoscopic images we collected for experiment were taken under random lighting conditions, zooming and optical magnification, including 1104 endoscopic nonpolyp images taken under both white-light and narrowband imaging (nbi) endoscopy and 826 nbi endoscopic polyp images, of which 263 images were hyperplasia and 563 were adenoma as confirmed by histology. the proposed method identified polyp images from nonpolyp images in the beginning followed by predicting the polyp histology. when compared with visual inspection by endoscopists, the results of this study show that the proposed method has similar precision (87.3% versus 86.4%) but a higher recall rate (87.6% versus 77.0%) and a higher accuracy (85.9% versus 74.3%). in conclusion, automatic algorithms can assist endoscopists in identifying polyps that are adenomatous but have been incorrectly judged as hyperplasia and, therefore, enable timely resection of these polyps at an early stage before they develop into invasive cancer.","['level cnn features', 'transferring low', 'nonmedical domain', 'colorectal polyps', 'automatic detection', 'classification']"
"driver distraction is one of the major causes of traffic accidents. in recent years, given the advance in connectivity and social networks, the use of smartphones while driving has become more frequent and a serious problem for safety. texting, calling, and reading while driving are types of distractions caused by the use of smartphones. in this paper, we propose a non-intrusive technique that uses only data from smartphone sensors and machine learning to automatically distinguish between drivers and passengers while reading a message in a vehicle. we model and evaluate seven cutting-edge machine-learning techniques in different scenarios. the convolutional neural network and gradient boosting were the models with the best results in our experiments. results show accuracy, precision, recall, f1-score, and kappa metrics superior to 0.95.","['learning approach', 'drivers reading', 'distinguish passengers', 'machine', 'driving']"
"efficacy of candidate antibacterial treatments must be demonstrated in animal models of infection as part of the discovery and development process, preferably in models which mimic the intended clinical indication. a method for inducing robust lung infections in immunocompetent rats and mice is described which allows for the assessment of treatments in a model of serious pneumonia caused by s. pneumoniae, h. influenzae, p. aeruginosa, k. pneumoniae or a. baumannii. animals are anesthetized, and an agar-based inoculum is deposited deep into the lung via nonsurgical intratracheal intubation. the resulting infection is consistent, reproducible, and stable for at least 48 h and up to 96 h for most isolates. studies with marketed antibacterials have demonstrated good correlation between in vivo efficacy and in vitro susceptibility, and concordance between pharmacokinetic/pharmacodynamic targets determined in this model and clinically accepted targets has been observed. although there is an initial time investment when learning the technique, it can be performed quickly and efficiently once proficiency is achieved. benefits of the model include elimination of the neutropenic requirement, increased robustness and reproducibility, ability to study more pathogens and isolates, improved flexibility in study design and establishment of a challenging infection in an immunocompetent host.","['robust pneumonia model', 'evaluate antibacterial efficacy', 'immunocompetent rodents', 'pneumoniae', 'p', 'k', 'influenzae', 'h', 'baumannii', 'aeruginosa']"
"immunohistochemistry (ihc) is the most widely used assay for identification of molecular biomarkers. however, ihc is time consuming and costly, depends on tissue-handling protocols, and relies on pathologists' subjective interpretation. image analysis by machine learning is gaining ground for various applications in pathology but has not been proposed to replace chemical-based assays for molecular detection.","['assess hormonal status', 'artificial intelligence algorithms', 'tissue microarrays', 'breast cancer', 'patients']"
genetic risk variants in the hemizygous allele may influence neuropsychiatric manifestations and clinical course in 3q29 deletion carriers.,"['3q29 deletion carriers', 'neuropsychiatric phenotype', 'hemizygous allele', 'gene variants', 'case series', 'relation']"
"identifying novel indications for approved drugs can accelerate drug development and reduce research costs. most previous studies used shallow models for prioritizing the potential drug-related diseases and failed to deeply integrate the paths between drugs and diseases which may contain additional association information. a deep-learning-based method for predicting drug-disease associations by integrating useful information is needed. we proposed a novel method based on a convolutional neural network (cnn) and bidirectional long short-term memory (bilstm)-cbpred-for predicting drug-related diseases. our method deeply integrates similarities and associations between drugs and diseases, and paths among drug-disease pairs. the cnn-based framework focuses on learning the original representation of a drug-disease pair from their similarities and associations. as the drug-disease association possibility also depends on the multiple paths between them, the bilstm-based framework mainly learns the path representation of the drug-disease pair. in addition, considering that different paths have discriminate contributions to the association prediction, an attention mechanism at path level is constructed. our method, cbpred, showed better performance and retrieved more real associations in the front of the results, which is more important for biologists. case studies further confirmed that cbpred can discover potential drug-disease associations.","['convolutional neural network', 'bidirectional long short', 'term memory', 'predicting drug', 'disease associations', 'based method']"
"hyperspectral imaging (hsi) is an emerging imaging modality that can provide a noninvasive tool for cancer detection and image-guided surgery. hsi acquires high-resolution images at hundreds of spectral bands, providing big data to differentiating different types of tissue. we proposed a deep learning based method for the detection of head and neck cancer with hyperspectral images. since the deep learning algorithm can learn the feature hierarchically, the learned features are more discriminative and concise than the handcrafted features. in this study, we adopt convolutional neural networks (cnn) to learn the deep feature of pixels for classifying each pixel into tumor or normal tissue. we evaluated our proposed classification method on the dataset containing hyperspectral images from 12 tumor-bearing mice. experimental results show that our method achieved an average accuracy of 91.36%. the preliminary study demonstrated that our deep learning method can be applied to hyperspectral images for detecting head and neck tumors in animal models.","['deep learning based classification', 'neck cancer detection', 'hyperspectral imaging', 'animal model', 'head']"
"ultrasound imaging is well known to play an important role in the detection of thyroid disease, but the management of thyroid ultrasound remains inconsistent. both standardized diagnostic criteria and new ultrasound technologies are essential for improving the accuracy of thyroid ultrasound. this study reviewed the global guidelines of thyroid ultrasound and analyzed their common characteristics for basic clinical screening. advances in the application of a combination of thyroid ultrasound and artificial intelligence (ai) were also presented.","['artificial intelligence techniques', 'thyroid ultrasound', 'narrative review', 'diagnostic criteria', 'update']"
"accurate estimation of heading date of paddy rice greatly helps the breeders to understand the adaptability of different crop varieties in a given location. the heading date also plays a vital role in determining grain yield for research experiments. visual examination of the crop is laborious and time consuming. therefore, quick and precise estimation of heading date of paddy rice is highly essential.","['paddy rice using deep learning', 'heading date', 'automatic estimation']"
"chembl biological activities prediction for 1-5-bromofur-2-il-2-bromo-2-nitroethene (g1) is a difficult task for cytokine immunotoxicity. the current study presents experimental results for g1 interaction with mouse th1/th2 and pro-inflammatory cytokines using a cytometry bead array (cba). in the in vitro test of cba, the results show no significant differences between the mean values of the th1/th2 cytokines for the samples treated with g1 with respect to the negative control, but there are moderate differences for cytokine values between different periods (24/48 h). the experiments show no significant differences between the mean values of the pro-inflammatory cytokines for the samples treated with g1, regarding the negative control, except for the values of tumor necrosis factor (tnf) and interleukin (il6) between the group treated with g1 and the negative control at 48 h. differences occur for these cytokines in the periods (24/48 h). the study confirmed that the antimicrobial g1 did not alter the th1/th2 cytokines concentration in vitro in different periods, but it can alter tnf and il6. g1 promotes free radicals production and activates damage processes in macrophages culture. in order to predict all chembl activities for drugs in other experimental conditions, a chembl data set was constructed using 25 biological activities, 1366 assays, 2 assay types, 4 assay organisms, 2 organisms, and 12 cytokine targets. molecular descriptors calculated with rcpi and 15 machine learning methods were used to find the best model able to predict if a drug could be active or not against a specific cytokine, in specific experimental conditions. the best model is based on 120 selected molecular descriptors and a deep neural network with area under the curve of the receiver operating characteristic of 0.904 and accuracy of 0.832. this model predicted 1384 g1 biological activities against cytokines in all chembl data set experimental conditions.","['antimicrobial g1 using cytometric bead arrays', 'perturbation theory machine learning modeling', 'drugs targeting inflammatory cytokines', 'study', 'immunotoxicity']"
"automatic skeletal muscle image segmentation (mis) is crucial in the diagnosis of muscle-related diseases. however, accurate methods often suffer from expensive computations, which are not scalable to large-scale, whole-slide muscle images. in this paper, we present a fast and accurate method to enable the more clinically meaningful whole-slide mis. leveraging on recently popular convolutional neural network (cnn), we train our network in an end-to-end manner so as to directly perform pixelwise classification. our deep network is comprised of the encoder and decoder modules. the encoder module captures rich and hierarchical representations through a series of convolutional and max-pooling layers. then, the multiple decoders utilize multilevel representations to perform multiscale predictions. the multiscale predictions are then combined together to generate a more robust dense segmentation as the network output. the decoder modules have independent loss function, which are jointly trained with a weighted loss function to address fine-grained pixelwise prediction. we also propose a two-stage transfer learning strategy to effectively train such deep network. sufficient experiments on a challenging muscle image dataset demonstrate the significantly improved efficiency and accuracy of our method compared with recent state of the arts.","['slide skeletal muscle image segmentation', 'deep hierarchically connected networks', 'towards fine whole']"
"optical coherence tomography provides volumetric reconstruction of brain structure with micrometer resolution. gray matter and white matter can be highlighted using conventional and polarization-based contrasts; however, vasculature in ex-vivo fixed brain has not been investigated at large scale due to lack of intrinsic contrast. we present contrast enhancement to visualize the vasculature by perfusing titanium dioxide particles transcardially into the mouse vascular system. the brain, after dissection and fixation, is imaged by a serial optical coherence scanner. accumulation of particles in blood vessels generates distinguishable optical signals. among these, the cross-polarization images reveal the vasculature organization remarkably well. the conventional and polarization-based contrasts are still available for probing the gray matter and white matter structures. the segmentation and reconstruction of the vasculature are presented by using a deep learning algorithm. axonal fiber pathways in the mouse brain are delineated by utilizing the retardance and optic axis orientation contrasts. this is a low-cost method that can be further developed to study neurovascular diseases and brain injury in animal models.","['enhanced serial optical coherence scanner', 'deep learning network reveals vasculature', 'white matter organization', 'mouse brain', 'contrast']"
"wilms' tumor is one of the most frequent malignant solid tumors in childhood. accurate segmentation of tumor tissue is a key step during therapy and treatment planning. since it is difficult to obtain a comprehensive set of tumor data of children, there is no benchmark so far allowing evaluation of the quality of human or computer-based segmentations. the contributions in our paper are threefold: (i)\xa0we present the first heterogeneous wilms' tumor benchmark data set. it contains multisequence mri data sets before and after chemotherapy, along with ground truth annotation, approximated based on the consensus of five human experts. (ii)\xa0we analyze human expert annotations and interrater variability, finding that the current clinical practice of determining tumor volume is inaccurate and that manual annotations after chemotherapy may differ substantially. (iii)\xa0we evaluate six computer-based segmentation methods, ranging from classical approaches to recent deep-learning techniques. we show that the best ones offer a quality comparable to human expert annotations.","['popular segmentation algorithms perform well', 'current clinical practice fail', 'multisequence mri data', 'benchmarking wilms', 'tumor']"
"functional integration or connectivity in brain is directional, non-linear as well as variable in time-lagged dependence. deep neural networks (dnn) have become an indispensable tool everywhere, by learning higher levels of abstract and complex patterns from raw data. however, in neuroscientific community they generally work as black-boxes, leading to the explanation of results difficult and less intuitive. we aim to propose a brain-connectivity measure based on an explainable nn (xnn) approach.","['novel relative relevance score', 'explainable neural network approach', 'fmri data using', 'estimating brain connectivity']"
"cardiovascular disease (cvd) is an important cause of death in breast cancer survivors. some breast cancer treatments including anthracyclines, trastuzumab and radiotherapy can increase the risk of cvd, especially for patients with pre-existing cvd risk factors. early identification of patients at increased cvd risk may allow switching to less cardiotoxic treatments, active surveillance or treatment of cvd risk factors. one of the strongest independent cvd risk factors is the presence and extent of coronary artery calcifications (cac). in clinical practice, cac are generally quantified on ecg-triggered cardiac ct scans. patients with breast cancer treated with radiotherapy routinely undergo radiotherapy planning ct scans of the chest, and those scans could provide the opportunity to routinely assess cac before a potentially cardiotoxic treatment. the bragatston study aims to investigate the association between calcifications in the coronary arteries, aorta and heart valves (hereinafter called 'cardiovascular calcifications') measured automatically on planning ct scans of patients with breast cancer and cvd risk.","['radiotherapy planning ct scans', 'multicentre cohort study', 'bragatston study protocol', 'cardiovascular risk prediction', 'cardiovascular calcifications', 'breast cancer', 'automated quantification', 'patients']"
"in the study of compressed sensing (cs), the two main challenges are the design of sampling matrix and the development of reconstruction method. on the one hand, the usually used random sampling matrices (e.g. grm) are signal independent, which ignore the characteristics of the signal. on the other hand, the state-of-the-art image cs methods (e.g. gsr and mh) achieve quite good performance, however with much higher computational complexity. to deal with the two challenges, we propose an image cs framework using convolutional neural network (dubbed csnet) that includes a sampling network and a reconstruction network, which are optimized jointly. the sampling network adaptively learns the sampling matrix from the training images, which makes the cs measurements retain more image structural information for better reconstruction. specifically, three types of sampling matrices are learned, i.e. floating-point matrix, {0,1}-binary matrix, and {-1,+1}-bipolar matrix. the last two matrices are specially designed for easy storage and hardware implementation. the reconstruction network, which contains a linear initial reconstruction network and a non-linear deep reconstruction network, learns an end-to-end mapping between the cs measurements and the reconstructed images. experimental results demonstrate that csnet offers state-of-the-art reconstruction quality, while achieving fast running speed. in addition, csnet with {0,1}-binary matrix, and {-1,+1}-bipolar matrix gets comparable performance with the existing deep learning based cs methods, and outperforms the traditional cs methods. what's more, the experimental results further suggest that the learned sampling matrices can improve the traditional image cs reconstruction methods significantly.",['image compressed sensing using convolutional neural network']
"the n400 component of the event-related brain potential has aroused much interest because it is thought to provide an online measure of meaning processing in the brain. however, the underlying process remains incompletely understood and actively debated. here we present a computationally explicit account of this process and the emerging representation of sentence meaning. we simulate n400 amplitudes as the change induced by an incoming stimulus in an implicit and probabilistic representation of meaning captured by the hidden unit activation pattern in a neural network model of sentence comprehension, and we propose that the process underlying the n400 also drives implicit learning in the network. the model provides a unified account of 16 distinct findings from the n400 literature and connects human language comprehension with recent deep learning approaches to language processing.","['n400 brain potential', 'probabilistic representation', 'modelling', 'meaning', 'change']"
"identification of disease-associated mirnas (disease mirnas) are critical for understanding etiology and pathogenesis. most previous methods focus on integrating similarities and associating information contained in heterogeneous mirna-disease networks. however, these methods establish only shallow prediction models that fail to capture complex relationships among mirna similarities, disease similarities, and mirna-disease associations. we propose a prediction method on the basis of network representation learning and convolutional neural networks to predict disease mirnas, called cnnmda. cnnmda deeply integrates the similarity information of mirnas and diseases, mirna-disease associations, and representations of mirnas and diseases in low-dimensional feature space. the new framework based on deep learning was built to learn the original and global representation of a mirna-disease pair. first, diverse biological premises about mirnas and diseases were combined to construct the embedding layer in the left part of the framework, from a biological perspective. second, the various connection edges in the mirna-disease network, such as similarity and association connections, were dependent on each other. therefore, it was necessary to learn the low-dimensional representations of the mirna and disease nodes based on the entire network. the right part of the framework learnt the low-dimensional representation of each mirna and disease node based on non-negative matrix factorization, and these representations were used to establish the corresponding embedding layer. finally, the left and right embedding layers went through convolutional modules to deeply learn the complex and non-linear relationships among the similarities and associations between mirnas and diseases. experimental results based on cross validation indicated that cnnmda yields superior performance compared to several state-of-the-art methods. furthermore, case studies on lung, breast, and pancreatic neoplasms demonstrated the powerful ability of cnnmda to discover potential disease mirnas.","['network representation learning', 'convolutional neural networks', 'associated mirnas based', 'inferring', 'disease']"
"fault diagnosis is critical to ensuring the safety and reliable operation of rotating machinery systems. long short-term memory networks (lstm) have received a great deal of attention in this field. most of the lstm-based fault diagnosis methods have too many parameters and calculation, resulting in large memory occupancy and high calculation delay. thus, this paper proposes a low-delay lightweight recurrent neural network (llrnn) model for mechanical fault diagnosis, based on a special lstm cell structure with a forget gate. the input vibration signal is segmented into several shorter sub-signals in order to shorten the length of the time sequence. then, these sub-signals are sent into the network directly and converted into the final diagnostic results without any manual participation. compared with some existing methods, our experiments illustrate that the proposed method has less memory space occupancy and lower computational delay while maintaining the same level of accuracy.","['delay lightweight recurrent neural network', 'low', 'llrn']"
"typically, lane departure warning systems rely on lane lines being present on the road.however, in many scenarios, e.g., secondary roads or some streets in cities, lane lines are eithernot present or not sufficiently well signaled. in this work, we present a vision-based method tolocate a vehicle within the road when no lane lines are present using only rgb images as input.to this end, we propose to fuse together the outputs of a semantic segmentation and a monoculardepth estimation architecture to reconstruct locally a semantic 3d point cloud of the viewed scene.we only retain points belonging to the road and, additionally, to any kind of fences or walls thatmight be present right at the sides of the road. we then compute the width of the road at a certainpoint on the planned trajectory and, additionally, what we denote as the fence-to-fence distance.our system is suited to any kind of motoring scenario and is especially useful when lane lines arenot present on the road or do not signal the path correctly. the additional fence-to-fence distancecomputation is complementary to the road's width estimation. we quantitatively test our methodon a set of images featuring streets of the city of munich that contain a road-fence structure, so asto compare our two proposed variants, namely the road's width and the fence-to-fence distancecomputation. in addition, we also validate our system qualitatively on the stuttgart sequence of thepublicly available cityscapes dataset, where no fences or walls are present at the sides of the road,thus demonstrating that our system can be deployed in a standard city-like environment. for thebenefit of the community, we make our software open source.","['roads without lane lines', 'monocular depth estimation', 'fusing semantic segmentation', 'enabling autonomous driving', 'semanticdepth']"
"in the case of space-based space surveillance (sbss), images of the target space objects captured by space-based imaging sensors usually suffer from low spatial resolution due to the extremely long distance between the target and the imaging sensor. image super-resolution is an effective data processing operation to get informative high resolution images. in this paper, we comparably study four recent popular models for single image super-resolution based on convolutional neural networks (cnns) with the purpose of space applications. we specially fine-tune the super-resolution models designed for natural images using simulated images of space objects, and test the performance of different cnn-based models in different conditions that are mainly considered for sbss. experimental results show the advantages and drawbacks of these models, which could be helpful for the choice of proper cnn-based super-resolution method to deal with image data of space objects.","['based single image super', 'based imaging sensors', 'comparable study', 'space', 'resolution', 'cnn']"
"advances in both imaging and computers have led to the rise in the potential use of artificial intelligence (ai) in various tasks in breast imaging, going beyond the current use in computer-aided detection to include diagnosis, prognosis, response to therapy, and risk assessment. the automated capabilities of ai offer the potential to enhance the diagnostic expertise of clinicians, including accurate demarcation of tumor volume, extraction of characteristic cancer phenotypes, translation of tumoral phenotype features to clinical genotype implications, and risk prediction. the combination of image-specific findings with the underlying genomic, pathologic, and clinical features is becoming of increasing value in breast cancer. the concurrent emergence of newer imaging techniques has provided radiologists with greater diagnostic tools and image datasets to analyze and interpret. integrating an ai-based workflow within breast imaging enables the integration of multiple data streams into powerful multidisciplinary applications that may lead the path to personalized patient-specific medicine. in this article we describe the goals of ai in breast cancer imaging, in particular mri, and review the literature as it relates to the current application, potential, and limitations in breast cancer. level of evidence: 3 technical efficacy: stage 3 j. magn. reson. imaging 2020;51:1310-1324.","['breast cancer', 'artificial intelligence', 'mri', 'interpretation']"
"most existing tracking methods are direct trackers, which directly exploit foreground or/and background information for object appearance modeling and decide whether an image patch is target object or not. as a result, these trackers cannot perform well when target appearance changes heavily and becomes different from its model. to deal with this issue, we propose a novel relative tracker, which can effectively exploit the relative relationship among image patches from both foreground and background for object appearance modeling. different from direct trackers, the proposed relative tracker is robust to localize target object by use of the best image patch with the highest relative score to target appearance model. to model relative relationship among large-scale image patch pairs, we propose a novel and effective deep relative learning algorithm via convolutional neural network. we test the proposed approach on challenging sequences involving heavy occlusion, drastic illumination changes, and large pose variations. experimental results show that our method consistently outperforms state-of-the-art trackers due to the powerful capacity of the proposed deep relative model.",['deep relative tracking']
"cancer is one of the leading causes of deaths in the last two decades. it is either diagnosed malignant or benign - depending upon the severity of the infection and the current stage. the conventional methods require a detailed physical inspection by an expert dermatologist, which is time-consuming and imprecise. therefore, several computer vision methods are introduced lately, which are cost-effective and somewhat accurate. in this work, we propose a new automated approach for skin lesion detection and recognition using a deep convolutional neural network (dcnn). the proposed cascaded design incorporates three fundamental steps including; a) contrast enhancement through fast local laplacian filtering (fllpf) along hsv color transformation; b) lesion boundary extraction using color cnn approach by following xor operation; c) in-depth features extraction by applying transfer learning using inception v3 model prior to feature fusion using hamming distance (hd) approach. an entropy controlled feature selection method is also introduced for the selection of the most discriminant features. the proposed method is tested on ph2 and isic 2017 datasets, whereas the recognition phase is validated on ph2, isbi 2016, and isbi 2017 datasets. from the results, it is concluded that the proposed method outperforms several existing methods and attained accuracy 98.4% on ph2 dataset, 95.1% on isbi dataset and 94.8% on isbi 2017 dataset.","['deep cnn features fusion', 'skin cancer', 'region extraction', 'heterogeneous framework', 'reduction', 'classification']"
"a rapid learning health care system for oncology will require scalable methods for extracting clinical end points from electronic health records (ehrs). outside of clinical trials, end points such as cancer progression and response are not routinely encoded into structured data.","['deep natural language processing', 'ascertaining oncologic outcomes', 'radiology reports', 'assessment']"
"seizure prediction has made important advances over the last decade, with the recent demonstration that prospective seizure prediction is possible, though there remain significant obstacles to broader application. in this review, we will describe insights gained from long-term trials, with the aim of identifying research goals for the next decade.","['seizure prediction', 'looking review', 'forward']"
"understanding the relationships between local environmental conditions and plant structure and function is critical for both fundamental science and for improving the performance of crops in field settings. wind-induced plant motion is important in most agricultural systems, yet the complexity of the field environment means that it remained understudied. despite the ready availability of image sequences showing plant motion, the cultivation of crop plants in dense field stands makes it difficult to detect features and characterize their general movement traits. here, we present a robust method for characterizing motion in field-grown wheat plants (triticum aestivum) from time-ordered sequences of red, green, and blue images. a series of crops and augmentations was applied to a dataset of 290 collected and annotated images of ear tips to increase variation and resolution when training a convolutional neural network. this approach enables wheat ears to be detected in the field without the need for camera calibration or a fixed imaging position. videos of wheat plants moving in the wind were also collected and split into their component frames. ear tips were detected using the trained network, then tracked between frames using a probabilistic tracking algorithm to approximate movement. these data can be used to characterize key movement traits, such as periodicity, and obtain more detailed static plant properties to assess plant structure and function in the field. automated data extraction may be possible for informing lodging models, breeding programs, and linking movement properties to canopy light distributions and dynamic light fluctuation.","['dense field environments via deep learning', 'multiple object tracking', 'induced plant motion', 'recovering wind']"
"learning visual representations from web data has recently attracted attention for object recognition. previous studies have mainly focused on overcoming label noise and data bias and have shown promising results by learning directly from web data. however, we argue that it might be better to transfer knowledge from existing human labeling resources to improve performance at nearly no additional cost. in this paper, we propose a new semi-supervised method for learning via web data. our method has the unique design of exploiting strong supervision, i.e., in addition to standard image-level labels, our method also utilizes detailed annotations including object bounding boxes and part landmarks. by transferring as much knowledge as possible from existing strongly supervised datasets to weakly supervised web images, our method can benefit from sophisticated object recognition algorithms and overcome several typical problems found in webly-supervised learning. we consider the problem of fine-grained visual categorization, in which existing training resources are scarce, as our main research objective. comprehensive experimentation and extensive analysis demonstrate encouraging performance of the proposed approach, which, at the same time, delivers a new pipeline for fine-grained visual categorization that is likely to be highly effective for real-world applications.","['grained visual categorization via deep domain adaptation', 'supervised fine', 'webly']"
"classification of benign-malignant lung nodules on chest ct is the most critical step in the early detection of lung cancer and prolongation of patient survival. despite their success in image classification, deep convolutional neural networks (dcnns) always require a large number of labeled training data, which are not available for most medical image analysis applications due to the work required in image acquisition and particularly image annotation. in this paper, we propose a semi-supervised adversarial classification (ssac) model that can be trained by using both labeled and unlabeled data for benign-malignant lung nodule classification. this model consists of an adversarial autoencoder-based unsupervised reconstruction network r, a supervised classification network c, and learnable transition layers that enable the adaption of the image representation ability learned by r to c. the ssac model has been extended to the multi-view knowledge-based collaborative learning, aiming to employ three ssacs to characterize each nodule's overall appearance, heterogeneity in shape and texture, respectively, and to perform such characterization on nine planar views. the mk-ssac model has been evaluated on the benchmark lidc-idri dataset and achieves an accuracy of 92.53% and an auc of 95.81%, which are superior to the performance of other lung nodule classification and semi-supervised learning approaches.","['malignant lung nodule classification', 'supervised adversarial model', 'chest ct', 'semi', 'benign']"
"the subthalamic nucleus (stn) and globus pallidus internus (gpi) have recently been shown to encode reward, but few studies have been performed in humans. we investigated stn and gpi encoding of reward and loss (i.e., valence) in humans with parkinson's disease. to test the hypothesis that stn and gpi neurons would change their firing rate in response to reward- and loss-related stimuli, we recorded the activity of individual neurons while participants performed a behavioral task. in the task, action choices were associated with potential rewarding, punitive, or neutral outcomes. we found that stn and gpi neurons encode valence-related information during action control, but the proportion of valence-responsive neurons was greater in the stn compared to the gpi. in the stn, reward-related stimuli mobilized a greater proportion of neurons than loss-related stimuli. we also found surprising limbic overlap with the sensorimotor regions in both the stn and gpi, and this overlap was greater than has been previously reported. these findings may help to explain alterations in limbic function that have been observed following deep brain stimulation therapy of the stn and gpi. hum brain mapp 38:1952-1964, 2017.","['globus pallidus internus differentially encode reward', 'human subthalamic nucleus', 'action control']"
"internet-of-things applications that use machine-learning algorithms have increased the demand for application-specific energy-efficient hardware that can perform both learning and inference tasks to adapt to endpoint users or environmental changes. this paper presents a multilayer-learning neuromorphic system with analog-based multiplier-accumulator (mac), which can learn training data by stochastic gradient descent algorithm. as a component of the proposed system, a current-mode mac processor, fabricated in 28-nm cmos technology, performs both forward and backward processing in a crossbar structure of 500\xa0×\xa0500 6-b transposable sram arrays. the proposed system is verified in a two-layer neural network by using two prototype chips and an fpga. without any calibration circuit for the analog-based mac, the proposed system compensates for non-idealities from analog operations by learning training data with the analog-based mac. with 1-b (+1, 0, -1) batch update of 6-b synaptic weights, the proposed system achieves a recognition rate of 96.6% with a peak energy efficiency of 2.99 tops/w (1 op = one unsigned 8-b\xa0×\xa0signed 6-b mac operation) in the classification of the mnist dataset.","['mode neuromorphic system', 'learning current', 'error compensation', 'multilayer', 'analog']"
"to promote graduate students' active learning, deep reading of high quality papers was done by graduate students enrolled in biochemistry and microbiology pharmacy curriculum offered by college of life science, jiangxi normal university from 2013 to 2015. the number of graduate students, who participated in the course in 2013, 2014, and 2015 were eleven, thirteen and fifteen, respectively. through deep reading of papers, presentation, and group discussion in the lecture, these graduate students have improved their academic performances effectively, such as literature search, ppt document production, presentation management, specialty document reading, academic inquiry, and analytical and comprehensive ability. the graduate students also have increased their understanding level of frontier research, scientific research methods, and experimental methods.","['promoting active learning', 'microbiology pharmacy curriculum', 'graduate student', 'deep reading', 'biochemistry']"
"cytopathologic testing is one of the most critical steps in the diagnosis of diseases, including cancer. however, the task is laborious and demands skill. associated high cost and low throughput drew considerable interest in automating the testing process. several neural network architectures were designed to provide human expertise to machines. in this paper, we explore and propose the feasibility of using deep-learning networks for cytopathologic analysis by performing the classification of three important unlabeled, unstained leukemia cell lines (k562, molt, and hl60). the cell images used in the classification are captured using a low-cost, high-throughput cell imaging technique: microfluidics-based imaging flow cytometry. we demonstrate that without any conventional fine segmentation followed by explicit feature extraction, the proposed deep-learning algorithms effectively classify the coarsely localized cell lines. we show that the designed deep belief network as well as the deeply pretrained convolutional neural network outperform the conventionally used decision systems and are important in the medical domain, where the availability of labeled data is limited for training. we hope that our work enables the development of a clinically significant high-throughput microfluidic microscopy-based tool for disease screening/triaging, especially in resource-limited settings.","['cytopathological image analysis using deep', 'microfluidic microscopy', 'learning networks']"
"quantification of vascular morphodynamics during secondary growth has been hampered by the scale of the process. even in the tiny model plant arabidopsis thaliana, the xylem can include more than 2000 cells in a single cross section, rendering manual counting impractical. moreover, due to its deep location, xylem is an inaccessible tissue, limiting live imaging. a novel method to visualize and measure secondary growth progression has been proposed: ""the quantitative histology"" approach. this method is based on a detailed anatomical atlas, and image segmentation coupled with machine learning to automatically extract cell shapes and identify cell type. here we present a new version of this approach, with a user-friendly interface implemented in the open source software lithographx.","['vascular morphodynamics', 'secondary growth']"
"protein quality assessment is a long-standing problem in bioinformatics. for more than a decade we have developed state-of-art predictors by carefully selecting and optimising inputs to a machine learning method. the correlation has increased from 0.60 in proq to 0.81 in proq2 and 0.85 in proq3 mainly by adding a large set of carefully tuned descriptions of a protein. here, we show that a substantial improvement can be obtained using exactly the same inputs as in proq2 or proq3 but replacing the support vector machine by a deep neural network. this improves the pearson correlation to 0.90 (0.85 using proq2 input features).","['improved model quality assessments using deep learning', 'proq3d']"
"deep brain stimulation is an effective way to treat movement disorders, and a powerful research tool for exploring brain functions. this report proposes a ""curved lead pathway"" method for lead implantation, such that a single lead can reach in sequence to any two intracranial targets. a new type of stereotaxic system for implanting a curved lead to the brain of human/primates was designed, the auxiliary device needed for this method to be used in rat/mouse was fabricated and verified in rat, and the excel algorithm used for automatically calculating the necessary parameters was implemented. this ""curved lead pathway"" method of lead implantation may complement the current method, make lead implantation for multiple targets more convenient, and expand the experimental techniques of brain function research.","['two intracranial targets', 'curved lead pathway', 'single lead', 'reach', 'method', 'enable']"
"early diagnosis of interstitial lung diseases is crucial for their treatment, but even experienced physicians find it difficult, as their clinical manifestations are similar. in order to assist with the diagnosis, computer-aided diagnosis systems have been developed. these commonly rely on a fixed scale classifier that scans ct images, recognizes textural lung patterns, and generates a map of pathologies. in a previous study, we proposed a method for classifying lung tissue patterns using a deep convolutional neural network (cnn), with an architecture designed for the specific problem. in this study, we present an improved method for training the proposed network by transferring knowledge from the similar domain of general texture classification. six publicly available texture databases are used to pretrain networks with the proposed architecture, which are then fine-tuned on the lung tissue data. the resulting cnns are combined in an ensemble and their fused knowledge is compressed back to a network with the original architecture. the proposed approach resulted in an absolute increase of about 2% in the performance of the proposed cnn. the results demonstrate the potential of transfer learning in the field of medical image analysis, indicate the textural nature of the problem and show that the method used for training a network can be as important as designing its architecture.","['multisource transfer learning', 'lung pattern analysis', 'convolutional neural networks']"
"attention deficit/hyperactivity disorder(adhd) is a behavioral disorder syndrome found mainly in school-age population. at present, the diagnosis of adhd mainly depends on the subjective methods, leading to the high rate of misdiagnosis and missed-diagnosis. to solve these problems, we proposed an algorithm for classifying adhd objectively based on convolutional neural network. at first, preprocessing steps, including skull stripping, gaussian kernel smoothing, et al., were applied to brain magnetic resonance imaging(mri). then, coarse segmentation was used for selecting the right caudate nucleus, left precuneus, and left superior frontal gyrus region. finally, a 3 level convolutional neural network was used for classification. experimental results showed that the proposed algorithm was capable of classifying adhd and normal groups effectively, the classification accuracies obtained by the right caudate nucleus and the left precuneus brain regions were greater than the highest classification accuracy(62.52%) in the adhd-200 competition, and among 3 brain regions in adhd and the normal groups, the classification accuracy from the right caudate nucleus was the highest. it is well concluded that the method for classification of adhd and normal groups proposed in this paper utilizing the coarse segmentation and deep learning is a useful method for the purpose. the classification accuracy of the proposed method is high, and the calculation is simple. and the method is able to extract the unobvious image features better, and can overcome the shortcomings of traditional methods of mri brain area segmentation, which are time-consuming and highly complicate. the method provides an objective diagnosis approach for adhd.","['hyperactivity disorder classification based', 'convolutional neural networks ].', 'attention deficit', 'study']"
"we provide a comprehensive account of recent advances in biomedical image analysis and classification from two complementary imaging modalities: terahertz (thz) pulse imaging and dynamic contrast-enhanced magnetic resonance imaging (dce-mri). the work aims to highlight underlining commonalities in both data structures so that a common multi-channel data fusion framework can be developed. signal pre-processing in both datasets is discussed briefly taking into consideration advances in multi-resolution analysis and model based fractional order calculus system identification. developments in statistical signal processing using principal component and independent component analysis are also considered. these algorithms have been developed independently by the thz-pulse imaging and dce-mri communities, and there is scope to place them in a common multi-channel framework to provide better software standardization at the pre-processing de-noising stage. a comprehensive discussion of feature selection strategies is also provided and the importance of preserving textural information is highlighted. feature extraction and classification methods taking into consideration recent advances in support vector machine (svm) and extreme learning machine (elm) classifiers and their complex extensions are presented. an outlook on clifford algebra classifiers and deep learning techniques suitable to both types of datasets is also provided. the work points toward the direction of developing a new unified multi-channel signal processing framework for biomedical image analysis that will explore synergies from both sensing modalities for inferring disease proliferation.","['thz pulse imaging', 'deep learning framework', 'unified multi', 'channel classification', 'toward', 'mris', 'exploring', 'dce', 'complementarity']"
"artificial intelligence (ai) is a general term that implies the use of a computer to model intelligent behavior with minimal human intervention. ai is generally accepted as having started with the invention of robots. the term derives from the czech word robota, meaning biosynthetic machines used as forced labor. in this field, leonardo da vinci\'s lasting heritage is today\'s burgeoning use of robotic-assisted surgery, named after him, for complex urologic and gynecologic procedures. da vinci\'s sketchbooks of robots helped set the stage for this innovation. ai, described as the science and engineering of making intelligent machines, was officially born in 1956. the term is applicable to a broad range of items in medicine such as robotics, medical diagnosis, medical statistics, and human biology-up to and including today\'s ""omics"". ai in medicine, which is the focus of this review, has two main branches: virtual and physical. the virtual branch includes informatics approaches from deep learning information management to control of health management systems, including electronic health records, and active guidance of physicians in their treatment decisions. the physical branch is best represented by robots used to assist the elderly patient or the attending surgeon. also embodied in this branch are targeted nanorobots, a unique new drug delivery system. the societal and ethical complexities of these applications require further reflection, proof of their medical utility, economic value, and development of interdisciplinary strategies for their wider application.","['artificial intelligence', 'medicine']"
"since there are complex geometric variations with 3d shapes, extracting efficient 3d shape features is one of the most challenging tasks in shape matching and retrieval. in this paper, we propose a deep shape descriptor by learning shape distributions at different diffusion time via a progressive shape-distribution-encoder (psde). first, we develop a shape distribution representation with the kernel density estimator to characterize the intrinsic geometry structures of 3d shapes. then, we propose to learn a deep shape feature through an unsupervised psde. specially, the unsupervised psde aims at modeling the complex non-linear transform of the estimated shape distributions between consecutive diffusion time. in order to characterize the intrinsic structures of 3d shapes more efficiently, we stack multiple psdes to form a network structure. finally, we concatenate all neurons in the middle hidden layers of the unsupervised psde network to form an unsupervised shape descriptor for retrieval. furthermore, by imposing an additional constraint on the outputs of all hidden layers, we propose a supervised psde to form a supervised shape descriptor. for each hidden layer, the similarity between a pair of outputs from the same class is as large as possible and the similarity between a pair of outputs from different classes is as small as possible. the proposed method is evaluated on three benchmark 3d shape data sets with large geometric variations, i.e., mcgill, shrec'10 shapegoogle, and shrec'14 human data sets, and the experimental results demonstrate the superiority of the proposed method to the existing approaches.","['learning 3d shape representation', 'progressive shape', 'encoder', 'distribution']"
"image representation has been intensively explored in the domain of computer vision for its significant influence on the relative tasks such as image clustering and classification. it is valuable to learn a low-dimensional representation of an image which preserves its inherent information from the original image space. at the perspective of manifold learning, this is implemented with the local invariant idea to capture the intrinsic low-dimensional manifold embedded in the high-dimensional input space. inspired by the recent successes of deep architectures, we propose a local invariant deep nonlinear mapping algorithm, called graph regularized auto-encoder (gae). with the graph regularization, the proposed method preserves the local connectivity from the original image space to the representation space, while the stacked auto-encoders provide explicit encoding model for fast inference and powerful expressive capacity for complex modeling. theoretical analysis shows that the graph regularizer penalizes the weighted frobenius norm of the jacobian matrix of the encoder mapping, where the weight matrix captures the local property in the input space. furthermore, the underlying effects on the hidden representation space are revealed, providing insightful explanation to the advantage of the proposed method. finally, the experimental results on both clustering and classification tasks demonstrate the effectiveness of our gae as well as the correctness of the proposed theoretical analysis, and it also suggests that gae is a superior solution to the current deep representation learning techniques comparing with variant auto-encoders and existing local invariant methods.","['graph regularized auto', 'image representation', 'encoders']"
"effective sleep analysis is hampered by the lack of automated tools catering to disordered sleep patterns and cumbersome monitoring hardware. in this paper, we apply deep learning on a set of 57 eeg features extracted from a maximum of two eeg channels to accurately differentiate between patients with insomnia or controls with no sleep complaints. we investigated two different approaches to achieve this. the first approach used eeg data from the whole sleep recording irrespective of the sleep stage (stage-independent classification), while the second used only eeg data from insomnia-impacted specific sleep stages (stage-dependent classification). we trained and tested our system using both healthy and disordered sleep collected from 41 controls and 42 primary insomnia patients. when compared with manual assessments, an nrem\xa0+\xa0rem based classifier had an overall discrimination accuracy of 92% and 86% between two groups using both two and one eeg channels, respectively. these results demonstrate that deep learning can be used to assist in the diagnosis of sleep disorders such as insomnia.","['deep learning', 'assisting clinicians', 'insomnia', 'diagnosis']"
"the recent movement towards open data in the biomedical domain has generated a large number of datasets that are publicly accessible. the big data to knowledge data indexing project, biomedical and healthcare data discovery index ecosystem (biocaddie), has gathered these datasets in a one-stop portal aiming at facilitating their reuse for accelerating scientific advances. however, as the number of biomedical datasets stored and indexed increases, it becomes more and more challenging to retrieve the relevant datasets according to researchers' queries. in this article, we propose an information retrieval (ir) system to tackle this problem and implement it for the biocaddie dataset retrieval challenge. the system leverages the unstructured texts of each dataset including the title and description for the dataset, and utilizes a state-of-the-art ir model, medical named entity extraction techniques, query expansion with deep learning-based word embeddings and a re-ranking strategy to enhance the retrieval performance. in empirical experiments, we compared the proposed system with 11 baseline systems using the biocaddie dataset retrieval challenge datasets. the experimental results show that the proposed system outperforms other systems in terms of inference average precision and inference normalized discounted cumulative gain, implying that the proposed system is a viable option for biomedical dataset retrieval. database url: https://github.com/yanshanwang/biocaddie2016mayodata.","['biomedical dataset retrieval using unstructured texts', 'medical entity extraction', 'leveraging word embeddings']"
"with a massive influx of multimodality data, the role of data analytics in health informatics has grown rapidly in the last decade. this has also prompted increasing interests in the generation of analytical, data driven models based on machine learning in health informatics. deep learning, a technique with its foundation in artificial neural networks, is emerging in recent years as a powerful tool for machine learning, promising to reshape the future of artificial intelligence. rapid improvements in computational power, fast data storage, and parallelization have also contributed to the rapid uptake of the technology in addition to its predictive power and ability to generate automatically optimized high-level features and semantic interpretation from the input data. this article presents a comprehensive up-to-date review of research employing deep learning in health informatics, providing a critical analysis of the relative merit, and potential pitfalls of the technique as well as its future outlook. the paper mainly focuses on key applications of deep learning in the fields of translational bioinformatics, medical imaging, pervasive sensing, medical informatics, and public health.","['health informatics', 'deep learning']"
"why some individuals, when presented with unstructured sensory inputs, develop altered perceptions not based in reality, is not well understood. machine learning approaches can potentially help us understand how the brain normally interprets sensory inputs. artificial neural networks (ann) progressively extract higher and higher-level features of sensory input and identify the nature of an object based on a priori information. however, some anns which use algorithms such as the ""deep-dreaming"" developed by google, allow the network to over-emphasize some objects it ""thinks"" it recognizes in those areas, and iteratively enhance such outputs leading to representations that appear farther and farther from ""reality"". we suggest that such ""deep dreaming"" anns may model aberrant salience, a mechanism suggested for pathogenesis of psychosis. such models can generate testable predictions for psychosis.","['artificial neural networks', 'deep dreaming', 'aberrant salience', 'psychosis', 'dots', 'connecting']"
"we present a deep convolutional neural network application based on autoencoders aimed at segmentation of increased signal regions in fluid-attenuated inversion recovery magnetic resonance imaging images. the convolutional autoencoders were trained on the publicly available brain tumor image segmentation benchmark (brats) data set, and the accuracy was evaluated on a data set where 3 expert segmentations were available. the simultaneous truth and performance level estimation (staple) algorithm was used to provide the ground truth for comparison, and dice coefficient, jaccard coefficient, true positive fraction, and false negative fraction were calculated. the proposed technique was within the interobserver variability with respect to dice, jaccard, and true positive fraction. the developed method can be used to produce automatic segmentations of tumor regions corresponding to signal-increased fluid-attenuated inversion recovery regions.","['flair mri using deep learning', 'hyperintense regions', 'automated segmentation']"
"it is estimated that 7% of women in the western world will develop palpable breast cysts in their lifetime. even though cysts have been correlated with risk of developing breast cancer, many of them are benign and do not require follow-up. we develop a method to discriminate benign solitary cysts from malignant masses in digital mammography. we think a system like this can have merit in the clinic as a decision aid or complementary to specialized modalities.","['pretrained deep convolutional neural network', 'soft tissue lesions', 'discriminating solitary cysts', 'mammography using']"
"advances in neuroradiological planning techniques in deep brain stimulation have put the need for intraoperative electrophysiological monitoring into doubt. moreover intraoperative monitoring prolongs surgical time and there is potential association between the use of microelectrodes and increased incidence of hemorrhagic complications. the aim of this study was to analyze the correlation between the anatomically planned trajectory and the final subthalamic electrode placement after electrophysiological monitoring in patients with parkinson""s disease and its change with the increasing experience of the surgical team.","['subthalamic nucleus stimulation', 'learning curve', 'electrophysiological correlations', 'anatomo']"
"neurochemical changes evoked by electrical stimulation of the nervous system have been linked to both therapeutic and undesired effects of neuromodulation therapies used to treat obsessive-compulsive disorder, depression, epilepsy, parkinson's disease, stroke, hypertension, tinnitus, and many other indications. in fact, interest in better understanding the role of neurochemical signaling in neuromodulation therapies has been a focus of recent government- and industry-sponsored programs whose ultimate goal is to usher in an era of personalized medicine by creating neuromodulation therapies that respond to real-time changes in patient status. a key element to achieving these precision therapeutic interventions is the development of mathematical modeling approaches capable of describing the nonlinear transfer function between neuromodulation parameters and evoked neurochemical changes. here, we propose two computational modeling frameworks, based on artificial neural networks (anns) and volterra kernels, that can characterize the input/output transfer functions of stimulation-evoked neurochemical release. we evaluate the ability of these modeling frameworks to characterize subject-specific neurochemical kinetics by accurately describing stimulation-evoked dopamine release across rodent (r2 = 0.83 volterra kernel, r2 = 0.86 ann), swine (r2 = 0.90 volterra kernel, r2 = 0.93 ann), and non-human primate (r2 = 0.98 volterra kernel, r2 = 0.96 ann) models of brain stimulation. ultimately, these models will not only improve understanding of neurochemical signaling in healthy and diseased brains but also facilitate the development of neuromodulation strategies capable of controlling neurochemical release via closed-loop strategies.","['neurotransmitter release evoked', 'evoked dopamine release', 'predicting stimulation', 'nonlinear approaches', 'electrical stimulation', 'computational modeling']"
"effective 3-d shape retrieval is an important problem in 3-d shape analysis. recently, feature learning-based shape retrieval methods have been widely studied, where the distance metrics between 3-d shape descriptors are usually hand-crafted. in this paper, motivated by the fact that deep neural network has the good ability to model nonlinearity, we propose to learn an effective nonlinear distance metric between 3-d shape descriptors for retrieval. first, the locality-constrained linear coding method is employed to encode each vertex on the shape and the encoding coefficient histogram is formed as the global 3-d shape descriptor to represent the shape. then, a novel deep metric network is proposed to learn a nonlinear transformation to map the 3-d shape descriptors to a nonlinear feature space. the proposed deep metric network minimizes a discriminative loss function that can enforce the similarity between a pair of samples from the same class to be small and the similarity between a pair of samples from different classes to be large. finally, the distance between the outputs of the metric network is used as the similarity for shape retrieval. the proposed method is evaluated on the mcgill, shrec'10 shapegoogle, and shrec'14 human shape datasets. experimental results on the three datasets validate the effectiveness of the proposed method.","['deep nonlinear metric learning', 'shape retrieval', '3']"
"human beings often assess the aesthetic quality of an image coupled with the identification of the image's semantic content. this paper addresses the correlation issue between automatic aesthetic quality assessment and semantic recognition. we cast the assessment problem as the main task among a multi-task deep model, and argue that semantic recognition task offers the key to address this problem. based on convolutional neural networks, we employ a single and simple multi-task framework to efficiently utilize the supervision of aesthetic and semantic labels. a correlation item between these two tasks is further introduced to the framework by incorporating the inter-task relationship learning. this item not only provides some useful insight about the correlation but also improves assessment accuracy of the aesthetic task. in particular, an effective strategy is developed to keep a balance between the two tasks, which facilitates to optimize the parameters of the framework. extensive experiments on the challenging aesthetic visual analysis dataset and photo.net dataset validate the importance of semantic recognition in aesthetic quality assessment, and demonstrate that multitask deep models can discover an effective aesthetic representation to achieve the state-of-the-art results.","['deep aesthetic quality assessment', 'semantic information']"
"the research on hand gestures has attracted many image processing-related studies, as it intuitively conveys the intention of a human as it pertains to motional meaning. various sensors have been used to exploit the advantages of different modalities for the extraction of important information conveyed by the hand gesture of a user. although many works have focused on learning the benefits of thermal information from thermal cameras, most have focused on face recognition or human body detection, rather than hand gesture recognition. additionally, the majority of the works that take advantage of multiple modalities (e.g., the combination of a thermal sensor and a visual sensor), usually adopting simple fusion approaches between the two modalities. as both thermal sensors and visual sensors have their own shortcomings and strengths, we propose a novel joint filter-based hand gesture recognition method to simultaneously exploit the strengths and compensate the shortcomings of each. our study is motivated by the investigation of the mutual supplementation between thermal and visual information in low feature level for the consistent representation of a hand in the presence of varying lighting conditions. accordingly, our proposed method leverages the thermal sensor's stability against luminance and the visual sensors textural detail, while complementing the low resolution and halo effect of thermal sensors and the weakness against illumination of visual sensors. a conventional region tracking method and a deep convolutional neural network have been leveraged to track the trajectory of a hand gesture and to recognize the hand gesture, respectively. our experimental results show stability in recognizing a hand gesture against varying lighting conditions based on the contribution of the joint kernels of spatial adjacency and thermal range similarity.","['thermal guided joint filter', 'air hand gesture based', 'tracking', 'classification']"
"protein contacts contain key information for the understanding of protein structure and function and thus, contact prediction from sequence is an important problem. recently exciting progress has been made on this problem, but the predicted contacts for proteins without many sequence homologs is still of low quality and not very useful for de novo structure prediction.","['accurate de novo prediction', 'protein contact map', 'deep learning model', 'ultra']"
"unsupervised neural network learning extracts hidden features from unlabeled training data. this is used as a pretraining step for further supervised learning in deep networks. hence, understanding unsupervised learning is of fundamental importance. here, we study the unsupervised learning from a finite number of data, based on the restricted boltzmann machine where only one hidden neuron is considered. our study inspires an efficient message-passing algorithm to infer the hidden feature and estimate the entropy of candidate features consistent with the data. our analysis reveals that the learning requires only a few data if the feature is salient and extensively many if the feature is weak. moreover, the entropy of candidate features monotonically decreases with data size and becomes negative (i.e., entropy crisis) before the message passing becomes unstable, suggesting a discontinuous phase transition. in terms of convergence time of the message-passing algorithm, the unsupervised learning exhibits an easy-hard-easy phenomenon as the training data size increases. all these properties are reproduced in an approximate hopfield model, with an exception that the entropy crisis is absent, and only continuous phase transition is observed. this key difference is also confirmed in a handwritten digits dataset. this study deepens our understanding of unsupervised learning from a finite number of data and may provide insights into its role in training deep networks.","['discontinuous versus continuous phase transition', 'unsupervised feature learning', 'message passing', 'finite data']"
"the capabilities of (i) learning transferable knowledge across domains; and (ii) fine-tuning the pre-learned base knowledge towards tasks with considerably smaller data scale are extremely important. many of the existing transfer learning techniques are supervised approaches, among which deep learning has the demonstrated power of learning domain transferrable knowledge with large scale network trained on massive amounts of labeled data. however, in many biomedical tasks, both the data and the corresponding label can be very limited, where the unsupervised transfer learning capability is urgently needed. in this paper, we proposed a novel multi-scale convolutional sparse coding (mscsc) method, that (i) automatically learns filter banks at different scales in a joint fashion with enforced scale-specificity of learned patterns; and (ii) provides an unsupervised solution for learning transferable base knowledge and fine-tuning it towards target tasks. extensive experimental evaluation of mscsc demonstrates the effectiveness of the proposed mscsc in both regular and transfer learning tasks in various biomedical domains.","['unsupervised transfer learning via multi', 'scale convolutional sparse coding', 'biomedical applications']"
"in today's society, every individual is subjected to stressful stimuli with different intensities and duration. this exposure can be a key trigger in several mental illnesses greatly affecting one's quality of life. yet not all subjects respond equally to the same stimulus and some are able to better adapt to them delaying the onset of its negative consequences. the neural specificities of this adaptation can be essential to understand the true dynamics of stress as well as to design new approaches to reduce its consequences. in the current work, we employed ex vivo high field diffusion magnetic resonance imaging (mri) to uncover the differences in white matter properties in the entire brain between fisher 344 (f344) and sprague-dawley (sd) rats, known to present different responses to stress, and to examine the effects of a 2-week repeated inescapable stress paradigm. we applied a tract-based spatial statistics (tbss) analysis approach to a total of 25 animals. after exposure to stress, sd rats were found to have lower values of corticosterone when compared with f344 rats. overall, stress was found to lead to an overall increase in fractional anisotropy (fa), on top of a reduction in mean and radial diffusivity (md and rd) in several white matter bundles of the brain. no effect of strain on the white matter diffusion properties was observed. the strain-by-stress interaction revealed an effect on sd rats in md, rd and axial diffusivity (ad), with lower diffusion metric levels on stressed animals. these effects were localized on the left side of the brain on the external capsule, corpus callosum, deep cerebral white matter, anterior commissure, endopiriform nucleus, dorsal hippocampus and amygdala fibers. the results possibly reveal an adaptation of the sd strain to the stressful stimuli through synaptic and structural plasticity processes, possibly reflecting learning processes.","['white matter changes', 'microstructure associated', 'maladaptive response', 'stress', 'rats']"
"passenger profiling plays a vital part of commercial aviation security, but classical methods become very inefficient in handling the rapidly increasing amounts of electronic records. this paper proposes a deep learning approach to passenger profiling. the center of our approach is a pythagorean fuzzy deep boltzmann machine (pfdbm), whose parameters are expressed by pythagorean fuzzy numbers such that each neuron can learn how a feature affects the production of the correct output from both the positive and negative sides. we propose a hybrid algorithm combining a gradient-based method and an evolutionary algorithm for training the pfdbm. based on the novel learning model, we develop a deep neural network (dnn) for classifying normal passengers and potential attackers, and further develop an integrated dnn for identifying group attackers whose individual features are insufficient to reveal the abnormality. experiments on data sets from air china show that our approach provides much higher learning ability and classification accuracy than existing profilers. it is expected that the fuzzy deep learning approach can be adapted for a variety of complex pattern analysis tasks.","['fuzzy deep machine learning', 'airline passenger profiling based']"
"learning high-level image representations using object proposals has achieved remarkable success in multi-label image recognition. however, most object proposals provide merely coarse information about the objects, and only carefully selected proposals can be helpful for boosting the performance of multi-label image recognition. in this paper, we propose an object-proposal-free framework for multi-label image recognition: random crop pooling (rcp). basically, rcp performs stochastic scaling and cropping over images before feeding them to a standard convolutional neural network, which works quite well with a max-pooling operation for recognizing the complex contents of multi-label images. to better fit the multi-label image recognition task, we further develop a new loss function-the dynamic weighted euclidean loss-for the training of the deep network. our rcp approach is amazingly simple yet effective. it can achieve significantly better image recognition performance than the approaches using object proposals. moreover, our adapted network can be easily trained in an end-to-end manner. extensive experiments are conducted on two representative multi-label image recognition data sets (i.e., pascal voc 2007 and pascal voc 2012), and the results clearly demonstrate the superiority of our approach.","['random crop pooling', 'label image recognition', 'beyond object proposals', 'multi']"
"real-world applications such as first-person video activity recognition require intelligent edge devices. however, size, weight, and power constraints of the embedded platforms cannot support resource intensive state-of-the-art algorithms. machine learning lite algorithms, such as reservoir computing, with shallow 3-layer networks are computationally frugal as only the output layer is trained. by reducing network depth and plasticity, reservoir computing minimizes computational power and complexity, making the algorithms optimal for edge devices. however, as a trade-off for their frugal nature, reservoir computing sacrifices computational power compared to state-of-the-art methods. a good compromise between reservoir computing and fully supervised networks are the proposed deep-lsm networks. the deep-lsm is a deep spiking neural network which captures dynamic information over multiple time-scales with a combination of randomly connected layers and unsupervised layers. the deep-lsm processes the captured dynamic information through an attention modulated readout layer to perform classification. we demonstrate that the deep-lsm achieves an average of 84.78% accuracy on the dogcentric video activity recognition task, beating state-of-the-art. the deep-lsm also shows up to 91.13% memory savings and up to 91.55% reduction in synaptic operations when compared to similar recurrent neural network models. based on these results we claim that the deep-lsm is capable of overcoming limitations of traditional reservoir computing, while maintaining the low computational cost associated with reservoir computing.","['deep liquid state machines', 'video activity recognition', 'neural plasticity']"
"deep neural networks (dnns) provide useful models of visual representational transformations. we present a method that enables a dnn (student) to learn from the internal representational spaces of a reference model (teacher), which could be another dnn or, in the future, a biological brain. representational spaces of the student and the teacher are characterized by representational distance matrices (rdms). we propose representational distance learning (rdl), a stochastic gradient descent method that drives the rdms of the student to approximate the rdms of the teacher. we demonstrate that rdl is competitive with other transfer learning techniques for two publicly available benchmark computer vision datasets (mnist and cifar-100), while allowing for architectural differences between student and teacher. by pulling the student's rdms toward those of the teacher, rdl significantly improved visual classification performance when compared to baseline networks that did not use transfer learning. in the future, rdl may enable combined supervised training of deep neural networks using task constraints (e.g., images and category labels) and constraints from brain-activity measurements, so as to build models that replicate the internal representational spaces of biological brains.","['representational distance learning', 'deep neural networks']"
"the purpose of this study was to investigate the potential of using clinically provided spine label annotations stored in a single institution image archive as training data for deep learning-based vertebral detection and labeling pipelines. lumbar and cervical magnetic resonance imaging cases with annotated spine labels were identified and exported from an image archive. two separate pipelines were configured and trained for lumbar and cervical cases respectively, using the same setup with convolutional neural networks for detection and parts-based graphical models to label the vertebrae. the detection sensitivity, precision and accuracy rates ranged between 99.1-99.8, 99.6-100, and 98.8-99.8% respectively, the average localization error ranges were 1.18-1.24 and 2.38-2.60\xa0mm for cervical and lumbar cases respectively, and with a labeling accuracy of 96.0-97.0%. failed labeling results typically involved failed s1 detections or missed vertebrae that were not fully visible on the image. these results show that clinically annotated image data from one image archive is sufficient to train a deep learning-based pipeline for accurate detection and labeling of mr images depicting the spine. further, these results support using deep learning to assist radiologists in their work by providing highly accurate labels that only require rapid confirmation.","['mr images using deep learning', 'training data', 'clinical annotations', 'vertebrae', 'labeling', 'detection']"
"amyotrophic lateral sclerosis (als) is a progressive neuromuscular disease, with large variation in survival between patients. currently, it remains rather difficult to predict survival based on clinical parameters alone. here, we set out to use clinical characteristics in combination with mri data to predict survival of als patients using deep learning, a machine learning technique highly effective in a broad range of big-data analyses. a group of 135 als patients was included from whom high-resolution diffusion-weighted and t1-weighted images were acquired at the first visit to the outpatient clinic. next, each of the patients was monitored carefully and survival time to death was recorded. patients were labeled as short, medium or long survivors, based on their recorded time to death as measured from the time of disease onset. in the deep learning procedure, the total group of 135 patients was split into a training set for deep learning (n\xa0=\xa083 patients), a validation set (n\xa0=\xa020) and an independent evaluation set (n\xa0=\xa032) to evaluate the performance of the obtained deep learning networks. deep learning based on clinical characteristics predicted survival category correctly in 68.8% of the cases. deep learning based on mri predicted 62.5% correctly using structural connectivity and 62.5% using brain morphology data. notably, when we combined the three sources of information, deep learning prediction accuracy increased to 84.4%. taken together, our findings show the added value of mri with respect to predicting survival in als, demonstrating the advantage of deep learning in disease prognostication.","['deep learning predictions', 'amyotrophic lateral sclerosis', 'survival based', 'mri']"
"deep convolutional neural networks (cnns) have shown their great success on image classification. cnns mainly consist of convolutional and pooling layers, both of which are performed on local image areas without considering the dependence among different image regions. however, such dependence is very important for generating explicit image representation. in contrast, recurrent neural networks (rnns) are well known for their ability of encoding contextual information in sequential data, and they only require a limited number of network parameters. thus, we proposed the hierarchical rnns (hrnns) to encode the contextual dependence in image representation. in hrnns, each rnn layer focuses on modeling spatial dependence among image regions from the same scale but different locations. while the cross rnn scale connections target on modeling scale dependencies among regions from the same location but different scales. specifically, we propose two rnn models: 1) hierarchical simple recurrent network (hsrn), which is fast and has low computational cost and 2) hierarchical long-short term memory recurrent network, which performs better than hsrn with the price of higher computational cost. in this paper, we integrate cnns with hrnns, and develop end-to-end convolutional hierarchical rnns (c-hrnns) for image classification. c-hrnns not only utilize the discriminative representation power of cnns, but also utilize the contextual dependence learning ability of our hrnns. on four of the most challenging object/scene image classification benchmarks, our c-hrnns achieve the state-of-the-art results on places 205, sun 397, and mit indoor, and the competitive results on ilsvrc 2012.","['convolutional hierarchical recurrent neural networks', 'learning contextual dependence']"
"lung cancer is the most common cause of cancer-related deaths in the usa. it can be detected and diagnosed using computed tomography images. for an automated classifier, identifying predictive features from medical images is a key concern. deep feature extraction using pretrained convolutional neural networks (cnns) has recently been successfully applied in some image domains. here, we applied a pretrained cnn to extract deep features from 40 computed tomography images, with contrast, of non-small cell adenocarcinoma lung cancer, and combined deep features with traditional image features and trained classifiers to predict short- and long-term survivors. we experimented with several pretrained cnns and several feature selection strategies. the best previously reported accuracy when using traditional quantitative features was 77.5% (area under the curve [au",['71']
"visual saliency is a fundamental problem in both cognitive and computational sciences, including computer vision. in this paper, we discover that a high-quality visual saliency model can be learned from multiscale features extracted using deep convolutional neural networks (cnns), which have had many successes in visual recognition tasks. for learning such saliency models, we introduce a neural network architecture, which has fully connected layers on top of cnns responsible for feature extraction at three different scales. the penultimate layer of our neural network has been confirmed to be a discriminative high-level feature vector for saliency detection, which we call deep contrast feature. to generate a more robust feature, we integrate handcrafted low-level features with our deep contrast feature. to promote further research and evaluation of visual saliency models, we also construct a new large database of 4447 challenging images and their pixelwise saliency annotations. experimental results demonstrate that our proposed method is capable of achieving the state-of-the-art performance on all public benchmarks, improving the f-measure by 6.12% and 10%, respectively, on the dut-omron data set and our new data set (hku-is), and lowering the mean absolute error by 9% and 35.3%, respectively, on these two data sets.","['visual saliency detection based', 'multiscale deep cnn features']"
"visual object tracking technology is one of the key issues in computer vision. in this paper, we propose a visual object tracking algorithm based on cross-modality featuredeep learning using gaussian-bernoulli deep boltzmann machines (dbm) with rgb-d sensors. first, a cross-modality featurelearning network based on agaussian-bernoulli dbm is constructed, which can extract cross-modality features of the samples in rgb-d video data. second, the cross-modality features of the samples are input into the logistic regression classifier, andthe observation likelihood model is established according to the confidence score of the classifier. finally, the object tracking results over rgb-d data are obtained using abayesian maximum a posteriori (map) probability estimation algorithm. the experimental results show that the proposed method has strong robustness to abnormal changes (e.g., occlusion, rotation, illumination change, etc.). the algorithm can steadily track multiple targets and has higher accuracy.","['visual object tracking based', 'bernoulli deep boltzmann machines', 'modality gaussian', 'sensors', 'rgb', 'cross']"
"exploration in an unknown environment is an elemental application for mobile robots. in this paper, we outlined a reinforcement learning method aiming for solving the exploration problem in a corridor environment. the learning model took the depth image from an rgb-d sensor as the only input. the feature representation of the depth image was extracted through a pre-trained convolutional-neural-networks model. based on the recent success of deep q-network on artificial intelligence, the robot controller achieved the exploration and obstacle avoidance abilities in several different simulated environments. it is the first time that the reinforcement learning is used to build an exploration strategy for mobile robots through raw sensor information.","['mobile robots exploration', 'based reinforcement learning', 'cnn']"
"learning from data has led to paradigm shifts in a multitude of disciplines, including web, text and image search, speech recognition, as well as bioinformatics. can machine learning enable similar breakthroughs in understanding quantum many-body systems? here we develop an efficient deep learning approach that enables spatially and chemically resolved insights into quantum-mechanical observables of molecular systems. we unify concepts from many-body hamiltonians with purpose-designed deep tensor neural networks, which leads to size-extensive and uniformly accurate (1\u2009kcal\u2009mol-1) predictions in compositional and configurational chemical space for molecules of intermediate size. as an example of chemical relevance, the model reveals a classification of aromatic rings with respect to their stability. further applications of our model for predicting atomic energies and local chemical potentials in molecules, reliable isomer energies, and molecules with peculiar electronic structure demonstrate the potential of machine learning for revealing insights into complex quantum-chemical systems.","['deep tensor neural networks', 'chemical insights', 'quantum']"
to describe our experience using the anterior internal pelvic fixator (infix) for treating pelvic ring injuries.,"['anterior subcutaneous internal pelvic fixator', 'midterm radiographic', 'functional outcomes', 'infi']"
"brain computer interfaces allow users to preform various tasks using only the electrical activity of the brain. bci applications often present the user a set of stimuli and record the corresponding electrical response. the bci algorithm will then have to decode the acquired brain response and perform the desired task. in rapid serial visual presentation (rsvp) tasks, the subject is presented with a continuous stream of images containing rare target images among standard images, while the algorithm has to detect brain activity associated with target images. in this work, we suggest a multimodal neural network for rsvp tasks. the network operates on the brain response and on the initiating stimulus simultaneously, providing more information for the bci application. we present two variants of the multimodal network, a supervised model, for the case when the targets are known in advanced, and a semi-supervised model for when the targets are unknown. we test the neural networks with a rsvp experiment on satellite imagery carried out with two subjects. the multimodal networks achieve a significant performance improvement in classification metrics. we visualize what the networks has learned and discuss the advantages of using neural network models for bci applications.","['rapid serial visual presentation brain computer interface', 'multimodal neural network']"
"early detection of prostate cancer increases chances of patients' survival. our automated non-invasive system for computer-aided diagnosis (cad) of prostate cancer segments the prostate on diffusion-weighted magnetic resonance images (dw-mri) acquired at different b-values, estimates its apparent diffusion coefficients (adc), and classifies their descriptors - empirical cumulative distribution functions (cdf) - with a trained deep learning network. to segment the prostate, an evolving geometric (level-set-based) deformable model is guided by a speed function depending on intensity attributes extracted from the dw-mri with nonnegative matrix factorization (nmf). for a more robust evolution, the attributes are fused with a probabilistic shape prior and estimated spatial dependencies between prostate voxels. to preserve continuity, the adcs of the segmented prostate volume at different b-values are normalized and refined using a generalized gauss-markov random field image model. the cdfs of the refined adcs at different b-values are considered global water diffusion features and used to distinguish between benign and malignant prostates. a deep learning network of stacked non-negativity-constrained auto-encoders (sncae) is trained to classify the benign or malignant prostates on the basis of the constructed cdfs. our experiments on 53 clinical dw-mri data sets resulted in 92.3% accuracy, 83.3% sensitivity, and 100% specificity, indicating that the proposed cad system could be used as a reliable non-invasive diagnostic tool.","['diagnosing prostate cancer', 'invasive framework', 'comprehensive non']"
"physical activity is widely known to be one of the key elements of a healthy life. the many benefits of physical activity described in the medical literature include weight loss and reductions in the risk factors for chronic diseases. with the recent advances in wearable devices, such as smartwatches or physical activity wristbands, motion tracking sensors are becoming pervasive, which has led to an impressive growth in the amount of physical activity data available and an increasing interest in recognizing which specific activity a user is performing. moreover, big data and machine learning are now cross-fertilizing each other in an approach called ""deep learning"", which consists of massive artificial neural networks able to detect complicated patterns from enormous amounts of input data to learn classification models. this work compares various state-of-the-art classification techniques for automatic cross-person activity recognition under different scenarios that vary widely in how much information is available for analysis. we have incorporated deep learning by using google\'s tensorflow framework. the data used in this study were acquired from pamap2 (physical activity monitoring in the ageing population), a publicly available dataset containing physical activity data. to perform cross-person prediction, we used the leave-one-subject-out (loso) cross-validation technique. when working with large training sets, the best classifiers obtain very high average accuracies (e.g., 96% using extra randomized trees). however, when the data volume is drastically reduced (where available data are only 0.001% of the continuous data), deep neural networks performed the best, achieving 60% in overall prediction accuracy. we found that even when working with only approximately 22.67% of the full dataset, we can statistically obtain the same results as when working with the full dataset. this finding enables the design of more energy-efficient devices and facilitates cold starts and big data processing of physical activity records.","['person physical activity recognition', 'comparison study', 'classifier algorithms', 'cross']"
"micrornas (mirnas) regulate genes that are associated with various diseases. to better understand mirnas, the mirna regulatory mechanism needs to be investigated and the real targets identified. here, we present mirtdl, a new mirna target prediction algorithm based on convolutional neural network (cnn). the cnn automatically extracts essential information from the input data rather than completely relying on the input dataset generated artificially when the precise mirna target mechanisms are poorly known. in this work, the constraint relaxing method is first used to construct a balanced training dataset to avoid inaccurate predictions caused by the existing unbalanced dataset. the mirtdl is then applied to 1,606 experimentally validated mirna target pairs. finally, the results show that our mirtdl outperforms the existing target prediction algorithms and achieves significantly higher sensitivity, specificity and accuracy of 88.43, 96.44, and 89.98 percent, respectively. we also investigate the mirna target mechanism, and the results show that the complementation features are more important than the others.","['mirna target prediction', 'deep learning approach', 'mirtdl']"
"deep brain stimulation (dbs) therapy relies on both precise neurosurgical targeting and systematic optimization of stimulation settings to achieve beneficial clinical outcomes. one recent advance to improve targeting is the development of dbs arrays (dbsas) with electrodes segmented both along and around the dbs lead. however, increasing the number of independent electrodes creates the logistical challenge of optimizing stimulation parameters efficiently.","['programming deep brain stimulation arrays', 'particle swarm optimization']"
"medical education, according to the constructivist education paradigm, puts students as the protagonists of the teaching and learning process. it demands changes in the practice of teaching. however, it is unclear whether this new model is coherent with the teachers\x92 ways to cope with learning.","['health careers ].', 'teaching practices', 'learning strategies']"
"treatment of moderate to severe slipped capital femoral epiphysis (scfe) is controversial. over the last years, 3 institutions in argentina adopted the modified dunn procedure for capital realignment in selected cases of scfe. our aim in this study was to evaluate the clinical outcome and the rate of complications of patients who had undergone surgical hip dislocation and capital realignment.","['slipped capital femoral epiphysis', 'modified dunn procedure', 'multicenter study', 'treatment']"
"prolonged deep space missions to planets and asteroids will expose astronauts to galactic cosmic radiation (gcr), a mixture of low-let ionizing radiations, high-energy protons and high-z and energy (hze) particles. ground-based experiments are used to determine whether this radiation environment will have an effect on the long-term health of astronauts and their ability to complete various tasks during their mission. emerging data suggest that mission-relevant hze doses impair several hippocampus-dependent neurocognitive processes in rodents, but that there is substantial interindividual variation in the severity of neurocognitive impairment, ranging from no observable effects to severe impairment. while the majority of studies have established the effect that the most abundant hze species (56fe) has on neurocognition, some studies suggest that the lighter 48ti hze particles may be equally, if not more, potent at impairing neurocognition. in this study, we assessed the effect that exposure to 5-20 cgy 1 gev/n 48ti had on the spatial memory performance of socially mature male wistar rats. acute exposures to mission-relevant doses (≤5 cgy) of 1 gev/n 48ti significantly (p < 0.05) reduced the mean spatial memory performance of the rats at three months after exposure, and significantly (p < 0.015) increased the percentage of rats that have severe (z score ≥ 2) impairment, i.e., poor performers. collectively, these data further support the notion that the let dependency of neurocognitive impairment may differ from that of cell killing.","['socially mature wistar rats', 'spatial memory performance', '5 cg', 'low', 'impaired', 'exposure']"
"while deep learning has led to remarkable advances across diverse applications, it struggles in domains where the data distribution changes over the course of learning. in stark contrast, biological neural networks continually adapt to changing domains, possibly by leveraging complex molecular machinery to solve many tasks simultaneously. in this study, we introduce intelligent synapses that bring some of this biological complexity into artificial neural networks. each synapse accumulates task relevant information over time, and exploits this information to rapidly store new memories without forgetting old ones. we evaluate our approach on continual learning of classification tasks, and show that it dramatically reduces forgetting while maintaining computational efficiency.","['synaptic intelligence', 'continual learning']"
diabetic retinopathy is one of the leading disabling chronic diseases and one of the leading causes of preventable blindness in developed world. early diagnosis of diabetic retinopathy enables timely treatment and in order to achieve it a major effort will have to be invested into automated population screening programs. detection of exudates in color fundus photographs is very important for early diagnosis of diabetic retinopathy.,"['fundus photographs using deep neural networks', 'anatomical landmark detection fusion', 'detection', 'exudates']"
"semi-non-negative matrix factorization is a technique that learns a low-dimensional representation of a dataset that lends itself to a clustering interpretation. it is possible that the mapping between this new representation and our original data matrix contains rather complex hierarchical information with implicit lower-level hidden attributes, that classical one level clustering methodologies cannot interpret. in this work we propose a novel model, deep semi-nmf, that is able to learn such hidden representations that allow themselves to an interpretation of clustering according to different, unknown attributes of a given dataset. we also present a semi-supervised version of the algorithm, named deep wsf, that allows the use of (partial) prior information for each of the known attributes of a dataset, that allows the model to be used on datasets with mixed attribute knowledge. finally, we show that our models are able to learn low-dimensional representations that are better suited for clustering, but also classification, outperforming semi-non-negative matrix factorization, but also other state-of-the-art methodologies variants.","['deep matrix factorization method', 'learning attribute representations']"
"complex tissues such as brain and bone marrow are made up of multiple cell types. as the study of biological tissue structure progresses, the role of cell-type-specific research becomes increasingly important. novel sequencing technology such as single-cell cytometry provides researchers access to valuable biological data. applying machine-learning techniques to these high-throughput datasets provides deep insights into the cellular landscape of the tissue where those cells are a part of. in this paper, we propose the use of random-forest-based single-cell profiling, a new machine-learning-based technique, to profile different cell types of intricate tissues using single-cell cytometry data. our technique utilizes random forests to capture cell marker dependences and model the cellular populations using the cell network concept. this cellular network helps us discover what cell types are in the tissue. our experimental results on public-domain datasets indicate promising performance and accuracy of our technique in extracting cell populations of complex tissues.","['cell expression data using random forest graphs', 'clustering single']"
"we present a novel and practical deep fully convolutional neural network architecture for semantic pixel-wise segmentation termed segnet. this core trainable segmentation engine consists of an encoder network, a corresponding decoder network followed by a pixel-wise classification layer. the architecture of the encoder network is topologically identical to the 13 convolutional layers in the vgg16 network [","['low resolution encoder feature maps', 'full input resolution feature maps', 'lower resolution input feature map', 'wise classification', 'segnet lies', 'decoder upsamples', 'decoder network', 'map', 'role', 'pixel', 'novelty', 'manner']"
"conventional metric learning methods usually assume that the training and test samples are captured in similar scenarios so that their distributions are assumed to be the same. this assumption does not hold in many real visual recognition applications, especially when samples are captured across different data sets. in this paper, we propose a new deep transfer metric learning (dtml) method to learn a set of hierarchical nonlinear transformations for cross-domain visual recognition by transferring discriminative knowledge from the labeled source domain to the unlabeled target domain. specifically, our dtml learns a deep metric network by maximizing the inter-class variations and minimizing the intra-class variations, and minimizing the distribution divergence between the source domain and the target domain at the top layer of the network. to better exploit the discriminative information from the source domain, we further develop a deeply supervised transfer metric learning (dstml) method by including an additional objective on dtml, where the output of both the hidden layers and the top layer are optimized jointly. to preserve the local manifold of input data points in the metric space, we present two new methods, dtml with autoencoder regularization and dstml with autoencoder regularization. experimental results on face verification, person re-identification, and handwritten digit recognition validate the effectiveness of the proposed methods.",['deep transfer metric learning']
"heart failure with preserved ejection fraction (hfpef) is a heterogeneous clinical syndrome that may benefit from improved subtyping in order to better characterize its pathophysiology and to develop novel targeted therapies. the united states precision medicine initiative comes amid the rapid growth in quantity and modality of clinical data for hfpef patients ranging from deep phenotypic to trans-omic data. tensor factorization, a form of machine learning, allows for the integration of multiple data modalities to derive clinically relevant hfpef subtypes that may have significant differences in underlying pathophysiology and differential response to therapies. tensor factorization also allows for better interpretability by supporting dimensionality reduction and identifying latent groups of data for meaningful summarization of both features and disease outcomes. in this narrative review, we analyze the modest literature on the application of tensor factorization to related biomedical fields including genotyping and phenotyping. based on the cited work including work of our own, we suggest multiple tensor factorization formulations capable of integrating the deep phenotypic and trans-omic modalities of data for hfpef, or accounting for interactions between genetic variants at different omic hierarchies. we encourage extensive experimental studies to tackle challenges in applying tensor factorization for precision medicine in hfpef, including effectively incorporating existing medical knowledge, properly accounting for uncertainty, and efficiently enforcing sparsity for better interpretability.","['preserved ejection fraction', 'tensor factorization', 'precision medicine', 'heart failure']"
"although hippocampal ca1 pyramidal neurons (pns) were thought to comprise a uniform population, recent evidence supports two distinct sublayers along the radial axis, with deep neurons more likely to form place cells than superficial neurons. ca1 pns also differ along the transverse axis with regard to direct inputs from entorhinal cortex (ec), with medial ec (mec) providing spatial information to pns toward ca2 (proximal ca1) and lateral ec (lec) providing non-spatial information to pns toward subiculum (distal ca1). we demonstrate that the two inputs differentially activate the radial sublayers and that this difference reverses along the transverse axis, with mec preferentially targeting deep pns in proximal ca1 and lec preferentially exciting superficial pns in distal ca1. this differential excitation reflects differences in dendritic spine numbers. our results reveal a heterogeneity in ec-ca1 connectivity that may help explain differential roles of ca1 pns in spatial and non-spatial learning and memory.","['lateral entorhinal cortex differentially excite deep versus superficial ca1 pyramidal neurons', 'medial']"
"inspired by the popular deep learning architecture, deep stacking network (dsn), a specific deep model for polarimetric synthetic aperture radar (polsar) image classification is proposed in this paper, which is named wishart dsn (w-dsn). first of all, a fast implementation of wishart distance is achieved by a special linear transformation, which speeds up the classification of polsar image and makes it possible to use this polarimetric information in the following neural network (nn). then, a single-hidden-layer nn based on the fast wishart distance is defined for polsar image classification, which is named wishart network (wn) and improves the classification accuracy. finally, a multi-layer nn is formed by stacking wns, which is in fact the proposed deep learning architecture w-dsn for polsar image classification and improves the classification accuracy further. in addition, the structure of wn can be expanded in a straightforward way by adding hidden units if necessary, as well as the structure of the w-dsn. as a preliminary exploration on formulating specific deep learning architecture for polsar image classification, the proposed methods may establish a simple but clever connection between polsar image interpretation and deep learning. the experiment results tested on real polsar image show that the fast implementation of wishart distance is very efficient (a polsar image with 768 000 pixels can be classified in 0.53 s), and both the single-hidden-layer architecture wn and the deep learning architecture w-dsn for polsar image classification perform well and work efficiently.","['wishart deep stacking network', 'fast polsar image classification']"
"this review aims at providing a practical overview of the use of statistical features and associated data science methods in bioimage informatics. to achieve a quantitative link between images and biological concepts, one typically replaces an object coming from an image (a segmented cell or intracellular object, a pattern of expression or localisation, even a whole image) by a vector of numbers. they range from carefully crafted biologically relevant measurements to features learnt through deep neural networks. this replacement allows for the use of practical algorithms for visualisation, comparison and inference, such as the ones from machine learning or multivariate statistics. while originating mainly, for biology, in high content screening, those methods are integral to the use of data science for the quantitative analysis of microscopy images to gain biological insight, and they are sure to gather more interest as the need to make sense of the increasing amount of acquired imaging data grows more pressing.","['data science uses', 'bioimage informatics', 'overview']"
"assessing the response of bladder cancer to neoadjuvant chemotherapy is crucial for reducing morbidity and increasing quality of life of patients. changes in tumor volume during treatment is generally used to predict treatment outcome. we are developing a method for bladder cancer segmentation in ct using a pilot data set of 62 cases. 65 000 regions of interests were extracted from pre-treatment ct images to train a deep-learning convolution neural network (dl-cnn) for tumor boundary detection using leave-one-case-out cross-validation. the results were compared to our previous ai-cals method. for all lesions in the data set, the longest diameter and its perpendicular were measured by two radiologists, and 3d manual segmentation was obtained from one radiologist. the world health organization (who) criteria and the response evaluation criteria in solid tumors (recist) were calculated, and the prediction accuracy of complete response to chemotherapy was estimated by the area under the receiver operating characteristic curve (auc). the aucs were 0.73 ± 0.06, 0.70 ± 0.07, and 0.70 ± 0.06, respectively, for the volume change calculated using dl-cnn segmentation, the ai-cals and the manual contours. the differences did not achieve statistical significance. the aucs using the who criteria were 0.63 ± 0.07 and 0.61 ± 0.06, while the aucs using recist were 0.65 ± 007 and 0.63 ± 0.06 for the two radiologists, respectively. our results indicate that dl-cnn can produce accurate bladder cancer segmentation for calculation of tumor size change in response to treatment. the volume change performed better than the estimations from the who criteria and recist for the prediction of complete response.","['learning convolution neural network', 'treatment response assessment', 'bladder cancer segmentation', 'pilot study', 'deep', 'ct', 'application']"
"we present a ""deep"" network architecture for chemical data analysis and classification together with a prospective proof-of-concept application. the model features a self-organizing map (som) as the input layer of a feedforward neural network. the som converts molecular descriptors to a two-dimensional image for further processing. we implemented lateral neuron inhibition for contrast enhancement. the model achieved improved classification accuracy and predictive robustness compared to feedforward network classifiers lacking the som layer. by nonlinear dimensionality reduction the networks extracted meaningful chemical features from the data and outperformed linear principal component analysis (pca). the learning machine was trained on the sequence-length independent recognition of antibacterial peptides and correctly predicted the killing activity of a synthetic test peptide against staphylococcus aureus in an in vitro experiment.","['hybrid network model', 'deep learning', 'chemical data', 'antimicrobial peptides', 'application']"
"we present a study on lung squamous cell carcinoma diagnosis using quantitative ti-dic microscopy and a deep convolutional neural network (dcnn). the 2-d phase map of unstained tissue sections is first retrieved from through-focus differential interference contrast (dic) images based on the transport of intensity equation (tie). the spatially resolved optical properties are then computed from the 2-d phase map via the scattering-phase theorem. the scattering coefficient ( μ s  ) and the reduced scattering coefficient ( μ s '  ) are found to increase whereas the anisotropy factor (g) is found to decrease with cancer. a dcnn classifier is developed afterwards to classify the tissue using either the dic images or 2-d optical property maps of μ s  , μ s '  and g. the dcnn classifier with the optical property maps exhibits high accuracy, significantly outperforming the same dcnn classifier on the dic images. the label-free quantitative phase microscopy together with deep learning may emerge as a promising approach for in situ rapid cancer diagnosis.","['deep convolutional neural network', 'quantitative dic microscopy', 'lung cancer diagnosis']"
"the pistons of sparse aperture systems need to be controlled within a fraction of a wavelength for the system's optimal imaging performance. in this paper, we demonstrate that deep learning is capable of performing piston sensing with a single wide-band image after appropriate training. taking the sensing issue as a fitting task, the deep learning-based method utilizes a deep convolutional neural network to learn complex input-output mapping relations between the broadband intensity distributions and corresponding piston values. given a trained network and one broadband focal intensity image as the input, the piston can be obtained directly and the capture range achieving the coherence length of the broadband light is available. simulations and experiments demonstrate the validity of the proposed method. using only in-focused broadband images as the inputs without defocus division and wavelength dispersion, obviously relaxes the optics complexity. in view of the efficiency and superiority, it's expected that the method proposed in this paper may be widely applied in multi-aperture imaging.","['single broadband image via deep learning', 'sparse aperture systems', 'piston sensing']"
"microsatellite instability determines whether patients with gastrointestinal cancer respond exceptionally well to immunotherapy. however, in clinical practice, not every patient is tested for msi, because this requires additional genetic or immunohistochemical tests. here we show that deep residual learning can predict msi directly from h&e histology, which is ubiquitously available. this approach has the potential to provide immunotherapy to a much broader subset of patients with gastrointestinal cancer.","['predict microsatellite instability directly', 'gastrointestinal cancer', 'deep learning', 'histology']"
"practical nurses have experienced an increasing scope of practice, including an expectation to care for complex patients and function on interdisciplinary teams. little is known about the degree to which patient safety principles are addressed in practical nursing education.","['newly registered practical nurses', 'practical nurses', 'sectional survey', 'patient safety', 'education', 'cross', 'canada']"
"direct electrical stimulation applied to the human medial temporal lobe (mtl) typically disrupts performance on memory tasks, however, the mechanism underlying this effect is not known.","['recall selectively enhances forgetting', 'human medial temporal lobe', 'stimulation', 'learning']"
"maintaining wild places increasingly involves intensive human interventions. several recent projects use semi-automated mediating technologies to enact conservation and restoration actions, including re-seeding and invasive species eradication. could a deep-learning system sustain the autonomy of nonhuman ecological processes at designated sites without direct human interventions? we explore here the prospects for automated curation of wild places, as well as the technical and ethical questions that such co-creation poses for ecologists, conservationists, and designers. our goal is to foster innovative approaches to creating and maintaining the autonomy of evolving ecological systems.","['new wildness', 'designing autonomy', 'opportunities', 'anthropocene']"
"robotic-assisted minimally invasive surgeries have gained a lot of popularity over conventional procedures as they offer many benefits to both surgeons and patients. nonetheless, they still suffer from some limitations that affect their outcome. one of them is the lack of force feedback which restricts the surgeon's sense of touch and might reduce precision during a procedure. to overcome this limitation, we propose a novel force estimation approach that combines a vision based solution with supervised learning to estimate the applied force and provide the surgeon with a suitable representation of it. the proposed solution starts with extracting the geometry of motion of the heart's surface by minimizing an energy functional to recover its 3d deformable structure. a deep network, based on a lstm-rnn architecture, is then used to learn the relationship between the extracted visual-geometric information and the applied force, and to find accurate mapping between the two. our proposed force estimation solution avoids the drawbacks usually associated with force sensing devices, such as biocompatibility and integration issues. we evaluate our approach on phantom and realistic tissues in which we report an average root-mean square error of 0.02 n.","['towards retrieving force feedback', 'vision approach', 'supervised neuro', 'assisted surgery', 'robotic', 'recurrent']"
"thanks to the recent advances in structural biology, nowadays 3d structures of various proteins are solved on a routine basis. a large portion of these structures contain structural repetitions or internal symmetries. to understand the evolution mechanisms of these proteins and how structural repetitions affect the protein function, we need to be able to detect such proteins very robustly. as deep learning is particularly suited to deal with spatially organized data, we applied it to the detection of proteins with structural repetitions.","['using 3d convolutional networks', 'tandem repeats', 'protein structures', 'internal symmetries', 'identification', 'deepsymmetry']"
"automatic segmentation of the prostate on ct images has many applications in prostate cancer diagnosis and therapy. however, prostate ct image segmentation is challenging because of the low contrast of soft tissue on ct images. in this paper, we propose an automatic segmentation method by combining a deep learning method and multi-atlas refinement. first, instead of segmenting the whole image, we extract the region of interesting (roi) to delete irrelevant regions. then, we use the convolutional neural networks (cnn) to learn the deep features for distinguishing the prostate pixels from the non-prostate pixels in order to obtain the preliminary segmentation results. cnn can automatically learn the deep features adapting to the data, which are different from some handcrafted features. finally, we select some similar atlases to refine the initial segmentation results. the proposed method has been evaluated on a dataset of 92 prostate ct images. experimental results show that our method achieved a dice similarity coefficient of 86.80% as compared to the manual segmentation. the deep learning based method can provide a useful tool for automatic segmentation of the prostate on ct images and thus can have a variety of clinical applications.","['ct images using deep learning', 'automatic segmentation', 'atlas fusion', 'prostate', 'multi']"
"under complex scattering conditions, it is very difficult to capture clear object images hidden behind the media by modelling the inverse problem. with regard to dynamic scattering media, the challenge increases. for solving the inverse problem, we propose a new class-specific image reconstruction algorithm. the method based on deep learning classifies blurred scattering images according to scattering conditions and then recovers to clear images hidden behind the media. the deep learning network is used to learn the mapping relationship between the object and the scattering image rather than characterizing the scattering media explicitly or parametrically. 25000 scattering images are obtained under five sets of dynamic scattering condition to verify the feasibility of the proposed method. in addition, the generalizability of the method has been verified successfully. compared with common cnn method, it's confirmed that our algorithm has better performance in reconstructing higher-quality images. furthermore, for a given scattering image with unknown scattering condition, the closest scattering condition information can be given by classification network, and then the corresponding clear image is restored by reconstruction network.","['dynamic scattering media based', 'image reconstruction', 'deep learning']"
"the gap between the computational and semantic features is the one of major factors that bottlenecks the computer-aided diagnosis (cad) performance from clinical usage. to bridge this gap, we exploit three multi-task learning (mtl) schemes to leverage heterogeneous computational features derived from deep learning models of stacked denoising autoencoder (sdae) and convolutional neural network (cnn), as well as hand-crafted haar-like and hog features, for the description of 9 semantic features for lung nodules in ct images. we regard that there may exist relations among the semantic features of ""spiculation"", ""texture"", ""margin"", etc., that can be explored with the mtl. the lung image database consortium (lidc) data is adopted in this study for the rich annotation resources. the lidc nodules were quantitatively scored w.r.t. 9 semantic features from 12 radiologists of several institutes in u.s.a. by treating each semantic feature as an individual task, the mtl schemes select and map the heterogeneous computational features toward the radiologists\' ratings with cross validation evaluation schemes on the randomly selected 2400 nodules from the lidc dataset. the experimental results suggest that the predicted semantic scores from the three mtl schemes are closer to the radiologists\' ratings than the scores from single-task lasso and elastic net regression methods. the proposed semantic attribute scoring scheme may provide richer quantitative assessments of nodules for better support of diagnostic decision and management. meanwhile, the capability of the automatic association of medical image contents with the clinical semantic terms by our method may also assist the development of medical search engine.","['task feature leverage', 'multiple semantic attributes', 'pulmonary nodules', 'ct images', 'automatic scoring', 'study', 'multi']"
"the accurate diagnosis of alzheimer's disease (ad) and its early stage, i.e., mild cognitive impairment, is essential for timely treatment and possible delay of ad. fusion of multimodal neuroimaging data, such as magnetic resonance imaging (mri) and positron emission tomography (pet), has shown its effectiveness for ad diagnosis. the deep polynomial networks (dpn) is a recently proposed deep learning algorithm, which performs well on both large-scale and small-size datasets. in this study, a multimodal stacked dpn (mm-sdpn) algorithm, which mm-sdpn consists of two-stage sdpns, is proposed to fuse and learn feature representation from multimodal neuroimaging data for ad diagnosis. specifically speaking, two sdpns are first used to learn high-level features of mri and pet, respectively, which are then fed to another sdpn to fuse multimodal neuroimaging information. the proposed mm-sdpn algorithm is applied to the adni dataset to conduct both binary classification and multiclass classification tasks. experimental results indicate that mm-sdpn is superior over the state-of-the-art multimodal feature-learning-based algorithms for ad diagnosis.","['multimodal stacked deep polynomial networks', 'multimodal neuroimaging feature learning', 'disease', 'diagnosis', 'alzheimer']"
"quantitative cephalometry plays an essential role in clinical diagnosis, treatment, and surgery. development of fully automated techniques for these procedures is important to enable consistently accurate computerized analyses. we study the application of deep convolutional neural networks (cnns) for fully automated quantitative cephalometry for the first time. the proposed framework utilizes cnns for detection of landmarks that describe the anatomy of the depicted patient and yield quantitative estimation of pathologies in the jaws and skull base regions. we use a publicly available cephalometric x-ray image dataset to train cnns for recognition of landmark appearance patterns. cnns are trained to output probabilistic estimations of different landmark locations, which are combined using a shape-based model. we evaluate the overall framework on the test set and compare with other proposed techniques. we use the estimated landmark locations to assess anatomically relevant measurements and classify them into different anatomical types. overall, our results demonstrate high anatomical landmark detection accuracy ([formula: see tex","['higher success detection rate', 'mm range compared', 'top benchmarks', 'literatur', '2']"
"deep learning has received significant attention recently as a promising solution to many problems in the area of artificial intelligence. among several deep learning architectures, convolutional neural networks (cnns) demonstrate superior performance when compared to other machine learning methods in the applications of object detection and recognition. we use a cnn for image enhancement and the detection of driving lanes on motorways. in general, the process of lane detection consists of edge extraction and line detection. a cnn can be used to enhance the input images before lane detection by excluding noise and obstacles that are irrelevant to the edge detection result. however, training conventional cnns requires considerable computation and a big dataset. therefore, we suggest a new learning algorithm for cnns using an extreme learning machine (elm). the elm is a fast learning method used to calculate network weights between output and hidden layers in a single iteration and thus, can dramatically reduce learning time while producing accurate results with minimal training data. a conventional elm can be applied to networks with a single hidden layer; as such, we propose a stacked elm architecture in the cnn framework. further, we modify the backpropagation algorithm to find the targets of hidden layers and effectively learn network weights while maintaining performance. experimental results confirm that the proposed method is effective in reducing learning time and improving performance.","['convolutional neural networks using extreme learning machine', 'fast learning method', 'lane detection', 'application']"
"artificial intelligence (ai) has gained major attention with a rapid increase in the number of published articles, mostly recently. this review provides a general understanding of how ai can or will be useful to the musculoskeletal radiologist. after a brief technical background on ai, machine learning, and deep learning, we illustrate, through examples from the musculoskeletal literature, potential ai applications in the various steps of the radiologist's workflow, from managing the request to communication of results. the implementation of ai solutions does not go without challenges and limitations. these are also discussed, as well as the trends and perspectives.","['musculoskeletal imaging', 'current literature', 'artificial intelligence', 'trends', 'review', 'challenges']"
"the body constitution is much related to the diseases and the corresponding treatment programs in traditional chinese medicine. it can be recognized by the tongue image diagnosis, so that it is essentially regarded as a problem of tongue image classification, where each tongue image is classified into one of nine constitution types. this paper first presents a system framework to automatically identify the constitution through natural tongue images, where deep convolutional neural networks are carefully designed for tongue coating detection, tongue coating calibration, and constitution recognition. under the system framework, a novel complexity perception (cp) classification method is proposed to nicely perform the constitution recognition, which can better deal with the bad influence of the variation of environmental condition and the uneven distribution of the tongue images on constitution recognition performance. cp performs the constitution recognition based on the complexity of individual tongue images by selecting the classifier with the corresponding complexity. to evaluate the performance of the proposed method, experiments are conducted on three sizes of clinic tongue images from hospitals. the experimental results illustrate that cp is effective to improve the accuracy of body constitution recognition.","['complexity perception classification method', 'tongue constitution recognition']"
"protein secondary structure prediction began in 1951 when pauling and corey predicted helical and sheet conformations for protein polypeptide backbone even before the first protein structure was determined. sixty-five years later, powerful new methods breathe new life into this field. the highest three-state accuracy without relying on structure templates is now at 82-84%, a number unthinkable just a few years ago. these improvements came from increasingly larger databases of protein sequences and structures for training, the use of template secondary structure information and more powerful deep learning techniques. as we are approaching to the theoretical limit of three-state prediction (88-90%), alternative to secondary structure prediction (prediction of backbone torsion angles and cα-atom-based angles and torsion angles) not only has more room for further improvement but also allows direct prediction of three-dimensional fragment structures with constantly improved accuracy. about 20% of all 40-residue fragments in a database of 1199 non-redundant proteins have <6\xa0å root-mean-squared distance from the native conformations by spider2. more powerful deep learning methods with improved capability of capturing long-range interactions begin to emerge as the next generation of techniques for secondary structure prediction. the time has come to finish off the final stretch of the long march towards protein secondary structure prediction.","['protein secondary structure prediction', 'long march', 'five years', 'final stretch', 'sixty']"
"given its importance, fault diagnosis has attracted considerable attention in the literature, and several machine learning methods have been proposed to discover the characteristics of different aspects in fault diagnosis. in this paper, we propose a hybrid deep belief network (hdbn) learning model that integrates data in different ways for intelligent fault diagnosis in motor drive systems, such as a vehicle drive system. in particular, we propose three data fusion methods: data union, data join, and data hybrid, based on detailed data fusion research. additionally, the significance of the fusion is explained from the energy perspective of the signal. in particular, the appropriate fusion methods and data structures suitable for model training requirements can help improve the accuracy of fault diagnosis. moreover, mixed-precision training is used as a special fusion method to further improve the performance of the model. experiments with the datasets obtained from the simulation platform demonstrate the superiority of our proposed model over the state-of-the-art methods.","['hybrid data fusion dbn', 'intelligent fault diagnosis', 'vehicle reducers']"
"extracting the high-level feature representation by using deep neural networks for detection of prostate cancer, and then based on high-level feature representation constructing hierarchical classification to refine the detection results.","['based prostate cancer detection', 'level representation', 'hierarchical classification', 'mri', 'high']"
"the semiconductor industry is currently challenged by the emergence of internet of things, big data, and deep-learning techniques to enable object recognition and inference in portable computers. these revolutions demand new technologies for memory and computation going beyond the standard cmos-based platform. in this scenario, resistive switching memory (rram) is extremely promising in the frame of storage technology, memory devices, and in-memory computing circuits, such as memristive logic or neuromorphic machines. to serve as enabling technology for these new fields, however, there is still a lack of industrial tools to predict the device behavior under certain operation schemes and to allow for optimization of the device properties based on materials and stack engineering. this work provides an overview of modeling approaches for rram simulation, at the level of technology computer aided design and high-level compact models for circuit simulations. finite element method modeling, kinetic monte carlo models, and physics-based analytical models will be reviewed. the adaptation of modeling schemes to various rram concepts, such as filamentary switching and interface switching, will be discussed. finally, application cases of compact modeling to simulate simple rram circuits for computing will be shown.","['resistive switching devices', 'based modeling approaches', 'memory computing applications', 'memory', 'physics']"
"coronary artery disease is a major cause of death in women. breast arterial calcifications (bacs), detected inmammograms, can be useful riskmarkers associated with the disease. we investigate the feasibility of automated and accurate detection ofbacsinmammograms for risk assessment of coronary artery disease. we develop a 12-layer convolutional neural network to discriminate bac from non-bac and apply a pixelwise, patch-based procedure for bac detection. to assess the performance of the system, we conduct a reader study to provide ground-truth information using the consensus of human expert radiologists. we evaluate the performance using a set of 840 full-field digital mammograms from 210 cases, using both free-responsereceiveroperatingcharacteristic (froc) analysis and calcium mass quantification analysis. the froc analysis shows that the deep learning approach achieves a level of detection similar to the human experts. the calcium mass quantification analysis shows that the inferred calcium mass is close to the ground truth, with a linear regression between them yielding a coefficient of determination of 96.24%. taken together, these results suggest that deep learning can be used effectively to develop an automated system for bac detection inmammograms to help identify and assess patients with cardiovascular risks.","['detecting cardiovascular disease', 'deep learning', 'mammograms']"
"g protein-coupled receptors (gpcrs) play a key role in many cellular signaling mechanisms, and must select among multiple coupling possibilities in a ligand-specific manner in order to carry out a myriad of functions in diverse cellular contexts. much has been learned about the molecular mechanisms of ligand-gpcr complexes from molecular dynamics (md) simulations. however, to explore ligand-specific differences in the response of a gpcr to diverse ligands, as is required to understand ligand bias and functional selectivity, necessitates creating very large amounts of data from the needed large-scale simulations. this becomes a big data problem for the high dimensionality analysis of the accumulated trajectories. here we describe a new machine learning (ml) approach to the problem that is based on transforming the analysis of gpcr function-related, ligand-specific differences encoded in the md simulation trajectories into a representation recognizable by state-of-the-art deep learning object recognition technology. we illustrate this method by applying it to recognize the pharmacological classification of ligands bound to the 5-ht2a and d2 subtypes of class-a gpcrs from the serotonin and dopamine families. the ml-based approach is shown to perform the classification task with high accuracy, and we identify the molecular determinants of the classifications in the context of gpcr structure and function. this study builds a framework for the efficient computational analysis of md big data collected for the purpose of understanding ligand-specific gpcr activity.","['specific functional mechanisms', 'machine learning approach', 'ligand', 'gpcrs', 'discovery']"
"objective. the objective of this article is to show how artificial intelligence (ai) has impacted different components of the imaging value chain thus far as well as to describe its potential future uses. conclusion. the use of ai has the potential to greatly enhance every component of the imaging value chain. from assessing the appropriateness of imaging orders to helping predict patients at risk for fracture, ai can increase the value that musculoskeletal imagers provide to their patients and to referring clinicians by improving image quality, patient centricity, imaging efficiency, and diagnostic accuracy.","['musculoskeletal imaging', 'future directions', 'current status', 'artificial intelligence']"
"measurement of stride-related, biomechanical parameters is the common rationale for objective gait impairment scoring. state-of-the-art double-integration approaches to extract these parameters from inertial sensor data are, however, limited in their clinical applicability due to the underlying assumptions. to overcome this, we present a method to translate the abstract information provided by wearable sensors to context-related expert features based on deep convolutional neural networks. regarding mobile gait analysis, this enables integration-free and data-driven extraction of a set of eight spatio-temporal stride parameters. to this end, two modeling approaches are compared: a combined network estimating all parameters of interest and an ensemble approach that spawns less complex networks for each parameter individually. the ensemble approach is outperforming the combined modeling in the current application. on a clinically relevant and publicly available benchmark dataset, we estimate stride length, width and medio-lateral change in foot angle up to -0.15 ± 6.09 cm, -0.09 ± 4.22 cm and 0.13 ± 3.78° respectively. stride, swing and stance time as well as heel and toe contact times are estimated up to ±0.07, ±0.05, ±0.07, ±0.07 and ±0.12 s respectively. this is comparable to and in parts outperforming or defining state of the art. our results further indicate that the proposed change in the methodology could substitute assumption-driven double-integration methods and enable mobile assessment of spatio-temporal stride parameters in clinically critical situations as, e.g., in the case of spastic gait impairments.","['deep convolutional neural networks', 'based gait parameter extraction', 'sensor']"
"this article about competence and patient safety in anaesthesia was inspired by a statement in the 2015 aagbi guidelines on monitoring during anaesthesia: 'the presence of an appropriately trained and experienced anaesthetist is important for patient safety during anaesthesia'. the review starts with a structured description of competence, presenting five dimensions of it; the first two dimensions are identical with the two classical attributes of competence, practical skills and theoretical knowledge. concerning skills, the value of aiming for a high level of proficiency early in a traning programme is pointed out, and deliberate practice is given as an example of a pedagogical model where aiming for excellence is a core idea. for theoretical knowledge, the value of a deep approach to learning physiology and basic sciences is stressed. the third dimension (anaesthetists' non-technical skills), represents skills necessary for good team-work in the operating theatre. the two last dimensions of competence are the understanding of work and intuitive expert knowing. understanding work means being aware of what the work is about, appreciating the different aspects of the anaesthetist's job. intuitive expert knowing, lastly, concerns the tacit dimension of knowledge and skills, which enables professional experts to quickly find a working solution for most clinical problems. the final part of the review is about the 'when' and 'how' of competence assessment. the main message is the importance of assessing the competence of clinically active anaesthetists regularly during their whole career.","['professional competence', 'patient safety', 'operating theatre', 'monitoring', 'anaesthetist']"
"deep learning has been successfully introduced for 2d-image denoising, but it is still unsatisfactory for hyperspectral image (hsi) denosing due to the unacceptable computational complexity of the end-to-end training process and the difficulty of building a universal 3d-image training dataset. in this paper, instead of developing an end-to-end deep learning denoising network, we propose a hyperspectral image denoising framework for the removal of mixed gaussian impulse noise, in which the denoising problem is modeled as a convolutional neural network (cnn) constrained non-negative matrix factorization problem. using the proximal alternating linearized minimization, the optimization can be divided into three steps: the update of the spectral matrix, the update of the abundance matrix and the estimation of the sparse noise. then, we design the cnn architecture and proposed two training schemes, which can allow the cnn to be trained with a 2d-image dataset. compared with the state-of-the-art denoising methods, the proposed method has relatively good performance on the removal of the gaussian and mixed gaussian impulse noises. more importantly, the proposed model can be only trained once by a 2d-image dataset, but can be used to denoise hsis with different numbers of channel bands.","['hyperspectral image denoising via matrix factorization', 'deep prior regularization']"
"early detection of sleep arousal in polysomnographic (psg) signals is crucial for monitoring or diagnosing sleep disorders and reducing the risk of further complications, including heart disease and blood pressure fluctuations.","['sleep arousals', 'lstm networks', 'hybrid scattering', 'automated detection']"
"background how measures of long-term exposure to elevated blood pressure might add to the performance of ""current"" blood pressure in predicting future cardiovascular disease is unclear. we compared incident cardiovascular disease risk prediction using past, current, and usual systolic blood pressure alone or in combination. methods and results using data from uk primary care linked electronic health records, we applied a landmark cohort study design and identified 80\xa0964 people, aged 50 years (derivation cohort=64\xa0772; validation cohort=16\xa0192), who, at study entry, had recorded blood pressure, no prior cardiovascular disease, and no previous antihypertensive or lipid-lowering prescriptions. we used systolic blood pressure recorded up to 10\xa0years before baseline to estimate past systolic blood pressure (mean, time-weighted mean, and variability) and usual systolic blood pressure (correcting current values for past time-dependent blood pressure fluctuations) and examined their prospective relation with incident cardiovascular disease (first hospitalization for or death from coronary heart disease or stroke/transient ischemic attack). we used cox regression to estimate hazard ratios and applied bayesian analysis within a machine learning framework in model development and validation. predictive performance of models was assessed using discrimination (area under the receiver operating characteristic curve) and calibration metrics. we found that elevated past, current, and usual systolic blood pressure values were separately and independently associated with increased incident cardiovascular disease risk. when used alone, the hazard ratio (95% credible interval) per 20-mm\xa0hg increase in current systolic blood pressure was 1.22 (1.18-1.30), but associations were stronger for past systolic blood pressure (mean and time-weighted mean) and usual systolic blood pressure (hazard ratio ranging from 1.39-1.45). the area under the receiver operating characteristic curve for a model that included current systolic blood pressure, sex, smoking, deprivation, diabetes mellitus, and lipid profile was 0.747 (95% credible interval, 0.722-0.811). the addition of past systolic blood pressure mean, time-weighted mean, or variability to this model increased the area under the receiver operating characteristic curve (95% credible interval) to 0.750 (0.727-0.811), 0.750 (0.726-0.811), and 0.748 (0.723-0.811), respectively, with all models showing good calibration. similar small improvements in area under the receiver operating characteristic curve were observed when testing models on the validation cohort, in sex-stratified analyses, or by using different landmark ages (40 or 60\xa0years). conclusions using multiple blood pressure recordings from patients\' electronic health records showed stronger associations with incident cardiovascular disease than a single blood pressure measurement, but their addition to multivariate risk prediction models had negligible effects on model performance.","['scale routine electronic health records', 'predicting incident cardiovascular disease', 'elevated systolic blood pressure', 'term exposure', 'long', 'large', 'evidence']"
to explore the ability of the deep learning network inception-v3 to differentiate between papillary thyroid carcinomas (ptcs) and benign nodules in ultrasound images.,"['deep learning based classification', 'ultrasound images', 'thyroid nodules', 'pilot study', 'large scale']"
"background: assessment of cognitive development is essential to identify children with faltering developmental attainment and monitor the impact of interventions. a key barrier to achieving these goals is the lack of standardized, scalable tools to assess cognitive abilities. objective: this study aimed to develop a tablet-based gamified assessment of cognitive abilities of 3-year-old children which can be administered by non-specialist field workers. methods: workshops among domain experts, literature search for established and gamified paradigms of cognitive assessments and rapid review of mobile games for 3-year-old children was done to conceptualize games for this study. formative household visits (n\xa0=\xa020) informed the design and content of the games. a cross-sectional pilot study (n\xa0=\xa0100) was done to assess feasibility of the tool and check if increasing levels of difficulty and the expected variability between children were evident in game metrics. in-depth interviews (n\xa0=\xa09) were conducted with mothers of participating children to assess its acceptability. results: six cognitive domains were identified as being integral to learning - divided attention, response inhibition, reasoning, visual form perception and integration and memory. a narrative, musical soundtrack and positive reinforcement were incorporated into the tool to enhance participant engagement. child performance determined level timers and difficulty levels in each game. pilot data indicate that children differ in their performance profile on the tool as measured by the number of game levels played and their accuracy and completion time indicating that it might be possible to differentiate children based on these metrics. qualitative data suggest high levels of acceptability of the tool amongst participants. conclusions: a developmental assessment on an e-platform (deep) has been created comprising distinct games woven into a narrative, which assess six cognitive domains, and shows high levels of acceptability and generates metrics which may be used for validation against gold standard cognitive assessments.","['gamified cognitive developmental assessment', 'platform', 'feasibility', 'e', 'development', 'dee', 'acceptability']"
"lens-free holographic microscopy (lfhm) provides a cost-effective tool for large field-of-view imaging in various biomedical applications. however, due to the unit optical magnification, its spatial resolution is limited by the pixel size of the imager. pixel super-resolution (psr) technique tackles this problem by using a series of sub-pixel shifted low-resolution (lr) lens-free holograms to form the high-resolution (hr) hologram. conventional iterative psr methods require a large number of measurements and a time-consuming reconstruction process, limiting the throughput of lfhm in practice. here we report a deep learning-based psr approach to enhance the resolution of lfhm. compared with the existing psr methods, our neural network-based approach outputs the hr hologram in an end-to-end fashion and maintains consistency in resolution improvement with a reduced number of lr holograms. moreover, by exploiting the resolution degradation model in the imaging process, the network can be trained with a data set synthesized from the lr hologram itself without resorting to the hr ground truth. we validated the effectiveness and the robustness of our method by imaging various types of samples using a single network trained on an entirely different data set. this deep learning-based psr approach can significantly accelerate both the data acquisition and the hr hologram reconstruction processes, therefore providing a practical solution to fast, lens-free, super-resolution imaging.","['free holographic microscopy using deep learning neural networks', 'pixel super', 'resolution', 'lens']"
"visual assessment of the electroencephalogram by experienced clinical neurophysiologists allows reliable outcome prediction of approximately half of all comatose patients after cardiac arrest. deep neural networks hold promise to achieve similar or even better performance, being more objective and consistent.","['postanoxic coma', 'outcome prediction', 'deep learning']"
"deep learning (dl) is a family of machine learning methods that has gained considerable attention in the scientific community, breaking benchmark records in areas such as speech and visual recognition. dl differs from conventional machine learning methods by virtue of its ability to learn the optimal representation from the raw data through consecutive nonlinear transformations, achieving increasingly higher levels of abstraction and complexity. given its ability to detect abstract and complex patterns, dl has been applied in neuroimaging studies of psychiatric and neurological disorders, which are characterised by subtle and diffuse alterations. here we introduce the underlying concepts of dl and review studies that have used this approach to classify brain-based disorders. the results of these studies indicate that dl could be a powerful tool in the current search for biomarkers of psychiatric and neurologic disease. we conclude our review by discussing the main promises and challenges of using dl to elucidate brain-based disorders, as well as possible directions for future research.","['using deep learning', 'neurological disorders', 'neuroimaging correlates', 'psychiatric', 'methods', 'investigate', 'applications']"
"the use of wearable devices to study gait and postural control is a growing field on neurodegenerative disorders such as alzheimer's disease (ad). in this paper, we investigate if machine-learning classifiers offer the discriminative power for the diagnosis of ad based on postural control kinematics. we compared support vector machines (svms), multiple layer perceptrons (mlps), radial basis function neural networks (rbns), and deep belief networks (dbns) on 72 participants (36 ad patients and 36 healthy subjects) exposed to seven increasingly difficult postural tasks. the decisional space was composed of 18 kinematic variables (adjusted for age, education, height, and weight), with or without neuropsychological evaluation (montreal cognitive assessment (moca) score), top ranked in an error incremental analysis. classification results were based on threefold cross validation of 50 independent and randomized runs sets: training (50%), test (40%), and validation (10%). having a decisional space relying solely on postural kinematics, accuracy of ad diagnosis ranged from 71.7 to 86.1%. adding the moca variable, the accuracy ranged between 91 and 96.6%. mlp classifier achieved top performance in both decisional spaces. having comprehended the interdynamic interaction between postural stability and cognitive performance, our results endorse machine-learning models as a useful tool for computer-aided diagnosis of ad based on postural control kinematics.","['postural control kinematics', 'machine learning', 'disease', 'diagnosis', 'application', 'alzheimer']"
"intrusion detection systems play an important role in preventing security threats and protecting networks from attacks. however, with the emergence of unknown attacks and imbalanced samples, traditional machine learning methods suffer from lower detection rates and higher false positive rates. we propose a novel intrusion detection model that combines an improved conditional variational autoencoder (icvae) with a deep neural network (dnn), namely icvae-dnn. icvae is used to learn and explore potential sparse representations between network data features and classes. the trained icvae decoder generates new attack samples according to the specified intrusion categories to balance the training data and increase the diversity of training samples, thereby improving the detection rate of the imbalanced attacks. the trained icvae encoder is not only used to automatically reduce data dimension, but also to initialize the weight of dnn hidden layers, so that dnn can easily achieve global optimization through back propagation and fine tuning. the nsl-kdd and unsw-nb15 datasets are used to evaluate the performance of the icvae-dnn. the icvae-dnn is superior to the three well-known oversampling methods in data augmentation. moreover, the icvae-dnn outperforms six well-known models in detection performance, and is more effective in detecting minority attacks and unknown attacks. in addition, the icvae-dnn also shows better overall accuracy, detection rate and false positive rate than the nine state-of-the-art intrusion detection methods.","['using improved conditional variational autoencoder', 'deep neural network', 'intrusion detection', 'classification effectiveness', 'improving']"
"discriminative features of 3-d meshes are significant to many 3-d shape analysis tasks. however, handcrafted descriptors and traditional unsupervised 3-d feature learning methods suffer from several significant weaknesses: 1) the extensive human intervention is involved; 2) the local and global structure information of 3-d meshes cannot be preserved, which is in fact an important source of discriminability; 3) the irregular vertex topology and arbitrary resolution of 3-d meshes do not allow the direct application of the popular deep learning models; 4) the orientation is ambiguous on the mesh surface; and 5) the effect of rigid and nonrigid transformations on 3-d meshes cannot be eliminated. as a remedy, we propose a deep learning model with a novel irregular model structure, called mesh convolutional restricted boltzmann machines (mcrbms). mcrbm aims to simultaneously learn structure-preserving local and global features from a novel raw representation, local function energy distribution. in addition, multiple mcrbms can be stacked into a deeper model, called mesh convolutional deep belief networks (mcdbns). mcdbn employs a novel local structure preserving convolution (lspc) strategy to convolve the geometry and the local structure learned by the lower mcrbm to the upper mcrbm. lspc facilitates resolving the challenging issue of the orientation ambiguity on the mesh surface in mcdbn. experiments using the proposed mcrbm and mcdbn were conducted on three common aspects: global shape retrieval, partial shape retrieval, and shape correspondence. results show that the features learned by the proposed methods outperform the other state-of-the-art 3-d shape features.","['mesh convolutional restricted boltzmann machines', 'unsupervised learning', 'structure preservation', 'meshes', 'features', '3']"
"numerous animal species emit vocalizations in response to various social stimuli. the neural basis of vocal communication has been investigated in monkeys, songbirds, rats, bats, and invertebrates resulting in deep insights into motor control, neural coding, and learning. mice, which recently became very popular as a model system for mammalian neuroscience, also utilize ultrasonic vocalizations (usvs) during mating behavior. however, our knowledge is lacking of both the behavior and its underlying neural mechanism. we developed a novel method for head-restrained male mice (hrmm) to interact with non-restrained female mice (nrfm) and show that mice can emit usvs in this context. we first recorded usvs in a free arena with non-restrained male mice (nrmm) and nrfm. of the nrmm, which vocalized in the free arena, the majority could be habituated to also vocalize while head-restrained but only when a female mouse was present in proximity. the usvs emitted by hrmm are similar to the usvs of nrmm in the presence of a female mouse in their spectral structure, inter-syllable interval distribution, and usv sequence length, and therefore are interpreted as social usvs. by analyzing the vocalizations of nrmm, we established criteria to predict which individuals are likely to vocalize while head fixed based on the usv rate and average syllable duration. to characterize the usvs emitted by hrmm, we analyzed the syllable composition of hrmm and nrmm and found that usvs emitted by hrmm have a higher proportion of usvs with complex spectral representation, supporting previous studies showing that mice social usvs are context dependent. our results suggest a way to study the neural mechanisms of production and control of social vocalization in mice using advanced methods requiring head fixation.","['social ultrasonic vocalization', 'restrained mouse', 'awake head']"
"despite the fact that deep learning has achieved remarkable success in various domains over the past decade, its application in molecular informatics and drug discovery is still limited. recent advances in adapting deep architectures to structured data have opened a new paradigm for pharmaceutical research. in this survey, we provide a systematic review on the emerging field of graph convolutional networks and their applications in drug discovery and molecular informatics. typically we are interested in why and how graph convolution networks can help in drug-related tasks. we elaborate the existing applications through four perspectives: molecular property and activity prediction, interaction prediction, synthesis prediction and de novo drug design. we briefly introduce the theoretical foundations behind graph convolutional networks and illustrate various architectures based on different formulations. then we summarize the representative applications in drug-related problems. we also discuss the current challenges and future possibilities of applying graph convolutional networks to drug discovery.","['graph convolutional networks', 'computational drug development', 'discovery']"
"accurately recognizing different categories of sceneries with sophisticated spatial configurations is a useful technique in computer vision and intelligent systems, e.g., scene understanding and autonomous driving. competitive accuracies have been observed by the deep recognition models recently. nevertheless, these deep architectures cannot explicitly characterize human visual perception, that is, the sequence of gaze allocation and the subsequent cognitive processes when viewing each scenery. in this paper, a novel spatially aware aggregation network is proposed for scene categorization, where the human gaze behavior is discovered in a semisupervised setting. in particular, as semantically labeling a large quantity of scene images is labor-intensive, a semisupervised and structure-preserved non-negative matrix factorization (nmf) is proposed to detect a set of visually/semantically salient regions from each scenery. afterward, the gaze shifting path (gsp) is engineered to characterize the process of humans perceiving each scene picture. to deeply describe each gsp, a novel spatially aware cnn termed sa-net is developed. it accepts input regions with various shapes and statistically aggregates all the salient regions along each gsp. finally, the learned deep gsp features from the entire scene images are fused into an image kernel, which is subsequently integrated into a kernel svm to categorize different sceneries. comparative experiments on six scene image sets have shown the advantage of our method.","['deeply learning gaze behavior', 'semisupervised context', 'scene categorization']"
we applied deep convolutional neural networks (cnns) to detect apical lesions (als) on panoramic dental radiographs.,"['radiographic detection', 'deep learning', 'apical lesions']"
the aim of this study was to determine whether machine learning could reduce the number of mammograms the radiologist must read by using a machine-learning classifier to correctly identify normal mammograms and to select the uncertain and abnormal examinations for radiological interpretation.,"['mammography using machine learning', 'improving workflow efficiency']"
"the pamono-sensor (plasmon assisted microscopy of nano-objects) demonstrated an ability to detect and quantify individual viruses and virus-like particles. however, another group of biological vesicles-microvesicles (100-1000 nm)-also attracts growing interest as biomarkers of different pathologies and needs development of novel techniques for characterization. this work shows the applicability of a pamono-sensor for selective detection of microvesicles in aquatic samples. the sensor permits comparison of relative concentrations of microvesicles between samples. we also study a possibility of repeated use of a sensor chip after elution of the microvesicle capturing layer. moreover, we improve the detection features of the pamono-sensor. the detection process utilizes novel machine learning techniques on the sensor image data to estimate particle size distributions of nano-particles in polydisperse samples. altogether, our ﬁndings expand analytical features and the application ﬁeld of the pamono-sensor. they can also serve for a maturation of diagnostic tools based on the pamono-sensor platform.","['particle size distribution', 'sensor', 'quantiﬁcation', 'pamono', 'nano', 'microvesicles', 'determination', 'application']"
"alzheimer's disease is a neuropsychiatric, progressive, also an irreversible disease. there is not an effective cure for the disease. however, early diagnosis has an important role for treatment planning to delay its progression since the treatments have the most impact at the early stage of the disease. neuroimages obtained by different imaging techniques (for example, diffusion tensor-based and magnetic resonance-based imaging) provide powerful information and help to diagnose the disease. in this work, a deeply supervised and robust method has been developed using three dimensional features to provide objective and accurate diagnosis from magnetic resonance images. the main contributions are (a) a new three dimensional convolutional neural network topology; (b) a new sobolev gradient-based optimization with weight values for each decision parameters; (c) application of the proposed topology and optimizer to diagnose alzheimer's disease; (d) comparisons of the results obtained from the recent techniques that have been implemented for alzheimer's disease diagnosis. experimental results and quantitative evaluations indicated that the proposed network model is able to achieve to extract desired features from images and provides automated diagnosis with 98.06% accuracy.","['3d convolutional neural network', 'sobolev gradient', 'based optimization', 'disease', 'diagnosis', 'alzheimer']"
"ultra-deep sequencing (uds) enabled identification of specific changes in human genome occurring in malignant tumors, with current approaches calling for the detection of specific mutations associated with certain cancers. however, such associations are frequently idiosyncratic and cannot be generalized for diagnostics. mitochondrial dna (mtdna) has been shown to be functionally associated with several cancer types. here, we study the association of intra-host mtdna diversity with hepatocellular carcinoma (hcc).","['mitochondrial dna circulating', 'hepatocellular carcinoma', 'entropy', 'blood', 'associated']"
"phase unwrapping is an important but challenging issue in phase measurement. even with the research efforts of a few decades, unfortunately, the problem remains not well solved, especially when heavy noise and aliasing (undersampling) are present. we propose a database generation method for phase-type objects and a one-step deep learning phase unwrapping method. with a trained deep neural network, the unseen phase fields of living mouse osteoblasts and dynamic candle flame are successfully unwrapped, demonstrating that the complicated nonlinear phase unwrapping task can be directly fulfilled in one step by a single deep neural network. excellent anti-noise and anti-aliasing performances outperforming classical methods are highlighted in this paper.","['step robust deep learning phase unwrapping', 'one']"
"many adverse drug reactions are thought to be caused by electrophilically reactive drug metabolites that conjugate to nucleophilic sites within dna and proteins, causing cancer or toxic immune responses. quinone species, including quinone-imines, quinone-methides, and imine-methides, are electrophilic michael acceptors that are often highly reactive and comprise over 40% of all known reactive metabolites. quinone metabolites are created by cytochromes p450 and peroxidases. for example, cytochromes p450 oxidize acetaminophen to n-acetyl-p-benzoquinone imine, which is electrophilically reactive and covalently binds to nucleophilic sites within proteins. this reactive quinone metabolite elicits a toxic immune response when acetaminophen exceeds a safe dose. using a deep learning approach, this study reports the first published method for predicting quinone formation: the formation of a quinone species by metabolic oxidation. we model both one- and two-step quinone formation, enabling accurate quinone formation predictions in nonobvious cases. we predict atom pairs that form quinones with an auc accuracy of 97.6%, and we identify molecules that form quinones with 88.2% auc. by modeling the formation of quinones, one of the most common types of reactive metabolites, our method provides a rapid screening tool for a key drug toxicity risk. the xenosite quinone formation model is available at http://swami.wustl.edu/xenosite/p/quinone .","['quinone species', 'drug metabolism', 'deep learning', 'predict', 'formation']"
"recent work in computer science has shown the power of deep learning driven by the backpropagation algorithm in networks of artificial neurons. but real neurons in the brain are different from most of these artificial ones in at least three crucial ways: they emit spikes rather than graded outputs, their inputs and outputs are related dynamically rather than by piecewise-smooth functions, and they have no known way to coordinate arrays of synapses in separate forward and feedback pathways so that they change simultaneously and identically, as they do in backpropagation. given these differences, it is unlikely that current deep learning algorithms can operate in the brain, but we that show these problems can be solved by two simple devices: learning rules can approximate dynamic input-output relations with piecewise-smooth functions, and a variation on the feedback alignment algorithm can train deep networks without having to coordinate forward and feedback synapses. our results also show that deep spiking networks learn much better if each neuron computes an intracellular teaching signal that reflects that cell's nonlinearity. with this mechanism, networks of spiking neurons show useful learning in synapses at least nine layers upstream from the output cells and perform well compared to other spiking networks in the literature on the mnist digit recognition task.","['fixed feedback weights', 'dynamic spiking neurons', 'deep learning']"
"the heart muscle pumps blood to vital organs, which is indispensable for human life. congestive heart failure (chf) is characterized by the inability of the heart to pump blood adequately throughout the body without an increase in intracardiac pressure. the symptoms include lung and peripheral congestion, leading to breathing difficulty and swollen limbs, dizziness from reduced delivery of blood to the brain, as well as arrhythmia. coronary artery disease, myocardial infarction, and medical co-morbidities such as kidney disease, diabetes, and high blood pressure all take a toll on the heart and can impair myocardial function. chf prevalence is growing worldwide. it afflicts millions of people globally, and is a leading cause of death. hence, proper diagnosis, monitoring and management are imperative. the importance of an objective chf diagnostic tool cannot be overemphasized. standard diagnostic tests for chf include chest x-ray, magnetic resonance imaging (mri), nuclear imaging, echocardiography, and invasive angiography. however, these methods are costly, time-consuming, and they can be operator-dependent. electrocardiography (ecg) is inexpensive and widely accessible, but ecg changes are typically not specific for chf diagnosis. a properly designed computer-aided detection (cad) system for chf, based on the ecg, would potentially reduce subjectivity and provide quantitative assessment for informed decision-making. herein, we review existing cad for automatic chf diagnosis, and highlight the development of an ecg-based cad diagnostic system that employs deep learning algorithms to automatically detect chf.","['congestive heart failure using ecg signals', 'aided diagnosis', 'review', 'computer']"
"as a key candidate technique for fifth-generation (5g) mobile communication systems, non-orthogonal multiple access (noma) has attracted considerable attention in the field of wireless communication. successive interference cancellation (sic) is the main noma detection method applied at receivers for both uplink and downlink noma transmissions. however, sic is limited by the receiver complex and error propagation problems. toward this end, we explore a high-performance, high-efficiency tool-deep learning (dl). in this paper, we propose a learning method that automatically analyzes the channel state information (csi) of the communication system and detects the original transmit sequences. in contrast to existing sic schemes, which must search for the optimal order of the channel gain and remove the signal with higher power allocation factor while detecting a signal with a lower power allocation factor, the proposed deep learning method can combine the channel estimation process with recovery of the desired signal suffering from channel distortion and multiuser signal superposition. extensive performance simulations were conducted for the proposed mimo-noma-dl system, and the results were compared with those of the conventional sic method. according to our simulation results, the deep learning method can successfully address channel impairment and achieve good detection performance. in contrast to implementing well-designed detection algorithms, mimo-noma-dl searches for the optimal solution via a neural network (nn). consequently, deep learning is a powerful and effective tool for noma signal detection.","['noma downlink signal detection', 'deep learning approach', 'mimo']"
"root-zone environment is considered difficult to analyze, particularly in interpreting interactions between environment and plant. closed-loop soilless cultures have been introduced to prevent environmental pollution, but difficulties in managing nutrients can cause nutrient imbalances with an adverse effect on crop growth. recently, deep learning has been used to draw meaningful results from nonlinear data and long short-term memory (lstm) is showing state-of-the-art results in analyzing time-series data. therefore the macronutrient ion concentrations affected by accumulated environment conditions can be analyzed using lstm.","['macronutrient ion concentrations', 'loop soilless cultures', 'term memory', 'long short', 'free estimation', 'zone', 'root', 'model', 'closed']"
"high-throughput screening technologies have provided a large amount of drug sensitivity data for a panel of cancer cell lines and hundreds of compounds. computational approaches to analyzing these data can benefit anticancer therapeutics by identifying molecular genomic determinants of drug sensitivity and developing new anticancer drugs. in this study, we have developed a deep learning architecture to improve the performance of drug sensitivity prediction based on these data. we integrated both genomic features of cell lines and chemical information of compounds to predict the half maximal inhibitory concentrations (ic50) on the cancer cell line encyclopedia (ccle) and the genomics of drug sensitivity in cancer (gdsc) datasets using a deep neural network, which we called deepdsc. specifically, we first applied a stacked deep autoencoder to extract genomic features of cell lines from gene expression data, and then combined the compounds' chemical features to these genomic features to produce final response data. we conducted 10-fold cross-validation to demonstrate the performance of our deep model in terms of root-mean-square error (rmse) and coefficient of determination r2 . we show that our model outperforms the previous approaches with rmse of 0.23 and r2 of 0.78 on ccle dataset, and rmse of 0.52 and r2 of 0.78 on gdsc dataset, respectively. moreover, to demonstrate the prediction ability of our models on novel cell lines or novel compounds, we left cell lines originating from the same tissue and each compound out as the test sets, respectively, and the rest as training sets. the performance was comparable to other methods.","['predict drug sensitivity', 'deep learning method', 'cancer cell lines', 'deepdsc']"
"cerebral micro-bleedings (cmbs) are small chronic brain hemorrhages that have many side effects. for example, cmbs can result in long-term disability, neurologic dysfunction, cognitive impairment and side effects from other medications and treatment. therefore, it is important and essential to detect cmbs timely and in an early stage for prompt treatment. in this research, because of the limited labeled samples, it is hard to train a classifier to achieve high accuracy. therefore, we proposed employing densely connected neural network (densenet) as the basic algorithm for transfer learning to detect cmbs. to generate the subsamples for training and test, we used a sliding window to cover the whole original images from left to right and from top to bottom. based on the central pixel of the subsamples, we could decide the target value. considering the data imbalance, the cost matrix was also employed. then, based on the new model, we tested the classification accuracy, and it achieved 97.71%, which provided better performance than the state of art methods.","['densely connected neural network', 'bleeding detection based', 'cerebral micro']"
to develop and evaluate a novel deep learning-based reconstruction framework called santis (sampling-augmented neural network with incoherent structure) for efficient mr image reconstruction with improved robustness against sampling pattern discrepancy.,"['mr image reconstruction', 'augmented neural network', 'incoherent structure', 'santis', 'sampling']"
"electroencephalography (eeg) is a complex signal and can require several years of training, as well as advanced signal processing and feature extraction methodologies to be correctly interpreted. recently, deep learning (dl) has shown great promise in helping make sense of eeg signals due to its capacity to learn good feature representations from raw data. whether dl truly presents advantages as compared to more traditional eeg processing approaches, however, remains an open question.","['based electroencephalography analysis', 'systematic review', 'deep learning']"
"single-molecule techniques for protein sequencing are making headway towards single-cell proteomics and are projected to propel our understanding of cellular biology and disease. yet, single cell proteomics presents a substantial unmet challenge due to the unavailability of protein amplification techniques, and the vast dynamic-range of protein expression in cells. here, we describe and computationally investigate the feasibility of a novel approach for single-protein identification using tri-color fluorescence and plasmonic-nanopore devices. comprehensive computer simulations of denatured protein translocation processes through the nanopores show that the tri-color fluorescence time-traces retain sufficient information to permit pattern-recognition algorithms to correctly identify the vast majority of proteins in the human proteome. importantly, even when taking into account realistic experimental conditions, which restrict the spatial and temporal resolutions as well as the labeling efficiency, and add substantial noise, a deep-learning protein classifier achieves 97% whole-proteome accuracies. applying our approach for protein datasets of clinical relevancy, such as the plasma proteome or cytokine panels, we obtain ~98% correct protein identification. this study suggests the feasibility of a method for accurate and high-throughput protein identification, which is highly versatile and applicable.","['protein nanopore sensing shows feasibility', 'proteome identification', 'whole', 'single', 'simulation']"
"applied research on artificial intelligence, mainly in deep learning, is widely performed. if medical images can be evaluated using artificial intelligence, this could substantially improve examination efficiency.","['evaluating medical images using deep convolutional neural networks', 'simulated ct phantom image study']"
phenotype information is crucial for the interpretation of genomic variants. so far it has only been accessible for bioinformatics workflows after encoding into clinical terms by expert dysmorphologists.,"['image analysis', 'exome data', 'prioritization', 'pedia']"
"the combination of machine vision and soft computing approaches in the clinical decisions, using training data, can improve medical decisions and treatments. the cardiotocography (ctg) monitoring and uterine activity (ua) provides useful information about the condition of the fetus and the cesarean or natural delivery. the visual assessment by the pathologists takes a lot of time and may be incompatible. therefore, creating a computer intelligent method to assess fetal wellbeing before the mother labour is very important. in this study, many diverse approaches are suggested for predicting fetal state classes based on artificial intelligence. the various topologies of multi-layer architecture of a sub-adaptive neuro fuzzy inference system (mla-anfis) using multiple input features, neural networks (nn), deep stacked sparse auto-encoders (dssaes), and deep-anfis models are implemented on a ctg data set. experimental results contributing to dssae are more accurate than other suggested techniques to predict fetal state. the proposed method achieved a sensitivity of 99.716, specificity of 97.500 and geometric mean of 98.602 with accuracy of 99.503.","['cardiotocogram recordings using neural network models', 'fetal state', 'prediction']"
"extracting local features from 3d shapes is an important and challenging task that usually requires carefully designed 3d shape descriptors. however, these descriptors are hand-crafted and require intensive human intervention with prior knowledge. to tackle this issue, we propose a novel deep learning model, namely circle convolutional restricted boltzmann machine (ccrbm), for unsupervised 3d local feature learning. ccrbm is specially designed to learn from raw 3d representations. it effectively overcomes obstacles such as irregular vertex topology, orientation ambiguity on the 3d surface, and rigid or slightly non-rigid transformation invariance in the hierarchical learning of 3d data that cannot be resolved by the existing deep learning models. specifically, by introducing the novel circle convolution, ccrbm holds a novel ring-like multi-layer structure to learn 3d local features in a structure preserving manner. circle convolution convolves across 3d local regions via rotating a novel circular sector convolution window in a consistent circular direction. in the process of circle convolution, extra points are sampled in each 3d local region and projected onto the tangent plane of the center of the region. in this way, the projection distances in each sector window are employed to constitute a novel local raw 3d representation called projection distance distribution (pdd). in addition, to eliminate the initial location ambiguity of a sector window, the fourier transform modulus is used to transform the pdd into the fourier domain, which is then conveyed to ccrbm. experiments using the learned local features are conducted on three aspects: global shape retrieval, partial shape retrieval, and shape correspondence. the experimental results show that the learned local features outperform other state-of-the-art 3d shape descriptors.","['unsupervised 3d local feature learning', 'circle convolutional restricted boltzmann machine']"
"long non-protein-coding rnas (lncrnas) identification and analysis are pervasive in transcriptome studies due to their roles in biological processes. in particular, lncrna-protein interaction has plausible relevance to gene expression regulation and in cellular processes such as pathogen resistance in plants. while lncrna-protein interaction has been studied in animals, there has yet to be extensive research in plants. in this paper, we propose a novel plant lncrna-protein interaction prediction method, namely plrpim, which combines deep learning and shallow machine learning methods. the selection of an optimal feature subset and subsequent efficient compression are significant challenges for deep learning models. the proposed method adopts k-mer and extracts high-level abstraction sequence-based features using stacked sparse autoencoder. based on the extracted features, the fusion of random forest (rf) and light gradient boosting machine (lgbm) is used to build the prediction model. the performances are evaluated on arabidopsis thaliana and zea mays datasets. results from experiments demonstrate plrpim's superiority compared with other prediction tools on the two datasets. based on 5-fold cross-validation, we obtain 89.98% and 93.44% accuracy, 0.954 and 0.982 auc for arabidopsis thaliana and zea mays, respectively. plrpim predicts potential lncrna-protein interaction pairs effectively, which can facilitate lncrna related research including function prediction.","['hybrid prediction method', 'protein interaction', 'plant lncrna']"
"neuroimaging analysis is currently crucial for an early assessment of glioblastoma, to help improving treatment and tumor follow-up. to this end, multiple functional and morphological mri sequences are usually employed, requiring the development of automated tools capable to extract the relevant information from these sources. in this work we present oncohabitats (https://www.oncohabitats.upv.es): an online open access system for glioblastoma analysis based on mri data.","['glioblastoma heterogeneity assessment', 'system', 'oncohabitats', 'mri']"
"an important task of macromolecular structure determination by cryo-electron microscopy (cryo-em) is the identification of single particles in micrographs (particle picking). due to the necessity of human involvement in the process, current particle picking techniques are time consuming and often result in many false positives and negatives. adjusting the parameters to eliminate false positives often excludes true particles in certain orientations. the supervised machine learning (e.g. deep learning) methods for particle picking often need a large training dataset, which requires extensive manual annotation. other reference-dependent methods rely on low-resolution templates for particle detection, matching and picking, and therefore, are not fully automated. these issues motivate us to develop a fully automated, unbiased framework for particle picking.","['fully automated single particle picking', 'unsupervised learning approach', 'em images', 'cryo', 'autocryopicker']"
"the increase in stroke incidence with the aging of the korean population will rapidly impose an economic burden on society. timely treatment can improve stroke prognosis. awareness of stroke warning signs and appropriate actions in the event of a stroke improve outcomes. medical service use and health behavior data are easier to collect than medical imaging data. here, we used a deep neural network to detect stroke using medical service use and health behavior data; we identified 15,099 patients with stroke. principal component analysis (pca) featuring quantile scaling was used to extract relevant background features from medical records; we used these to predict stroke. we compared our method (a scaled pca/deep neural network [dn",['proac']
"this paper proposes a computer-aided cirrhosis diagnosis system to diagnose cirrhosis based on ultrasound images. we first propose a method to extract a liver capsule on an ultrasound image, then, based on the extracted liver capsule, we fine-tune a deep convolutional neural network (cnn) model to extract features from the image patches cropped around the liver capsules. finally, a trained support vector machine (svm) classifier is applied to classify the sample into normal or abnormal cases. experimental results show that the proposed method can effectively extract the liver capsules and accurately classify the ultrasound images.","['liver capsule guided ultrasound image classification', 'diagnose cirrhosis', 'learning']"
"allergies to airborne pollen are a significant issue affecting millions of americans. consequently, accurately predicting the daily concentration of airborne pollen is of significant public benefit in providing timely alerts. this study presents a method for the robust estimation of the concentration of airborne ambrosia pollen using a suite of machine learning approaches including deep learning and ensemble learners. each of these machine learning approaches utilize data from the european centre for medium-range weather forecasts (ecmwf) atmospheric weather and land surface reanalysis. the machine learning approaches used for developing a suite of empirical models are deep neural networks, extreme gradient boosting, random forests and bayesian ridge regression methods for developing our predictive model. the training data included twenty-four years of daily pollen concentration measurements together with ecmwf weather and land surface reanalysis data from 1987 to 2011 is used to develop the machine learning predictive models. the last six years of the dataset from 2012 to 2017 is used to independently test the performance of the machine learning models. the correlation coefficients between the estimated and actual pollen abundance for the independent validation datasets for the deep neural networks, random forest, extreme gradient boosting and bayesian ridge were 0.82, 0.81, 0.81 and 0.75 respectively, showing that machine learning can be used to effectively forecast the concentrations of airborne pollen.","['forecast airborne ambrosia pollen', 'ensemble machine learning methods', 'applying deep neural networks']"
"we show that langevin markov chain monte carlo inference in an energy-based model with latent variables has the property that the early steps of inference, starting from a stationary point, correspond to propagating error gradients into internal layers, similar to backpropagation. the backpropagated error is with respect to output units that have received an outside driving force pushing them away from the stationary point. backpropagated error gradients correspond to temporal derivatives with respect to the activation of hidden units. these lead to a weight update proportional to the product of the presynaptic firing rate and the temporal rate of change of the postsynaptic firing rate. simulations and a theoretical argument suggest that this rate-based update rule is consistent with those associated with spike-timing-dependent plasticity. the ideas presented in this article could be an element of a theory for explaining how brains perform credit assignment in deep hierarchies as efficiently as backpropagation does, with neural computation corresponding to both approximate inference in continuous-valued latent variables and error backpropagation, at the same time.","['compatible approximation', 'based model', 'stdp', 'energy', 'backpropagation']"
"the lifestyle of modern society has changed significantly with the emergence of artificial intelligence (ai), machine learning (ml), and deep learning (dl) technologies in recent years. artificial intelligence is a multidimensional technology with various components such as advanced algorithms, ml and dl. together, ai, ml, and dl are expected to provide automated devices to ophthalmologists for early diagnosis and timely treatment of ocular disorders in the near future. in fact, ai, ml, and dl have been used in ophthalmic setting to validate the diagnosis of diseases, read images, perform corneal topographic mapping and intraocular lens calculations. diabetic retinopathy (dr), age-related macular degeneration (amd), and glaucoma are the 3 most common causes of irreversible blindness on a global scale. ophthalmic imaging provides a way to diagnose and objectively detect the progression of a number of pathologies including dr, amd, glaucoma, and other ophthalmic disorders. there are 2 methods of imaging used as diagnostic methods in ophthalmic practice: fundus digital photography and optical coherence tomography (oct). of note, oct has become the most widely used imaging modality in ophthalmology settings in the developed world. changes in population demographics and lifestyle, extension of average lifespan, and the changing pattern of chronic diseases such as obesity, diabetes, dr, amd, and glaucoma create a rising demand for such images. furthermore, the limitation of availability of retina specialists and trained human graders is a major problem in many countries. consequently, given the current population growth trends, it is inevitable that analyzing such images is time-consuming, costly, and prone to human error. therefore, the detection and treatment of dr, amd, glaucoma, and other ophthalmic disorders through unmanned automated applications system in the near future will be inevitable. we provide an overview of the potential impact of the current ai, ml, and dl methods and their applications on the early detection and treatment of dr, amd, glaucoma, and other ophthalmic diseases.","['promising artificial intelligence', 'deep learning algorithms', 'machine learning', 'ophthalmology']"
"continuous blood pressure (bp) monitoring can produce a significant amount of digital data, which increases the chance of early diagnosis and improve the rate of survival for people diagnosed with hypertension and cardiovascular diseases (cvds). however, mining and processing this vast amount of data are challenging. this research is aimed to address this challenge by proposing a deep learning technique, convolutional neural network (cnn), to estimate the systolic blood pressure (sbp) using electrocardiogram (ecg) and photoplethysmography (ppg) signals. two different methods are investigated and compared in this research. in the first method, continuous wavelet transform (cwt) and cnn have been employed to estimate the sbp. for the second method, we used random sampling within the stochastic gradient descent (sgd) optimization of cnn and the raw ecg and ppg signals for training the network. the medical information mart for intensive care (mimic iii) database is used for both methods, which split to two parts, 70% for training our network and the remaining used for testing the performance of the network. both methods are capable of learning how to extract relevant features from the signals. therefore, there is no need for engineered feature extraction compared to previous works. our experimental results show high accuracy for both cnn-based methods which make them promising and reliable architectures for sbp estimation.",['estimating systolic blood pressure using convolutional neural networks']
"population imaging studies generate data for developing and implementing personalised health strategies to prevent, or more effectively treat disease. large prospective epidemiological studies acquire imaging for pre-symptomatic populations. these studies enable the early discovery of alterations due to impending disease, and enable early identification of individuals at risk. such studies pose new challenges requiring automatic image analysis. to date, few large-scale population-level cardiac imaging studies have been conducted. one such study stands out for its sheer size, careful implementation, and availability of top quality expert annotation; the uk biobank (ukb). the resulting massive imaging datasets (targeting ca. 100,000 subjects) has put published approaches for cardiac image quantification to the test. in this paper, we present and evaluate a cardiac magnetic resonance (cmr) image analysis pipeline that properly scales up and can provide a fully automatic analysis of the ukb cmr study. without manual user interactions, our pipeline performs end-to-end image analytics from multi-view cine cmr images all the way to anatomical and functional bi-ventricular quantification. all this, while maintaining relevant quality controls of the cmr input images, and resulting image segmentations. to the best of our knowledge, this is the first published attempt to fully automate the extraction of global and regional reference ranges of all key functional cardiovascular indexes, from both left and right cardiac ventricles, for a population of 20,000 subjects imaged at 50 time frames per subject, for a total of one million cmr volumes. in addition, our pipeline provides 3d anatomical bi-ventricular models of the heart. these models enable the extraction of detailed information of the morphodynamics of the two ventricles for subsequent association to genetic, omics, lifestyle habits, exposure information, and other information provided in population imaging studies. we validated our proposed cmr analytics pipeline against manual expert readings on a reference cohort of 4620 subjects with contour delineations and corresponding clinical indexes. our results show broad significant agreement between the manually obtained reference indexes, and those automatically computed via our framework. 80.67% of subjects were processed with mean contour distance of less than 1\xa0pixel, and 17.50% with mean contour distance between 1 and 2\xa0pixels. finally, we compare our pipeline with a recently published approach reporting on ukb data, and based on deep learning. our comparison shows similar performance in terms of segmentation accuracy with respect to human experts.","['uk biobank imaging study', 'quantitative cmr population imaging', 'rv quantification pipeline', '000 subjects', 'lv', 'evaluation', '20']"
"we present a deep architecture and learning framework for establishing correspondences across cross-spectral visible and infrared images in an unpaired setting. to overcome the unpaired cross-spectral data problem, we design the unified image translation and feature extraction modules to be learned in a joint and boosting manner. concretely, the image translation module is learned only with the unpaired cross-spectral data, and the feature extraction module is learned with an input image and its translated image. by learning two modules simultaneously, the image translation module generates the translated image that preserves not only the domain-specific attributes with separate latent spaces but also the domain-agnostic contents with feature consistency constraint. in an inference phase, the cross-spectral feature similarity is augmented by intra-spectral similarities between the features extracted from the translated images. experimental results show that this model outperforms the state-of-the-art unpaired image translation methods and cross-spectral feature descriptors on various visible and infrared benchmarks.","['find unpaired cross', 'spectral correspondences', 'learning']"
"diabetic retinopathy (dr) is the leading cause of blindness worldwide, and therefore its early detection is important in order to reduce disease-related eye injuries. dr is diagnosed by inspecting fundus images. since microaneurysms (ma) are one of the main symptoms of the disease, distinguishing this complication within the fundus images facilitates early dr detection. in this paper, an automatic analysis of retinal images using convolutional neural network (cnn) is presented.","['step convolutional neural network', 'fundus images using', 'microaneurysm detection', 'two']"
"a non-intrusive method is presented for measuring different fluidic properties in a microfluidic chip by optically monitoring the flow of droplets. a neural network is used to extract the desired information from the images of the droplets. we demonstrate the method in two applications: measurement of the concentration of each component of a water/alcohol mixture, and measurement of the flow rate of the same mixture. a large number of droplet images are recorded and used to train deep neural networks (dnn) to predict the flow rate or the concentration. it is shown that this method can be used to quantify the concentrations of each component with a 0.5% accuracy and the flow rate with\xa0a resolution of 0.05\u2009ml/h. the proposed method can in principle be used to measure other properties of the fluid such as surface tension and viscosity.","['microfluidic channels using deep neural networks', 'droplet flows', 'learning']"
"the high incidence, seasonal pattern and frequent outbreaks of hand, foot, and mouth disease (hfmd) represent a threat for millions of children in mainland china. and advanced response is being used to address this. here, we aimed to model time series with a long short-term memory (lstm) based on the hfmd notified data from june 2008 to june 2018 and the ultimate performance was compared with the autoregressive integrated moving average (arima) and nonlinear auto-regressive neural network (nar). the results indicated that the identified best-fitting lstm with the better superiority, be it in modeling dataset or two robustness tests dataset, than the best-conducting nar and seasonal arima (sarima) methods in forecasting performances, including the minimum indices of root mean square error, mean absolute error and mean absolute percentage error. the epidemic trends of hfmd remained stable during the study period, but the reported cases were even at significantly high levels with a notable high-risk seasonality in summer, and the incident cases projected by the lstm would still be fairly high with a slightly upward trend in the future. in this regard, the lstm approach should be highlighted in forecasting the epidemics of hfmd, and therefore assisting decision makers in making efficient decisions derived from the early detection of the disease incidents.","['mouth disease incidence', 'deep learning approach', 'modeling seasonality', 'mainland china', 'trends', 'hand', 'foot', 'evaluation', 'development']"
"accurate and precise brain tumor mr images classification plays important role in clinical diagnosis and decision making for patient treatment. the key challenge in mr images classification is the semantic gap between the low-level visual information captured by the mri machine and the high-level information perceived by the human evaluator. the traditional machine learning techniques for classification focus only on low-level or high-level features, use some handcrafted features to reduce this gap and require good feature extraction and classification methods. recent development on deep learning has shown great progress and deep convolution neural networks (cnns) have succeeded in the images classification task. deep learning is very powerful for feature representation that can depict low-level and high-level information completely and embed the phase of feature extraction and classification into self-learning but require large training dataset in general. for most of the medical imaging scenario, the training datasets are small, therefore, it is a challenging task to apply the deep learning and train cnn from scratch on the small dataset. aiming this problem, we use pre-trained deep cnn model and propose a block-wise fine-tuning strategy based on transfer learning. the proposed method is evaluated on t1-weighted contrast-enhanced magnetic resonance images (ce-mri) benchmark dataset. our method is more generic as it does not use any handcrafted features, requires minimal preprocessing and can achieve average accuracy of 94.82% under five-fold cross-validation. we compare our results not only with the traditional machine learning but also with deep learning methods using cnns. experimental results show that our proposed method outperforms state-of-the-art classification on the ce-mri dataset.","['mr images using transfer learning', 'brain tumor classification', 'tuning', 'fine']"
to investigate a fully automated abdominal ct-based muscle tool in a large adult screening population.,"['longitudinal adult screening cohort', 'based muscle segmentation', 'sarcopenia assessment', 'deep learning', 'abdominal ct', 'quantification', 'application']"
"picosecond laser pulses have been used as a surface colouring technique for noble metals, where the colours result from plasmonic resonances in the metallic nanoparticles created and redeposited on the surface by ablation and deposition processes. this technology provides two datasets which we use to train artificial neural networks, data from the experiment itself (laser parameters vs. colours) and data from the corresponding numerical simulations (geometric parameters vs. colours). we apply deep learning to predict the colour in both cases. we also propose a method for the solution of the inverse problem - wherein the geometric parameters and the laser parameters are predicted from colour - using an iterative multivariable inverse design method.","['plasmonic colours predicted', 'deep learning']"
"local dimming techniques have been widely studied to achieve a high contrast ratio and low power consumption for liquid crystal displays. the luminance of a backlight is reduced according to some characteristics of an input image and the pixel data are boosted to compensate for the dimmed backlight. in addition, because a backlight block is affected by adjacent ones, the pixel compensation algorithm requires huge processing power as well as many iterations along with the overall luminance profile information of a backlight. however, a proposed deep-learning-based local dimming algorithm generates the compensated image directly from an input image without any information of backlight's dimming levels. the proposed compensation network is constructed on the basis of the u-net to maintain the high-resolution features in the up-sampling paths through skip-connections. in addition, it is also ensured that the bi-linear interpolation can be used without visible image quality degradation for the reduction on the number of parameters. the proposed networks are trained and verified on a div2k 2k image dataset.","['local dimming liquid crystal displays', 'based pixel compensation algorithm', 'dot backlights', 'quantum', 'learning', 'deep']"
"we explored whether the use of deep learning to model combinations of symptom-physical signs and objective tests, such as lung function tests and the bronchial challenge test, would improve model performance in predicting the initial diagnosis of adult asthma when compared to the conventional machine learning diagnostic method.","['deep learning facilitates', 'adult asthma', 'diagnosis']"
"deep learning models have become the state-of-the-art for many tasks, from text sentiment analysis to facial image recognition. however, understanding why certain models perform better than others or how one model learns differently than another is often difficult yet critical for increasing their effectiveness, improving prediction accuracy, and enabling fairness. traditional methods for comparing models' efficacy, such as accuracy, precision, and recall provide a quantitative view of performance; however, the qualitative intricacies of why one model performs better than another are hidden. in this paper, we interview machine learning practitioners to understand their evaluation and comparison workflow. from there, we iteratively design a visual analytic approach, deepcompare, to systematically compare the results of deep learning models, in order to provide insight into the model behavior and interactively assess tradeoffs between two such models. the tool allows users to evaluate model results, identify and compare activation patterns for misclassifications, and link the test results back to specific neurons. we conduct a preliminary evaluation through two real-world case studies to show that experts can make more informed decisions about the effectiveness of different types of models, understand in more detail the strengths and weaknesses of the models, and holistically evaluate the behavior of the models.","['deep learning model performance', 'interactive comparison', 'visual', 'deepcompare']"
"wearable devices have evolved as screening tools for atrial fibrillation (af). a photoplethysmographic (ppg) af detection algorithm was developed and applied to a convenient smartphone-based device with good accuracy. however, patients with paroxysmal af frequently exhibit premature atrial complexes (pacs), which result in poor unmanned af detection, mainly because of rule-based or handcrafted machine learning techniques that are limited in terms of diagnostic accuracy and reliability.","['detect atrial fibrillation using photoplethysmographic signals', 'deep learning approaches', 'algorithms development study']"
we propose a deep learning based method to estimate high-resolution images from multiple fiber bundle images. our approach first aligns raw fiber bundle image sequences with a motion estimation neural network and then applies a 3d convolution neural network to learn a mapping from aligned fiber bundle image sequences to their ground truth images. evaluations on lens tissue samples and a 1951 usaf resolution target suggest that our proposed method can significantly improve spatial resolution for fiber bundle imaging systems.,['fiber bundle imaging resolution enhancement using deep learning']
"several researchers have contemplated deep learning-based post-filters to increase the quality of statistical parametric speech synthesis, which perform a mapping of the synthetic speech to the natural speech, considering the different parameters separately and trying to reduce the gap between them. the long short-term memory (lstm) neural networks have been applied successfully in this purpose, but there are still many aspects to improve in the results and in the process itself. in this paper, we introduce a new pre-training approach for the lstm, with the objective of enhancing the quality of the synthesized speech, particularly in the spectrum, in a more efficient manner. our approach begins with an auto-associative training of one lstm network, which is used as an initialization for the post-filters. we show the advantages of this initialization for the enhancing of the mel-frequency cepstral parameters of synthetic speech. results show that the initialization succeeds in achieving better results in enhancing the statistical parametric speech spectrum in most cases when compared to the common random initialization approach of the networks.","['trained lstm neural networks', 'artificial speech using pre', 'improving post', 'filtering']"
"to define the role of erk1/2 signaling in the quiescent endothelium, we induced endothelial erk2 knockout in adult erk1-/- mice. this resulted in a rapid onset of hypertension, a decrease in enos expression, and an increase in endothelin-1 plasma levels, with all mice dying within 5 wk. immunostaining and endothelial fate mapping showed a robust increase in tgfβ signaling leading to widespread endothelial-to-mesenchymal transition (endmt). fibrosis affecting the cardiac conduction system was responsible for the universal lethality in these mice. other findings included renal endotheliosis, loss of fenestrated endothelia in endocrine organs, and hemorrhages. an ensemble computational intelligence strategy, comprising deep learning and probabilistic programing of rna-seq data, causally linked the loss of erk1/2 in huvecs in vitro to activation of tgfβ signaling, endmt, suppression of enos, and induction of endothelin-1 expression. all in silico predictions were verified in vitro and in vivo. in summary, these data establish the key role played by erk1/2 signaling in the maintenance of vascular normalcy.","['2 signaling maintains integrity', 'quiescent endothelium', 'endothelial erk1']"
"the uncontrollable growth of cells in the breast tissue causes breast cancer which is the second most common type of cancer affecting women in the united states. normally, human epidermal growth factor receptor 2 (her2) proteins are responsible for the division and growth of healthy breast cells. her2 status is currently assessed using immunohistochemistry (ihc) as well as in situ hybridization (ish) in equivocal cases. manual her2 evaluation of ihc stained microscopic images involves an error-prone, tedious, inter-observer variable, and time-consuming routine lab work due to diverse staining, overlapped regions, and non-homogeneous remarkable large slides. to address these issues, digital pathology offers reproducible, automatic, and objective analysis and interpretation of whole slide image (wsi). in this paper, we present a machine learning (ml) framework to segment, classify, and quantify ihc breast cancer images in an effective way. the proposed method consists of two major classifying and segmentation parts. since her2 is associated with tumors of an epithelial region and most of the breast tumors originate in epithelial tissue, it is crucial to develop an approach to segment different tissue structures. the proposed technique is comprised of three steps. in the first step, a superpixel-based support vector machine (svm) feature learning classifier is proposed to classify epithelial and stromal regions from wsi. in the second stage, on classified epithelial regions, a convolutional neural network (cnn) based segmentation method is applied to segment membrane regions. finally, divided tiles are merged and the overall score of each slide is evaluated. experimental results for 127 slides are presented and compared with state-of-the-art handcraft and deep learning-based approaches. the experiments demonstrate that the proposed method achieved promising performance on ihc stained data. the presented automated algorithm was shown to outperform other approaches in terms of superpixel based classifying of epithelial regions and segmentation of membrane staining using cnn.","['whole slide images using', 'modified deep learning network', 'evaluate her2 status', 'cell membranes', 'automated segmentation']"
"in this paper, a deep learning (dl)-based physical (phy) layer authentication framework is proposed to enhance the security of industrial wireless sensor networks (iwsns). three algorithms, the deep neural network (dnn)-based sensor nodes' authentication method, the convolutional neural network (cnn)-based sensor nodes' authentication method, and the convolution preprocessing neural network (cpnn)-based sensor nodes' authentication method, have been adopted to implement the phy-layer authentication in iwsns. among them, the improved cpnn-based algorithm requires few computing resources and has extremely low latency, which enable a lightweight multi-node phy-layer authentication. the adaptive moment estimation (adam) accelerated gradient algorithm and minibatch skill are used to accelerate the training of the neural networks. simulations are performed to evaluate the performance of each algorithm and a brief analysis of the application scenarios for each algorithm is discussed. moreover, the experiments have been performed with universal software radio peripherals (usrps) to evaluate the authentication performance of the proposed algorithms. due to the trainings being performed on the edge sides, the proposed method can implement a lightweight authentication for the sensor nodes under the edge computing (ec) system in iwsns.","['industrial wireless sensor networks', 'based physical layer authentication', 'learning', 'deep']"
to noninvasively differentiate meningioma grades by deep learning radiomics (dlr) model based on routine post-contrast mri.,"['deep learning radiomics model', 'preoperative grading', 'meningioma']"
"precise delineation of organs at risk (oars) in head and neck cancer (hnc) is necessary for accurate radiotherapy. although guidelines exist, significant interobserver variability (iov) remains. the aim was to validate a 3d convolutional neural network (cnn) for semi-automated delineation of oars with respect to delineation accuracy, efficiency and consistency compared to manual delineation.","['neck cancer', 'deep learning', 'risk', 'organs', 'head', 'delineation', 'benefits']"
"we present a novel deep-learning-based approach for one-class transfer learning in which labeled data from an unrelated task is used for feature learning in one-class classification. the proposed method operates on top of a convolutional neural network (cnn) of choice and produces descriptive features while maintaining a low intra-class variance in the feature space for the given class. for this purpose two loss functions, compactness loss and descriptiveness loss, are proposed along with a parallel cnn architecture. a template matching-based framework is introduced to facilitate the testing process. extensive experiments on publicly available anomaly detection, novelty detection, and mobile active authentication datasets show that the proposed deep one-class (doc) classification method achieves significant improvements over the state-of-the-art.","['learning deep features', 'class classification', 'one']"
"airplane engines are vital aircraft components, so regular inspections of the engines are required to ensure their stable operation. a dynamic computed tomography (ct) system has been proposed by our group for in situ nondestructive testing of airplane engines, which takes advantage of the rotor's self-rotation. however, static parts of the engines cause blocked artifacts in the reconstructed image, leading to misinterpretations of the condition of engines. in this paper, in order to remove the artifacts produced by the projection of the static parts in ct reconstruction, two deep-learning-based methods are proposed, which use u-net to perform correction in the projection domain. the projection of static parts can be estimated by a well-trained u-net and subsequently can be subtracted from the projections of the engine. finally, the rotor can be reconstructed from the corrected projections. the results shown in this paper indicate that the proposed methods are practical and effective for removing those blocked artifacts and recovering the details of rotating parts, which will, in turn, maximize the utilization of the dynamic ct system for in situ engine tests.","['based blocked artifacts removal method', 'dynamic computed tomography', 'u', 'net']"
"the limitations of traditional computer-aided detection (cad) systems for mammography, the extreme importance of early detection of breast cancer and the high impact of the false diagnosis of patients drive researchers to investigate deep learning (dl) methods for mammograms (mgs). recent breakthroughs in dl, in particular, convolutional neural networks (cnns) have achieved remarkable advances in the medical fields. specifically, cnns are used in mammography for lesion localization and detection, risk assessment, image retrieval, and classification tasks. cnns also help radiologists providing more accurate diagnosis by delivering precise quantitative analysis of suspicious lesions.","['deep convolutional neural networks', 'mammography', 'challenges', 'applications', 'advances']"
"the ability to differentiate post-cancer from healthy tongue muscle coordination patterns is necessary for the advancement of speech motor control theories and for the development of therapeutic and rehabilitative strategies. a deep learning approach is presented to classify two groups using muscle coordination patterns from magnetic resonance imaging (mri). the proposed method uses tagged-mri to track the tongue's internal tissue points and atlas-driven non-negative matrix factorization to reduce the dimensionality of the deformation fields. a convolutional neural network is applied to the classification task yielding an accuracy of 96.90%, offering the potential to the development of therapeutic or rehabilitative strategies in speech-related disorders.","['healthy tongue muscle coordination patterns', 'speech using deep learning', 'differentiating post', 'cancer']"
to develop a deep learning-based algorithm to automatically identify optimal portal venous phase timing (pvp-timing) so that image analysis techniques can be accurately performed on post contrast studies.,"['optimal portal venous phase timing', 'convolutional neural networks', 'automated identification']"
"growing interest exists for superolateral medial forebrain bundle (slmfb) deep brain stimulation (dbs) in psychiatric disorders. the surgical approach warrants tractographic rendition. commercial stereotactic planning systems use deterministic tractography which suffers from inherent limitations, is dependent on manual interaction (roi definition), and has to be regarded as subjective. we aimed to develop an objective but patient-specific tracking of the slmfb which at the same time allows the use of a commercial surgical planning system in the context of deep brain stimulation.","['superolateral medial forebrain bundle using hamlet', 'aided personalized dti tractographic planning', 'deep brain stimulation', 'machine learning']"
"this paper presents a novel method for predicting suicidal ideation from electronic health records (ehr) and ecological momentary assessment (ema) data using deep sequential models. both ehr longitudinal data and ema question forms are defined by asynchronous, variable length, randomly sampled data sequences. in our method, we model each of them with a recurrent neural network, and both sequences are aligned by concatenating the hidden state of each of them using temporal marks. furthermore, we incorporate attention schemes to improve performance in long sequences and time-independent pre-trained schemes to cope with very short sequences. using a database of 1023 patients, our experimental results show that the addition of ema records boosts the system recall to predict the suicidal ideation diagnosis from 48.13% obtained exclusively from ehr-based state-of-the-art methods to 67.78%. additionally, our method provides interpretability through the t-distributed stochastic neighbor embedding (t-sne) representation of the latent space. furthermore, the most relevant input features are identified and interpreted medically.","['multiple source data', 'deep sequential models', 'suicidal ideation']"
"conditional maximum mean discrepancy (cmmd) can capture the discrepancy between conditional distributions by drawing support from nonlinear kernel functions; thus, it has been successfully used for pattern classification. however, cmmd does not work well on complex distributions, especially when the kernel function fails to correctly characterize the difference between intraclass similarity and interclass similarity. in this paper, a new kernel learning method is proposed to improve the discrimination performance of cmmd. it can be operated with deep network features iteratively and thus denoted as kln for abbreviation. the cmmd loss and an autoencoder (ae) are used to learn an injective function. by considering the compound kernel, that is, the injective function with a characteristic kernel, the effectiveness of cmmd for data category description is enhanced. kln can simultaneously learn a more expressive kernel and label prediction distribution; thus, it can be used to improve the classification performance in both supervised and semisupervised learning scenarios. in particular, the kernel-based similarities are iteratively learned on the deep network features, and the algorithm can be implemented in an end-to-end manner. extensive experiments are conducted on four benchmark datasets, including mnist, svhn, cifar-10, and cifar-100. the results indicate that kln achieves the state-of-the-art classification performance.","['based image classification', 'matching discrepancy', 'learning kernel', 'conditional moment']"
"convolutional neural networks (cnns) can not only classify images but can also generate key features, e.g., the google neural network that learned to identify cats by simply watching youtube videos, for the classification. in this paper, crop models are distilled by cnn to evaluate the ability of deep learning to identify the plant physiology knowledge behind such crop models simply by learning. due to difficulty in collecting big data on crop growth, a crop model was used to generate datasets. the generated datasets were fed into cnn for distillation of the crop model. the models trained by cnn were evaluated by the visualization of saliency maps. in this study, three saliency maps were calculated using all datasets (case 1) and using datasets with spikelet sterility due to either high temperature at anthesis (case 2) or cool summer damage (case 3). the results of case 1 indicated that cnn determined the developmental index of paddy rice, which was implemented in the crop model, simply by learning. moreover, cnn identified the important individual environmental factors affecting the grain yield. although cnn had no prior knowledge of spikelet sterility, cases 2 and 3 indicated that cnn realized about paddy rice becoming sensitive to daily mean and maximum temperatures during specific periods. such deep learning approaches can be used to accelerate the understanding of crop models and make the models more portable. moreover, the results indicated that cnn can be used to develop new plant physiology theories simply by learning.","['learn plant physiology theories using machine learning', 'crop models', 'distillation']"
"humans can feel, weigh and grasp diverse objects, and simultaneously infer their material properties while applying the right amount of force-a challenging set of tasks for a modern robot1. mechanoreceptor networks that provide sensory feedback and enable the dexterity of the human grasp2 remain difficult to replicate in robots. whereas computer-vision-based robot grasping strategies3-5 have progressed substantially with the abundance of visual data and emerging machine-learning tools, there are as yet no equivalent sensing platforms and large-scale datasets with which to probe the use of the tactile information that humans rely on when grasping objects. studying the mechanics of how humans grasp objects will complement vision-based robotic object handling. importantly, the inability to record and analyse tactile signals currently limits our understanding of the role of tactile information in the human grasp itself-for example, how tactile maps are used to identify objects and infer their properties is unknown6. here we use a scalable tactile glove and deep convolutional neural networks to show that sensors uniformly distributed over the hand can be used to identify individual objects, estimate their weight and explore the typical tactile patterns that emerge while grasping objects. the sensor array (548 sensors) is assembled on a knitted glove, and consists of a piezoresistive film connected by a network of conductive thread electrodes that are passively probed. using a low-cost (about us$10) scalable tactile glove sensor array, we record a large-scale tactile dataset with 135,000 frames, each covering the full hand, while interacting with 26 different objects. this set of interactions with different objects reveals the key correspondences between different regions of a human hand while it is manipulating objects. insights from the tactile signatures of the human grasp-through the lens of an artificial analogue of the natural mechanoreceptor network-can thus aid the future design of prosthetics7, robot grasping tools and human-robot interactions1,8-10.","['scalable tactile glove', 'human grasp using', 'signatures', 'learning']"
"lung cancer is a disease with a dismal prognosis and is the major cause of cancer deaths in many countries. nonetheless, rapid technological developments in genome science guarantees more effective prevention and treatment strategies.","['specific gene pairs based', 'deep learning prediction model', 'lung adenocarcinoma', 'genetic algorithm', 'recognition', 'establishment']"
we develop a fast learning algorithm combining symbolic dynamics and brain-inspired hyperdimensional computing for both seizure onset detection and identification of ictogenic (seizure generating) brain regions from intracranial electroencephalography (ieeg).,"['ictogenic brain regions using short', 'time ieeg recordings', 'local binary patterns', 'shot learning', 'seizure onset', 'hyperdimensional computing', 'one', 'identification']"
"computer assisted image acquisition techniques, including confocal microscopy, require efficient tools for an automatic sorting of vast amount of generated image data. the complexity of the classification process, absence of adequate tools, and insufficient amount of reference data has made the automated processing of images challenging. mastering of this issue would allow implementation of statistical analysis in research areas such as in research on formation of t-tubules in cardiac myocytes. we developed a system aimed at automatic assessment of cardiomyocyte development stages (saacs). the system classifies confocal images of cardiomyocytes with fluorescent dye stained sarcolemma. we based saacs on a densely connected convolutional network (densenet) topology. we created a set of labelled source images, proposed an appropriate data augmentation technique and designed a class probability graph. we showed that the densenet topology, in combination with the augmentation technique is suitable for the given task, and that high-resolution images are instrumental for image categorization. saacs, in combination with the automatic high-throughput confocal imaging, will allow application of statistical analysis in the research of the tubular system development or remodelling and loss.","['confocal microscopy images using deep convolutional networks', 'cardiomyocyte development stages', 'automatic assessment']"
"the web-based presentation software prezi was used to create a digital presentation in order to facilitate antibiotic knowledge in an undergraduate course on infectious diseases in the karolinska institutet medical programme. it was unclear how the students used this in their learning, and there is a lack of research on using prezi presentations in higher education, as well as on learner-content interaction in blended learning in general.","['medical students learn', 'qualitative study', 'digital presentation', 'help', 'exploring']"
"recently, pervasive sensing technologies have been widely applied to comprehensive patient monitoring in order to improve clinical treatment. various types of biomedical signals collected by different sensing channels provide different aspects of patient health information. however, due to the uncertainty and variability in clinical observation, not all the channels are relevant and important to the target task. thus, in order to extract informative representations from multi-channel biosignals, channel awareness has become a key enabler for deep learning in biosignal processing and has attracted increasing research interest in health informatics. towards this end, we propose fusionatt-a deep fusional attention network that can learn channel-aware representations of multi-channel biosignals, while preserving complex correlations among all the channels. fusionatt is able to dynamically quantify the importance of each biomedical channel, and relies on more informative ones to enhance feature representation in an end-to-end manner. we empirically evaluated fusionatt in two clinical tasks: multi-channel seizure detection and multivariate sleep stage classification. experimental results showed that fusionatt consistently outperformed the state-of-the-art models in four different evaluation measurements, demonstrating the effectiveness of the proposed fusional attention mechanism.","['deep fusional attention networks', 'channel biomedical signals', 'multi', 'fusionatt']"
"accurate delineation of protein domain boundary plays an important role for protein engineering and structure prediction. although machine-learning methods are widely used to predict domain boundary, these approaches often ignore long-range interactions among residues, which have been proven to improve the prediction performance. however, how to simultaneously model the local and global interactions to further improve domain boundary prediction is still a challenging problem.","['predicting protein domain boundary', 'deep neural network', 'sequence alone', 'dom', 'dnn']"
"the implementation of deep learning (dl) techniques, object detection and classification has achieved remarkable results in remote sensing application. deep learning with recurrent neural network (rnn) technique on hyper-spectral data has been presented here. the only model which can analyze the hyper-spectral pixels as the sequence of information and also to identify the additional information categories through network reasoning is rnn model. this is first time that the framework of rnn has been introduced for the classification of hyper spectral image. an activation function is proposed by the dl-rnn and also the parameter rectified functions for analyzing the sequence of data in the hyper-spectral images. throughout the training procedure, the higher learning rates are fairly used by the activation function which has been proposed by avoiding the risk of divergence. in the proposed system the pixels of hyper-spectral images through the sequential perspective has been processed for capturing the sequence based data. the experimental result also shows that the proposed rnn has produced the improved f- score than the traditional deep learning methods.",['hyperspectral image features classification using deep learning recurrent neural networks']
"the human epidermal growth factor receptor 2 (her2) gene amplification status is a crucial marker for evaluating clinical therapies of breast or gastric cancer. we propose a deep learning-based pipeline for the detection, localization and classification of interphase nuclei depending on their her2 gene amplification state in fluorescence in situ hybridization (fish) images. our pipeline combines two retinanet-based object localization networks which are trained (1) to detect and classify interphase nuclei into distinct classes normal, low-grade and high-grade and (2) to detect and classify fish signals into distinct classes her2 or centromere of chromosome 17 (cen17). by independently classifying each nucleus twice, the two-step pipeline provides both robustness and interpretability for the automated detection of the her2 amplification status. the accuracy of our deep learning-based pipeline is on par with that of three pathologists and a set of 57 validation images containing several hundreds of nuclei are accurately classified. the automatic pipeline is a first step towards assisting pathologists in evaluating the her2 status of tumors using fish images, for analyzing fish images in retrospective studies, and for optimizing the documentation of each tumor sample by automatically annotating and reporting of the her2 gene amplification specificities.","['her2 gene amplification status', 'situ hybridization images', 'cancer tissues', 'automated detection', 'fluorescence', 'diagnostics']"
"deep learning-based image segmentation is by now firmly established as a robust tool in image segmentation. it has been widely used to separate homogeneous areas as the first and critical component of diagnosis and treatment pipeline. in this article, we present a critical appraisal of popular methods that have employed deep-learning techniques for medical image segmentation. moreover, we summarize the most common challenges incurred and suggest possible solutions.","['medical image segmentation', 'deep learning techniques', 'challenges', 'achievements']"
"recent studies showed agreement between how the human brain and neural networks represent objects, suggesting that we might start to understand the underlying computations. however, we know that the human brain is prone to biases at many perceptual and cognitive levels, often shaped by learning history and evolutionary constraints. here, we explore one such perceptual phenomenon, perceiving animacy, and use the performance of neural networks as a benchmark. we performed an fmri study that dissociated object appearance (what an object looks like) from object category (animate or inanimate) by constructing a stimulus set that includes animate objects (e.g., a cow), typical inanimate objects (e.g., a mug), and, crucially, inanimate objects that look like the animate objects (e.g., a cow mug). behavioral judgments and deep neural networks categorized images mainly by animacy, setting all objects (lookalike and inanimate) apart from the animate ones. in contrast, activity patterns in ventral occipitotemporal cortex (vtc) were better explained by object appearance: animals and lookalikes were similarly represented and separated from the inanimate objects. furthermore, the appearance of an object interfered with proper object identification, such as failing to signal that a cow mug is a mug. the preference in vtc to represent a lookalike as animate was even present when participants performed a task requiring them to report the lookalikes as inanimate. in conclusion, vtc representations, in contrast to neural networks, fail to represent objects when visual appearance is dissociated from animacy, probably due to a preferred processing of visual features typical of animate objects.significance statement how does the brain represent objects that we perceive around us? recent advances in artificial intelligence have suggested that object categorization and its neural correlates have now been approximated by neural networks. here, we show that neural networks can predict animacy according to human behavior but do not explain visual cortex representations. in ventral occipitotemporal cortex, neural activity patterns were strongly biased toward object appearance, to the extent that objects with visual features resembling animals were represented closely to real animals and separated from other objects from the same category. this organization that privileges animals and their features over objects might be the result of learning history and evolutionary constraints.","['ventral visual pathway represents animal appearance', 'unlike human behavior', 'deep neural networks', 'animacy']"
"magnetic resonance imaging (mri) has been widely used in combination with computed tomography (ct) radiation therapy because mri improves the accuracy and reliability of target delineation due to its superior soft tissue contrast over ct. the mri-only treatment process is currently an active field of research since it could eliminate systematic mr-ct co-registration errors, reduce medical cost, avoid diagnostic radiation exposure, and simplify clinical workflow. the purpose of this work is to validate the application of a deep learning-based method for abdominal synthetic ct (sct) generation by image evaluation and dosimetric assessment in a commercial proton pencil beam treatment planning system (tps). this study proposes to integrate dense block into a 3d cycle-consistent generative adversarial networks (cycle gan) framework in an effort to effectively learn the nonlinear mapping between mri and ct pairs. a cohort of 21 patients with co-registered ct and mr pairs were used to test the deep learning-based sct image quality by leave-one-out cross validation. the ct image quality, dosimetric accuracy and the distal range fidelity were rigorously checked, using side-by-side comparison against the corresponding original ct images. the average mean absolute error (mae) was 72.87\u2009\u2009±\u2009\u200918.16 hu. the relative differences of the statistics of the ptv dose volume histogram (dvh) metrics between sct and ct were generally less than 1%. mean 3d gamma analysis passing rate of 1\u2009mm/1%, 2\u2009mm/2%, 3\u2009mm/3% criteria with 10% dose threshold were 90.76%\u2009\u2009±\u2009\u20095.94%, 96.98%\u2009\u2009±\u2009\u20092.93% and 99.37%\u2009\u2009±\u2009\u20090.99%, respectively. the median, mean and standard deviation of absolute maximum range differences were 0.170\u2009cm, 0.186\u2009cm and 0.155\u2009cm. the image similarity, dosimetric and distal range agreement between sct and original ct suggests the feasibility of further development of an mri-only workflow for liver proton radiotherapy.","['based liver synthetic ct generation method', 'based treatment planning', 'proton radiotherapy', 'dosimetric validation', 'deep learning', 'mri']"
"it is crucial for doctors to fully understand the interaction between drugs in prescriptions, especially when a patient takes multiple medications at the same time during treatment. the purpose of drug drug interaction (ddi) extraction is to automatically obtain the interaction between drugs from biomedical literature. current state-of-the-art approaches for ddi extraction task are based on artificial intelligence and natural language processing. while such existing ddi extraction methods can provide more knowledge and enhance the performance through external resources such as biomedical databases or ontologies, due to the difficulty of updating, these external resources are delayed. in fact, user generated content (ugc) is another kind of external medical resources that can be quickly updated. we are trying to use ugc resources to provide more available information for our deep learning ddi extraction method. in this paper, we present a ddi extraction approach through a new attention mechanism called full-attention which can combine the ugc information with contextual information. we conducted a series of experiments on the ddi 2013 evaluation dataset to evaluate our method. experiments show improved performance compared with the state of the art and ugc-ddi model achieves a competitive f-score of 0.712.","['drug drug interaction extraction based', 'incorporating user generated content', 'full attention mechanism']"
"3d reconstruction of a targeted area (""safe"" triangle and kambin triangle) may benefit the viability assessment of transforaminal epidural steroid injection, especially at the l5/s1 level. however, manual segmentation of lumbosacral nerves for 3d reconstruction is time-consuming. the aim of this study was to investigate the feasibility of deep learning-based segmentation of lumbosacral nerves on ct and the reconstruction of the safe triangle and kambin triangle.","['based automatic segmentation', 'translational study', 'spinal intervention', 'lumbosacral nerves', 'deep learning', 'ct']"
"synthetic aperture radar (sar) scene classification is challenging but widely applied, in which deep learning can play a pivotal role because of its hierarchical feature learning ability. in the paper, we propose a new scene classification framework, named feature recalibration network with multi-scale spatial features (frn-msf), to achieve high accuracy in sar-based scene classification. first, a multi-scale omnidirectional gaussian derivative filter (msogdf) is constructed. then, multi-scale spatial features (msf) of sar scenes are generated by weighting msogdf, a gray level gradient co-occurrence matrix (glgcm) and gabor transformation. these features were processed by the feature recalibration network (frn) to learn high-level features. in the network, the depthwise separable convolution (dsc), squeeze-and-excitation (se) block and convolution neural network (cnn) are integrated. finally, these learned features will be classified by the softmax function. eleven types of sar scenes obtained from four systems combining different bands and resolutions were trained and tested, and a mean accuracy of 98.18% was obtained. to validate the generality of frn-msf, five types of sar scenes sampled from two additional large-scale gaofen-3 and terrasar-x images were evaluated for classification. the mean accuracy of the five types reached 94.56%; while the mean accuracy for the same five types of the former tested 11 types of scene was 96%. the high accuracy indicates that the frn-msf is promising for sar scene classification without losing generality.","['sar scene classification based', 'new deep learning algorithm', 'spatial statistical modeling', 'features', 'calibration']"
"the implementation of intelligent software to identify and classify objects and individuals in visual fields is a technology of growing importance to operatives in many fields, including wildlife conservation and management. to non-experts, the methods can be abstruse and the results mystifying. here, in the context of applying cutting edge methods to classify wildlife species from camera-trap data, we shed light on the methods themselves and types of features these methods extract to make efficient identifications and reliable classifications. the current state of the art is to employ convolutional neural networks (cnn) encoded within deep-learning algorithms. we outline these methods and present results obtained in training a cnn to classify 20 african wildlife species with an overall accuracy of 87.5% from a dataset containing 111,467 images. we demonstrate the application of a gradient-weighted class-activation-mapping (grad-cam) procedure to extract the most salient pixels in the final convolution layer. we show that these pixels highlight features in particular images that in some cases are similar to those used to train humans to identify these species. further, we used mutual information methods to identify the neurons in the final convolution layer that consistently respond most strongly across a set of images of one particular species. we then interpret the features in the image where the strongest responses occur, and present dataset biases that were revealed by these extracted features. we also used hierarchical clustering of feature vectors (i.e., the state of the final fully-connected layer in the cnn) associated with each image to produce a visual similarity dendrogram of identified species. finally, we evaluated the relative unfamiliarity of images that were not part of the training set when these images were one of the 20 species ""known"" to our cnn in contrast to images of the species that were ""unknown"" to our cnn.","['approaches using deep learning', 'classify wildlife', 'insights']"
"deep brain stimulation (dbs) is an established and effective treatment for several movement disorders and is being developed to treat a host of neuropsychiatric disorders including epilepsy, chronic pain, obsessive compulsive disorder, and depression. however, the neural mechanisms through which dbs produces therapeutic benefits, and in some cases unwanted side effects, in these disorders are only partially understood. non-invasive neuroimaging techniques that can assess the neural effects of active stimulation are important for advancing our understanding of the neural basis of dbs therapy. magnetoencephalography (meg) is a safe, passive imaging modality with relatively high spatiotemporal resolution, which makes it a potentially powerful method for examining the cortical network effects of dbs. however, the degree to which magnetic artifacts produced by stimulation and the associated hardware can be suppressed from meg data, and the comparability between signals measured during dbs-on and dbs-off conditions, have not been fully quantified. the present study used machine learning methods in conjunction with a visual perception task, which should be relatively unaffected by dbs, to quantify how well neural data can be salvaged from artifact contamination introduced by dbs and how comparable dbs-on and dbs-off data are after artifact removal. machine learning also allowed us to determine whether the spatiotemporal pattern of neural activity recorded during stimulation are comparable to those recorded when stimulation is off. the spatiotemporal patterns of visually evoked neural fields could be accurately classified in all 8 patients with dbs implants during both dbs-on and dbs-off conditions and performed comparably across those two conditions. further, the classification accuracy for classifiers trained on the spatiotemporal patterns evoked during dbs-on trials and applied to dbs-off trials, and vice versa, were similar to that of the classifiers trained and tested on either trial type, demonstrating the comparability of these patterns across conditions. together, these results demonstrate the ability of meg preprocessing techniques, like temporal signal space separation, to salvage neural data from recordings contaminated with dbs artifacts and validate meg as a powerful tool to study the cortical consequences of dbs.","['deep brain stimulation', 'artifact suppression techniques', 'quantitatively validating', 'cortical consequences', 'study', 'magnetoencephalography', 'efficacy']"
"【中文题目：基于深度学习的人工智能胸部ct肺结节检测效能评估】 【中文摘要：背景与目的 肺结节精确检测是实现肺癌早诊的基础。基于深度学习的人工智能在肺内结节检测领域发展迅速，对其效能进行验证是促进其应用于临床的前提。本研究旨在评估基于深度学习技术的人工智能软件在胸部计算机断层扫描（computed tomography, ct）恶性及非钙化结节检出中的价值。方法 由天津医科大学总医院自建胸部ct肺结节数据库中随机抽取200例胸部ct数据，包含病理证实的肺癌及随访结节病例，导入肺结节人工智能识别系统，记录软件自动识别结节，并与原始影像报告结果进行对比。人工智能软件及阅片者检测到的结节由2名胸部专家进行评估并记录其大小及特征。计算灵敏度、假阳性率评估人工智能软件及医师的结节检测效能，应用mcnemar检验确定二者之间是否存在显著性差异。结果 200例胸部多层螺旋ct共包含非钙化结节889枚，其中肺癌结节133枚，小于5 mm结节442枚。人工智能及放射科医师肺癌检出率皆为100%。人工智能软件结节检测灵敏度明显高于放射科医师（99.1% vs 43%, p<0.001）。人工智能总体假阳性率为每例ct 4.9个，排除5 mm以下结节后降为1.5个。结论 基于深度学习的人工智能软件能实现恶性肺结节的无漏诊检出，具有较医师更高的结节检出灵敏度，在排除微小结节后可降低假阳性率。\u2029】 【中文关键词：计算机体层成像；肺结节；深度学习；人工智能；检出】.","['chest ct ].', 'based artificial intelligence', 'pulmonary nodules', 'performance', 'learning', 'detection', 'deep']"
"each year in the united states, over 80 million people are affected by acne, atopic dermatitis, rosacea, psoriasis, and impetigo. artificial intelligence and machine learning could prove to be a good tool for assisting in the diagnosis of dermatological conditions. the objective of this study was to evaluate the use of data augmentation in machine learning image recognition of five dermatological disease manifestations-acne, atopic dermatitis, impetigo, psoriasis, and rosacea.","['dermatology image recognition using machine learning', 'data augmentation']"
"currently, many critical care indices are not captured automatically at a granular level, rather are repetitively assessed by overburdened nurses. in this pilot study, we examined the feasibility of using pervasive sensing technology and artificial intelligence for autonomous and granular monitoring in the intensive care unit (icu). as an exemplary prevalent condition, we characterized delirious patients and their environment. we used wearable sensors, light and sound sensors, and a camera to collect data on patients and their environment. we analyzed collected data to detect and recognize patient's face, their postures, facial action units and expressions, head pose variation, extremity movements, sound pressure levels, light intensity level, and visitation frequency. we found that facial expressions, functional status entailing extremity movement and postures, and environmental factors including the visitation frequency, light and sound pressure levels at night were significantly different between the delirious and non-delirious patients. our results showed that granular and autonomous monitoring of critically ill patients and their environment is feasible using a noninvasive system, and we demonstrated its potential for characterizing critical care patients and environmental factors.","['autonomous patient monitoring using pervasive sensing', 'intelligent icu', 'deep learning']"
"recent introduction of data-driven approaches based on deep-learning technology has revolutionized the field of nanophotonics by allowing efficient inverse design methods. in this paper, a simultaneous inverse design of materials and structure parameters of core-shell nanoparticles is achieved for the first time using deep learning of a neural network. a neural network to learn the correlation between the extinction spectra of electric and magnetic dipoles and core-shell nanoparticle designs, which include material information and shell thicknesses, is developed and trained. we demonstrate deep-learning-assisted inverse design of core-shell nanoparticles for (1) spectral tuning electric dipole resonances, (2) finding spectrally isolated pure magnetic dipole resonances, and (3) finding spectrally overlapped electric dipole and magnetic dipole resonances. our finding paves the way for the rapid development of nanophotonics by allowing a practical utilization of deep-learning technology for nanophotonic inverse design.","['dipole resonance engineering using core', 'structures via deep learning', 'simultaneous inverse design', 'shell nanoparticles', 'materials', 'demonstration']"
"social media use is now ubiquitous, but the growth in social media communications has also made it a convenient digital platform for drug dealers selling controlled substances, opioids, and other illicit drugs. previous studies and news investigations have reported the use of popular social media platforms as conduits for opioid sales. this study uses deep learning to detect illicit drug dealing on the image and video sharing platform instagram.","['model evaluation study', 'machine learning approach', 'illicit drug dealers', 'instagram', 'detection', 'characterization']"
"precise placement of needles is a challenge in a number of clinical applications such as brachytherapy or biopsy. forces acting at the needle cause tissue deformation and needle deflection which in turn may lead to misplacement or injury. hence, a number of approaches to estimate the forces at the needle have been proposed. yet, integrating sensors into the needle tip is challenging and a careful calibration is required to obtain good force estimates.","['temporal deep learning models', 'tip force estimation', 'needle insertion', 'spatio']"
"lung lobe segmentation in chest ct has been used for the analysis of lung functions and surgical planning. however, accurate lobe segmentation is difficult as 80% of patients have incomplete and/or fake fissures. furthermore, lung diseases such as chronic obstructive pulmonary disease (copd) can increase the difficulty of differentiating the lobar fissures. lobar fissures have similar intensities to those of the vessels and airway wall, which could lead to segmentation error in automated segmentation. in this study, a fully automated lung lobe segmentation method with 3d u-net was developed and validated with internal and external datasets. the volumetric chest ct scans of 196 normal and mild-to-moderate copd patients from three centers were obtained. each scan was segmented using a conventional image processing method and manually corrected by an expert thoracic radiologist to create gold standards. the lobe regions in the ct images were then segmented using a 3d u-net architecture with a deep convolutional neural network (cnn) using separate training, validation, and test datasets. in addition, 40 independent external ct images were used to evaluate the model. the segmentation results for both the conventional and deep learning methods were compared quantitatively to the gold standards using four accuracy metrics including the dice similarity coefficient (dsc), jaccard similarity coefficient (jsc), mean surface distance (msd), and hausdorff surface distance (hsd). in internal validation, the segmentation method achieved high accuracy for the dsc, jsc, msd, and hsd (0.97\xa0±\xa00.02, 0.94\xa0±\xa00.03, 0.69\xa0±\xa00.36, and 17.12\xa0±\xa011.07, respectively). in external validation, high accuracy was also obtained for the dsc, jsc, msd, and hsd (0.96\xa0±\xa00.02, 0.92\xa0±\xa00.04, 1.31\xa0±\xa00.56, and 27.89\xa0±\xa07.50, respectively). this method took 6.49\xa0±\xa01.19\xa0s and 8.61\xa0±\xa01.08\xa0s for lobe segmentation of the left and right lungs, respectively. although various automatic lung lobe segmentation methods have been developed, it is difficult to develop a robust segmentation method. however, the deep learning-based 3d u-net method showed reasonable segmentation accuracy and computational time. in addition, this method could be adapted and applied to severe lung diseases in a clinical workflow.","['fully automated lung lobe segmentation', 'volumetric chest ct', '3d u', 'validation', 'net', 'intra', 'extra', 'datasets']"
"shadow detection and shadow removal are fundamental and challenging tasks, requiring an understanding of the global image semantics. this paper presents a novel deep neural network design for shadow detection and removal by analyzing the spatial image context in a direction-aware manner. to achieve this, we first formulate the direction-aware attention mechanism in a spatial recurrent neural network (rnn) by introducing attention weights when aggregating spatial context features in the rnn. by learning these weights through training, we can recover direction-aware spatial context (dsc) for detecting and removing shadows. this design is developed into the dsc module and embedded in a convolutional neural network to learn the dsc features at different levels. moreover, we design a weighted cross entropy loss to make effective the training for shadow detection and further adopt the network for shadow removal by using a euclidean loss function and formulating a color transfer function to address the color and luminosity inconsistencies in the training pairs. we employed two shadow detection benchmark datasets and two shadow removal benchmark datasets, and performed various experiments to evaluate our method. experimental results show that our method performs favorably against the state-of-the-art methods for both shadow detection and shadow removal.","['aware spatial context features', 'shadow detection', 'removal', 'direction']"
"many studies have explored the relationship between housing prices and environmental characteristics using the hedonic price model (hpm). however, few studies have deeply examined the impact of scene perception near residential units on housing prices. this article used house purchasing records from fang.com and open access geolocation data (including massive street view pictures, point of interest (poi) data and road network data) and proposed a framework named ""open-access-dataset-based hedonic price modeling (oadb-hpm)"" for comprehensive analysis in beijing and shanghai, china. a state-of-the-art deep learning framework and massive baidu street view panoramas were employed to visualize and quantify three major scene perception characteristics (greenery, sky and building view indexes, abbreviated gvi, svi and bvi, respectively) at the street level. then, the newly introduced scene perception characteristics were combined with other traditional characteristics in the hpm to calculate marginal prices, and the results for beijing and shanghai were explored and compared. the empirical results showed that the greenery and sky perceptual elements at the property level can significantly increase the housing price in beijing (rmb 39,377 and 6011, respectively) and shanghai (rmb 21,689 and 2763, respectively), indicating an objectively higher willingness by buyers to pay for houses that provide the ability to perceive natural elements in the surrounding environment. this study developed quantification tools to help decision makers and planners understand and analyze the interaction between residents and urban scene components.","['level scene perceptions affect housing prices', 'analysis using open access datasets', 'deep learning', 'chinese megacities', 'street']"
"machine learning has several potential uses in medical imaging for semantic labeling of images to improve radiologist workflow and to triage studies for review. the purpose of this study was to (1) develop deep convolutional neural networks (dcnns) for automated classification of 2d mammography views, determination of breast laterality, and assessment and of breast tissue density; and (2) compare the performance of dcnns on these tasks of varying complexity to each other. we obtained 3034 2d-mammographic images from the digital database for screening mammography, annotated with mammographic view, image laterality, and breast tissue density. these images were used to train a dcnn to classify images for these three tasks. the dcnn trained to classify mammographic view achieved receiver-operating-characteristic (roc) area under the curve (auc) of 1. the dcnn trained to classify breast image laterality initially misclassified right and left breasts (auc 0.75); however, after discontinuing horizontal flips during data augmentation, auc improved to 0.93 (p\xa0<\u20090.0001). breast density classification proved more difficult, with the dcnn achieving 68% accuracy. automated semantic labeling of 2d mammography is feasible using dcnns and can be performed with small datasets. however, automated classification of differences in breast density is more difficult, likely requiring larger datasets.","['based semantic labeling', 'machine learning tasks', '2d mammography', 'learning', 'deep', 'complexity', 'comparison']"
"training deep models of video recognition usually requires sufficient labeled videos in order to achieve good performance without over-fitting. however, it is quite labor-intensive and time-consuming to collect and annotate a large amount of videos. moreover, training deep neural networks on large-scale video datasets always demands huge computational resources which further hold back many researchers and practitioners. to resolve that, collecting and training on annotated images are much easier. however, thoughtlessly applying images to help recognize videos may result in noticeable performance degeneration due to the well-known domain shift and feature heterogeneity. this proposes a novel symmetric adversarial learning approach for heterogeneous image-to-video adaptation, which augments deep image and video features by learning domain-invariant representations of source images and target videos. primarily focusing on an unsupervised scenario where the labeled source images are accompanied by unlabeled target videos in the training phrase, we present a data-driven approach to respectively learn the augmented features of images and videos with superior transformability and distinguishability. starting with learning a common feature space (called image-frame feature space) between images and video frames, we then build new symmetric generative adversarial networks (sym-gans) where one gan maps image-frame features to video features and the other maps video features to image-frame features. using the sym-gans, the source image feature is augmented with the generated video-specific representation to capture the motion dynamics while the target video feature is augmented with the image-specific representation to take the static appearance information. finally, the augmented features from the source domain are fed into a network with fully connected layers for classification. thanks to an end-to-end training procedure of the sym-gans and the classification network, our approach achieves better results than other state-of-the-arts, which is clearly validated by experiments on two video datasets, i.e., the ucf101 and hmdb51 datasets.","['heterogeneous feature augmentation via symmetric adversarial learning', 'video recognition', 'exploiting images']"
"the use of neural networks to predict molecular properties calculated from high level quantum mechanical calculations has made significant advances in recent years, but most models need input geometries from dft optimizations which limit their applicability in practice. in this work, we explored how machine learning can be used to predict molecular atomization energies and conformation stability using optimized geometries from merck molecular force field (mmff). on the basis of the recently introduced deep tensor neural network (dtnn) approach, we first improved its training efficiency and performed an extensive search of its hyperparameters, and developed a dtnn_7ib model which has a test accuracy of 0.34 kcal/mol mean absolute error (mae) on qm9 data set. then using atomic vector representations in the dtnn_7ib model, we employed transfer learning (tl) strategy to train readout layers on the qm9m data set, in which qm properties are the same as in qm9 [calculated at the b3lyp/6-31g(2df,p) leve","['molecular energy prediction using mmff geometries', 'improved deep tensor neural network', 'predicting molecular energy using force', 'mol using mmff optimized geometries', 'deep tensor neural network', 'corresponding local minima optimized', 'emol9_cm conformation data set', 'atomic vector representations learned', 'molecular energy prediction', 'achieved using force', 'field optimized geometries', 'ile molecular geometries', 'molecular conformation analysis', 'atomic vector representation', 'integrated molecular modeling', 'mmff94 force field', 'transfer learning strategy', 'powerful computational tools', 'machine learning would', 'machine learning model']"
few studies have proposed alternative salvage methods of deep brain stimulation (dbs) intracranial lead once the infection has already occurred.,"['deep brain stimulation hardware infection', 'antibiotic impregnated catheter coating technique', 'avoid intracranial lead removal', 'effective method']"
"the histological analysis of tissue samples, widely used for disease diagnosis, involves lengthy and laborious tissue preparation. here, we show that a convolutional neural network trained using a generative adversarial-network model can transform wide-field autofluorescence images of unlabelled tissue sections into images that are equivalent to the bright-field images of histologically stained versions of the same samples. a blind comparison, by board-certified pathologists, of this virtual staining method and standard histological staining using microscopic images of human tissue sections of the salivary gland, thyroid, kidney, liver and lung, and involving different types of stain, showed no major discordances. the virtual-staining method bypasses the typically labour-intensive and costly histological staining procedures, and could be used as a blueprint for the virtual staining of tissue images acquired with other label-free imaging modalities.","['autofluorescence images via deep learning', 'virtual histological staining', 'unlabelled tissue']"
"the worldwide utilization of surveillance cameras in smart cities has enabled researchers to analyze a gigantic volume of data to ensure automatic monitoring. an enhanced security system in smart cities, schools, hospitals, and other surveillance domains is mandatory for the detection of violent or abnormal activities to avoid any casualties which could cause social, economic, and ecological damages. automatic detection of violence for quick actions is very significant and can efficiently assist the concerned departments. in this paper, we propose a triple-staged end-to-end deep learning violence detection framework. first, persons are detected in the surveillance video stream using a light-weight convolutional neural network (cnn) model to reduce and overcome the voluminous processing of useless frames. second, a sequence of 16 frames with detected persons is passed to 3d cnn, where the spatiotemporal features of these sequences are extracted and fed to the softmax classifier. furthermore, we optimized the 3d cnn model using an open visual inference and neural networks optimization toolkit developed by intel, which converts the trained model into intermediate representation and adjusts it for optimal execution at the end platform for the final prediction of violent activity. after detection of a violent activity, an alert is transmitted to the nearest police station or security department to take prompt preventive actions. we found that our proposed method outperforms the existing state-of-the-art methods for different benchmark datasets.","['violence detection using spatiotemporal features', '3d convolutional neural network']"
"the need for robust unsupervised anomaly detection in streaming data is increasing rapidly in the current era of smart devices, where enormous data are gathered from numerous sensors. these sensors record the internal state of a machine, the external environment, and the interaction of machines with other machines and humans. it is of prime importance to leverage this information in order to minimize downtime of machines, or even avoid downtime completely by constant monitoring. since each device generates a different type of streaming data, it is normally the case that a specific kind of anomaly detection technique performs better than the others depending on the data type. for some types of data and use-cases, statistical anomaly detection techniques work better, whereas for others, deep learning-based techniques are preferred. in this paper, we present a novel anomaly detection technique, fusead, which takes advantage of both statistical and deep-learning-based approaches by fusing them together in a residual fashion. the obtained results show an increase in area under the curve (auc) as compared to state-of-the-art anomaly detection methods when fusead is tested on a publicly available dataset (yahoo webscope benchmark). the obtained results advocate that this fusion-based technique can obtain the best of both worlds by combining their strengths and complementing their weaknesses. we also perform an ablation study to quantify the contribution of the individual components in fusead, i.e., the statistical arima model as well as the deep-learning-based convolutional neural network (cnn) model.","['unsupervised anomaly detection', 'streaming sensors data', 'deep learning models', 'fusing statistical', 'fusead']"
"in this paper, we propose deeply supervised object detectors (dsod), an object detection framework that can be trained from scratch. recent advances in object detection heavily depend on the off-the-shelf models pre-trained on large-scale classification datasets like imagenet and openimage. however, one problem is that adopting pre-trained models from classification to detection task may incur learning bias due to the different objective function and diverse distributions of object categories. techniques like fine-tuning on detection task could alleviate this issue to some extent but are still not fundamental. furthermore, transferring these pre-trained models across discrepant domains will be more difficult (e.g., from rgb to depth images). thus, a better solution to handle these critical problems is to train object detectors from scratch, which motivates our proposed method. previous efforts on this direction mainly failed by reasons of the limited training data and naive backbone network structures for object detection. in dsod, we contribute a set of design principles for learning object detectors from scratch. one of the key principles is the deep supervision, enabled by layer-wise dense connections in both backbone networks and prediction layers, plays a critical role in learning good detectors from scratch. after involving several other principles, we build our dsod based on the single-shot detection framework (ssd). we evaluate our method on pascal voc 2007, 2012 and coco datasets. dsod achieves consistently better results than the state-of-the-art methods with much more compact models. specifically, dsod outperforms baseline method ssd on all three benchmarks, while requiring only 1/2 parameters. we also observe that dsod can achieve comparable/slightly better results than mask rcnn [","['similar input siz', 'fpn', '2']"
"the breast imaging reporting and data system (bi-rads) lexicon was developed to standardize mammographic reporting to assess cancer risk and facilitate the decision to biopsy. because of substantial interobserver variability in the application of the bi-rads lexicon, the decision to biopsy varies greatly and results in overdiagnosis and excessive biopsies. the false-positive rate from mammograms is estimated to be 7% to approximately 10% overall, but within the bi-rads 4 category, it is greater than 70%. therefore, we developed the breast cancer risk calculator (brisk) to target a well-characterized and specific patient subgroup (bi-rads 4) rather than a broad heterogeneous group in assessing breast cancer risk.","['based decision support tool', 'precision risk assessment', 'deep learning', 'breast cancer']"
"introduction: drug discovery is the process through which potential new compounds are identified by means of biology, chemistry, and pharmacology. due to the high complexity of genomic data, ai techniques are increasingly needed to help reduce this and aid the adoption of optimal decisions. phenotypic prediction is of particular use to drug discovery and precision medicine where sets of genes that predict a given phenotype are determined. phenotypic prediction is an undetermined problem given that the number of monitored genetic probes markedly exceeds the number of collected samples (from patients). this imbalance creates ambiguity in the characterization of the biological pathways that are responsible for disease development. areas covered: in this paper, the authors present ai methodologies that perform a robust deep sampling of altered genetic pathways to locate new therapeutic targets, assist in drug repurposing and speed up and optimize the drug selection process. expert opinion: ai is a potential solution to a number of drug discovery problems, though one should, bear in mind that the quality of data predicts the overall quality of the prediction, as in any modeling task in data science. the use of transparent methodologies is crucial, particularly in drug repositioning/repurposing in rare diseases.","['using artificial intelligence methods', 'drug discovery', 'speed']"
to clarify ct diagnostic performance in extranodal extension of cervical lymph node metastases using deep learning classification.,"['oral squamous cell carcinoma using deep learning classification', 'cervical lymph node metastases', 'extranodal extension', 'ct evaluation', 'patients']"
"deep learning techniques have been successfully applied to bioimaging problems; however, these methods are highly data demanding. an approach to deal with the lack of data and avoid overfitting is the application of data augmentation, a technique that generates new training samples from the original dataset by applying different kinds of transformations. several tools exist to apply data augmentation in the context of image classification, but it does not exist a similar tool for the problems of localization, detection, semantic segmentation or instance segmentation that works not only with 2 dimensional images but also with multi-dimensional images (such as stacks or videos).","['instance segmentation tasks', 'semantic segmentation', 'tool', 'localization', 'detection', 'clodsa', 'classification', 'augmentation']"
"the computational identification of peptides that can bind the major histocompatibility complex (mhc) with high affinity is an essential step in developing personal immunotherapies and vaccines. we introduce puffin, a deep residual network-based computational approach that quantifies uncertainty in peptide-mhc affinity prediction that arises from observational noise and the lack of relevant training examples. with puffin's uncertainty metrics, we define binding likelihood, the probability a peptide binds to a given mhc allele at a specified affinity threshold. compared to affinity point estimates, we find that binding likelihood correlates better with the observed affinity and reduces false positives in\xa0high-affinity peptide design. when applied to examine an existing peptide vaccine, puffin identifies an alternative vaccine formulation with higher binding likelihood. puffin is freely available for download at http://github.com/gifford-lab/puffin.","['mhc binding prediction improves high', 'affinity peptide selection', 'therapeutic design', 'peptide', 'uncertainty', 'quantification']"
"aspect-level sentiment analysis is a crucial problem in fine-grained sentiment analysis, which aims to automatically predict the sentiment polarity of the specific aspect in its context. although remarkable progress has been made by deep learning based methods, aspect-level sentiment classification in real-world remains a challenging task. the human reading cognition is rarely explored in sentiment classification, which however is able to improve the effectiveness of the sentiment classification by considering the process of reading comprehension and logical thinking. motivated by the process of the human reading cognition that follows a hierarchical routine, we propose a novel hierarchical human-like strategy for aspect-level sentiment classification (hhas). the model contains three major components, a sentiment-aware mutual attention module, an aspect-specific knowledge distillation module, and a reinforcement learning based re-reading module, which are consistent with the stages of the human reading cognitive process (i.e., pre-reading, active reading, and post-reading). to measure the effectiveness of hhas, extensive experiments are conducted on three widely used datasets. experimental results demonstrate that hhas achieves impressive results and yields state-of-the-art results on the three datasets.","['sentiment linguistic knowledge', 'level sentiment classification', 'reinforcement learning', 'like strategy', 'hierarchical human', 'aspect']"
"in this paper, we address the hyperspectral image (hsi) classification task with a generative adversarial network and conditional random field (gan-crf)-based framework, which integrates a semisupervised deep learning and a probabilistic graphical model, and make three contributions. first, we design four types of convolutional and transposed convolutional layers that consider the characteristics of hsis to help with extracting discriminative features from limited numbers of labeled hsi samples. second, we construct semisupervised generative adversarial networks (gans) to alleviate the shortage of training samples by adding labels to them and implicitly reconstructing real hsi data distribution through adversarial training. third, we build dense conditional random fields (crfs) on top of the random variables that are initialized to the softmax predictions of the trained gans and are conditioned on hsis to refine classification maps. this semisupervised framework leverages the merits of discriminative and generative models through a game-theoretical approach. moreover, even though we used very small numbers of labeled training hsi samples from the two most challenging and extensively studied datasets, the experimental results demonstrated that spectral-spatial gan-crf (ss-gan-crf) models achieved top-ranking accuracy for semisupervised hsi classification.","['hyperspectral image classification', 'generative adversarial networks', 'conditional random fields']"
"glioma is one of the most common and aggressive brain tumors. segmentation and subsequent quantitative analysis of brain tumor mri are routine and crucial for treatment. due to the time-consuming and tedious manual segmentation, automatic segmentation methods are required for accurate and timely treatment. recently, segmentation methods based on deep learning are popular because of their self-learning and generalization ability. therefore, we propose a novel automatic 3d cnn-based method for brain tumor segmentation. in order to better capture the contextual information, we design the network architecture based on u-net and replace the simple skip connection with encoder adaptation blocks. to further improve the performance and reduce computational burden at the same time, we also use dense connected fusion blocks in decoder. we train our model with generalised dice loss function to alleviate the problem of class imbalance. the proposed model is evaluated on the brats 2015 testing dataset and obtains dice scores of 0.84, 0.72 and 0.62 for whole tumor, tumor core and enhancing tumor, respectively. our model is accurate and efficient, achieving results that comparable to the reported state-of-the-art results.","['dense residual refine networks', 'automatic brain tumor segmentation', 'drrnet']"
"the interpretation and analysis of wireless capsule endoscopy (wce) recordings is a complex task which requires sophisticated computer aided decision (cad) systems to help physicians with video screening and, finally, with the diagnosis. most cad systems used in capsule endoscopy share a common system design, but use very different image and video representations. as a result, each time a new clinical application of wce appears, a new cad system has to be designed from the scratch. this makes the design of new cad systems very time consuming. therefore, in this paper we introduce a system for small intestine motility characterization, based on deep convolutional neural networks, which circumvents the laborious step of designing specific features for individual motility events. experimental results show the superiority of the learned features over alternative classifiers constructed using state-of-the-art handcrafted features. in particular, it reaches a mean classification accuracy of 96% for six intestinal motility events, outperforming the other classifiers by a large margin (a 14% relative performance increase).","['wireless capsule endoscopy analysis', 'generic feature learning']"
"the medical image analysis field has traditionally been focused on the development of organ-, and disease-specific methods. recently, the interest in the development of more comprehensive computational anatomical models has grown, leading to the creation of multi-organ models. multi-organ approaches, unlike traditional organ-specific strategies, incorporate inter-organ relations into the model, thus leading to a more accurate representation of the complex human anatomy. inter-organ relations are not only spatial, but also functional and physiological. over the years, the strategies proposed to efficiently model multi-organ structures have evolved from the simple global modeling, to more sophisticated approaches such as sequential, hierarchical, or machine learning-based models. in this paper, we present a review of the state of the art on multi-organ analysis and associated computation anatomy methodology. the manuscript follows a methodology-based classification of the different techniques available for the analysis of multi-organs and multi-anatomical structures, from techniques using point distribution models to the most recent deep learning-based approaches. with more than 300 papers included in this review, we reflect on the trends and challenges of the field of computational anatomy, the particularities of each anatomical region, and the potential of multi-organ analysis to increase the impact of medical imaging applications on the future of healthcare.","['organ analysis', 'medical imaging', 'computational anatomy', 'review', 'multi']"
"cancer is a well-known killer of human beings, which has led to countless deaths and misery. anticancer peptides open a promising perspective for cancer treatment, and they have various attractive advantages. conventional wet experiments are expensive and inefficient for finding and identifying novel anticancer peptides. there is an urgent need to develop a novel computational method to predict novel anticancer peptides. in this study, we propose a deep learning long short-term memory (lstm) neural network model, acp-dl, to effectively predict novel anticancer peptides. more specifically, to fully exploit peptide sequence information, we developed an efficient feature representation approach by integrating binary profile feature and k-mer sparse matrix of the reduced amino acid alphabet. then we implemented a deep lstm model to automatically learn how to identify anticancer peptides and non-anticancer peptides. to our knowledge, this is the first time that the deep lstm model has been applied to predict anticancer peptides. it was demonstrated by cross-validation experiments that the proposed acp-dl remarkably outperformed other comparison methods with high accuracy and satisfied specificity on benchmark datasets. in addition, we also contributed two new anticancer peptides benchmark datasets, acp740 and acp240, in this work. the source code and datasets are available at https://github.com/haichengyi/acp-dl.","['predict anticancer peptides using high', 'deep learning long short', 'term memory model', 'efficiency feature representation', 'dl', 'acp']"
"predicting one-dimensional structure properties has played an important role to improve prediction of protein three-dimensional structures and functions. the most commonly predicted properties are secondary structure and accessible surface area (asa) representing local and nonlocal structural characteristics, respectively. secondary structure prediction is further complemented by prediction of continuous main-chain torsional angles. here we describe a newly developed method spider2 that utilizes three iterations of deep learning neural networks to improve the prediction accuracy of several structural properties simultaneously. for an independent test set of 1199 proteins spider2 achieves 82 % accuracy for secondary structure prediction, 0.76 for the correlation coefficient between predicted and actual solvent accessible surface area, 19° and 30° for mean absolute errors of backbone φ and ψ angles, respectively, and 8° and 32° for mean absolute errors of cα-based θ and τ angles, respectively. the method provides state-of-the-art, all-in-one accurate prediction of local structure and solvent accessible surface area. the method is implemented, as a webserver along with a standalone package that are available in our website: http://sparks-lab.org .","['predict secondary structure', 'deep neural networks', 'chain torsional angles', 'accessible surface area', 'spider2', 'package', 'main']"
"*machines that dream, the restless impulse for technical change that has marked radiology from its beginning and forays into deep neural networks, will no doubt unsettle long-held institu- tional practices in radiology. *a willingness to collaborate and puzzle through machine intelligence has come from those who have not accepted the status quo. a certain form of scientific curiosity has been a guiding principle in their work. *in radiology, machine intelligence has been extremely useful and built into just about every major technical innovation. but it has only been the last several years that a subfield of al, machine learning, has begun to show remarkably fast development due to faster comput- er processing capabilities and advanced modeling and results emerging from the application of deep learning.","['part 1', 'diagnostic imagination', 'radiology']"
"recent advances in deep neural networks (dnns) owe their success to training algorithms that use backpropagation and gradient-descent. backpropagation, while highly effective on von neumann architectures, becomes inefficient when scaling to large networks. commonly referred to as the weight transport problem, each neuron's dependence on the weights and errors located deeper in the network require exhaustive data movement which presents a key problem in enhancing the performance and energy-efficiency of machine-learning hardware. in this work, we propose a bio-plausible alternative to backpropagation drawing from advances in feedback alignment algorithms in which the error computation at a single synapse reduces to the product of three scalar values. using a sparse feedback matrix, we show that a neuron needs only a fraction of the information previously used by the feedback alignment algorithms. consequently, memory and compute can be partitioned and distributed whichever way produces the most efficient forward pass so long as a single error can be delivered to each neuron. we evaluate our algorithm using standard datasets, including imagenet, to address the concern of scaling to challenging problems. our results show orders of magnitude improvement in data movement and 2× improvement in multiply-and-accumulate operations over backpropagation. like previous work, we observe that any variant of feedback alignment suffers significant losses in classification accuracy on deep convolutional neural networks. by transferring trained convolutional layers and training the fully connected layers using direct feedback alignment, we demonstrate that direct feedback alignment can obtain results competitive with backpropagation. furthermore, we observe that using an extremely sparse feedback matrix, rather than a dense one, results in a small accuracy drop while yielding hardware advantages. all the code and results are available under https://github.com/bcrafton/ssdfa.","['direct feedback alignment', 'sparse connections', 'local learning']"
"advances in machine learning and deep learning methods, together with the increasing availability of large-scale pharmacological, genomic, and chemical datasets, have created opportunities for identifying potentially useful relationships within biochemical networks. knowledge embedding models have been found to have value in detecting knowledge-based correlations among entities, but little effort has been made to apply them to networks of biochemical entities. this is because such networks tend to be unbalanced and sparse, and knowledge embedding models do not work well on them. however, to some extent, the shortcomings of knowledge embedding models can be compensated for if they are used in association with graph embedding. in this paper, we combine knowledge embedding and graph embedding to represent biochemical entities and their relations as dense and low-dimensional vectors. we build a cascade learning framework which incorporates semantic features from the knowledge embedding model, and graph features from the graph embedding model, to score the probability of linking. the proposed method performs noticeably better than the models with which it is compared. it predicted links and entities with an accuracy of 93%, and its average hits@10 score has an average of 8.6% absolute improvement compared with original knowledge embedding model, 1.1% to 9.7% absolute improvement compared with other knowledge and graph embedding algorithm. in addition, we designed a meta-path algorithm to detect path relations in the biomedical network. case studies further verify the value of the proposed model in finding potential relationships between diseases, drugs, genes, treatments, etc. amongst the findings of the proposed model are the suggestion that vdr (vitamin d receptor) may be linked to prostate cancer. this is backed by evidence from medical databases and published research, supporting the suggestion that our proposed model could be of value to biomedical researchers.","['predicting biomedical relationships using', 'graph embedding cascade model', 'knowledge']"
"almost all protein residue contact prediction methods rely on the availability of deep multiple sequence alignments (msas). however, many proteins from the poorly populated families do not have sufficient number of homologs in the conventional uniprot database. here we aim to solve this issue by exploring the rich sequence data from the metagenome sequencing projects.","['protein contact prediction using metagenome sequence data', 'residual neural networks']"
"collective activity recognition, which tells what activity a group of people is performing, is a cutting-edge research topic in computer vision. different from action performed by individuals, collective activity needs to consider the complex interactions among different people. however, most previous works require exhaustive annotations such as accurate label information of individual actions, pairwise interactions, and poses, which could not be easily available in practice. moreover, most of them treat human detection as a decoupled task before collective activity recognition and leverage all detected persons. this not only ignores the mutual relation between the two tasks, which makes it hard for filtering out irrelevant people, but also probably increases the computation burden when reasoning the collective activities. in this paper, we propose a fast weakly supervised deep learning architecture for collective activity recognition. for fast inference, we propose to make the actor detection and weakly supervised collective activity reasoning collaborate in an end-to-end framework by sharing convolutional layers between them. the joint learning makes the two tasks united and reinforced each other, so that it is more effective to filter out the outliers who are not involved in the activity. for the weakly supervised learning, we propose a latent embedding scheme for mining person-group interactive relationship to get rid of the use of any pairwise relation between people and the individual action labels as well. the experimental results show that the proposed framework achieves comparable or even better performance as compared to the state-of-the-art on three datasets. our joint modelling reasons collective activities at the speed of 22.65 fps, which is the fastest ever known and substantially makes collective activity recognition more towards real-time applications.","['fast collective activity recognition', 'weak supervision']"
"accurate monitoring of the depth of anesthesia (doa) is essential for intraoperative and postoperative patient's health. commercially available electroencephalograph (eeg)-based doa monitors are recommended only for certain anesthetic drugs and specific age-group patients. this paper presents a machine learning classification processor for accurate doa estimation irrespective of the patient's age and anesthetic drug. the classification is solely based on six features extracted from eeg signal, i.e., spectral edge frequency (sef), beta ratio, and four bands of spectral energy (fbse). a machine learning fine decision tree classifier is adopted to achieve a four-class doa classification (deep, moderate, and light doa versus awake state). the feature selection and the classification processor are optimized to achieve the highest classification accuracy for the state of moderate anesthesia required for the surgical operations. the proposed 256-point fast fourier transform accelerator is implemented to realize sef, beta ratio, and fbse that enables minimal latency and high accuracy feature extraction. the proposed doa processor is implemented using a 65 nm cmos technology and experimentally verified using field programming gate array (fpga) based on the eeg recordings of 75 patients undergoing elective surgery with different types of anesthetic agents. the processor achieves an average accuracy of 92.2% for all doa states, with a latency of 1s the 0.09 mm2 doa processor consumes 140nj/classification.","['machine learning based eeg processor', 'accurate estimation', 'implementation', 'design', 'depth', 'anesthesia']"
"clinical trials, prospective research studies on human participants carried out by a distributed team of clinical investigators, play a crucial role in the development of new treatments in health care. this is a complex and expensive process where investigators aim to enroll volunteers with predetermined characteristics, administer treatment(s), and collect safety and efficacy data. therefore, choosing top-enrolling investigators is essential for efficient clinical trial execution and is 1 of the primary drivers of drug development cost.",['optimizing clinical trials recruitment via deep learning']
"lung densitometry is being frequently adopted in ct-based emphysema quantification, yet known to be affected by the choice of reconstruction kernel. this study presents a two-step deep learning architecture that enables accurate normalization of reconstruction kernel effects on emphysema quantification in low-dose ct. deep learning is used to convert a ct image of a sharp kernel to that of a standard kernel with restoration of truncation artifacts and smoothing-free pixel size normalization. we selected 353 scans reconstructed by both standard and sharp kernels from four different ct scanners from the united states national lung screening trial program database. a truncation artifact correction model was constructed with a combination of histogram extrapolation and a deep learning model trained with truncated and non-truncated image sets. then, we performed frequency domain zero-padding to normalize reconstruction field of view effects while preventing image smoothing effects. the kernel normalization model has a u-net based architecture trained for each ct scanner dataset. three lung density measurements including relative lung area under 950 hu (ra950), lower 15th percentile threshold (perc15), and mean lung density were obtained in the datasets from standard, sharp, and normalized kernels. the effect of kernel normalization was evaluated with pair-wise differences in lung density metrics. the mean of pair-wise differences in ra950 between standard and sharp kernel reconstructions was reduced from 10.75% to\u2009\u2009-0.07% using kernel normalization. the difference for perc15 decreased from\u2009\u2009-31.03 hu to\u2009\u2009-0.30 hu after kernel normalization. our study demonstrated the feasibility of applying deep learning techniques for normalizing ct kernel effects, thereby reducing the kernel-induced variability in lung density measurements. the deep learning model could increase the accuracy of emphysema quantification, thereby allowing reliable surveillance of emphysema in lung cancer screening even when follow-up ct scans are acquired with different reconstruction kernels.","['reconstruction kernel effects', 'enabled accurate normalization', 'emphysema quantification', 'dose ct', 'deep learning', 'low']"
"the fast identification and quantification of illicit drugs in biofluids are of great significance in clinical detection. however, existing drug detection strategies cannot fully meet clinical needs, and the on-site identification and quantification of various illicit drugs in biofluids remain a great challenge. here, we report the development of a deep learning-assisted three-dimensional (3d) fluorescence difference spectroscopy for rapid identification and semiquantification of illicit drugs in biofluids. this strategy introduces highly fluorescent silver nanoclusters into the biofluids with illicit drugs as signal sources. the interaction between silver nanoclusters and drug molecules changed the fluorescence performance of the mixture. deep learning methods were applied to grasp the subtle fingerprint information from the 3d fluorescence difference spectra to identify and semiquantify various illicit drugs in biofluids, including codeine, 4,5-methylene-dioxy amphetamine, 3,4-methylene dioxy methamphetamine, meperidine, and methcathinone. this approach can achieve a high prediction accuracy rate of 88.07% and a broad detection range from 2 μg/ml to 100 mg/ml. it opens up a new way for the detection of small molecules with or without fluorescence in complicated matrixes.","['dimensional fluorescence difference spectroscopy', 'illicit drugs', 'deep learning', 'assisted three', 'semiquantification', 'identification', 'biofluids']"
"we present in this paper the application of deep convolutional neural networks (cnns), which is a state-of-the-art artificial intelligence (ai) approach in machine learning, for automated time-independent prediction of burn depth. color images of four types of burn depth injured in first few days, including normal skin and background, acquired by a tivi camera were trained and tested with four pretrained deep cnns: vgg-16, googlenet, resnet-50, and resnet-101. in the end, the best 10-fold cross-validation results obtained from resnet-101 with an average, minimum, and maximum accuracy are 81.66, 72.06, and 88.06%, respectively; and the average accuracy, sensitivity, and specificity for the four different types of burn depth are 90.54, 74.35, and 94.25%, respectively. the accuracy was compared with the clinical diagnosis obtained after the wound had healed. hence, application of ai is very promising for prediction of burn depth and, therefore, can be a useful tool to help in guiding clinical decision and initial treatment of burn wounds.","['burn depth using deep convolutional neural networks', 'independent prediction', 'time']"
"currently, single fault diagnosis has received mass concern, and the related research achievements are remarkable. however, because of the mutual interaction of subsystems and the coupling of faults characteristics, the diagnosis of multiple intermittent faults commonly existing in industrial systems is still an intractable problem. in order to solve the problem, an improved constrained sparse autoencoder integrated with correlation analysis (ca-csae) is proposed, further, a diagnosis scheme for multiple intermittent faults is formulated in this paper. the main strategies are as follows. (1) an adaptive loss function and a constraint for initial weight are designed to improve the diversity and accuracy of sae feature learning. (2) a relational constraint term is constructed to mitigate the effect of data correlation. (3) the evaluation criterion of data correlation degree is put forward to quantify the scope of the method. (4) in order to improve the diagnostic efficiency, relu is introduced as the activation function of hidden layer, and l-bfgs algorithm is employed to obtain the optimal solution. (5) softmax classifier is employed as the output layer to identify fault mode and ensure the reliability of diagnosis results. finally, comparison experiments and results analysis are conducted to verify the effectiveness and practicability of the proposed method.","['multiple intermittent faults diagnosis', 'deep model integrated', 'data correlation analysis']"
"aging and time are interconnected because aging is basically living seen in a temporal perspective. this makes 'time' an important concept in trying to explain aging. however, throughout modernity time has increasingly been identified as clock time: perfectly fit to measure 'age' as time since birth but failing to explain 'age' as an indicator of aging processes and even less adequate to grasp the lived time of human beings. moreover, the clock as a cultural idol of instrumentalist perfection has led to approaching human aging in terms of maintenance and repair, inspiring a neglect and depreciation of human vulnerability. the instrumentalist culture of late modern society, including its health cure system, has difficulties to relate to the elusive but inevitable limitations of finite life. this tendency is supported by outspoken approaches in biogerontology indulging in perspectives of infinite human lives; a message that is eagerly consumed by the mass media. moreover, as most people can be expected to survive into old age, thinking about finitude is easily postponed and reserved for those who are 'really old'. instead of reducing aging to the opposite or mere continuation of vital adulthood, it should be seen as something with a potentially broad and deep significance: a process of learning to live a finite life.","['human aging', 'finite lives', 'idealization', 'clocks']"
"spectral computed tomography (ct) has the capability to resolve the energy levels of incident photons, which has the potential to distinguish different material compositions. although material decomposition methods based on x-ray attenuation characteristics have good performance in dual-energy ct imaging, there are some limitations in terms of image contrast and noise levels.","['spectral ct images via fully convolutional densenets', 'material decomposition', 'multi']"
"modeling in-vivo protein-dna binding is not only fundamental for further understanding of the regulatory mechanisms, but also a challenging task in computational biology. deep-learning based methods have succeed in modeling in-vivo protein-dna binding, but they often (1) follow the fully supervised learning framework and overlook the weakly supervised information of genomic sequences that a bound dna sequence may has multiple tfbs(s), and, (2) use one-hot encoding to encode dna sequences and ignore the dependencies among nucleotides. in this paper, we propose a weakly supervised framework, which combines multiple-instance learning with a hybrid deep neural network and uses k-mer encoding to transform dna sequences, for modeling in-vivo protein-dna binding. firstly, this framework segments sequences into multiple overlapping instances using a sliding window, and then encodes all instances into image-like inputs of high-order dependencies using k-mer encoding. secondly, it separately computes a score for all instances in the same bag using a hybrid deep neural network that integrates convolutional and recurrent neural networks. finally, it integrates the predicted values of all instances as the final prediction of this bag using the noisy-and method. the experimental results on in-vivo datasets demonstrate the superior performance of the proposed framework. in addition, we also explore the performance of the proposed framework when using k-mer encoding, and demonstrate the performance of the noisy-and method by comparing it with other fusion methods, and find that adding recurrent layers can improve the performance of the proposed framework.","['hybrid deep neural network', 'vivo protein', 'instance learning', 'dna binding', 'combining multiple', 'modeling']"
to evaluate the diagnostic performance of deep learning with a multichannel fusion three-dimensional convolutional neural network (mcf-3dcnn) in the differentiation of the pathologic grades of hepatocellular carcinoma (hcc) based on dynamic contrast-enhanced magnetic resonance images (dce-mr images).,"['hepatocellular carcinoma using mcf', 'pilot study', 'pathologic grade', 'noninvasive evaluation', '3dcnn']"
"we applied deep convolutional neural networks (cnns) to detect periodontal bone loss (pbl) on panoramic dental radiographs. we synthesized a set of 2001 image segments from panoramic radiographs. our reference test was the measured % of pbl. a deep feed-forward cnn was trained and validated via 10-times repeated group shuffling. model architectures and hyperparameters were tuned using grid search. the final model was a seven-layer deep neural network, parameterized by a total number of 4,299,651 weights. for comparison, six dentists assessed the image segments for pbl. averaged over 10 validation folds the mean (sd) classification accuracy of the cnn was 0.81 (0.02). mean (sd) sensitivity and specificity were 0.81 (0.04), 0.81 (0.05), respectively. the mean (sd) accuracy of the dentists was 0.76 (0.06), but the cnn was not statistically significant superior compared to the examiners (p\u2009=\u20090.067/t-test). mean sensitivity and specificity of the dentists was 0.92 (0.02) and 0.63 (0.14), respectively. a cnn trained on a limited amount of radiographic image segments showed at least similar discrimination ability as dentists for assessing pbl on panoramic radiographs. dentists' diagnostic efforts when using radiographs may be reduced by applying machine-learning based technologies.","['periodontal bone loss', 'radiographic detection', 'deep learning']"
"diagnosis and treatment guidance are aided by detecting relevant biomarkers in medical images. although supervised deep learning can perform accurate segmentation of pathological areas, it is limited by requiring a priori definitions of these regions, large-scale annotations, and a representative patient cohort in the training set. in contrast, anomaly detection is not limited to specific definitions of pathologies and allows for training on healthy samples without annotation. anomalous regions can then serve as candidates for biomarker discovery. knowledge about normal anatomical structure brings implicit information for detecting anomalies. we propose to take advantage of this property using bayesian deep learning, based on the assumption that epistemic uncertainties will correlate with anatomical deviations from a normal training set. a bayesian u-net is trained on a well-defined healthy environment using weak labels of healthy anatomy produced by existing methods. at test time, we capture epistemic uncertainty estimates of our model using monte carlo dropout. a novel post-processing technique is then applied to exploit these estimates and transfer their layered appearance to smooth blob-shaped segmentations of the anomalies. we experimentally validated this approach in retinal optical coherence tomography (oct) images, using weak labels of retinal layers. our method achieved a dice index of 0.789 in an independent anomaly test set of age-related macular degeneration (amd) cases. the resulting segmentations allowed very high accuracy for separating healthy and diseased cases with late wet amd, dry geographic atrophy (ga), diabetic macular edema (dme) and retinal vein occlusion (rvo). finally, we qualitatively observed that our approach can also detect other deviations in normal scans such as cut edge artifacts.","['exploiting epistemic uncertainty', 'retinal oct', 'anomaly detection', 'anatomy segmentation']"
"we propose brainnetcnn, a convolutional neural network (cnn) framework to predict clinical neurodevelopmental outcomes from brain networks. in contrast to the spatially local convolutions done in traditional image-based cnns, our brainnetcnn is composed of novel edge-to-edge, edge-to-node and node-to-graph convolutional filters that leverage the topological locality of structural brain networks. we apply the brainnetcnn framework to predict cognitive and motor developmental outcome scores from structural brain networks of infants born preterm. diffusion tensor images (dti) of preterm infants, acquired between 27 and 46 weeks gestational age, were used to construct a dataset of structural brain connectivity networks. we first demonstrate the predictive capabilities of brainnetcnn on synthetic phantom networks with simulated injury patterns and added noise. brainnetcnn outperforms a fully connected neural-network with the same number of model parameters on both phantoms with focal and diffuse injury patterns. we then apply our method to the task of joint prediction of bayley-iii cognitive and motor scores, assessed at 18 months of age, adjusted for prematurity. we show that our brainnetcnn framework outperforms a variety of other methods on the same data. furthermore, brainnetcnn is able to identify an infant's postmenstrual age to within about 2 weeks. finally, we explore the high-level features learned by brainnetcnn by visualizing the importance of each connection in the brain with respect to predicting the outcome scores. these findings are then discussed in the context of the anatomy and function of the developing preterm infant brain.","['towards predicting neurodevelopment', 'convolutional neural networks', 'brain networks', 'brainnetcnn']"
to elucidate the cognitive profiles of post-stroke vascular mild cognitive impairment (vamci) in comparison to mci of non-vascular etiology and cognitively normal healthy controls at a tertiary-care hospital in southern india.,"['stroke cognitive impairment', 'sectional comparison study', 'mild cognitive impairment', 'vascular etiology', 'vascular', 'post', 'non', 'cross']"
"machine learning-based approaches now outperform competing methods in most disciplines relevant to diagnostic radiology. image-guided procedures, however, have not yet benefited substantially from the advent of deep learning, in particular because images for procedural guidance are not archived and thus unavailable for learning, and even if they were available, annotations would be a severe challenge due to the vast amounts of data. in silico simulation of x-ray images from 3d ct is an interesting alternative to using true clinical radiographs since labeling is comparably easy and potentially readily available.","['based procedures via realistic simulation', 'enabling machine learning', 'image formation', 'x', 'ray']"
"malaria is a life-threatening disease caused by plasmodium parasites that infect the red blood cells (rbcs). manual identification and counting of parasitized cells in microscopic thick/thin-film blood examination remains the common, but burdensome method for disease diagnosis. its diagnostic accuracy is adversely impacted by inter/intra-observer variability, particularly in large-scale screening under resource-constrained settings.","['deep neural ensembles toward malaria parasite detection', 'blood smear images', 'performance evaluation', 'thin']"
"disease diagnosis is one of the major data mining questions by the clinicians. the current diagnosis models usually have a strong assumption that one patient has only one disease, i.e. a single-label data mining problem. but the patients, especially when at the late stages, may have more than one disease and require a multi-label diagnosis. the multi-label data mining is much more difficult than a single-label one, and very few algorithms have been developed for this situation. deep learning is a data mining algorithm with highly dense inner structure and has achieved many successful applications in the other areas. we propose a hypothesis that rectified-linear-unit-based deep learning algorithm may also be good at the clinical questions, by revising the last layer as a multi-label output. the proof-of-concept experimental data support the hypothesis, and the community may be interested in trying more applications.","['based deep learning', 'label data', 'biomedical multi', 'unit', 'rectified', 'linear']"
"we propose a deep boosting framework (dbf) for real-world image denoising by integrating the deep learning technique into the boosting algorithm. the dbf replaces conventional handcrafted boosting units by elaborate convolutional neural networks, which brings notable advantages in terms of both performance and speed. we design a lightweight dense dilated fusion network (ddfn) as an embodiment of the boosting unit, which addresses the vanishing of gradients during training due to the cascading of networks while promoting the efficiency of limited parameters. the capabilities of the proposed method are first validated on several representative simulation tasks including non-blind and blind gaussian denoising and jpeg image deblocking. we then focus on a practical scenario to tackle with the complex and challenging real-world noise. to facilitate leaning-based methods including ours, we build a new real-world image denoising (rid) dataset, which contains 200 pairs of high-resolution images with diverse scene content under various shooting conditions. moreover, we conduct comprehensive analysis on the domain shift issue for real-world denoising and propose an effective one-shot domain transfer scheme to address this issue. comprehensive experiments on widely used benchmarks demonstrate that the proposed method significantly surpasses existing methods on the task of real-world image denoising.","['world image denoising', 'deep boosting', 'real']"
"the evaluation of large amounts of digital image data is of growing importance for biology, including for the exploration and monitoring of marine habitats. however, only a tiny percentage of the image data collected is evaluated by marine biologists who manually interpret and annotate the image contents, which can be slow and laborious. in order to overcome the bottleneck in image annotation, two strategies are increasingly proposed: ""citizen science"" and ""machine learning"". in this study, we investigated how the combination of citizen science, to detect objects, and machine learning, to classify megafauna, could be used to automate annotation of underwater images. for this purpose, multiple large data sets of citizen science annotations with different degrees of common errors and inaccuracies observed in citizen science data were simulated by modifying ""gold standard"" annotations done by an experienced marine biologist. the parameters of the simulation were determined on the basis of two citizen science experiments. it allowed us to analyze the relationship between the outcome of a citizen science study and the quality of the classifications of a deep learning megafauna classifier. the results show great potential for combining citizen science with machine learning, provided that the participants are informed precisely about the annotation protocol. inaccuracies in the position of the annotation had the most substantial influence on the classification accuracy, whereas the size of the marking and false positive detections had a smaller influence.","['deep learning based classification', 'derived data quality', 'marine images', 'citizen science', 'impact']"
"machine learning enables computers to address problems by learning from data. deep learning is a type of machine learning that uses a hierarchical recombination of features to extract pertinent information and then learn the patterns represented in the data. over the last eight years, its abilities have increasingly been applied to a wide variety of chemical challenges, from improving computational chemistry to drug and materials design and even synthesis planning. this review aims to explain the concepts of deep learning to chemists from any background and follows this with an overview of the diverse applications demonstrated in the literature. we hope that this will empower the broader chemical community to engage with this burgeoning field and foster the growing movement of deep learning accelerated chemistry.","['deep learning', 'chemistry']"
"with only coarse labels, weakly supervised learning typically uses top-down attention maps generated by back-propagating gradients as priors for tasks such as object localization and semantic segmentation. while these attention maps are intuitive and informative explanations of deep neural network, there is no effective mechanism to manipulate the network attention during learning process. in this paper, we address three shortcomings of previous approaches in modeling such attention maps in one common framework. first, we make attention maps a natural and explicit component in the training pipeline such that they are end-to-end trainable. moreover, we provide self-guidance directly on these maps by exploring supervision from the network itself to improve them towards specific target tasks. lastly, we proposed a design to seamlessly bridge the gap between using weak and extra supervision if available. despite its simplicity, experiments on the semantic segmentation task demonstrate the effectiveness of our methods. besides, the proposed framework provides a way not only explaining the focus of the learner but also feeding back with direct guidance towards specific tasks. under mild assumptions our method can also be understood as a plug-in to existing convolutional neural networks to improve their generalization performance.",['guided attention inference network']
we propose a novel dual-domain convolutional neural network framework to improve structural information of routine 3\u202ft images. we introduce a parameter-efficient butterfly network that involves two complementary domains: a spatial domain and a frequency domain. the butterfly network allows the interaction of these two domains in learning the complex mapping from 3\u202ft to 7\u202ft images. we verified the efficacy of the dual-domain strategy and butterfly network using 3\u202ft and 7\u202ft image pairs. experimental results demonstrate that the proposed framework generates synthetic 7\u202ft-like images and achieves performance superior to state-of-the-art methods.,"['domain convolutional neural networks', 'improving structural information', 'u202ft mri', 'dual', '3']"
"a deep learning network called ""residual neural network"" (resnet) was used to decode raman spectra-encoded suspension arrays (sas). with narrow bandwidths and stable signals, raman spectra have ideal encoding properties. the different raman reporter molecules assembled micro-quartz pieces (mqps) were grafted with various biomolecule probes, which enabled simultaneous detection of numerous target analytes in a single sample. multiple types of mixed mqps were measured by raman spectroscopy and then decoded by resnet to acquire the type information of analytes. the good classification performance of resnet was verified by a t-distributed stochastic neighbor embedding (t-sne) diagram. compared with other machine learning models, these experiments showed that resnet was obviously superior in terms of classification stability and training convergence to different datasets. this method simplified the decoding process and the classification accuracy reached 100%.","['encoded suspension arrays using deep learning', 'raman spectra', 'accurate decoding', 'fast']"
"structure-based drug design is becoming an essential tool for faster and more cost-efficient lead discovery relative to the traditional method. genomic, proteomic, and structural studies have provided hundreds of new targets and opportunities for future drug discovery. this situation poses a major problem: the necessity to handle the ""big data"" generated by combinatorial chemistry. artificial intelligence (ai) and deep learning play a pivotal role in the analysis and systemization of larger data sets by statistical machine learning methods. advanced ai-based sophisticated machine learning tools have a significant impact on the drug discovery process including medicinal chemistry. in this review, we focus on the currently available methods and algorithms for structure-based drug design including virtual screening and de novo drug design, with a special emphasis on ai- and deep-learning-based methods used for drug discovery.","['based drug discovery paradigm', 'structure']"
"stem cell differentiation is guided by contact with the physical microenvironment, influence by both topography and mechanical properties of the matrix. in this study, the combined effect of substratum nano-topography and mechanical stiffness in directing mesenchymal stem cell (msc) chondrogenesis was investigated. three polyesters of varying stiffness were thermally imprinted to create nano-grating or pillar patterns of the same dimension. the surface of the nano-patterned substrate was coated with chondroitin sulfate (cs) to provide an even surface chemistry, with cell-adhesive and chondro-inductive properties, across all polymeric substrates. the surface characteristic, mechanical modulus, and degradation of the cs-coated patterned polymeric substrates were analyzed. the cell morphology adopted on the nano-topographic surfaces were accounted by f-actin distribution, and correlated to the cell proliferation and chondrogenic differentiation outcomes. results show that substratum stiffness and topographical cues affected msc morphology and aggregation, and influenced the phenotypic development at the earlier stage of chondrogenic differentiation. hyaline-like cartilage with middle/deep zone cartilage characteristics was generated on softer pillar surface, while on stiffer nano-pillar material mscs showed potential to generate constituents of hyaline/fibro/hypertrophic cartilage. fibro/superficial zone-like cartilage could be derived from nano-grating of softer stiffness, while stiffer nano-grating resulted in insignificant chondrogenesis. this study demonstrates the possibility of refining the phenotype of cartilage generated from mscs by manipulating surface topography and material stiffness.","['mesenchymal stem cells', 'surface topography', 'substrate stiffness', 'combined effect', 'chondrogenic differentiation']"
"numerous tasks at the core of statistics, learning and vision areas are specific cases of ill-posed inverse problems. recently, learning-based (e.g., deep) iterative methods have been empirically shown to be useful for these problems. nevertheless, integrating learnable structures into iterations is still a laborious process, which can only be guided by intuitions or empirical insights. moreover, there is a lack of rigorous analysis about the convergence behaviors of these reimplemented iterations, and thus the significance of such methods is a little bit vague. this paper moves beyond these limits and proposes flexible iterative modularization algorithm (fima), a generic and provable paradigm for nonconvex inverse problems. our theoretical analysis reveals that fima allows us to generate globally convergent trajectories for learning-based iterative methods. meanwhile, the devised scheduling policies on flexible modules should also be beneficial for classical numerical methods in the nonconvex scenario. extensive experiments on real applications verify the superiority of fima.","['nonconvex inverse problems', 'based iterative methods', 'learning', 'convergence']"
"identification of drug combinations that could be effective in alzheimer's disease treatment is made difficult by the sheer number of possible combinations. this analysis identifies as potentially therapeutic those drug combinations that rank highest when their efficacy is determined jointly from two independent data sources. estimates of the efficacy of the same drug combinations were derived from a clinical dataset on cognitively impaired elderly participants and from pre-clinical data, in the form of a computational model of neuroinflammation. linear regression was used to show that the two sets of estimates were correlated, and to rule out confounds. the ten highest ranking, jointly determined drug combinations most frequently consisted of cox2 inhibitors and aspirin, along with various antihypertensive medications. ten combinations of from five to nine drugs, and the three-drug combination of a cox2 inhibitor, aspirin, and a calcium-channel blocker, are discussed as candidates for consideration in future pre-clinical and clinical studies.","['drug combinations predicted', 'drug combinations', 'computational model', 'cognitive benefits', 'clinical database', 'exploring', 'efficacies', 'correlation']"
"the human genome consists of 98.5% non-coding dna sequences, and most of them have no known function. however, a majority of disease-associated variants lie in these regions. therefore, it is critical to predict the function of non-coding dna. hence, we propose the ncnet, which integrates deep residual learning and sequence-to-sequence learning networks, to predict the transcription factor (tf) binding sites, which can then be used to predict non-coding functions. in ncnet, deep residual learning networks are used to enhance the identification rate of regulatory patterns of motifs, so that the sequence-to-sequence learning network may make the most out of the sequential dependency between the patterns. with the identity shortcut technique and deep architectures of the networks, ncnet achieves significant improvement compared to the original hybrid model in identifying regulatory markers.","['deep learning network models', 'predicting function', 'coding dna', 'non', 'ncnet']"
"we paired existing land use regression (lur) models for ambient ultrafine particles in montreal and toronto, canada with satellite images and deep convolutional neural networks as a means of extending the spatial coverage of these models. our findings demonstrate that this method can be used to expand the spatial scale of lur models, thus providing exposure estimates for larger populations. the cost of this approach is a small loss in precision as the training data are themselves modelled values.","['ambient ultrafine particles using satellite images', 'land use regression models', 'deep convolutional neural networks', 'spatial scale', 'extending']"
"a deeply supervised attention-enabled boosted convolutional neural network (dab-cnn) is presented as a superior alternative to current state-of-the-art convolutional neural networks (cnns) for semantic ct segmentation. spatial attention gates (ags) were incorporated into a novel 3d cascaded cnn framework to prioritize relevant anatomy and suppress redundancies within the network. due to the complexity and size of the network, incremental channel boosting was used to decrease memory usage and facilitate model convergence. deep supervision was used to encourage semantically meaningful deep features and mitigate local minima traps during training. the accuracy of dab-cnn is compared to seven architectures: a variation of u-net (unet), attention-enabled u-net (a-unet), boosted u-net (b-unet), deeply-supervised u-net (d-unet), u-net with resnext blocks (resnext), life-long learning segmentation cnn (ll-cnn), and deeply supervised attention-enabled u-net (da-unet). the accuracy of each method was assessed based on dice score compared to manually delineated contours as the gold standard. one hundred and twenty patients who had definitive prostate radiotherapy were used in this study. training, validation, and testing followed kaggle competition rules, with 80 patients used for training, 20 patients used for internal validation, and 20 test patients used to report final accuracies. comparator p\u200a-values indicate that dab-cnn achieved significantly superior dice scores than all alternative algorithms for the prostate, rectum, and penile bulb. this study demonstrated that attention-enabled boosted convolutional neural networks (cnns) using deep supervision are capable of achieving superior prediction accuracy compared to current state-of-the-art automatic segmentation methods.","['semantic ct segmentation using deep supervision', 'enabled 3d boosted convolutional neural networks', 'attention']"
"protein-protein interactions (ppis) play an important role in the life activities of organisms. with the availability of large amounts of protein sequence data, ppis prediction methods have attracted increasing attention. a variety of protein sequence coding methods have emerged, but the training of these methods is particularly time consuming. to solve this issue, we have proposed a novel matrix sequence coding method. based on deep neural network (dnn) and a novel matrix protein sequence descriptor, we constructed a protein interaction prediction model for predicting ppis. when performed on human ppis data, the method achieved an accuracy of 94.34%, a recall of 98.28%, an area under the curve (auc) of 97.79% and a loss of 23.25%. a non-redundant dataset was used to evaluate this prediction model, and the prediction accuracy is 88.29%. these results indicate that the matrix of sequence (mos) descriptor can enhance the predictive power of ppis and reduce training time, which can be a useful complement for future proteomics research. the experimental code and experimental results can be found at https://github.com/smalltalkman/hppi-tensorflow.","['amino acid sequences', 'sequence descriptors', 'protein interactions', 'predicting protein', 'novel matrix']"
"recently, machine learning, especially deep learning, has been a core algorithm to be widely used in many fields such as natural language processing, speech recognition, object recognition, and so on. at the same time, another trend is that more and more applications are moved to wearable and mobile devices. however, traditional deep learning methods such as convolutional neural network (cnn) and its variants consume a lot of memory resources. in this case, these powerful deep learning methods are difficult to apply on mobile memory-limited platforms. in order to solve this problem, we present a novel memory-management strategy called mmcnn in this paper. with the help of this method, we can easily deploy a trained large-size cnn on any memory size platform such as gpu, fpga, or memory-limited mobile devices. in our experiments, we run a feed-forward cnn process in some extremely small memory sizes (as low as 5\u2009mb) on a gpu platform. the result shows that our method saves more than 98% memory compared to a traditional cnn algorithm and further saves more than 90% compared to the state-of-the-art related work ""vdnns"" (virtualized deep neural networks). our work in this paper improves the computing scalability of lightweight applications and breaks the memory bottleneck of using deep learning method on memory-limited devices.","['large convolutional neural network', 'scheduling strategy', 'limited devices', 'novel memory', 'memory']"
to investigate the performance of deep learning (dl) based on fully convolutional neural network (fcnn) in segmenting brain tissues in a large cohort of multiple sclerosis (ms) patients.,"['multiple sclerosis using fully convolutional neural networks', 'scale study', 'lesion segmentation', 'large', 'brain']"
"influenza is one of the main causes of death, not only in the usa but worldwide. its significant economic and public health impacts necessitate development of accurate and efficient algorithms for forecasting of any upcoming influenza outbreaks. most currently available methods for influenza prediction are based on parametric time series and regression models that impose restrictive and often unverifiable assumptions on the data. in turn, more flexible machine learning models and, particularly, deep learning tools whose utility is proven in a wide range of disciplines, remain largely under-explored in epidemiological forecasting. we study the seasonal influenza in dallas county by evaluating the forecasting ability of deep learning with feedforward neural networks as well as performance of more conventional statistical models, such as beta regression, autoregressive integrated moving average (arima), least absolute shrinkage and selection operators (lasso), and non-parametric multivariate adaptive regression splines (mars) models for one week and two weeks ahead forecasting. furthermore, we assess forecasting utility of google search queries and meteorological data as exogenous predictors of influenza activity. finally, we develop a probabilistic forecasting of influenza in dallas county by fusing all the considered models using bayesian model averaging.","['statistical model fusion', 'probabilistic forecasting', 'deep learning', 'dallas county', 'usa', 'texas', 'power', 'influenza', 'complementing']"
"the dental disease is a common disease for a human. screening and visual diagnosis that are currently performed in clinics possibly cost a lot in various manners. along with the progress of the internet of things (iot) and artificial intelligence, the internet-based intelligent system have shown great potential in applying home-based healthcare. therefore, a smart dental health-iot system based on intelligent hardware, deep learning, and mobile terminal is proposed in this paper, aiming at exploring the feasibility of its application on in-home dental healthcare. moreover, a smart dental device is designed and developed in this study to perform the image acquisition of teeth. based on the data set of 12\xa0600 clinical images collected by the proposed device from 10 private dental clinics, an automatic diagnosis model trained by mask r-cnn is developed for the detection and classification of 7 different dental diseases including decayed tooth, dental plaque, uorosis, and periodontal disease, with the diagnosis accuracy of them reaching up to 90%, along with high sensitivity and high specificity. following the one-month test in ten clinics, compared with that last month when the platform was not used, the mean diagnosis time reduces by 37.5% for each patient, helping explain the increase in the number of treated patients by 18.4%. furthermore, application software (apps) on mobile terminal for client side and for dentist side are implemented to provide service of pre-examination, consultation, appointment, and evaluation.","['smart dental health', 'iot platform based', 'mobile terminal', 'intelligent hardware', 'deep learning']"
"we have attempted to reproduce the results in development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs, published in jama 2016; 316(22), using publicly available data sets. we re-implemented the main method in the original study since the source code is not available. the original study used non-public fundus images from eyepacs and three hospitals in india for training. we used a different eyepacs data set from kaggle. the original study used the benchmark data set messidor-2 to evaluate the algorithm's performance. we used another distribution of the messidor-2 data set, since the original data set is no longer available. in the original study, ophthalmologists re-graded all images for diabetic retinopathy, macular edema, and image gradability. we have one diabetic retinopathy grade per image for our data sets, and we assessed image gradability ourselves. we were not able to reproduce the original study's results with publicly available data. our algorithm's area under the receiver operating characteristic curve (auc) of 0.951 (95% ci, 0.947-0.956) on the kaggle eyepacs test set and 0.853 (95% ci, 0.835-0.871) on messidor-2 did not come close to the reported auc of 0.99 on both test sets in the original study. this may be caused by the use of a single grade per image, or different data. this study shows the challenges of reproducing deep learning method results, and the need for more replication and reproduction studies to validate deep learning methods, especially for medical image analysis. our source code and instructions are available at: https://github.com/mikevoets/jama16-retina-replication.","['reproduction study using public data', 'retinal fundus photographs', 'deep learning algorithm', 'diabetic retinopathy', 'validation', 'development', 'detection']"
"skeletal bone age assessment is a common clinical practice to investigate endocrinology, genetic and growth disorders in children. it is generally performed by radiological examination of the left hand by using either the greulich and pyle (g&p) method or the tanner-whitehouse (tw) one. however, both clinical procedures show several limitations, from the examination effort of radiologists to (most importantly) significant intra- and inter-operator variability. to address these problems, several automated approaches (especially relying on the tw method) have been proposed; nevertheless, none of them has been proved able to generalize to different races, age ranges and genders. in this paper, we propose and test several deep learning approaches to assess skeletal bone age automatically; the results showed an average discrepancy between manual and automatic evaluation of about 0.8 years, which is state-of-the-art performance. furthermore, this is the first automated skeletal bone age assessment work tested on a public dataset and for all age ranges, races and genders, for which the source code is available, thus representing an exhaustive baseline for future research in the field. beside the specific application scenario, this paper aims at providing answers to more general questions about deep learning on medical images: from the comparison between deep-learned features and manually-crafted ones, to the usage of deep-learning methods trained on general imagery for medical problems, to how to train a cnn with few images.","['automated skeletal bone age assessment', 'ray images', 'deep learning', 'x']"
"image/video processing for fruit detection in the tree using hard-coded feature extraction algorithms has shown high accuracy on fruit detection during recent years. while accurate, these approaches even with high-end hardware are still computationally intensive and too slow for real-time systems. this paper details the use of deep convolution neural networks architecture based on single-stage detectors. using deep-learning techniques eliminates the need for hard-code specific features for specific fruit shapes, color and/or other attributes. this architecture takes the input image and divides into axa grid, where a is a configurable hyper-parameter that defines the fineness of the grid. to each grid cell an image detection and localization algorithm is applied. each of those cells is responsible to predict bounding boxes and confidence score for fruit (apple and pear in the case of this study) detected in that cell. we want this confidence score to be high if a fruit exists in a cell, otherwise to be zero, if no fruit is in the cell. more than 100 images of apple and pear trees were taken. each tree image with approximately 50 fruits, that at the end resulted on more than 5000 images of apple and pear fruits each. labeling images for training consisted on manually specifying the bounding boxes for fruits, where (x, y) are the center coordinates of the box and (w, h) are width and height. this architecture showed an accuracy of more than 90% fruit detection. based on correlation between number of visible fruits, detected fruits on one frame and the real number of fruits on one tree, a model was created to accommodate this error rate. processing speed is higher than 20 fps which is fast enough for any grasping/harvesting robotic arm or other real-time applications.","['time fruit detection within', 'shot convolution neural networks', 'tree', 'single', 'real']"
"effective brain-computer interfaces (bcis) require that the time-varying activation patterns of 2-d neural ensembles be modelled. the cluster variation method (cvm) offers a means for the characterization of 2-d local pattern distributions. this paper provides neuroscientists and bci researchers with a cvm tutorial that will help them to understand how the cvm statistical thermodynamics formulation can model 2-d pattern distributions expressing structural and functional dynamics in the brain. the premise is that local-in-time free energy minimization works alongside neural connectivity adaptation, supporting the development and stabilization of consistent stimulus-specific responsive activation patterns. the equilibrium distribution of local patterns, or configuration variables, is defined in terms of a single interaction enthalpy parameter (h) for the case of an equiprobable distribution of bistate (neural/neural ensemble) units. thus, either one enthalpy parameter (or two, for the case of non-equiprobable distribution) yields equilibrium configuration variable values. modeling 2-d neural activation distribution patterns with the representational layer of a computational engine, we can thus correlate variational free energy minimization with specific configuration variable distributions. the cvm triplet configuration variables also map well to the notion of a m = 3 functional motif. this paper addresses the special case of an equiprobable unit distribution, for which an analytic solution can be found.","['cluster variation method', 'primer', 'neuroscientists']"
"individuals post-stroke sustain motor deficits years after the stroke. despite recent advancements in the applications of non-invasive brain stimulation techniques and deep brain stimulation in humans, there is a lack of evidence supporting their use for rehabilitation after brain lesions. non-invasive brain stimulation is already in use for treating motor deficits in individuals with parkinson's disease and post-stroke. deep brain stimulation has become an established treatment for individuals with movement disorders, such as parkinson's disease, essential tremor, epilepsy, cerebral palsy and dystonia. it has also been utilized for the treatment of tourette's syndrome, alzheimer's disease and neuropsychiatric conditions such as obsessive-compulsive disorder, major depression and anorexia nervosa. there exists growing scientific knowledge from animal studies supporting the use of deep brain stimulation to enhance motor recovery after brain damage. nevertheless, these results are currently not applicable to humans. this review details the current literature supporting the use of these techniques to enhance motor recovery, both from human and animal studies, aiming to encourage development in this domain.","['neuromodulation techniques optimally exploit cerebello', 'enhance motor learning post', 'cortical circuit properties', 'thalamo', 'stroke']"
"since the state-of-the-art deep learning algorithms demand a large training dataset, which is often unavailable in some domains, the transfer of knowledge from one domain to another has been a trending technique in the computer vision field. however, this method may not be a straight-forward task considering several issues such as original network size or large differences between the source and target domain. in this paper, we perform transfer learning for semantic segmentation of off-road driving environments using a pre-trained segmentation network called deconvnet. we explore and verify two important aspects regarding transfer learning. first, since the original network size was very large and did not perform well for our application, we proposed a smaller network, which we call the light-weight network. this light-weight network is half the size to the original deconvnet architecture. we transferred the knowledge from the pre-trained deconvnet to our light-weight network and fine-tuned it. second, we used synthetic datasets as the intermediate domain before training with the real-world off-road driving data. fine-tuning the model trained with the synthetic dataset that simulates the off-road driving environment provides more accurate results for the segmentation of real-world off-road driving environments than transfer learning without using a synthetic dataset does, as long as the synthetic dataset is generated considering real-world variations. we also explore the issue whereby the use of a too simple and/or too random synthetic dataset results in negative transfer. we consider the freiburg forest dataset as a real-world off-road driving dataset.","['road autonomous driving', 'transfer learning', 'semantic segmentation']"
"measuring facial traits by quantitative means is a prerequisite to investigate epidemiological, clinical, and forensic questions. this measurement process has received intense attention in recent years. we divided this process into the registration of the face, landmarking, morphometric quantification, and dimension reduction. face registration is the process of standardizing pose and landmarking annotates positions in the face with anatomic description or mathematically defined properties (pseudolandmarks). morphometric quantification computes pre-specified transformations such as distances. landmarking: we review face registration methods which are required by some landmarking methods. although similar, face registration and landmarking are distinct problems. the registration phase can be seen as a pre-processing step and can be combined independently with a landmarking solution. existing approaches for landmarking differ in their data requirements, modeling approach, and training complexity. in this review, we focus on 3d surface data as captured by commercial surface scanners but also cover methods for 2d facial pictures, when methodology overlaps. we discuss the broad categories of active shape models, template based approaches, recent deep-learning algorithms, and variations thereof such as hybrid algorithms. the type of algorithm chosen depends on the availability of pre-trained models for the data at hand, availability of an appropriate landmark set, accuracy characteristics, and training complexity. quantification: landmarking of anatomical landmarks is usually augmented by pseudo-landmarks, i.e., indirectly defined landmarks that densely cover the scan surface. such a rich data set is not amenable to direct analysis but is reduced in dimensionality for downstream analysis. we review classic dimension reduction techniques used for facial data and face specific measures, such as geometric measurements and manifold learning. finally, we review symmetry registration and discuss reliability.","['facial traits', 'quantification']"
"the basal ganglia and cerebellum are implicated in both motor learning and parkinson's disease. deep brain stimulation (dbs) is an established treatment for advanced parkinson's disease that leads to motor and non-motor effects by modulating specific neural pathways. recently, a disynaptic projection from the subthalamic nucleus (stn) to cerebellar hemispheres was discovered. to investigate the functional significance of this pathway in motor learning, short-term improvement in motor execution in 20 patients with parkinson's disease on and off stn-dbs and 20 age-matched healthy controls was studied in a visuomotor task combined with whole-brain connectomics. motor learning was impaired in parkinson's disease off stimulation but was partially restored through dbs. connectivity between active dbs contacts and a distributed network of brain regions correlated with improvement in motor learning. region of interest analysis revealed connectivity from active contact to cerebellar hemisphere ipsilateral to hand movement as the strongest predictor for change in motor learning. peak predictive voxels in the cerebellum localized to crus ii of lobule vii, which also showed higher stn than motor cortex connectivity, suggestive of a connection surpassing motor cortex. our findings provide new insight into the circuit nature of parkinson's disease and the distributed network effects of dbs in motor learning.","['subthalamic neuromodulation improves short', 'term motor learning', 'parkinson', 'disease']"
"microelectrode recordings along preplanned trajectories are often used for accurate definition of the subthalamic nucleus (stn) borders during deep brain stimulation (dbs) surgery for parkinson's disease. usually, the demarcation of the stn borders is performed manually by a neurophysiologist. the exact detection of the borders is difficult, especially detecting the transition between the stn and the substantia nigra pars reticulata. consequently, demarcation may be inaccurate, leading to suboptimal location of the dbs lead and inadequate clinical outcomes.","['deep brain stimulation surgery', 'subthalamic exit', 'border ahead', 'automatic detection', 'stop']"
"brain functional connectivity (fc) extracted from resting-state fmri (rs-fmri) has become a popular approach for disease diagnosis, where discriminating subjects with mild cognitive impairment (mci) from normal controls (nc) is still one of the most challenging problems. dynamic functional connectivity (dfc), consisting of time-varying spatiotemporal dynamics, may characterize ""chronnectome"" diagnostic information for improving mci classification. however, most of the current dfc studies are based on detecting discrete major ""brain status"" via spatial clustering, which ignores rich spatiotemporal dynamics contained in such chronnectome. we propose deep chronnectome learning for exhaustively mining the comprehensive information, especially the hidden higher-level features, i.e., the dfc time series that may add critical diagnostic power for mci classification. to this end, we devise a new fully-connected bidirectional long short-term memory (lstm) network (full-bilstm) to effectively learn the periodic brain status changes using both past and future information for each brief time segment and then fuse them to form the final output. we have applied our method to a rigorously built large-scale multi-site database (i.e., with 164 data from ncs and 330 from mcis, which can be further augmented by 25 folds). our method outperforms other state-of-the-art approaches with an accuracy of 73.6% under solid cross-validations. we also made extensive comparisons among multiple variants of lstm models. the results suggest high feasibility of our method with promising value also for other brain disorder diagnoses.","['deep chronnectome learning via full bidirectional long short', 'term memory networks', 'mci diagnosis']"
"the importance of sleep is paramount to health. insufficient sleep can reduce physical, emotional, and mental well-being and can lead to a multitude of health complications among people with chronic conditions. physical activity and sleep are highly interrelated health behaviors. our physical activity during the day (ie, awake time) influences our quality of sleep, and vice versa. the current popularity of wearables for tracking physical activity and sleep, including actigraphy devices, can foster the development of new advanced data analytics. this can help to develop new electronic health (ehealth) applications and provide more insights into sleep science.","['wearable data using deep learning', 'sleep quality prediction']"
"the classification of electrocardiograms (ecg) plays an important role in the clinical diagnosis of heart disease. this paper proposes an effective system development and implementation for ecg classification based on faster regions with a convolutional neural network (faster r-cnn) algorithm. the original one-dimensional ecg signals contain the preprocessed patient ecg signals and some ecg recordings from the mit-bih database in this experiment. each ecg beat of one-dimensional ecg signals was transformed into a two-dimensional image for experimental training sets and test sets. as a result, we classified the ecg beats into five categories with an average accuracy of 99.21%. in addition, we did a comparative experiment using the one versus rest support vector machine (ovr svm) algorithm, and the classification accuracy of the proposed faster r-cnn was shown to be 2.59% higher.","['electrocardiogram classification based', 'convolutional neural network', 'faster regions']"
"artificial intelligence capabilities have, recently, greatly improved. in the past few years, one of the deep learning algorithms, the recurrent neural network (rnn), has shown an outstanding ability in sequence labeling and prediction tasks for sequential data. we built a reliable visual field prediction algorithm using rnn and evaluated its performance in comparison with the conventional pointwise ordinary linear regression (olr) method. a total of 1,408 eyes were used as a training dataset and another dataset, comprising 281 eyes, was used as a test dataset. five consecutive visual field tests were provided to the constructed rnn as input and a 6th visual field test was compared with the output of the rnn. the performance of the rnn was compared with that of olr by predicting the 6th visual field in the test dataset. the overall prediction performance of rnn was significantly better than olr. the pointwise prediction error of the rnn was significantly smaller than that of the olr in most areas known to be vulnerable to glaucomatous damage. the rnn was also more robust and reliable regarding worsening in the visual field examination. in clinical practice, the rnn model can therefore assist in decision-making for further treatment of glaucoma.",['visual field prediction using recurrent neural network']
"in this issue, wester et\xa0al. (2019) examine the obligate relationship between cortical interneurons and pyramidal neurons. by genetically converting superficial it pyramidal cells into pt-like deep-layer pyramidal cells, they alter the position, connectivity, and gene expression within cge-derived interneurons.","['learning', 'job', 'interneurons']"
"more than 60 million people in india have diabetes and are at risk for diabetic retinopathy (dr), a vision-threatening disease. automated interpretation of retinal fundus photographs can help support and scale a robust screening program to detect dr.","['learning algorithm vs manual grading', 'detecting diabetic retinopathy', 'performance', 'india', 'deep']"
"longitudinal measurement of glioma burden with mri is the basis for treatment response assessment. in this study, we developed a deep learning algorithm that automatically segments abnormal fluid attenuated inversion recovery (flair) hyperintensity and contrast-enhancing tumor, quantitating tumor volumes as well as the product of maximum bidimensional diameters according to the response assessment in neuro-oncology (rano) criteria (autorano).","['fully automated volumetric', 'deep learning algorithm', 'glioma burden', 'bidimensional measurement', 'automatic assessment']"
"the brain processes information through multiple layers of neurons. this deep architecture is representationally powerful, but complicates learning because it is difficult to identify the responsible neurons when a mistake is made. in machine learning, the backpropagation algorithm assigns blame by multiplying error signals with all the synaptic weights on each neuron's axon and further downstream. however, this involves a precise, symmetric backward connectivity pattern, which is thought to be impossible in the brain. here we demonstrate that this strong architectural constraint is not required for effective error propagation. we present a surprisingly simple mechanism that assigns blame by multiplying errors by even random synaptic weights. this mechanism can transmit teaching signals across multiple layers of neurons and performs as effectively as backpropagation on a variety of tasks. our results help reopen questions about how the brain could use error signals and dispel long-held assumptions about algorithmic constraints on learning.","['random synaptic feedback weights support error backpropagation', 'deep learning']"
deep learning has the potential to augment clinician performance in medical imaging interpretation and reduce time to diagnosis through automated segmentation. few studies to date have explored this topic.,"['cerebral aneurysms using', 'headxnet model', 'deep learning', 'assisted diagnosis']"
"mr images of fetuses allow clinicians to detect brain abnormalities in an early stage of development. the cornerstone of volumetric and morphologic analysis in fetal mri is segmentation of the fetal brain into different tissue classes. manual segmentation is cumbersome and time consuming, hence automatic segmentation could substantially simplify the procedure. however, automatic brain tissue segmentation in these scans is challenging owing to artifacts including intensity inhomogeneity, caused in particular by spontaneous fetal movements during the scan. unlike methods that estimate the bias field to remove intensity inhomogeneity as a preprocessing step to segmentation, we propose to perform segmentation using a convolutional neural network that exploits images with synthetically introduced intensity inhomogeneity as data augmentation. the method first uses a cnn to extract the intracranial volume. thereafter, another cnn with the same architecture is employed to segment the extracted volume into seven brain tissue classes: cerebellum, basal ganglia and thalami, ventricular cerebrospinal fluid, white matter, brain stem, cortical gray matter and extracerebral cerebrospinal fluid. to make the method applicable to slices showing intensity inhomogeneity artifacts, the training data was augmented by applying a combination of linear gradients with random offsets and orientations to image slices without artifacts. to evaluate the performance of the method, dice coefficient (dc) and mean surface distance (msd) per tissue class were computed between automatic and manual expert annotations. when the training data was enriched by simulated intensity inhomogeneity artifacts, the average achieved dc over all tissue classes and images increased from 0.77 to 0.88, and msd decreased from 0.78\u202fmm to 0.37\u202fmm. these results demonstrate that the proposed approach can potentially replace or complement preprocessing steps, such as bias field corrections, and thereby improve the segmentation performance.","['fetal mri using convolutional neural networks', 'automatic brain tissue segmentation']"
"the problem of camera calibration is two-fold. on the one hand, the parameters are estimated from known correspondences between the captured image and the real world. on the other, these correspondences themselves-typically in the form of chessboard corners-need to be found. many distinct approaches for this feature template extraction are available, often of large computational and/or implementational complexity. we exploit the generalized nature of deep learning networks to detect checkerboard corners: our proposed method is a convolutional neural network (cnn) trained on a large set of example chessboard images, which generalizes several existing solutions. the network is trained explicitly against noisy inputs, as well as inputs with large degrees of lens distortion. the trained network that we evaluate is as accurate as existing techniques while offering improved execution time and increased adaptability to specific situations with little effort. the proposed method is not only robust against the types of degradation present in the training set (lens distortions, and large amounts of sensor noise), but also to perspective deformations, e.g., resulting from multi-camera set-ups.","['adaptive calibration template detection', 'machine learning', 'mate']"
"alternative polyadenylation (apa) is a major driver of transcriptome diversity in human cells. here, we use deep learning to predict apa from dna sequence alone. we trained our model (aparent, apa regression net) on isoform expression data from over 3 million apa reporters. aparent's predictions are highly accurate when tasked with inferring apa in synthetic and human 3'utrs. visualizing features learned across all network layers reveals that aparent recognizes sequence motifs known to recruit apa regulators, discovers previously unknown sequence determinants of 3' end processing, and integrates these features into a comprehensive, interpretable, cis-regulatory code. we apply aparent to forward engineer functional polyadenylation signals with precisely defined cleavage position and isoform usage and validate predictions experimentally. finally, we use aparent to quantify the impact of genetic variants on apa. our approach detects pathogenic variants in a wide range of disease contexts, expanding our understanding of the genetic origins of disease.","['engineering alternative polyadenylation', 'deep neural network', 'predicting']"
"rapid progress in deep learning has spurred its application to bioinformatics problems including protein structure prediction and design. in classic machine learning problems like computer vision, progress has been driven by standardized data sets that facilitate fair assessment of new methods and lower the barrier to entry for non-domain experts. while data sets of protein sequence and structure exist, they lack certain components critical for machine learning, including high-quality multiple sequence alignments and insulated training/validation splits that account for deep but only weakly detectable homology across protein space.","['standardized data set', 'protein structure', 'machine learning', 'proteinnet']"
"digital pathology has advanced substantially over the last decade with the adoption of slide scanners in pathology labs. the use of digital slides to analyse diseases at the microscopic level is both cost-eﬀective and eﬃcient. identifying complex tumour patterns in digital slides is a challenging problem but holds significant importance for tumour burden assessment, grading and many other pathological assessments in cancer research. the use of convolutional neural networks (cnns) to analyse such complex images has been well adopted in digital pathology. however, in recent years, the architecture of cnns has altered with the introduction of inception modules which have shown great promise for classification tasks. in this paper, we propose a modified 'transition' module which encourages generalisation in a deep learning framework with few training samples. in the transition module, filters of varying sizes are used to encourage class-specific filters at multiple spatial resolutions followed by global average pooling. we demonstrate the performance of the transition module in alexnet and zfnet, for classifying breast tumours in two independent data-sets of scanned histology sections; the inclusion of the transition module in these cnns improved performance.","['convolutional neural networks', 'transition module', 'preventing overfitting', 'method']"
"while molecular imaging with positron emission tomography or single-photon emission computed tomography already reports on tumour molecular mechanisms on a macroscopic scale, there is increasing evidence that there are multiple additional features within medical images that can further improve tumour characterization, treatment prediction and prognostication. early reports have already revealed the power of radiomics to personalize and improve patient management and outcomes. what remains unclear is how these additional metrics relate to underlying molecular mechanisms of disease. furthermore, the ability to deal with increasingly large amounts of data from medical images and beyond in a rapid, reproducible and transparent manner is essential for future clinical practice. here, artificial intelligence (ai) may have an impact. ai encompasses a broad range of 'intelligent' functions performed by computers, including language processing, knowledge representation, problem solving and planning. while rule-based algorithms, e.g. computer-aided diagnosis, have been in use for medical imaging since the 1990s, the resurgent interest in ai is related to improvements in computing power and advances in machine learning (ml). in this review we consider why molecular and cellular processes are of interest and which processes have already been exposed to ai and ml methods as reported in the literature. non-small-cell lung cancer is used as an exemplar and the focus of this review as the most common tumour type in which ai and ml approaches have been tested and to illustrate some of the concepts.","['molecular mechanisms underlying disease', 'artificial intelligence teach us']"
"the ability to recognize faces of family members, friends, and acquaintances plays an important role in our daily interactions. the other-race effect is the reduced ability to recognize other-race faces as compared to own-race faces. previous studies showed different patterns of event-related potentials (erps) associated with recollection and familiarity during memory encoding (i.e., dm) and recognition (i.e., parietal old/new effect) for own-race and other-race faces in a subjective-recollection task (remember-know judgments). the present study investigated the same neural correlates of the other-race effect in an associative-memory task, in which caucasian and east asian participants learned and recognized own-race and other-race faces along with background colors. participants made more false alarms for other-race faces indicating lower memory performance. during the study phase, subsequently recognized other-race faces (with and without correct background information) elicited more positive mean amplitudes than own-race faces, suggesting increased neural activation during encoding of other-race faces. during the test phase, recollection-related old/new effects dissociated between own-race and other-race faces. old/new effects were significant only for own-race but not for other-race faces, indicating that recognition only of own-race faces was supported by recollection and led to more detailed memory retrieval. most of these results replicated previous studies that used a subjective-recollection task. our study also showed that the increased demand on memory encoding during an associative-memory task led to dm patterns that indicated similarly deep memory encoding for own-race and other-race faces.","['neural correlates', 'memory task', 'memory encoding', 'race faces', 'race', 'recognition', 'associative']"
"this study aims to automatically diagnose thoracic diseases depicted on the chest x-ray (cxr) images using deep convolutional neural networks. the existing methods generally used the entire cxr images for training purposes, but this strategy may suffer from two drawbacks. first, potential misalignment or the existence of irrelevant objects in the entire cxr images may cause unnecessary noise and thus limit the network performance. second, the relatively low image resolution caused by the resizing operation, which is a common pre-processing procedure for training neural networks, may lead to the loss of image details, making it difficult to detect pathologies with small lesion regions. to address these issues, we present a novel method termed as segmentation-based deep fusion network (sdfn), which leverages the domain knowledge and the higher-resolution information of local lung regions. specifically, the local lung regions were identified and cropped by the lung region generator (lrg). two cnn-based classification models were then used as feature extractors to obtain the discriminative features of the entire cxr images and the cropped lung region images. lastly, the obtained features were fused by the feature fusion module for disease classification. evaluated by the nih benchmark split on the chest x-ray 14 dataset, our experimental result demonstrated that the developed method achieved more accurate disease classification compared with the available approaches via the receiver operating characteristic (roc) analyses. it was also found that the sdfn could localize the lesion regions more precisely as compared to the traditional method.","['based deep fusion network', 'thoracic disease classification', 'ray images', 'chest x', 'segmentation', 'sdfn']"
"radiology-pathology correlation has long been foundational to continuing education, peer learning, quality assurance, and multidisciplinary patient care. the objective of this study was to determine whether modern deep-learning language-modeling techniques could reliably match pathology reports to pertinent radiology reports.","['pathology correlation', 'modeling approach', 'learning language', 'iterative radiology', 'personalized', 'deep', 'automated']"
undergraduate research is a high-impact educational practice that fosters deep learning. study design is an important factor to consider when planning for student success.,"['undergraduate nursing honors research', 'alternative design', 'q', 'methodology']"
"in this chapter, we explain how text mining can support the curation of molecular biology databases dealing with protein functions. we also show how curated data can play a disruptive role in the developments of text mining methods. we review a decade of efforts to improve the automatic assignment of gene ontology (go) descriptors, the reference ontology for the characterization of genes and gene products. to illustrate the high potential of this approach, we compare the performances of an automatic text categorizer and show a large improvement of +225\u2009% in both precision and recall on benchmarked data. we argue that automatic text categorization functions can ultimately be embedded into a question-answering (qa) system to answer questions related to protein functions. because go descriptors can be relatively long and specific, traditional qa systems cannot answer such questions. a new type of qa system, so-called deep qa which uses machine learning methods trained with curated contents, is thus emerging. finally, future advances of text mining instruments are directly dependent on the availability of high-quality annotated contents at every curation step. databases workflows must start recording explicitly all the data they curate and ideally also some of the data they do not curate.","['support gene ontology curation', 'vice versa', 'text mining']"
"recent studies have developed simple techniques for monitoring and assessing sleep. however, several issues remain to be solved for example high-cost sensor and algorithm as a home-use device. in this study, we aimed to develop an inexpensive and simple sleep monitoring system using a camera and video processing. polysomnography (psg) recordings were performed in six subjects for four consecutive nights. subjects' body movements were simultaneously recorded by the web camera. body movement was extracted by video processing from the video data and five parameters were calculated for machine learning. four sleep stages (wake, light, deep and rem) were estimated by applying these five parameters to a support vector machine. the overall estimation accuracy was 70.3\u2009±\u200911.3% with the highest accuracy for deep (82.8\u2009±\u20094.7%) and the lowest for light (53.0\u2009±\u20094.0%) compared with correct sleep stages manually scored on psg data by a sleep technician. estimation accuracy for rem sleep was 68.0\u2009±\u20096.8%. the kappa was 0.19\u2009±\u20090.04 for all subjects. the present non-contact sleep monitoring system showed sufficient accuracy in sleep stage estimation with rem sleep detection being accomplished. low-cost computing power of this system can be advantageous for mobile application and modularization into home-device.","['sleep stage estimation method using', 'home use', 'camera']"
the purpose of this study was to examine the relationship between participation in co-curricular activities and academic performance of pharmacy students enrolled in a traditional pharmd program.,"['pharmacy students', 'curricular involvement', 'academic success', 'impact', 'co']"
"magnetic resonance (mr) perfusion imaging non-invasively measures cerebral perfusion, which describes the blood's passage through the brain's vascular network. therefore, it is widely used to assess cerebral ischaemia. convolutional neural networks (cnn) constitute the state-of-the-art method in automatic pattern recognition and hence, in segmentation tasks. but none of the cnn architectures developed to date have achieved high accuracy when segmenting ischaemic stroke lesions, being the main reasons their heterogeneity in location, shape, size, image intensity and texture, especially in this imaging modality. we use a freely available cnn framework, developed for mr imaging lesion segmentation, as core algorithm to evaluate the impact of enhanced machine learning techniques, namely data augmentation, transfer learning and post-processing, in the segmentation of stroke lesions using the isles 2017 dataset, which contains expert annotated diffusion-weighted perfusion and diffusion brain mri of 43 stroke patients. of all the techniques evaluated, data augmentation with binary closing achieved the best results, improving the mean dice score in 17% over the baseline model. consistent with previous works, better performance was obtained in the presence of large lesions.","['brain magnetic resonance perfusion images using', 'segmenting ischaemic stroke lesions', 'convolutional neural network scheme', 'enhanced learning techniques', 'evaluation']"
"crispr-cpf1 has recently been reported as another rna-guided endonuclease of class 2 crispr-cas system, which expands the molecular biology toolkit for genome editing. however, most of the online tools and applications to date have been developed primarily for the cas9. there are a limited number of tools available for the cpf1.","['cpf1 using convolutional deep learning neural networks', 'specificity', 'prediction', 'crispr', 'activity']"
"recent works have extensively investigated the possibility to predict brain aging from t1-weighted mri brain scans. the main purposes of these studies are the investigation of subject-specific aging mechanisms and the development of accurate models for age prediction. deviations between predicted and chronological age are known to occur in several neurodegenerative diseases; as a consequence, reaching higher levels of age prediction accuracy is of paramount importance to develop diagnostic tools. in this work, we propose a novel complex network model for brain based on segmenting t1-weighted mri scans in rectangular boxes, called patches, and measuring pairwise similarities using pearson's correlation to define a subject-specific network. we fed a deep neural network with nodal metrics, evaluating both the intensity and the uniformity of connections, to predict subjects' ages. our model reaches high accuracies which compare favorably with state-of-the-art approaches. we observe that the complex relationships involved in this brain description cannot be accurately modeled with standard machine learning approaches, such as ridge and lasso regression, random forest, and support vector machines, instead a deep neural network has to be used.","['multiplex networks', 'deep learning', 'brain age', 'accurate modeling']"
"more than two decades of research have enabled dihedral angle predictions at an accuracy that makes them an interesting alternative or supplement to secondary structure prediction that provides detailed local structure information for every residue of a protein. the evolution of dihedral angle prediction methods is closely linked to advancements in machine learning and other relevant technologies. consequently recent improvements in large-scale training of deep neural networks have led to the best method currently available, which achieves a mean absolute error of 19° for phi, and 30° for psi. this performance opens interesting perspectives for the application of dihedral angle prediction in the comparison, prediction, and design of protein structures.",['backbone dihedral angle prediction']
"in recent years, obtaining rna secondary structure information has played an important role in rna and gene function research. although some rna secondary structures can be gained experimentally, in most cases, efficient, and accurate computational methods are still needed to predict rna secondary structure. current rna secondary structure prediction methods are mainly based on the minimum free energy algorithm, which finds the optimal folding state of rna in vivo using an iterative method to meet the minimum energy or other constraints. however, due to the complexity of biotic environment, a true rna structure always keeps the balance of biological potential energy status, rather than the optimal folding status that meets the minimum energy. for short sequence rna its equilibrium energy status for the rna folding organism is close to the minimum free energy status; therefore, the minimum free energy algorithm for predicting rna secondary structure has higher accuracy. nevertheless, in a longer sequence rna, constant folding causes its biopotential energy balance to deviate far from the minimum free energy status. this deviation is because of its complex structure and results in a serious decline in the prediction accuracy of its secondary structure. in this paper, we propose a novel rna secondary structure prediction algorithm using a convolutional neural network model combined with a dynamic programming method to improve the accuracy with large-scale rna sequence and structure data. we analyze current experimental rna sequences and structure data to construct a deep convolutional network model, and then we extract implicit features of an effective classification from large-scale data to predict the pairing probability of each base in an rna sequence. for the obtained probabilities of rna sequence base pairing, an enhanced dynamic programming method is applied to obtain the optimal rna secondary structure. results indicate that our proposed method is superior to the common rna secondary structure prediction algorithms in predicting three benchmark rna families. based on the characteristics of deep learning algorithm, it can be inferred that the method proposed in this paper has a 30% higher prediction success rate when compared with other algorithms, which will be needed as the amount of real rna structure data increases in the future.","['rna secondary structure prediction based', 'convolutional neural network', 'new method', 'dynamic programming']"
the study aimed to explore the modification to cortical oscillations of parkinson disease (pd) patients by subthalamic nucleus deep brain stimulation (stn dbs).,"['subthalamic deep brain stimulation', 'parkinson disease', 'meg study', 'cortical oscillations', 'patients', 'modulations']"
"we propose a new iterative segmentation model which can be accurately learned from a small dataset. a common approach is to train a model to directly segment an image, requiring a large collection of manually annotated images to capture the anatomical variability in a cohort. in contrast, we develop a segmentation model that recursively evolves a segmentation in several steps, and implement it as a recurrent neural network. we learn model parameters by optimizing the intermediate steps of the evolution in addition to the final segmentation. to this end, we train our segmentation propagation model by presenting incomplete and/or inaccurate input segmentations paired with a recommended next step. our work aims to alleviate challenges in segmenting heart structures from cardiac mri for patients with congenital heart disease (chd), which encompasses a range of morphological deformations and topological changes. we demonstrate the advantages of this approach on a dataset of 20 images from chd patients, learning a model that accurately segments individual heart chambers and great vessels. compared to direct segmentation, the iterative method yields more accurate segmentation for patients with the most severe chd malformations.","['limited training data', 'congenital heart disease', 'iterative segmentation', 'applications']"
"intracranial self-stimulation (icss) of the medial forebrain bundle is a treatment capable of consistently facilitating acquisition of learning and memory in a wide array of experimental paradigms in rats. however, the evidence supporting this effect on implicit memory comes mainly from classical conditioning and avoidance tasks. the present work aims to determine whether icss would also improve the performance of rats in another type of implicit task such as cued simultaneous visual discrimination in the morris water maze. the icss treatment was administered immediately after each of the five acquisition sessions and its effects on retention and reversal were evaluated 72h later. results showed that icss subjects committed fewer errors than sham subjects and adopted more accurate trajectories during the acquisition of the task. this improvement was maintained until the probe test at 72h. however, icss animals experienced more difficulties than the sham group during the reversal of the same learning, reflecting an impairment in cognitive flexibility. we conclude that post-training icss could also be an effective treatment for improving implicit visual discrimination learning and memory.","['stimulation also facilitates learning', 'visual discrimination task', 'morris water maze', 'intracranial self', 'rats']"
"the purpose of this study was to explore whether two types of emotional labor, surface acting and deep acting, are related to hair cortisol concentration among kindergarten teachers.","['hair among female kindergarten teachers', 'emotional labor', 'cortisol concentration', 'correlation']"
the purpose of this work is to develop and validate a learning-based method to derive electron density from routine anatomical mri for potential mri-based sbrt treatment planning.,"['based synthetic ct generation method', 'liver stereotactic body radiotherapy', 'based treatment planning', 'deep learning', 'validation', 'mri']"
"the success of enhanced sampling molecular simulations that accelerate along collective variables (cvs) is predicated on the availability of variables coincident with the slow collective motions governing the long-time conformational dynamics of a system. it is challenging to intuit these slow cvs for all but the simplest molecular systems, and their data-driven discovery directly from molecular simulation trajectories has been a central focus of the molecular simulation community to both unveil the important physical mechanisms and drive enhanced sampling. in this work, we introduce state-free reversible vampnets (srv) as a deep learning architecture that learns nonlinear cv approximants to the leading slow eigenfunctions of the spectral decomposition of the transfer operator that evolves equilibrium-scaled probability distributions through time. orthogonality of the learned cvs is naturally imposed within network training without added regularization. the cvs are inherently explicit and differentiable functions of the input coordinates making them well-suited to use in enhanced sampling calculations. we demonstrate the utility of srvs in capturing parsimonious nonlinear representations of complex system dynamics in applications to 1d and 2d toy systems where the true eigenfunctions are exactly calculable and to molecular dynamics simulations of alanine dipeptide and the ww domain protein.","['slow molecular modes using state', 'free reversible vampnets', 'nonlinear discovery']"
"we present a system for activity recognition from passive rfid data using a deep convolutional neural network. we directly feed the rfid data into a deep convolutional neural network for activity recognition instead of selecting features and using a cascade structure that first detects object use from rfid data followed by predicting the activity. because our system treats activity recognition as a multi-class classification problem, it is scalable for applications with large number of activity classes. we tested our system using rfid data collected in a trauma room, including 14 hours of rfid data from 16 actual trauma resuscitations. our system outperformed existing systems developed for activity recognition and achieved similar performance with process-phase detection as systems that require wearable sensors or manually-generated input. we also analyzed the strengths and limitations of our current deep learning architecture for activity recognition from rfid data.","['based activity recognition', 'deep learning', 'rfid']"
automated segmentation of brain structures is an important task in structural and functional image analysis. we developed a fast and accurate method for the striatum segmentation using deep convolutional neural networks (cnn).,"['striatum using deep convolutional neural networks', 'robust segmentation', 'fast']"
"live-cell imaging has opened an exciting window into the role cellular heterogeneity plays in dynamic, living systems. a major critical challenge for this class of experiments is the problem of image segmentation, or determining which parts of a microscope image correspond to which individual cells. current approaches require many hours of manual curation and depend on approaches that are difficult to share between labs. they are also unable to robustly segment the cytoplasms of mammalian cells. here, we show that deep convolutional neural networks, a supervised machine learning method, can solve this challenge for multiple cell types across the domains of life. we demonstrate that this approach can robustly segment fluorescent images of cell nuclei as well as phase images of the cytoplasms of individual bacterial and mammalian cells from phase contrast images without the need for a fluorescent cytoplasmic marker. these networks also enable the simultaneous segmentation and identification of different mammalian cell types grown in co-culture. a quantitative comparison with prior methods demonstrates that convolutional neural networks have improved accuracy and lead to a significant reduction in curation time. we relay our experience in designing and optimizing deep convolutional neural networks for this task and outline several design rules that we found led to robust performance. we conclude that deep convolutional neural networks are an accurate method that require less curation time, are generalizable to a multiplicity of cell types, from bacteria to mammalian cells, and expand live-cell imaging capabilities to include multi-cell type systems.","['deep learning automates', 'cell imaging experiments', 'quantitative analysis', 'individual cells', 'live']"
white matter hyperintensities (wmhs) are foci of abnormal signal intensity in white matter regions seen with magnetic resonance imaging (mri). wmhs are associated with normal ageing and have shown prognostic value in neurological conditions such as traumatic brain injury (tbi). the impracticality of manually quantifying these lesions limits their clinical utility and motivates the utilization of machine learning techniques for automated segmentation workflows.,"['white matter hyperintensities', 'traumatic brain injury', 'supervised learning technique', 'automated identification']"
"the purpose of this study was to design a one-hour brain dissection protocol for a medical neuroscience course and evaluate the short and long-term effects of its implementation on medical students. first-year medical students (n\u2009=\u2009166) participated in a brain dissection activity that included dissection of the basal nuclei and associated deep brain structures. short-term retention was assessed by administering identical pre- and post-activity tests involving identification of brain structures. following the brain dissection, the students' posttest scores were significantly higher (68.8%\u2009±\u200917.8%; mean percent score\u2009±\u2009sd) than their pretest scores (35.8%\u2009±\u200920.0%) (p\u2009≤\u20090.0001). long-term retention was evaluated by conducting an identical assessment five months after completion of the course. students who participated in the dissection activity (n\u2009=\u200980) had significantly higher scores (46.6%\u2009±\u200923.8%) than the students who did not participate in the dissection activity (n\u2009=\u200985) (38.1%\u2009±\u200923.9%) (p\u2009≤\u20090.05). in addition to the long-term retention assessment, the nbme® subject examination scores of students who participated in the dissection activity were significantly higher than the students who did not participate in the dissection activity (p\u2009≤\u20090.01). results suggest that this succinct brain dissection activity may be a practical addition to an undergraduate medical neuroscience course for increasing the effectiveness of neuroanatomy training. this effect may have long-term benefits on knowledge retention and may be correlated with higher performance levels on standardized subject examinations. anat sci educ 9: 565-574.","['medical neuroscience laboratory enhances learning', 'brain dissection within', 'integration']"
"deep learning demonstrates greater competence over traditional machine learning techniques for many tasks. in last several years, deep learning has been applied to protein function prediction and a series of good achievements has been obtained. these findings extensively advanced our understanding of protein function. however, the accuracy of protein function prediction based upon deep learning still has yet to be improved. in article number 1900019, issue 12, zhang et\xa0al. construct deepfunc, a deep learning framework using derived feature information of protein sequence and protein interactions network. they find that implementing deepfunc for protein function prediction is more accurate than using deepgo, a similar method reported previously. meanwhile, they find that the method of combining multiple derived feature information in deepfunc is much better than the method of using only single derived feature information. due to its fully exploiting feature representation learning ability, deep learning with more derived feature information will enable it to be a promising method for solving more complicated protein function prediction problems and other bioinformatics challenges. recent researches have provided some major insights into the value for using deep learning to protein function prediction problem.","['protein function prediction', 'traditional classifier', 'deep learning']"
"multicolored gene reporters for light microscopy are indispensable for biomedical research, but equivalent genetic tools for electron microscopy (em) are still rare despite the increasing importance of nanometer resolution for reverse engineering of molecular machinery and reliable mapping of cellular circuits. we here introduce the fully genetic encapsulin/cargo system of quasibacillus thermotolerans (qt), which in combination with the recently characterized encapsulin system from myxococcus xanthus (mx) enables multiplexed gene reporter imaging via conventional transmission electron microscopy (tem) in mammalian cells. cryo-electron reconstructions revealed that the qt encapsulin shell self-assembles to nanospheres with t = 4 icosahedral symmetry and a diameter of ∼43 nm harboring two putative pore regions at the 5-fold and 3-fold axes. we also found that upon heterologous expression in mammalian cells, the native cargo is autotargeted to the inner surface of the shell and exhibits ferroxidase activity leading to efficient intraluminal iron biomineralization, which enhances cellular tem contrast. we furthermore demonstrate that the two differently sized encapsulins of qt and mx do not intermix and can be robustly differentiated by conventional tem via a deep learning classifier to enable automated multiplexed em gene reporter imaging.","['multiplexed electron microscopy gene reporters', 'sequestering nanocompartments', 'iron']"
"humans can easily classify different kinds of objects whereas it is quite difficult for computers. as a hot and difficult problem, objects classification has been receiving extensive interests with broad prospects. inspired by neuroscience, deep learning concept is proposed. convolutional neural network (cnn) as one of the methods of deep learning can be used to solve classification problem. but most of deep learning methods, including cnn, all ignore the human visual information processing mechanism when a person is classifying objects. therefore, in this paper, inspiring the completed processing that humans classify different kinds of objects, we bring forth a new classification method which combines visual attention model and cnn. firstly, we use the visual attention model to simulate the processing of human visual selection mechanism. secondly, we use cnn to simulate the processing of how humans select features and extract the local features of those selected areas. finally, not only does our classification method depend on those local features, but also it adds the human semantic features to classify objects. our classification method has apparently advantages in biology. experimental results demonstrated that our method made the efficiency of classification improve significantly.","['based visual saliency model', 'convolutional neural network', 'objects classification', 'learning']"
"a prerequisite for many eye tracking and video-oculography (vog) methods is an accurate localization of the pupil. several existing techniques face challenges in images with artifacts and under naturalistic low-light conditions, e.g. with highly dilated pupils.","['neuroscience using deep learning', 'source pupil segmentation', 'gaze estimation', 'open', 'deepvog']"
"deep multitask learning for face analysis has received increasing attentions. from literature, most existing methods focus on optimizing a main task by jointly learning several auxiliary tasks. it is challenging to consider the performance of each task in a multitask framework due to the following reasons: 1) different face tasks usually rely on different levels of semantic features; 2) each task has different learning convergence rate, which could affect the whole performance when joint training; and 3) multitask model needs rich label information for efficient training, but existing facial datasets provide limited annotations. to address these issues, we propose a task-oriented feature-fused network (tfn) for simultaneously solving face detection, landmark localization, and attribute analysis. in this network, a task-oriented feature-fused block is designed to learn task-specific feature combinations; then, an alternative multitask training scheme is presented to optimize each task with considering of their different learning capacities. we also present a large-scale face dataset called jfa in support of proposed method, which provides multivariate labels, including face bounding box, 68 facial landmarks, and 3 attribute labels (i.e., apparent age, gender, and ethnicity). the experimental results suggest that the tfn outperforms several multitask models on the jfa dataset. furthermore, our approach achieves competitive performances on wider face and 300w dataset, and obtains state-of-the-art results for gender recognition on the morph ii dataset.","['joint face analysis', 'oriented feature', 'multivariate dataset', 'fused network', 'task']"
"in this paper, we present a deep regression approach for face alignment. the deep regressor is a neural network that consists of a global layer and multistage local layers. the global layer estimates the initial face shape from the whole image, while the following local layers iteratively update the shape with local image observations. combining standard derivations and numerical approximations, we make all layers able to backpropagate error differentials, so that we can apply the standard backpropagation to jointly learn the parameters from all layers. we show that the resulting deep regressor gradually and evenly approaches the true facial landmarks stage by stage, avoiding the tendency that often occurs in the cascaded regression methods and deteriorates the overall performance: yielding early stage regressors with high alignment accuracy gains but later stage regressors with low alignment accuracy gains. experimental results on standard benchmarks demonstrate that our approach brings significant improvements over previous cascaded regression algorithms.","['face alignment', 'deep regression']"
"optical coherence tomography angiography (octa) is a relatively new imaging modality that generates microvasculature map. meanwhile, deep learning has been recently attracting considerable attention in image-to-image translation, such as image denoising, super-resolution and prediction. in this paper, we propose a deep learning based pipeline for octa. this pipeline consists of three parts: training data preparation, model learning and octa predicting using the trained model. to be mentioned, the datasets used in this work were automatically generated by a conventional system setup without any expert labeling. promising results have been validated by in-vivo animal experiments, which demonstrate that deep learning is able to outperform traditional octa methods. the image quality is improved in not only higher signal-to-noise ratio but also better vasculature connectivity by laser speckle eliminating, showing potential in clinical use. schematic description of the deep learning based optical coherent tomography angiography pipeline.","['optical coherence tomography angiography', 'deep learning based pipeline']"
"künstliche neuronale netze als methoden der künstlichen intelligenz (ki) können der endoskopie neue möglichkeiten eröffnen, etwa im sinne einer automatischen polypenerkennung oder der präzisen vorhersage des histopathologischen befunds einer läsion anhand ihres endoskopischen bildes. während erste versuche tatsächlich ein weitreichendes potenzial erahnen lassen, leiten sich öffentliche und medial transportierte erwartungen häufig mehr von einer abstrakten faszination als von der detaillierten funktionsweise der methoden ab. dieser artikel soll anhand einer selektiven literaturübersicht ein intuitives verständnis der methoden vermitteln und helfen, die lücke zwischen funktion und faszination zu schließen, um potenzial und grenzen dieser techniken im bereich der endoskopie realistisch abschätzen zu können.mit ihrem erfolg bei der maschinellen klassifikation von bildern haben insbesondere „tiefe neuronale netze“ der ki nach jahrzehntelanger forschung zu rasant anwachsendem interesse verholfen. wir umreißen kurz die diesbezüglichen entwicklungen und die gründe für ihre bedeutung weit über die informatik hinaus. durch den vergleich von maschinellem und menschlichem sehen wird ein verständnis der detaillierten funktionsweise dieser methoden und ihrer erfolge bei seh-aufgaben vermittelt. darauf aufbauend analysieren wir die funktionsweise jüngst demonstrierter anwendungen in hinblick auf methodische perspektiven und grenzen, die aussagekraft bisher erbrachter leistungsnachweise und die notwendigkeit weiterer tests. zudem geben wir einen eindruck von weiteren, konkret absehbaren einzelanwendungen und besprechen, welchen charakter diese dem einsatz der künstlichen intelligenz in der endoskopie insgesamt geben könnten.","['deep neural nets', 'xa0computer vision', 'perspectives ].', 'artificial intelligence', 'xa0endoscopic', 'methods', 'endoscopy']"
"the volume of pelvic hematoma at ct has been shown to be the strongest independent predictor of major arterial injury requiring angioembolization in trauma victims with pelvic fractures, and also correlates with transfusion requirement and mortality. measurement of pelvic hematomas (unopacified extraperitoneal blood accumulated from time of injury) using semi-automated seeded region growing is time-consuming and requires trained experts, precluding routine measurement at the point of care. pelvic hematomas are markedly variable in shape and location, have irregular ill-defined margins, have low contrast with respect to viscera and muscle, and reside within anatomically distorted pelvises. furthermore, pelvic hematomas occupy a small proportion of the entire volume of a chest, abdomen, and pelvis (c/a/p) trauma ct. the challenges are many, and no automated methods for segmentation and volumetric analysis have been described to date. traditional approaches using fully convolutional networks result in coarse segmentations and class imbalance with suboptimal convergence. in this study, we implement a modified coarse-to-fine deep learning approach-the recurrent saliency transformation network (rstn) for pelvic hematoma volume segmentation. rstn previously yielded excellent results in pancreas segmentation, where low contrast with adjacent structures, small target volume, variable location, and fine contours are also problematic. we have curated a unique single-institution corpus of 253 c/a/p admission trauma ct studies in patients with bleeding pelvic fractures with manually labeled pelvic hematomas. we hypothesized that rstn would result in sufficiently high dice similarity coefficients to facilitate accurate and objective volumetric measurements for outcome prediction (arterial injury requiring angioembolization). cases were separated into five combinations of training and test sets in an 80/20 split and fivefold cross-validation was performed. dice scores in the test set were 0.71 (sd\u2009±\u20090.10) using rstn, compared to 0.49 (sd\u2009±\u20090.16) using a baseline deep learning tool kit (dltk) reference 3d u-net architecture. mean inference segmentation time for rstn was 0.90\xa0min (±\u20090.26). pearson correlation between predicted and manual labels was 0.95 with p\xa0<\u20090.0001. measurement bias was within 10\xa0ml. auc of hematoma volumes for predicting need for angioembolization was 0.81 (predicted) versus 0.80 (manual). qualitatively, predicted labels closely followed hematoma contours and avoided muscle and displaced viscera. further work will involve validation using a federated dataset and incorporation into a predictive model using multiple segmented features.","['traumatic pelvic hematomas', 'deep learning algorithm', 'automated segmentation', 'quantification', 'performance', 'ct']"
"the successful early diagnosis of brain tumors plays a major role in improving the treatment outcomes and thus improving patient survival. manually evaluating the numerous magnetic resonance imaging (mri) images produced routinely in the clinic is a difficult process. thus, there is a crucial need for computer-aided methods with better accuracy for early tumor diagnosis. computer-aided brain tumor diagnosis from mri images consists of tumor detection, segmentation, and classification processes. over the past few years, many studies have focused on traditional or classical machine learning techniques for brain tumor diagnosis. recently, interest has developed in using deep learning techniques for diagnosing brain tumors with better accuracy and robustness. this study presents a comprehensive review of traditional machine learning techniques and evolving deep learning techniques for brain tumor diagnosis. this review paper identifies the key achievements reflected in the performance measurement metrics of the applied algorithms in the three diagnosis processes. in addition, this study discusses the key findings and draws attention to the lessons learned as a roadmap for future research.","['brain tumor diagnosis', 'practical implications', 'mri images', 'lessons learned', 'key achievements', 'review']"
"magnetic resonance imaging (mri) offers the most detailed brain structure image available today; it can identify tiny lesions or cerebral cortical abnormalities. the primary purpose of the procedure is to confirm whether there is structural variation that causes epilepsy, such as hippocampal sclerotherapy, local cerebral cortical dysplasia, and cavernous hemangioma. cerebrovascular disease, the second most common factor of death in the world, is also the fourth leading cause of death in taiwan, with cerebrovascular disease having the highest rate of stroke. among the most common are large vascular atherosclerotic lesions, small vascular lesions, and cardiac emboli. the purpose of this thesis is to establish a computer-aided diagnosis system based on small blood vessel lesions in mri images, using the method of convolutional neural network and deep learning to analyze brain vascular occlusion by analyzing brain mri images. blocks can help clinicians more quickly determine the probability and severity of stroke in patients. we analyzed mri data from 50 patients, including 30 patients with stroke, 17 patients with occlusion but no stroke, and 3 patients with dementia. this system mainly helps doctors find out whether there are cerebral small vessel lesions in the brain mri images, and to output the found results into labeled images. the marked contents include the position coordinates of the small blood vessel blockage, the block range, the area size, and if it may cause a stroke. finally, all the mri images of the patient are synthesized, showing a 3d display of the small blood vessels in the brain to assist the doctor in making a diagnosis or to provide accurate lesion location for the patient.","['cerebral small vessel disease biomarkers detection', 'deep learning', 'based image', 'sensor', 'mri']"
"drug-induced liver injury (dili), one of the most common adverse effects, leads to drug development failure or withdrawal from the market in most cases, showing an emerging challenge that is to accurately predict dili in the early stage. recently, the vast amount of gene expression data provides us valuable information for distinguishing dili on a genomic scale. moreover, the deep learning algorithm is a powerful strategy to automatically learn important features from raw and noisy data and shows great success in the field of medical diagnosis. in this study, a gene expression data based deep learning model was developed to predict dili in advance by using gene expression data associated with dili collected from arrayexpress and then optimized by feature gene selection and parameters optimization. in addition, the previous machine learning algorithm support vector machine (svm) was also used to construct another prediction model based on the same data sets, comparing the model performance with the optimal dl model. finally, the evaluation test using 198 randomly selected samples showed that the optimal dl model achieved 97.1% accuracy, 97.4% sensitivity, 96.8% specificity, 0.942 matthews correlation coefficient, and 0.989 area under the roc curve, while the performance of svm model only reached 88.9% accuracy, 78.8% sensitivity, 99.0% specificity, 0.794 matthews correlation coefficient, and 0.901 area under the roc curve. furthermore, external data sets verification and animal experiments were conducted to assess the optimal dl model performance. finally, the predicted results of the optimal dl model were almost consistent with experiment results. these results indicated that our gene expression data based deep learning model could systematically and accurately predict dili in advance. it could be a useful tool to provide safety information for drug discovery and clinical rational drug use in early stage and become an important part of drug safety assessment.","['gene expression data based deep learning model', 'induced liver injury', 'accurate prediction', 'drug', 'advance']"
"crop yield is a highly complex trait determined by multiple factors such as genotype, environment, and their interactions. accurate yield prediction requires fundamental understanding of the functional relationship between yield and these interactive factors, and to reveal such relationship requires both comprehensive datasets and powerful algorithms. in the 2018 syngenta crop challenge, syngenta released several large datasets that recorded the genotype and yield performances of 2,267 maize hybrids planted in 2,247 locations between 2008 and 2016 and asked participants to predict the yield performance in 2017. as one of the winning teams, we designed a deep neural network (dnn) approach that took advantage of state-of-the-art modeling and solution techniques. our model was found to have a superior prediction accuracy, with a root-mean-square-error (rmse) being 12% of the average yield and 50% of the standard deviation for the validation dataset using predicted weather data. with perfect weather data, the rmse would be reduced to 11% of the average yield and 46% of the standard deviation. we also performed feature selection based on the trained dnn model, which successfully decreased the dimension of the input space without significant drop in the prediction accuracy. our computational results suggested that this model significantly outperformed other popular methods such as lasso, shallow neural networks (snn), and regression tree (rt). the results also revealed that environmental factors had a greater effect on the crop yield than genotype.",['crop yield prediction using deep neural networks']
"the spread of antibiotic resistance is one of the most serious global public-health problems. here we show that a particular class of homomers with binding sites spanning multiple protein chains is particularly suitable for targeting by broad-spectrum antibacterial agents because due to the slow evolutionary change of such binding pockets, ligands of such homomers are much more likely to bind their homologs than ligands of monomers, or homomers with a single-chain binding site. additionally, using de novo ligand design and deep learning, we show that the chemical compounds that can bind several different receptors have common structural characteristics and that halogens and fragments similar to the building blocks existing antimicrobials are overrepresented in them. finally, we show that binding multiple receptors selects for flexible compounds, which are less likely to accumulate in gram-negative bacteria; thus there is trade-off between reducing the emergence of resistance by multitargeting and broad-spectrum antibacterial activity.","['common structural characteristics', 'broad binding capabilities', 'antibiotic design perspective', 'receptors', 'ligands']"
"multi-target regression (mtr) comprises the prediction of multiple continuous target variables from a common set of input variables. there are two major challenges when addressing the mtr problem: the exploration of the inter-target dependencies and the modeling of complex input-output relationships. this paper proposes a neural network model that is able to simultaneously address these two challenges in a flexible way. a deep architecture well suited for learning multiple continuous outputs is designed, providing some flexibility to model the inter-target relationships by sharing network parameters as well as the possibility to exploit target-specific patterns by learning a set of nonshared parameters for each target. the effectiveness of the proposal is analyzed through an extensive experimental study on 18 datasets, demonstrating the benefits of using a shared representation that exploits the commonalities between target variables. according to the experimental results, the proposed model is competitive with respect to the state-of-the-art in mtr.","['target regression via', 'based deep network', 'performing multi', 'parameter sharing']"
"multi-instance learning (mil) is widely acknowledged as a fundamental method to solve weakly supervised problems. while mil is usually effective in standard weakly supervised object recognition tasks, in this paper, we investigate the applicability of mil on an extreme case of weakly supervised learning on the task of fine-grained visual categorization, in which intra-class variance could be larger than inter-class due to the subtle differences between subordinate categories. for this challenging task, we propose a new method that generalizes the standard multi-instance learning framework, for which a novel multi-task co-localization algorithm is proposed to take advantage of the relationship among fine-grained categories and meanwhile performs as an effective initialization strategy for the non-convex multi-instance objective. the localization results also enable object-level domain-specific fine-tuning of deep neural networks, which significantly boosts the performance. experimental results on three fine-grained datasets reveal the effectiveness of the proposed method, especially the importance of exploiting inter-class relationships between object categories in weakly supervised fine-grained recognition.","['weak supervision', 'grained categorization', 'friend', 'foe', 'fine']"
"space flight factors (sff) significantly affect the operating activity of astronauts during deep space missions. in contrast to an orbital flight, leaving the earth's magnetic field is fraught with the dangers of exposure to ionizing radiation and more specifically, the high-energy nuclei component of galactic cosmic rays. microgravity, just another critical non-radiation factor, significantly affects the normal functioning of the cns. some morphological structures of the brain, such as the prefrontal cortex and the hippocampus, that are rich in monoaminergic and acetylcholinergic neurones, are the most sensitive to the effects of ionizing radiation and non-radiation spaceflight factors (sff). in this work we have studied the combined effects of microgravity (in antiorthostatic suspension model, as) and irradiation (γ-ray and protons in spread-out bragg peak) on the behaviour, cognitive abilities, and metabolism of monoamines and acetylcholine in the key structures of the rat's brain. irradiation (as independently as combined with as) resulted in the decrease of thigmotaxis in rats. learning problems, caused by the malfunctioning of the working memory but not the spatial memory, were observed in response to as as well as to the sff in combination. analysis of monoamines metabolism showed that the serotoninergic system was the most affected by the sff. concentration of acetylcholine in the hippocampus significantly increased in the groups of irradiated rats, and in the groups which were exposed to the sff in combination, compared to the rats exposed only to as.","['different brain structures', 'neurotransmitters changes', 'ionizing radiation', 'combined effects', 'antiorthostatic suspension', 'rats', 'behaviour']"
"microwave ablation (mwa) for cancer treatment is frequently monitored by ultrasound (us) b-mode imaging in the clinic, which often fails due to the low intrinsic contrast between the thermal lesion and normal tissue. deep learning, especially convolutional neural network (cnn), has shown significant improvements in medical image analysis. here, we propose and evaluate an us imaging based on a cnn architecture for the detection and monitoring of thermal lesions induced by mwa in porcine livers. unlike dealing with images in many visual object recognition tasks, us radiofrequency (rf) data backscattered from the ablated region were utilized to capture features related to the thermal lesion. the dataset comprised of 1640 us rf envelope data matrices and their corresponding gross-pathology images, and were utilized for training and testing. after envelope detection, us b-mode, segmentation results based on cnn (sicnn), and modified cnn (sim-cnn) for us data were simultaneously reconstructed to reveal the suitability for monitoring of mwa. the sicnn and sim-cnn outperformed b-mode images for the detection and monitoring of mwa-induced thermal lesions. the values of the area under the receiver operating characteristic curve were 0.8728 and 0.8948 for the sicnn and sim-cnn, respectively, which were both higher than the value of 0.6904 for b-mode images. ablated regions that were assessed using sim-cnn showed a good correlation (j 0.8845, r 0.8739, and e 0.410) to gross-pathology images. this study was the first to illustrate that sim-cnn has the potential to detect and monitor thermal lesions, and may be utilized as an alternative modality for image-guided mwa treatments.","['microwave ablation using ultrasound imaging', 'thermal lesions induced', 'convolutional neural networks', 'monitoring', 'detection']"
"in the era of mobile internet, location based services (lbs) have developed dramatically. seamless indoor and outdoor navigation and localization (snal) has attracted a lot of attention. no single positioning technology was capable of meeting the various positioning requirements in different environments. selecting different positioning techniques for different environments is an alternative method. detecting the users' current environment is crucial for this technique. in this paper, we proposed to detect the indoor/outdoor environment automatically without high energy consumption. the basic idea was simple: we applied a machine learning algorithm to classify the neighboring global system for mobile (gsm) communication cellular base station's signal strength in different environments, and identified the users' current context by signal pattern recognition. we tested the algorithm in four different environments. the results showed that the proposed algorithm was capable of identifying open outdoors, semi-outdoors, light indoors and deep indoors environments with 100% accuracy using the signal strength of four nearby gsm stations. the required hardware and signal are widely available in our daily lives, implying its high compatibility and availability.","['smart phone sensor', 'outdoor detection using', 'indoor']"
"background and purpose- we evaluated deep learning algorithms' segmentation of acute ischemic lesions on heterogeneous multi-center clinical diffusion-weighted magnetic resonance imaging (mri) data sets and explored the potential role of this tool for phenotyping acute ischemic stroke. methods- ischemic stroke data sets from the mri-genie (mri-genetics interface exploration) repository consisting of 12 international genetic research centers were retrospectively analyzed using an automated deep learning segmentation algorithm consisting of an ensemble of 3-dimensional convolutional neural networks. three ensembles were trained using data from the following: (1) 267 patients from an independent single-center cohort, (2) 267 patients from mri-genie, and (3) mixture of (1) and (2). the algorithms' performances were compared against manual outlines from a separate 383 patient subset from mri-genie. univariable and multivariable logistic regression with respect to demographics, stroke subtypes, and vascular risk factors were performed to identify phenotypes associated with large acute diffusion-weighted mri volumes and greater stroke severity in 2770 mri-genie patients. stroke topography was investigated. results- the ensemble consisting of a mixture of mri-genie and single-center convolutional neural networks performed best. subset analysis comparing automated and manual lesion volumes in 383 patients found excellent correlation (ρ=0.92; p<0.0001). median (interquartile range) diffusion-weighted mri lesion volumes from 2770 patients were 3.7 cm3 (0.9-16.6 cm3). patients with small artery occlusion stroke subtype had smaller lesion volumes ( p<0.0001) and different topography compared with other stroke subtypes. conclusions- automated accurate clinical diffusion-weighted mri lesion segmentation using deep learning algorithms trained with multi-center and diverse data is feasible. both lesion volume and topography can provide insight into stroke subtypes with sufficient sample size from big heterogeneous multi-center clinical imaging phenotype data sets.","['phenotyping acute ischemic stroke using automated lesion segmentation', 'center magnetic resonance imaging data', 'big data approaches', 'multi']"
"neuromodulation is a promising treatment modality for disorders of learning and memory, offering the possibility of precise alteration of disordered neural circuits. studies to date have failed to identify an optimal target and stimulation paradigm. six epilepsy patients with depth electrodes implanted for seizure localization participated in our study. we recorded local field potentials from implanted electrodes while subjects participated in an associative learning task requiring them to learn an association between presented images and a button press. three subjects participated in stimulation sessions during which caudate or putamen stimulation was delivered for some images during feedback after correct responses. caudate stimulation enhanced learning. both caudate and dorsolateral prefrontal cortex demonstrated a beta power increase during the feedback period of the learning task that was greater following correct than incorrect trials. in dorsolateral prefrontal cortex, this difference increased with learning and persisted beyond the end of the feedback period. caudate stimulation was associated with increased dorsolateral prefrontal cortex beta power following feedback. these findings suggest that temporally specific caudate stimulation is a promising neuromodulation strategy to improve learning in disorders of learning and memory.",['caudate stimulation enhances learning']
"deep learning has become the dominant technology for protein contact prediction. however, the factors that affect the performance of deep learning in contact prediction have not been systematically investigated.","['several key factors influencing deep learning', 'residue contact prediction', 'based inter', 'analysis']"
"academic medical centers (amcs) in the united states built world-class infrastructure to successfully combat disease in the 20th century, which is inadequate for the complexity of sustaining and improving population health. amcs must now build first-rate 21st-century infrastructure to connect combating disease and promoting health. this infrastructure must acknowledge the bio-psycho-social-environmental factors impacting health and will need to reach far beyond the amc walls to foster community ""laboratories"" that support the ""science of health,"" complementary to those supporting the ""science of medicine""; cultivate community ""classrooms"" to stimulate learning and discovery in the places where people live, work, and play; and strengthen bridges between academic centers and these community laboratories and classrooms to facilitate bidirectional teaching, learning, innovation, and discovery.private and public entities made deep financial investments that contributed to the amc disease-centered approach to clinical care, education, and research in the 20th century. many of these same funders now recognize the need to transform u.s. health care into a system that is accountable for population health and the need for a medical workforce equipped with the skills to measure and improve health. innovative ideas about communities as centers of learning, the importance of social factors as major determinants of health, and the need for multidisciplinary perspectives to solve complex problems are not new; many are 20th-century ideas still waiting to be fully implemented. the window of opportunity is now. the authors articulate how amcs must take bigger and bolder steps to become leaders in population health.","['improving population health', 'academic medical centers', 'creating 21st', 'century laboratories', 'classrooms', 'call', 'action']"
"histone modifications are among the most important factors that control gene regulation. computational methods that predict gene expression from histone modification signals are highly desirable for understanding their combinatorial effects in gene regulation. this knowledge can help in developing 'epigenetic drugs' for diseases like cancer. previous studies for quantifying the relationship between histone modifications and gene expression levels either failed to capture combinatorial effects or relied on multiple methods that separate predictions and combinatorial analysis. this paper develops a unified discriminative framework using a deep convolutional neural network to classify gene expression using histone modification data as input. our system, called deepchrome, allows automatic extraction of complex interactions among important features. to simultaneously visualize the combinatorial interactions among histone modifications, we propose a novel optimization-based technique that generates feature pattern maps from the learnt deep model. this provides an intuitive description of underlying epigenetic mechanisms that regulate genes.","['predicting gene expression', 'histone modifications', 'learning', 'deepchrome', 'deep']"
"new technologies and procedures have the potential to improve outcomes; however, initial implementation is often associated with a steep learning curve, decreased efficiency, and patient safety implications. implementation of a real-time, ultrasound-based prostate high-dose rate brachytherapy procedure involved a multidisciplinary team composed of approximately 6-8 team members and numerous complex tasks. to characterize time spent on various aspects of the procedure and improve efficiency, the team developed a detailed process map, time study, and team debriefings. a benchmark was created based on an experienced institution which has performed >100 procedures annually. the process map was analyzed based on clinical tasks and treatment planning tasks. over the course of 17 cases at a single institution, total procedure time ranged from 222 to 107 minutes. implementation of the process map resulted in a reduction of total time by 52%. the implementation of a new procedure benefits from the integration and utilization of a process map. we were able to reduce procedure time significantly, which resulted in decreased time under general anesthesia, reduced risk of deep vein thrombosis, improved overall patient safety, patient throughput, and decreases in staffing demands.","['dose rate prostate brachytherapy', 'new procedure implementation', 'time study', 'process mapping', 'improve efficiency', 'high']"
to develop a natural language processing system that identifies relations of medications with adverse drug events from clinical narratives. this project is part of the 2018 n2c2 challenge.,"['adverse drug events using recurrent convolutional neural networks', 'identifying relations', 'gradient boosting', 'medications']"
"ongoing curricular renewal is a necessary phenomenon in nursing education to align learning with ever-changing professional practice demands. the mcmaster mohawk conestoga bscn program in hamilton, ontario, canada recently engaged in a comprehensive curriculum renewal. the purpose of this study was to evaluate the impact of curricular changes on students' deep learning. faculty perceptions about student learning outcomes during final year clinical placements were gathered through a combination of individual interviews and focus groups using interpretive descriptive qualitative research methodology. twenty five faculty members who supervised bscn students in clinical placements before and after curriculum renewal shared perceptions of changes in students' overall performance. the chosen clinical learning outcomes were: changes in students' performance related to person-centred care, clinical reasoning and judgment, pathophysiology, and evidence-informed decision-making. faculty described three major themes in students' performance 1) pulling it all together, 2) seeing the whole person, and 3) finding their nursing voices. this reflected a shift to person-centred care, increasing professional confidence, and improved clinical reasoning and judgment and no changes to integrating pathophysiology or evidence-informed decision-making. in this study curriculum renewal provided an excellent starting point for the scholarship of teaching and learning within nursing education.","['clinical learning outcomes', 'curricular changes', 'bscn students', 'impact']"
"precision medicine relies on an increasing amount of heterogeneous data. advances in radiation oncology, through the use of ct scan, dosimetry and imaging performed before each fraction, have generated a considerable flow of data that needs to be integrated. in the same time, electronic health records now provide phenotypic profiles of large cohorts of patients that could be correlated to this information. in this review, we describe methods that could be used to create integrative predictive models in radiation oncology. potential uses of machine learning methods such as support vector machine, artificial neural networks, and deep learning are also discussed.","['radiation oncology', 'machine learning', 'future prospects', 'big data', 'state', 'art']"
"for 3d imaging and shape measurement, simultaneously achieving real-time and high-accuracy performance remains a challenging task in practice. in this paper, a fringe-projection-based 3d imaging and shape measurement technique using a three-chip liquid-crystal-display (3lcd) projector and a deep machine learning scheme is presented. by encoding three phase-shifted fringe patterns into the red, green, and blue (rgb) channels of a color image and controlling the 3lcd projector to project the rgb channels individually, the technique can synchronize the projector and the camera to capture the required fringe images at a fast speed. in the meantime, the 3d imaging and shape measurement accuracy is dramatically improved by introducing a novel phase determination approach built on a fully connected deep neural network (dnn) learning model. the proposed system allows performing 3d imaging and shape measurement of multiple complex objects at a real-time speed of 25.6\xa0fps with relative accuracy of 0.012%. experiments have shown great promise for advancing scientific and engineering applications.","['time 3d shape measurement using 3lcd projection', 'deep machine learning', 'real']"
"with the rapid development of urbanization and industrialization, many developing countries are suffering from heavy air pollution. governments and citizens have expressed increasing concern regarding air pollution because it affects human health and sustainable development worldwide. current air quality prediction methods mainly use shallow models; however, these methods produce unsatisfactory results, which inspired us to investigate methods of predicting air quality based on deep architecture models. in this paper, a novel spatiotemporal deep learning (stdl)-based air quality prediction method that inherently considers spatial and temporal correlations is proposed. a stacked autoencoder (sae) model is used to extract inherent air quality features, and it is trained in a greedy layer-wise manner. compared with traditional time series prediction models, our model can predict the air quality of all stations simultaneously and shows the temporal stability in all seasons. moreover, a comparison with the spatiotemporal artificial neural network (stann), auto regression moving average (arma), and support vector regression (svr) models demonstrates that the proposed method of performing air quality predictions has a superior performance.","['deep learning architecture', 'air quality predictions']"
"antibodies often undergo substantial engineering en route to the generation of a therapeutic candidate with good developability properties. characterization of antibody libraries has shown that retaining native-like sequence improves the overall quality of the library. motivated by recent advances in deep learning, we developed a bi-directional long short-term memory (lstm) network model to make use of the large amount of available antibody sequence information, and use this model to quantify the nativeness of antibody sequences. the model scores sequences for their similarity to naturally occurring antibodies, which can be used as a consideration during design and engineering of libraries. we demonstrate the performance of this approach by training a model on human antibody sequences and show that our method outperforms other approaches at distinguishing human antibodies from those of other species. we show the applicability of this method for the evaluation of synthesized antibody libraries and humanization of mouse antibodies.","['antibody sequences using long short', 'term memory networks', 'quantifying', 'nativeness']"
"deep brain stimulation, as a primary surgical treatment for various neurological disorders, involves implanting electrodes to stimulate target nuclei within millimeter accuracy. accurate pre-operative target selection is challenging due to the poor contrast in its surrounding region in mr images. in this paper, we present a learning-based method to automatically and rapidly localize the target using multi-modal images. a learning-based technique is applied first to spatially normalize the images in a common coordinate space. given a point in this space, we extract a heterogeneous set of features that capture spatial and intensity contextual patterns at different scales in each image modality. regression forests are used to learn a displacement vector of this point to the target. the target is predicted as a weighted aggregation of votes from various test samples, leading to a robust and accurate solution. we conduct five-fold cross validation using 100 subjects and compare our method to three indirect targeting methods, a state-of-the-art statistical atlas-based approach, and two variations of our method that use only a single modality image. with an overall error of 2.63±1.37mm, our method improves upon the single modality-based variations and statistically significantly outperforms the indirect targeting ones. our technique matches state-of-the-art registration methods but operates on completely different principles. both techniques can be used in tandem in processing pipelines operating on large databases or in the clinical flow for automated error detection.","['deep brain stimulation procedures', 'operative targeting', 'modal learning', 'based pre', 'multi']"
"the study aimed to determine if computer vision techniques rooted in deep learning can use a small set of radiographs to perform clinically relevant image classification with high fidelity. one thousand eight hundred eighty-five chest radiographs on 909 patients obtained between january 2013 and july 2015 at our institution were retrieved and anonymized. the source images were manually annotated as frontal or lateral and randomly divided into training, validation, and test sets. training and validation sets were augmented to over 150,000 images using standard image manipulations. we then pre-trained a series of deep convolutional networks based on the open-source googlenet with various transformations of the open-source imagenet (non-radiology) images. these trained networks were then fine-tuned using the original and augmented radiology images. the model with highest validation accuracy was applied to our institutional test set and a publicly available set. accuracy was assessed by using the youden index to set a binary cutoff for frontal or lateral classification. this retrospective study was irb approved prior to initiation. a network pre-trained on 1.2 million greyscale imagenet images and fine-tuned on augmented radiographs was chosen. the binary classification method correctly classified 100\xa0% (95\xa0% ci 99.73-100\xa0%) of both our test set and the publicly available images. classification was rapid, at 38 images per second. a deep convolutional neural network created using non-radiological images, and an augmented set of radiographs is effective in highly accurate classification of chest radiograph view type and is a feasible, rapid method for high-throughput annotation.","['radiographs using deep convolutional neural networks', 'throughput classification', 'high']"
in cognitive neuroscience the potential of deep neural networks (dnns) for solving complex classification tasks is yet to be fully exploited. the most limiting factor is that dnns as notorious 'black boxes' do not provide insight into neurophysiological phenomena underlying a decision. layer-wise relevance propagation (lrp) has been introduced as a novel method to explain individual network decisions.,"['interpretable deep neural networks', 'trial eeg classification', 'single']"
"wormlion larvae are sit-and-wait predators that construct cone-shaped pits in sandy patches to capture prey. wormlions select microhabitats that feature favorable conditions for pit construction, in a similar way to other trap-building predators, like spiders and antlions. we investigated whether wormlions exhibit an experience-based behavioral plasticity in their pit construction behavior. in a laboratory experiment, pit sizes and relocation distances were compared between larvae that experienced either a period of unfavorable conditions, i.e., surface obstacles, shallow or coarse sand, or a period of favorable conditions, i.e., clear, deep, and fine sand and were able to construct pits undisturbed. we expected that wormlions experiencing improving conditions would build larger pits than those experiencing deteriorating conditions. in addition, we expected that larvae experiencing unfavorable conditions would be less choosy in their new microhabitat and move over shorter distances. we observed a certain effect of recent experience on the trap-building behavior; however, it was not consistent among treatments. additionally, we detected a correlation between larval body mass, relocation distance, and pit area. these findings might suggest that past experience does not influence wormlion foraging behavior in a simple manner but that different types of experience induce different behavioral responses.","['trap construction', 'previous experience', 'movement distance', 'building predator', 'pit', 'effect']"
"we present a novel regularization method for a multilayer perceptron (mlp) that learns a regression function in the presence of noise regardless of how smooth the function is. unlike general mlp regularization methods assuming that a regression function is smooth, the proposed regularization method is also valid when a regression function has discontinuities (non-smoothness). since a true regression function to be learned is unknown, we examine a training set with our bayesian approach that identifies non-smooth data, analyzing discontinuities in a regression function. the use of a bayesian probability distribution identifies the non-smooth data. these identified data is used in a proposed objective function to fit an mlp response to the desired regression function regardless of its smoothness and noise. experimental simulations show that the mlp with our presented training method yields more accurate fits to non-smooth functions than other mlp training methods. further, we show that the suggested training methodology can be incorporated with deep learning models.","['approximate bayesian mlp regularization', 'regression', 'presence', 'noise']"
"rna editing is a post-transcriptional alteration of rna sequences that, via insertions, deletions or base substitutions, can affect protein structure as well as rna and protein expression. recently, it has been suggested that rna editing may be more frequent than previously thought. a great impediment, however, to a deeper understanding of this process is the paramount sequencing effort that needs to be undertaken to identify rna editing events. here, we describe an in silico approach, based on machine learning, that ameliorates this problem. using 41 nucleotide long dna sequences, we show that novel a-to-i rna editing events can be predicted from known a-to-i rna editing events intra- and interspecies. the validity of the proposed method was verified in an independent experimental dataset. using our approach, 203 202 putative a-to-i rna editing events were predicted in the whole human genome. out of these, 9% were previously reported. the remaining sites require further validation, e.g., by targeted deep sequencing. in conclusion, the approach described here is a useful tool to identify potential a-to-i rna editing events without the requirement of extensive rna sequencing.","['rna editing events', 'dna sequence', 'discriminative prediction']"
"mental disorders are a leading cause of disability, morbidity, and mortality among civilian and military populations. most available treatments have limited efficacy, particularly in disorders where symptoms vary over relatively short time scales. targeted modulation of neural circuits, particularly through open-loop deep brain stimulation (dbs), showed initial promise but has failed in blinded clinical trials. we propose a new approach, based on targeting neural circuits linked to functional domains that cut across diagnoses. through that framework, which includes measurement of patients using six psychophysical tasks, we seek to develop a closed-loop dbs system that corrects dysfunctional activity in brain circuits underlying those domains. we present convergent preliminary evidence from functional neuroimaging, invasive human electrophysiology, and human brain stimulation experiments suggesting that this approach is feasible. using the emotional conflict resolution (ecr) task as an example, we show that emotion-related networks can be identified and modulated in individual patients. invasive and non-invasive methodologies both identify a network between prefrontal cortex, cingulate cortex, insula, and amygdala. further, stimulation in cingulate and amygdala changes patients' performance in ways that are linked to the task's emotional content. we present preliminary statistical models that predict this change and allow us to track it at a single-trial level. as these diagnostic and modeling strategies are refined and embodied in an implantable device, they offer the prospect of a new approach to psychiatric treatment and its accompanying neuroscience.","['treating refractory mental illness', 'specific transdiagnostic approach', 'loop brain stimulation', 'progress towards', 'patient', 'closed']"
"the cerebellum plays a critical role in sensorimotor control. however, how the specific circuits and plastic mechanisms of the cerebellum are engaged in closed-loop processing is still unclear. we developed an artificial sensorimotor control system embedding a detailed spiking cerebellar microcircuit with three bidirectional plasticity sites. this proved able to reproduce a cerebellar-driven associative paradigm, the eyeblink classical conditioning (ebcc), in which a precise time relationship between an unconditioned stimulus (us) and a conditioned stimulus (cs) is established. we challenged the spiking model to fit an experimental data set from human subjects. two subsequent sessions of ebcc acquisition and extinction were recorded and transcranial magnetic stimulation (tms) was applied on the cerebellum to alter circuit function and plasticity. evolutionary algorithms were used to find the near-optimal model parameters to reproduce the behaviors of subjects in the different sessions of the protocol. the main finding is that the optimized cerebellar model was able to learn to anticipate (predict) conditioned responses with accurate timing and success rate, demonstrating fast acquisition, memory stabilization, rapid extinction, and faster reacquisition as in ebcc in humans. the firing of purkinje cells (pcs) and deep cerebellar nuclei (dcn) changed during learning under the control of synaptic plasticity, which evolved at different rates, with a faster acquisition in the cerebellar cortex than in dcn synapses. eventually, a reduced pc activity released dcn discharge just after the cs, precisely anticipating the us and causing the eyeblink. moreover, a specific alteration in cortical plasticity explained the ebcc changes induced by cerebellar tms in humans. in this paper, for the first time, it is shown how closed-loop simulations, using detailed cerebellar microcircuit models, can be successfully used to fit real experimental data sets. thus, the changes of the model parameters in the different sessions of the protocol unveil how implicit microcircuit mechanisms can generate normal and altered associative behaviors.the cerebellum plays a critical role in sensorimotor control. however, how the specific circuits and plastic mechanisms of the cerebellum are engaged in closed-loop processing is still unclear. we developed an artificial sensorimotor control system embedding a detailed spiking cerebellar microcircuit with three bidirectional plasticity sites. this proved able to reproduce a cerebellar-driven associative paradigm, the eyeblink classical conditioning (ebcc), in which a precise time relationship between an unconditioned stimulus (us) and a conditioned stimulus (cs) is established. we challenged the spiking model to fit an experimental data set from human subjects. two subsequent sessions of ebcc acquisition and extinction were recorded and transcranial magnetic stimulation (tms) was applied on the cerebellum to alter circuit function and plasticity. evolutionary algorithms were used to find the near-optimal model parameters to reproduce the behaviors of subjects in the different sessions of the protocol. the main finding is that the optimized cerebellar model was able to learn to anticipate (predict) conditioned responses with accurate timing and success rate, demonstrating fast acquisition, memory stabilization, rapid extinction, and faster reacquisition as in ebcc in humans. the firing of purkinje cells (pcs) and deep cerebellar nuclei (dcn) changed during learning under the control of synaptic plasticity, which evolved at different rates, with a faster acquisition in the cerebellar cortex than in dcn synapses. eventually, a reduced pc activity released dcn discharge just after the cs, precisely anticipating the us and causing the eyeblink. moreover, a specific alteration in cortical plasticity explained the ebcc changes induced by cerebellar tms in humans. in this paper, for the first time, it is shown how closed-loop simulations, using detailed cerebellar microcircuit models, can be successfully used to fit real experimental data sets. thus, the changes of the model parameters in the different sessions of the protocol unveil how implicit microcircuit mechanisms can generate normal and altered associative behaviors.","['eyeblink classical conditioning reveals', 'underlying structure', 'neuronal activity', 'driven analysis', 'cerebellar plasticity', 'model']"
"we propose an autoencoding sequence-based transceiver for communication over dispersive channels with intensity modulation and direct detection (im/dd), designed as a bidirectional deep recurrent neural network (brnn). the receiver uses a sliding window technique to allow for efficient data stream estimation. we find that this sliding window brnn (sbrnn), based on end-to-end deep learning of the communication system, achieves a significant bit-error-rate reduction at all examined distances in comparison to previous block-based autoencoders implemented as feed-forward neural networks (ffnns), leading to an increase of the transmission distance. we also compare the end-to-end sbrnn with a state-of-the-art im/dd solution based on two level pulse amplitude modulation with an ffnn receiver, simultaneously processing multiple received symbols and approximating nonlinear volterra equalization. our results show that the sbrnn outperforms such systems at both 42 and 84 gb/s, while training fewer parameters. our novel sbrnn design aims at tailoring the end-to-end deep learning-based systems for communication over nonlinear channels with memory, such as the optical im/dd fiber channel.","['modulated channels using bidirectional recurrent neural networks', 'end optimized transmission', 'dispersive intensity', 'end']"
"cathepsins b and l are two prominent members of cystein proteases with broad substrate specificity and are known to be involved in the process of intra- and extra-cellular protein degradation and turnover. the propeptide region of cathepsin l is identical to cytotoxic t-lymphocyte antigen-2α (ctla-2α) discovered in mouse activated t-cells and mast cells. ctla-2α exhibits selective inhibitory activities against papain and cathepsin l. we previously demonstrated the distribution pattern of the ctla-2α protein in mouse brain by immunohistochemistry, describing that it is preferentially localized within nerve fibre bundles than neuronal cell bodies. in the present study we report colocalization of cathepsin l and ctla-2α by double labeling immunofluorescence analysis in the mouse brain. in the telencephalon, immunoreactivity was identified in cerebral cortex and subcortical structures, hippocampus and amygdala. within the diencephalon intense colocalization was detected in stria medullaris of thalamus, mammillothalamic tract, medial habenular nucleus and choroid plexus. colocalization signals in the mesencephalon were strong in the hypothalamus within supramammillary nucleus and lateroanterior hypothalamic nucleus while in the cerebellum was in the deep white matter, granule cell layer and purkinje neurons but moderately in stellate, and basket cells of cerebellar cortex. the distribution pattern indicates that the fine equilibrium between synthesis and secretion of cathespin l and ctla-2α is part of the brain processes to maintain normal growth and development. the functional implication of cathespin l coexistence with ctla-2α in relation to learning, memory and disease mechanisms is discussed.","['cathepsin l coexists', 'mouse brain', 'lymphocyte antigen', 'distinct regions', '2 alpha', 'cytotoxic']"
"vector-valued neural learning has emerged as a promising direction in deep learning recently. traditionally, training data for neural networks (nns) are formulated as a vector of scalars; however, its performance may not be optimal since associations among adjacent scalars are not modeled. in this article, we propose a new vector neural architecture called the arbitrary bilinear product nn (abipnn), which processes information as vectors in each neuron, and the feedforward projections are defined using arbitrary bilinear products. such bilinear products can include circular convolution, 7-d vector product, skew circular convolution, reversed-time circular convolution, or other new products that are not seen in the previous work. as a proof-of-concept, we apply our proposed network to multispectral image denoising and singing voice separation. experimental results show that abipnn obtains substantial improvements when compared to conventional nns, suggesting that associations are learned during training.","['valued neurons using arbitrary bilinear products', 'vector', 'n', 'backpropagation']"
"segmentation of the liver from abdominal computed tomography (ct) images is an essential step in some computer-assisted clinical interventions, such as surgery planning for living donor liver transplant, radiotherapy and volume measurement. in this work, we develop a deep learning algorithm with graph cut refinement to automatically segment the liver in ct scans.","['segmentation via convolutional neural network', 'automatic 3d liver location', 'graph cut']"
"to compare performance of a deep-learning enhanced algorithm for automated detection of diabetic retinopathy (dr), to the previously published performance of that algorithm, the iowa detection program (idp)-without deep learning components-on the same publicly available set of fundus images and previously reported consensus reference standard set, by three us board certified retinal specialists.","['publicly available dataset', 'improved automated detection', 'diabetic retinopathy', 'deep learning', 'integration']"
"basic science courses are extremely important as a foundation for scaffolding knowledge and then applying it in future courses, clinical situations as well as in a professional career. anatomical sciences, which include tooth morphology, oral histology, oral embryology, and head and neck anatomy form a core part of the preclinical courses in dental technology programs. in this article, the importance and relevance of anatomical sciences to dental personnel with no direct contact with patients (dental technicians) and limited discipline related contact with patients (dental prosthetists) is highlighted. some light is shed on the role of anatomical sciences in the pedagogical framework and its significance in the educational process and interprofessional learning of dental technicians and prosthetists using oral biology as an example in the dental curriculum. to conclude, anatomical sciences allow dental technicians and prosthetists to a gain a better insight of how tissues function, leading to a better understanding of diagnosis, comprehensive treatment planning and referrals if needed. patient communication and satisfaction also increases as a result of this deep understanding of oral tissues. anatomical sciences bridge the gap between basic science, preclinical, and clinical courses, which leads to a holistic approach in patient management. finally, treatment outcomes are positively affected due to the appreciation of the macro and micro structure of oral tissues. anat sci educ 10: 395-404.","['solid learning experience', 'dental technology', 'dental prosthetics', 'anatomical sciences', 'foundation']"
"in recent years, some deep learning methods have been developed and applied to image classification applications, such as convolutional neuron network (cnn) and deep belief network (dbn). however they are suffering from some problems like local minima, slow convergence rate, and intensive human intervention. in this paper, we propose a rapid learning method, namely, deep convolutional extreme learning machine (dc-elm), which combines the power of cnn and fast training of elm. it uses multiple alternate convolution layers and pooling layers to effectively abstract high level features from input images. then the abstracted features are fed to an elm classifier, which leads to better generalization performance with faster learning speed. dc-elm also introduces stochastic pooling in the last hidden layer to reduce dimensionality of features greatly, thus saving much training time and computation resources. we systematically evaluated the performance of dc-elm on two handwritten digit data sets: mnist and usps. experimental results show that our method achieved better testing accuracy with significantly shorter training time in comparison with deep learning methods and other elm methods.","['deep convolutional extreme learning machine', 'handwritten digit classification', 'application']"
"zebrafish ( danio rerio) is an important vertebrate model organism in biomedical research, especially suitable for morphological screening due to its transparent body during early development. deep learning has emerged as a dominant paradigm for data analysis and found a number of applications in computer vision and image analysis. here we demonstrate the potential of a deep learning approach for accurate high-throughput classification of whole-body zebrafish deformations in multifish microwell plates. deep learning uses the raw image data as an input, without the need of expert knowledge for feature design or optimization of the segmentation parameters. we trained the deep learning classifier on as few as 84 images (before data augmentation) and achieved a classification accuracy of 92.8% on an unseen test data set that is comparable to the previous state of the art (95%) based on user-specified segmentation and deformation metrics. ablation studies by digitally removing whole fish or parts of the fish from the images revealed that the classifier learned discriminative features from the image foreground, and we observed that the deformations of the head region, rather than the visually apparent bent tail, were more important for good classification performance.",['deep fish']
"there is a worldwide focus on the early development of collaborative skills in medical students as reflected in the design of the medicine program at the university of new south wales, australia. integral to the success of student-centered curricula, is early development of students' self-directed and collaborative learning skills. the purpose of this innovative assessment is to develop and assess students' skills in self-directed and collaborative learning while they concurrently engage with stage-appropriate content knowledge.","['teamwork group projects', 'innovative assessment', 'directed learning', 'combines collaborative', 'self', 'knowledge', 'integration', 'application']"
"this paper introduces a new generative deep learning network for human motion synthesis and control. our key idea is to combine recurrent neural networks (rnns) and adversarial training for human motion modeling. we first describe an efficient method for training an rnn model from prerecorded motion data. we implement rnns with long short-term memory (lstm) cells because they are capable of addressing the nonlinear dynamics and long term temporal dependencies present in human motions. next, we train a refiner network using an adversarial loss, similar to generative adversarial networks (gans), such that refined motion sequences are indistinguishable from real mocap data using a discriminative network. the resulting model is appealing for motion synthesis and control because it is compact, contact-aware, and can generate an infinite number of naturally looking motions with infinite lengths. our experiments show that motions generated by our deep learning model are always highly realistic and comparable to high-quality motion capture data. we demonstrate the power and effectiveness of our models by exploring a variety of applications, ranging from random motion synthesis, online/offline motion control, and motion filtering. we show the superiority of our generative model by comparison against baseline models.","['combining recurrent neural networks', 'human motion synthesis', 'adversarial training', 'control']"
"objective deep brain stimulation (dbs) is a reversible, nonlesion-based treatment for patients with intractable obsessive-compulsive disorder (ocd). the first studies on dbs for ocd stimulating the ventral capsule/ventral striatum (vc/vs) yielded encouraging results for this neuroanatomical site's therapeutic efficacy. this investigation was conducted to better understand which regions of the cortico-striatal-thalamic-cortical network were acutely affected by vc/vs dbs for ocd. furthermore, the objective was to identify which brain regions demonstrated changes in perfusion, as stimulation was applied across a dorsoventral lead axis that corresponded to different anatomical locations in the vc/vs. methods six patients receiving vc/vs dbs for ocd underwent oxygen-15 positron emission tomography (15o-pet) scanning. monopolar dbs was delivered at each of the 4 different electrodes on the stimulating lead in the vc/vs. the data were analyzed using spm5. paired t-tests were run in spss to identify significant changes in regional cerebral blood flow (rcbf) between stimulation conditions. pearson's r correlations were run between these significant changes in rcbf and changes in ocd and depressive symptom severity. results perfusion in the dorsal anterior cingulate cortex (dacc) significantly increased when monopolar dbs was turned on at the most ventral dbs contact, and this increase in dacc activity was correlated with reductions in depressive symptom severity (r(5) = -0.994, p = 0.001). perfusion in the thalamus, striatum, and globus pallidus significantly increased when dbs was turned on at the most dorsal contact. conclusions dbs of the vc/vs appears to modulate activity in the regions implicated in the pathophysiology of ocd. different regions in the cortico-striatal-thalamic-cortical circuit showed increased perfusion based on whether the stimulation was more ventral or dorsal along the lead axis in the vc/vs. evidence was found that dbs at the most ventral site was associated with clinical changes in depressive symptom severity, but not ocd symptom severity.","['acute deep brain stimulation changes', 'regional cerebral blood flow', 'compulsive disorder', 'obsessive']"
"deep learning has shown great potential for curvilinear structure (e.g., retinal blood vessels and neurites) segmentation as demonstrated by a recent auto-context regression architecture based on filter banks learned by convolutional sparse coding. however, learning such filter banks is very time-consuming, thus limiting the amount of filters employed and the adaptation to other data sets (i.e., slow re-training). we address this limitation by proposing a novel acceleration strategy to speed-up convolutional sparse coding filter learning for curvilinear structure segmentation. our approach is based on a novel initialisation strategy (warm start), and therefore it is different from recent methods improving the optimisation itself. our warm-start strategy is based on carefully designed hand-crafted filters (scird-ts), modelling appearance properties of curvilinear structures which are then refined by convolutional sparse coding. experiments on four diverse data sets, including retinal blood vessels and neurites, suggest that the proposed method reduces significantly the time taken to learn convolutional filter banks (i.e., up to -82%) compared to conventional initialisation strategies. remarkably, this speed-up does not worsen performance; in fact, filters learned with the proposed strategy often achieve a much lower reconstruction error and match or exceed the segmentation performance of random and dct-based initialisation, when used as input to a random forest classifier.","['accelerating convolutional sparse coding', 'ts filter banks', 'curvilinear structures segmentation', 'refining scird']"
"functional annotation of protein sequence with high accuracy has become one of the most important issues in modern biomedical studies, and computational approaches of significantly accelerated analysis process and enhanced accuracy are greatly desired. although a variety of methods have been developed to elevate protein annotation accuracy, their ability in controlling false annotation rates remains either limited or not systematically evaluated. in this study, a protein encoding strategy, together with a deep learning algorithm, was proposed to control the false discovery rate in protein function annotation, and its performances were systematically compared with that of the traditional similarity-based and de novo approaches. based on a comprehensive assessment from multiple perspectives, the proposed strategy and algorithm were found to perform better in both prediction stability and annotation accuracy compared with other de novo methods. moreover, an in-depth assessment revealed that it possessed an improved capacity of controlling the false discovery rate compared with traditional methods. all in all, this study not only provided a comprehensive analysis on the performances of the newly proposed strategy but also provided a tool for the researcher in the fields of protein function annotation.","['false discovery rate achieved', 'simultaneously improved stability', 'protein functional annotation', 'based deep learning', 'sequence', 'accuracy']"
"electronic interactions present in material compositions close to the superconducting dome play a key role in the manifestation of high-t c superconductivity. in many correlated electron systems, however, the parent or underdoped states exhibit strongly inhomogeneous electronic landscape at the nanoscale that may be associated with competing, coexisting, or intertwined chemical disorder, strain, magnetic, and structural order parameters. here we demonstrate an approach based on a combination of scanning tunneling microscopy/spectroscopy and advanced statistical learning for an automatic separation and extraction of statistically significant electronic behaviors in the spin density wave regime of a lightly (∼1%) gold-doped bafe2as2. we show that the decomposed sts spectral features have a direct relevance to fundamental physical properties of the system, such as sdw-induced gap, pseudogap-like state, and impurity resonance states.","['lightly doped bafe2as2', 'intertwined electronic responses', 'deep data mining', 'real space', 'separation']"
"models based on deep convolutional networks have dominated recent image interpretation tasks; we investigate whether models which are also recurrent are effective for tasks involving sequences, visual and otherwise. we describe a class of recurrent convolutional architectures which is end-to-end trainable and suitable for large-scale visual understanding tasks, and demonstrate the value of these models for activity recognition, image captioning, and video description. in contrast to previous models which assume a fixed visual representation or perform simple temporal averaging for sequential processing, recurrent convolutional models are ""doubly deep"" in that they learn compositional representations in space and time. learning long-term dependencies is possible when nonlinearities are incorporated into the network state updates. differentiable recurrent models are appealing in that they can directly map variable-length inputs (e.g., videos) to variable-length outputs (e.g., natural language text) and can model complex temporal dynamics; yet they can be optimized with backpropagation. our recurrent sequence models are directly connected to modern visual convolutional network models and can be jointly trained to learn temporal dynamics and convolutional perceptual representations. our results show that such models have distinct advantages over state-of-the-art models for recognition or generation which are separately defined or optimized.","['term recurrent convolutional networks', 'visual recognition', 'long', 'description']"
"simulation is firmly established as a mainstay of clinical education, and extensive research has demonstrated its value. current practice uses inanimate simulators (with a range of complexity, sophistication and cost) to address the patient 'as body' and trained actors or lay people (simulated patients) to address the patient 'as person'. these approaches are often separate.healthcare simulation to date has been largely for the training and assessment of clinical 'insiders', simulating current practices. a close coupling with the clinical world restricts access to the facilities and practices of simulation, often excluding patients, families and publics. yet such perspectives are an essential component of clinical practice.",['simulation reframed']
"a detailed understanding of space objects is one of the important goals of space situational awareness. the geostationary orbit (geo) belt is an important space asset for human beings, so the identification of geo satellites is one of the measures to ensure the safety of geo objects (geos). in this paper, we propose using deep learning based on recurrent neural networks (rnns) and convolutional neural networks (cnns), and multiple kernel learning (mkl) to identify the shape and attitude of geos synchronously via light curves. our algorithm focuses mainly on optical data obtained from the real measured data collected by optical laboratory and computer simulation. we first acquired light curves of five geo satellites for 1 year; then, we constructed a network architecture consisting of cnns and rnns to automatically extract the different scale characteristics of the collected light curves of geos. next, we use the mkl to fuse the extracted features of different scales. finally, the support vector machine is used to provide the classification and recognition results of the shape and attitude of five geos. the network architecture proposed is compared with more conventional machine learning techniques (e.g., principal component analysis, linear discriminant analysis) and is shown to outperform such methods. at the same time, the classification effect of the multiple kernel is better than the single kernel in this experiment.","['multiple kernel learning', 'deep learning', 'geosynchronous satellites', 'classification']"
"protein intrinsic disorder describes the tendency of sequence residues to not fold into a rigid three-dimensional shape by themselves. however, some of these disordered regions can transition from disorder to order when interacting with another molecule in segments known as molecular recognition features (morfs). previous analysis has shown that these morf regions are indirectly encoded within the prediction of residue disorder as low-confidence predictions [i.e. in a semi-disordered state p(d)≈0.","['morf residues would allow us', 'currently available annotated morf proteins', 'identifying molecular recognition features', 'disorder2 ensemble models built', 'large training set available', 'larger analytical models', 'intrinsically disordered regions', 'disorder prediction may', 'morf prediction', 'currently feasible', 'protein disorder', 'disorder prediction', 'transfer learning', 'take advantage', 'small number', 'new method', 'internal characterization', 'proteins', 'training', 'prediction']"
"recent advances in the areas of bioinformatics and chemogenomics are poised to accelerate the discovery of small molecule regulators of cell development. combining large genomics and molecular data sources with powerful deep learning techniques has the potential to revolutionize predictive biology. in this study, we present deep gene compound profiler (deepcop), a deep learning based model that can predict gene regulating effects of low-molecular weight compounds. this model can be used for direct identification of a drug candidate causing a desired gene expression response, without utilizing any information on its interactions with protein target(s).","['predict gene regulating effects', 'small molecules', 'deep learning', 'based approach', 'deepcop']"
"sharp-wave ripples (spw-rs) in the hippocampus are implied in memory consolidation, as shown by observational and interventional experiments. however, the mechanism of their generation remains unclear. using two-dimensional silicon probe arrays, we investigated the propagation of spw-rs across the hippocampal ca1, ca2, and ca3 subregions. synchronous activation of ca2 ensembles preceded spw-r-related population activity in ca3 and ca1 regions. deep ca2 neurons gradually increased their activity prior to ripples and were suppressed during the population bursts of ca3-ca1 neurons (ramping cells). activity of superficial ca2 cells preceded the activity surge in ca3-ca1 (phasic cells). the trigger role of the ca2 region in spw-r was more pronounced during waking than sleeping. these results point to the ca2 region as an initiation zone for spw-rs.","['hippocampal ca2 region', 'wave ripples', 'triggering sharp', 'role']"
"the academic success and degree completion of tertiary students depends on their academic performance (ap), commonly measured by the percentage grades for the units they complete. no research has examined whether occupational therapy students' approaches to study are predictive of their ap. this study investigated whether approaches to study were predictive of the ap among a group of australian undergraduate occupational therapy students.","['academic performance among australian undergraduate occupational therapy students', 'study', 'relationship', 'approaches']"
"everyday, we encounter situations where available choices are nearly equally rewarding (high conflict) calling for some tough decision making. experimental recordings showed that the activity of sub thalamic nucleus (stn) increases during such situations providing the extra time needed to make the right decision, teasing apart the most rewarding choice from the runner up closely trailing behind. this prolonged deliberation necessary for decision making under high conflict was absent in parkinson's disease (pd) patients who underwent deep brain stimulation (dbs) surgery of stn. in an attempt to understand the underlying cause of such adverse response, we built a 2d spiking network model (50 × 50 lattice) of basal ganglia incorporating the key nuclei. using the model we studied the probabilistic learning task (plt) in untreated, treated (l-dopa and dopamine agonist) and stn-dbs pd conditions. based on the experimental observation that dopaminergic activity is analogous to temporal difference (td) and induces cortico-striatal plasticity, we introduced learning in the cortico-striatal weights. the results show that healthy and untreated conditions of pd model were able to more or less equally select (avoid) the rewarding (punitive) choice, a behavior that was absent in treated pd condition. the time taken to select a choice in high conflict trials was high in normal condition, which is in agreement with experimental results. the treated pd (dopamine agonist) patients made impulsive decisions (small reaction time) which in turn led to poor performance. the underlying cause of the observed impulsivity in dbs patients was studied in the model by (1) varying the electrode position within stn, (2) causing antidromic activation of gpe neurons. the effect of electrode position on reaction time was analyzed by studying the activity of stn neurons where, a decrease in stn neural activity was observed for certain electrode positions. we also observed that a higher antidromic activation of gpe neurons does not impact the learning ability but decreases reaction time as reported in dbs patients. these results suggest a probable role of electrode and antidromic activation in modulating the stn activity and eventually affecting the patient's performance on plt.","['dbs electrode position', 'impulsivity using', 'computational model', 'basal ganglia', 'antidromic activation', 'role', 'probing', 'medication']"
"the theory of predictive coding assumes that higher-order representations influence lower-order representations by generating predictions about sensory input. in congenital deafness, one identified dysfunction is a reduced activation of deep layers in the auditory cortex. since these layers play a central role for processing top-down influences, congenital deafness might interfere with the integration of top-down and bottom-up information flow. studies in humans suggest more deficits in higher-order than in primary cortical areas in congenital deafness. that opens up the question how well neurons in higher-order areas can be activated by the input through the deprived auditory pathway after restoration of hearing with cochlear implants. further it is unclear whether their interconnections to lower order areas are impaired by absence of hearing. corticocortical anatomical fiber tracts and general auditory responsiveness in both primary and higher-order areas are generally preserved in absence of auditory experience. however, the existing data suggest a dichotomy between preservation of anatomical cortical connectivity in congenital deafness and functional deficits in corticocortical coupling. further, cross-modal reorganization observed in congenital deafness in specific cortical areas appears to be established by functional synaptic changes and rests on anatomically preserved, genetically-predetermined and molecularly patterned circuitry connecting the sensory systems. current data indicate a reduced corticocortical functional coupling between cortical auditory areas in congenital deafness, both in bottom-up and top-down information stream. consequently, congenital deafness is likely to result in a deficit in predictive coding that affects learning ability after late cochlear implantation.","['order auditory areas', 'corticocortical decoupling', 'congenital deafness', 'top', 'interactions', 'higher']"
"peripheral nerve imaging is recognized as a complement to clinical and neurophysiological assessment in the evaluation of peripheral nerves with the ability to impact patient management, even for small and difficult nerves. the european society of musculoskeletal radiology, suggest to use ultrasound (us) for nerve evaluation due to the fact that, in sever anatomical area, magnetic resonance imaging is not able to give additional informations. us could be considered the first-choice approach for the assessment of peripheral nerves. the relative drawback of peripheral nerve us is the long learning curve and the deep anatomic competence to evaluate even small nerves. in the recent years, the role of us in peripheral nerve evaluation has been widened. in the past, nerve us was mainly used to assess nerve-cross sectional area, but now more advanced measurements and considerations are desirable and can boost the role of peripheral nerve us. nerve echotexture evaluation was defined in 2010: the ratio between the hypoechoic and hyperechoic areas of peripheral nerves on us was called ""nerve density"". for evaluation of patients who have peripheral neuropathies, the role of peripheral nerve is us wider than simple cross-sectional area evaluation. quantitative measurements describing the internal fascicular echotexture of peripheral nerves introduce the concept of considering us as a possible quantitative imaging biomarker technique. the potential of nerve us has started to be uncovered. it seems clear that only cross-sectional area measurement is no more sufficient for a comprehensive us evaluation of peripheral nerves.","['peripheral nerve imaging', 'sectional area', 'cross']"
"big sensor data provide significant potential for chemical fault diagnosis, which involves the baseline values of security, stability and reliability in chemical processes. a deep neural network (dnn) with novel active learning for inducing chemical fault diagnosis is presented in this study. it is a method using large amount of chemical sensor data, which is a combination of deep learning and active learning criterion to target the difficulty of consecutive fault diagnosis. dnn with deep architectures, instead of shallow ones, could be developed through deep learning to learn a suitable feature representation from raw sensor data in an unsupervised manner using stacked denoising auto-encoder (sdae) and work through a layer-by-layer successive learning process. the features are added to the top softmax regression layer to construct the discriminative fault characteristics for diagnosis in a supervised manner. considering the expensive and time consuming labeling of sensor data in chemical applications, in contrast to the available methods, we employ a novel active learning criterion for the particularity of chemical processes, which is a combination of best vs. second best criterion (bvsb) and a lowest false positive criterion (lfp), for further fine-tuning of diagnosis model in an active manner rather than passive manner. that is, we allow models to rank the most informative sensor data to be labeled for updating the dnn parameters during the interaction phase. the effectiveness of the proposed method is validated in two well-known industrial datasets. results indicate that the proposed method can obtain superior diagnosis accuracy and provide significant performance improvement in accuracy and false positive rate with less labeled chemical sensor data by further active learning compared with existing methods.","['active deep neural network', 'fault diagnosis based', 'chemical sensor data']"
"here, we provide a comprehensive overview of the current status of in silico repurposing methods by establishing links between current technological trends, data availability and characteristics of the algorithms used in these methods. using the case of the computational repurposing of fasudil as an alternative autophagy enhancer, we suggest a generic modular organization of a repurposing workflow. we also review 3d structure-based, similarity-based, inference-based and machine learning (ml)-based methods. we summarize the advantages and disadvantages of these methods to emphasize three current technical challenges. we finish by discussing current directions of research, including possibilities offered by new methods, such as deep learning.","['silico drug repurposing', 'efficient computational workflows', 'design']"
"[this corrects the article on p. 38 in vol. 7, pmid: 27688929","['eosin stained breast cancer samples', 'tumor infiltrating immune cells', 'antibody supervised deep learning', 'quantification', 'hematoxylin', 'erratum']"
"the binding affinities (ic50) reported for diverse structural and chemical classes of human β-secretase 1 (bace-1) inhibitors in literature were modeled using multiple in silico ligand based modeling approaches and statistical techniques. the descriptor space encompasses simple binary molecular fingerprint, one- and two-dimensional constitutional, physicochemical, and topological descriptors, and sophisticated three-dimensional molecular fields that require appropriate structural alignments of varied chemical scaffolds in one universal chemical space. the affinities were modeled using qualitative classification or quantitative regression schemes involving linear, nonlinear, and deep neural network (dnn) machine-learning methods used in the scientific literature for quantitative-structure activity relationships (qsar). in a departure from tradition, ∼20% of the chemically diverse data set (205 compounds) was used to train the model with the remaining ∼80% of the structural and chemical analogs used as part of an external validation (1273 compounds) and prospective test (69 compounds) sets respectively to ascertain the model performance. the machine-learning methods investigated herein performed well in both the qualitative classification (∼70% accuracy) and quantitative ic50 predictions (rmse ∼ 1 log). the success of the 2d descriptor based machine learning approach when compared against the 3d field based technique pursued for hbace-1 inhibitors provides a strong impetus for systematically applying such methods during the lead identification and optimization efforts for other protein families as well.","['secretase 1', 'computational modeling', 'β', 'bace']"
"natural control methods based on surface electromyography (semg) and pattern recognition are promising for hand prosthetics. however, the control robustness offered by scientific research is still not sufficient for many real life applications, and commercial prostheses are capable of offering natural control for only a few movements. in recent years deep learning revolutionized several fields of machine learning, including computer vision and speech recognition. our objective is to test its methods for natural control of robotic hands via semg using a large number of intact subjects and amputees. we tested convolutional networks for the classification of an average of 50 hand movements in 67 intact subjects and 11 transradial amputees. the simple architecture of the neural network allowed to make several tests in order to evaluate the effect of pre-processing, layer architecture, data augmentation and optimization. the classification results are compared with a set of classical classification methods applied on the same datasets. the classification accuracy obtained with convolutional neural networks using the proposed architecture is higher than the average results obtained with the classical classification methods, but lower than the results obtained with the best reference methods in our tests. the results show that convolutional neural networks with a very simple architecture can produce accurate results comparable to the average classical classification methods. they show that several factors (including pre-processing, the architecture of the net and the optimization parameters) can be fundamental for the analysis of semg data. larger networks can achieve higher accuracy on computer vision and object recognition tasks. this fact suggests that it may be interesting to evaluate if larger networks can increase semg classification accuracy too.","['convolutional neural networks applied', 'prosthetic hands', 'electromyography data', 'deep learning', 'resource', 'movements', 'classification']"
"deep brain stimulation (dbs) of the subthalamic nucleus in parkinson's disease is known to cause a subtle but important adverse impact on behaviour, with impulsivity its most widely reported manifestation. however, precisely which computational components of the decision process are modulated is not fully understood. here we probe a number of distinct subprocesses, including temporal discount, outcome utility, instrumental learning rate, instrumental outcome sensitivity, reward-loss trade-offs, and perseveration. we tested 22 parkinson's disease patients both on and off subthalamic nucleus deep brain stimulation (stn-dbs), while they performed an instrumental learning task involving financial rewards and losses, and an inter-temporal choice task for financial rewards. we found that instrumental learning performance was significantly worse following stimulation, due to modulation of instrumental outcome sensitivity. specifically, patients became less sensitive to decision values for both rewards and losses, but without any change to the learning rate or reward-loss trade-offs. however, we found no evidence that dbs modulated different components of temporal impulsivity. in conclusion, our results implicate the subthalamic nucleus in a modulation of outcome value in experience-based learning and decision-making in parkinson's disease, suggesting a more pervasive role of the subthalamic nucleus in the control of human decision-making than previously thought.","['subthalamic nucleus modulates sensitivity', 'deep brain stimulation', 'decision outcome value', 'parkinson', 'disease']"
"we present a multimodal deep-learning structure that automatically predicts phases of the trauma resuscitation process in real-time. the system first pre-processes the audio and video streams captured by a kinect\'s built-in microphone array and depth sensor. a multimodal deep learning structure then extracts video and audio features, which are later combined through a ""slow fusion"" model. the final decision is then made from the combined features through a modified softmax classification layer. the model was trained on 20 trauma resuscitation cases (>13 hours), and was tested on 5 other cases. our results showed over 80% online detection accuracy with 0.7 f-score, outperforming previous systems.",['online process phase detection using multimodal deep learning']
"convolutional neural networks (cnns) show potential for computer-aided diagnosis (cadx) by learning features directly from the image data instead of using analytically extracted features. however, cnns are difficult to train from scratch for medical images due to small sample sizes and variations in tumor presentations. instead, transfer learning can be used to extract tumor information from medical images via cnns originally pretrained for nonmedical tasks, alleviating the need for large datasets. our database includes 219 breast lesions (607 full-field digital mammographic images). we compared support vector machine classifiers based on the cnn-extracted image features and our prior computer-extracted tumor features in the task of distinguishing between benign and malignant breast lesions. five-fold cross validation (by lesion) was conducted with the area under the receiver operating characteristic (roc) curve as the performance metric. results show that classifiers based on cnn-extracted features (with transfer learning) perform comparably to those using analytically extracted features [area under the roc curve [formula: see tex","['either classifier type alone ([ formula', 'ensemble classifiers based', 'versus 0', 'significantly better', 'see text', 'formula', 'types', 'performance', '81']"
"a predictive framework for the evolution of stem cell biology in 3-d is currently lacking. in this study we propose deep image informatics of the nuclear biology of stem cells to elucidate how 3-d biomaterials steer stem cell lineage phenotypes. the approach is based on high content imaging informatics to capture minute variations in the 3-d spatial organization of splicing factor sc-35 in the nucleoplasm as a marker to classify emergent cell phenotypes of human mesenchymal stem cells (hmscs). the cells were cultured in varied 3-d culture systems including hydrogels, electrospun mats and salt leached scaffolds. the approach encompasses high resolution 3-d imaging of sc-35 domains and high content image analysis (hcia) to compute quantitative 3-d nuclear metrics for sc-35 organization in single cells in concert with machine learning approaches to construct a predictive cell-state classification model. our findings indicate that hmscs cultured in collagen hydrogels and induced to differentiate into osteogenic or adipogenic lineages could be classified into the three lineages (stem, adipogenic, osteogenic) with ⩾80% precision and sensitivity, within 72h. using this framework, the augmentation of osteogenesis by scaffold design exerted by porogen leached scaffolds was also profiled within 72h with ∼80% high sensitivity. furthermore, by employing 3-d sc-35 organizational metrics, differential osteogenesis induced by novel electrospun fibrous polymer mats incorporating decellularized matrix could also be elucidated and predictably modeled at just 3days with high precision. we demonstrate that 3-d sc-35 organizational metrics can be applied to model the stem cell state in 3-d scaffolds. we propose that this methodology can robustly discern minute changes in stem cell states within complex 3-d architectures and map single cell biological readouts that are critical to assessing population level cell heterogeneity.","['dimensional biomaterial niches using high content image informatics', 'profiling stem cell states', 'three']"
"protein intrinsically disordered regions (idrs) play an important role in many biological processes. two key properties of idrs are (i) the occurrence is proteome-wide and (ii) the ratio of disordered residues is about 6%, which makes it challenging to accurately predict idrs. most idr prediction methods use sequence profile to improve accuracy, which prevents its application to proteome-wide prediction since it is time-consuming to generate sequence profiles. on the other hand, the methods without using sequence profile fare much worse than using sequence profile.","['maximized deep convolutional neural fields', 'level protein disorder prediction', 'proteome', 'aucpred', 'auc']"
"early stage estrogen receptor positive (er+) breast cancer (bca) treatment is based on the presumed aggressiveness and likelihood of cancer recurrence. oncotype dx (odx) and other gene expression tests have allowed for distinguishing the more aggressive er+ bca requiring adjuvant chemotherapy from the less aggressive cancers benefiting from hormonal therapy alone. however these tests are expensive, tissue destructive and require specialized facilities. interestingly bca grade has been shown to be correlated with the odx risk score. unfortunately bloom-richardson (br) grade determined by pathologists can be variable. a constituent category in br grading is tubule formation. this study aims to develop a deep learning classifier to automatically identify tubule nuclei from whole slide images (wsi) of er+ bca, the hypothesis being that the ratio of tubule nuclei to overall number of nuclei (a tubule formation indicator - tfi) correlates with the corresponding odx risk categories. this correlation was assessed in 7513 fields extracted from 174 wsi. the results suggests that low odx/br cases have a larger tfi than high odx/br cases (p\u2009<\u20090.01). the low odx/br cases also presented a larger tfi than that obtained for the rest of cases (p\u2009<\u20090.05). finally, the high odx/br cases have a significantly smaller tfi than that obtained for the rest of cases (p\u2009<\u20090.01).","['breast cancer whole slide images', 'oncotype dx risk categories', 'automated tubule nuclei quantification', 'er', 'correlation']"
"progress testing (pt) is used in western countries to evaluate students' level of functional knowledge, and to enhance meaning-oriented and self-directed learning. however, the use of pt has not been investigated in east asia, where reproduction-oriented and teacher-centered learning styles prevail. here, we explored the applicability of pt by focusing on student perceptions.","['focus group study', 'east asian students', 'progress testing', 'first report', 'perception']"
"systems in nature capable of collective behaviour are nonlinear, operating across several scales. yet our ability to account for their collective dynamics differs in physics, chemistry and biology. here, we briefly review the similarities and differences between mathematical modelling of adaptive living systems versus physico-chemical systems. we find that physics-based chemistry modelling and computational neuroscience have a shared interest in developing techniques for model reductions aiming at the identification of a reduced subsystem or slow manifold, capturing the effective dynamics. by contrast, as relations and kinetics between biological molecules are less characterized, current quantitative analysis under the umbrella of bioinformatics focuses on signal extraction, correlation, regression and machine-learning analysis. we argue that model reduction analysis and the ensuing identification of manifolds bridges physics and biology. furthermore, modelling living systems presents deep challenges as how to reconcile rich molecular data with inherent modelling uncertainties (formalism, variables selection and model parameters). we anticipate a new generative data-driven modelling paradigm constrained by identified governing principles extracted from low-dimensional manifold analysis. the rise of a new generation of models will ultimately connect biology to quantitative mechanistic descriptions, thereby setting the stage for investigating the character of the model language and principles driving living systems.this article is part of the themed issue 'multiscale modelling at the physics-chemistry-biology interface'.","['models using low', 'driven model inference', 'dimensional manifolds', 'bridging scales', 'perspective', 'design', 'data']"
"suppression of bony structures in chest radiographs (cxrs) is potentially useful for radiologists and computer-aided diagnostic schemes. in this paper, we present an effective deep learning method for bone suppression in single conventional cxr using deep convolutional neural networks (convnets) as basic prediction units. the deep convnets were adapted to learn the mapping between the gradients of the cxrs and the corresponding bone images. we propose a cascade architecture of convnets (called camsnet) to refine progressively the predicted bone gradients in which the convnets work at successively increased resolutions. the predicted bone gradients at different scales from the camsnet are fused in a maximum-a-posteriori framework to produce the final estimation of a bone image. this estimation of a bone image is subtracted from the original cxr to produce a soft-tissue image in which the bone components are eliminated. our method was evaluated on a dataset that consisted of 504 cases of real two-exposure dual-energy subtraction chest radiographs (404 cases for training and 100 cases for test). the results demonstrate that our method can produce high-quality and high-resolution bone and soft-tissue images. the average relative mean absolute error of the produced bone images and peak signal-to-noise ratio of the produced soft-tissue images were 3.83% and 38.7db, respectively. the average bone suppression ratio of our method was 83.8% for the cxrs with pixel sizes of nearly 0.194mm. furthermore, we apply the trained camsnet model on the cxrs acquired by various types of x-ray machines, including scanned films, and our method can also produce visually appealing bone and soft-tissue images.","['scale convolutional neural networks', 'gradient domain', 'chest radiographs', 'bone suppression', 'multi', 'cascade']"
"accurate segmentation of cervical cells in pap smear images is an important step in automatic pre-cancer identification in the uterine cervix. one of the major segmentation challenges is overlapping of cytoplasm, which has not been well-addressed in previous studies. to tackle the overlapping issue, this paper proposes a learning-based method with robust shape priors to segment individual cell in pap smear images to support automatic monitoring of changes in cells, which is a vital prerequisite of early detection of cervical cancer. we define this splitting problem as a discrete labeling task for multiple cells with a suitable cost function. the labeling results are then fed into our dynamic multi-template deformation model for further boundary refinement. multi-scale deep convolutional networks are adopted to learn the diverse cell appearance features. we also incorporated high-level shape information to guide segmentation where cell boundary might be weak or lost due to cell overlapping. an evaluation carried out using two different datasets demonstrates the superiority of our proposed method over the state-of-the-art methods in terms of segmentation accuracy.","['accurate cervical cell segmentation', 'pap smear images', 'overlapping clumps']"
"decompression sickness (dcs) is a rare and dangerous complication from a rapid decrease in environmental pressure, commonly seen in patients leaving a compressed-air environment, such as scuba divers, aviators, and deep tunnel workers. failure to clinically diagnose and adequately treat dcs with hydration and supplemental oxygen before bridging to hyperbaric oxygen (hbo) therapy can result in permanent residual symptoms or, in rare cases, death. despite the increasing incidence of dcs, there are limited published simulation case studies discussing this perilous environmental exposure.","['treating decompression sickness', 'neurologic deep dive', 'emergency medicine residents', 'simulation case', 'diagnosing']"
"solving overfitting problems of privacy attacks on small-sample remote sensing data is still a big challenge in practical application. we propose a new privacy attack network, called joint residual network (jrn), for deep learning based privacy objects classification of small-sample remote sensing images in this paper. unlike the original residual network structure, which add the bottom feature map to top feature map, jrn fuses the bottom feature map with top feature map by matrix joint. it can reduce the possibility that convolution layers extract the noise of training set or consider the inherent attributes of training set as the whole sample attributes. a series benchmark experiments based on googlenet model have been enforced and finally, we compare the model process output and the classification accuracy on small-sample data sets. on the ucmlu data set, the googlenet-feat model which is integrated with jrn is 1.66% higher of accuracy than the original googlenet model and 1.87% higher than the googlenet-r model; on the whu-rs dataset, googlenet-feat model is 1.04% higher than the googlenet model, and is 3.12% higher than the googlenet-r model. compared with the contrast experiments, the classification accuracy of googlenet-feat is the highest when facing the overfitting problems resulting from the small samples.","['remote sensing images classification', 'new privacy attack network', 'small training samples']"
"we propose a transfer learning assisted deep neural network (dnn) method for optical-signal-to-noise ratio (osnr) monitoring and realize fast remodel to response to various system parameters changing, e.g. optical launch power, residual chromatic dispersion (cd) and bit rate. by transferring the hyper-parameters of dnn at the initial stage, we can fast response to the channel variation with fewer training set size and calculations to save consumptions. for feature extraction processing, we use amplitude histograms of received 56-gb/s qpsk signals as the input for dnn at the initial stage, which shows the root mean squared error (rmse) of osnr estimation is less than 0.1\u2005db with the osnrs ranging from 5 to 35\u2005db. then, we change several system parameters and find superior capabilities of fast remodeling and data resource saving with the proposed method. the required training epochs have about four times reduction, and the required training set size is only one-fifth compared to retraining the network without any accuracy penalty. the dnn assisted by transfer learning can save resources and will be beneficial for real-time application on osnr estimation.","['transfer learning assisted deep neural network', 'osnr estimation']"
"neural network learning for face sketch synthesis from photos has attracted substantial attention due to its favorable synthesis performance. however, most existing deep-learning-based face sketch synthesis models stacked only by multiple convolutional layers without structured regression often lose the common facial structures, limiting their flexibility in a wide range of practical applications, including intelligent security and digital entertainment. in this article, we introduce a neural network to a probabilistic graphical model and propose a novel face sketch synthesis framework based on the neural probabilistic graphical model (npgm) composed of a specific structure and a common structure. in the specific structure, we investigate a neural network for mapping the direct relationship between training photos and sketches, yielding the specific information and characteristic features of a test photo. in the common structure, the fidelity between the sketch pixels generated by the specific structure and their candidates selected from the training data are considered, ensuring the preservation of the common facial structure. experimental results on the chinese university of hong kong face sketch database demonstrate, both qualitatively and quantitatively, that the proposed npgm-based face sketch synthesis approach can more effectively capture specific features and recover common structures compared with the state-of-the-art methods. extensive experiments in practical applications further illustrate that the proposed method achieves superior performance.","['neural probabilistic graphical model', 'face sketch synthesis']"
"domain adaptation is one of the most challenging tasks of modern data analytics. if the adaptation is done correctly, models built on a specific data representation become more robust when confronted to data depicting the same classes, but described by another observation system. among the many strategies proposed, finding domain-invariant representations has shown excellent properties, in particular since it allows to train a unique classifier effective in all domains. in this paper, we propose a regularized unsupervised optimal transportation model to perform the alignment of the representations in the source and target domains. we learn a transportation plan matching both pdfs, which constrains labeled samples of the same class in the source domain to remain close during transport. this way, we exploit at the same time the labeled samples in the source and the distributions observed in both domains. experiments on toy and challenging real visual adaptation examples show the interest of the method, that consistently outperforms state of the art approaches. in addition, numerical experiments show that our approach leads to better performances on domain invariant deep learning features and can be easily adapted to the semi-supervised case where few labeled samples are available in the target domain.","['optimal transport', 'domain adaptation']"
"until recently tactical analysis in elite soccer were based on observational data using variables which discard most contextual information. analyses of team tactics require however detailed data from various sources including technical skill, individual physiological performance, and team formations among others to represent the complex processes underlying team tactical behavior. accordingly, little is known about how these different factors influence team tactical behavior in elite soccer. in parts, this has also been due to the lack of available data. increasingly however, detailed game logs obtained through next-generation tracking technologies in addition to physiological training data collected through novel miniature sensor technologies have become available for research. this leads however to the opposite problem where the shear amount of data becomes an obstacle in itself as methodological guidelines as well as theoretical modelling of tactical decision making in team sports is lacking. the present paper discusses how big data and modern machine learning technologies may help to address these issues and aid in developing a theoretical model for tactical decision making in team sports. as experience from medical applications show, significant organizational obstacles regarding data governance and access to technologies must be overcome first. the present work discusses these issues with respect to tactical analyses in elite soccer and propose a technological stack which aims to introduce big data technologies into elite soccer research. the proposed approach could also serve as a guideline for other sports science domains as increasing data size is becoming a wide-spread phenomenon.","['tactical analysis', 'sports science', 'future challenges', 'elite soccer', 'big data', 'opportunities']"
"the performance of deep learning models is dependent on the precise configuration of many layers and parameters. however, there are currently few systematic guidelines for how to configure a successful model. this means model builders often have to experiment with different configurations by manually programming different architectures (which is tedious and time consuming) or rely on purely automated approaches to generate and train the architectures (which is expensive). in this paper, we present rapid exploration of model architectures and parameters, or remap, a visual analytics tool that allows a model builder to discover a deep learning model quickly via exploration and rapid experimentation of neural network architectures. in remap, the user explores the large and complex parameter space for neural network architectures using a combination of global inspection and local experimentation. through a visual overview of a set of models, the user identifies interesting clusters of architectures. based on their findings, the user can run ablation and variation experiments to identify the effects of adding, removing, or replacing layers in a given architecture and generate new models accordingly. they can also handcraft new models using a simple graphical interface. as a result, a model builder can build deep learning models quickly, efficiently, and without manual programming. we inform the design of remap through a design study with four deep learning model builders. through a use case, we demonstrate that remap allows users to discover performant neural network architectures efficiently using visual exploration and user-defined semi-automated searches through the model space.","['discovering neural architectures', 'visual analytics', 'variate', 'contemplate', 'ablate']"
"neuroscience has focused on the detailed implementation of computation, studying neural codes, dynamics and circuits. in machine learning, however, artificial neural networks tend to eschew precisely designed codes, dynamics or circuits in favor of brute force optimization of a cost function, often using simple and relatively uniform initial architectures. two recent developments have emerged within machine learning that create an opportunity to connect these seemingly divergent perspectives. first, structured architectures are used, including dedicated systems for attention, recursion and various forms of short- and long-term memory storage. second, cost functions and training procedures have become more complex and are varied across layers and over time. here we think about the brain in terms of these ideas. we hypothesize that (1) the brain optimizes cost functions, (2) the cost functions are diverse and differ across brain locations and over development, and (3) optimization operates within a pre-structured architecture matched to the computational problems posed by behavior. in support of these hypotheses, we argue that a range of implementations of credit assignment through multiple layers of neurons are compatible with our current knowledge of neural circuitry, and that the brain's specialized systems can be interpreted as enabling efficient optimization for specific problem classes. such a heterogeneously optimized system, enabled by a series of interacting cost functions, serves to make learning data-efficient and precisely targeted to the needs of the organism. we suggest directions by which neuroscience could seek to refine and test these hypotheses.","['deep learning', 'toward', 'neuroscience', 'integration']"
"kinship verification has a number of applications such as organizing large collections of images and recognizing resemblances among humans. in this paper, first, a human study is conducted to understand the capabilities of human mind and to identify the discriminatory areas of a face that facilitate kinship-cues. the visual stimuli presented to the participants determine their ability to recognize kin relationship using the whole face as well as specific facial regions. the effect of participant gender and age and kin-relation pair of the stimulus is analyzed using quantitative measures such as accuracy, discriminability index d' , and perceptual information entropy. utilizing the information obtained from the human study, a hierarchical kinship verification via representation learning (kvrl) framework is utilized to learn the representation of different face regions in an unsupervised manner. we propose a novel approach for feature representation termed as filtered contractive deep belief networks (fcdbn). the proposed feature representation encodes relational information present in images using filters and contractive regularization penalty. a compact representation of facial images of kin is extracted as an output from the learned model and a multi-layer neural network is utilized to verify the kin accurately. a new wvu kinship database is created, which consists of multiple images per subject to facilitate kinship verification. the results show that the proposed deep learning framework (kvrl-fcdbn) yields the state-of-the-art kinship verification accuracy on the wvu kinship database and on four existing benchmark data sets. furthermore, kinship information is used as a soft biometric modality to boost the performance of face verification via product of likelihood ratio and support vector machine based approaches. using the proposed kvrl-fcdbn framework, an improvement of over 20% is observed in the performance of face verification.","['hierarchical representation learning', 'kinship verification']"
"this paper introduces a new methodology for dynamic learning, visualization, and classification of functional magnetic resonance imaging (fmri) as spatiotemporal brain data. the method is based on an evolving spatiotemporal data machine of evolving spiking neural networks (snns) exemplified by the neucube architecture [","['mapping spatial coordinates', 'several steps', 'method consists', 'fmri data', 'snn cube', 'snn', '3']"
"deep networks are now able to achieve human-level performance on a broad spectrum of recognition tasks. independently, neuromorphic computing has now demonstrated unprecedented energy-efficiency through a new chip architecture based on spiking neurons, low precision synapses, and a scalable communication network. here, we demonstrate that neuromorphic computing, despite its novel architectural primitives, can implement deep convolution networks that (i) approach state-of-the-art classification accuracy across eight standard datasets encompassing vision and speech, (ii) perform inference while preserving the hardware's underlying energy-efficiency and high throughput, running on the aforementioned datasets at between 1,200 and 2,600 frames/s and using between 25 and 275 mw (effectively >6,000 frames/s per watt), and (iii) can be specified and trained using backpropagation with the same ease-of-use as contemporary deep learning. this approach allows the algorithmic power of deep learning to be merged with the efficiency of neuromorphic processors, bringing the promise of embedded, intelligent, brain-inspired computing one step closer.","['efficient neuromorphic computing', 'convolutional networks', 'fast', 'energy']"
"astronauts are exposed to 56fe ions that may pose a significant health hazard during and following prolonged missions in deep space. we showed previously that object recognition requiring the hippocampus, a structure critical for cognitive function, is affected in 2-month-old mice irradiated with 56fe ions. here we examined object recognition in 6-month-old mice irradiated with 56fe ions, a biological age more relevant to the typical ages of astronauts. moreover, because the mechanisms mediating the detrimental effects of 56fe ions on hippocampal function are unclear, we examined changes in hippocampal networks involved in synaptic plasticity and memory, gene expression, and epigenetic changes in cytosine methylation (5mc) and hydroxymethylation (5hmc) that could accompany changes in gene expression. we assessed the effects of whole body 56fe ion irradiation at early (2 weeks) and late (20 weeks) time points on hippocampus-dependent memory and hippocampal network stability, and whether these effects are associated with epigenetic changes in hippocampal dna methylation (both 5mc and 5hmc) and gene expression.","['hippocampal dna methylation', 'term effects', 'gene expression', '56fe irradiation', 'short', 'long', 'cognition']"
"tracking individual-cell/object over time is important in understanding drug treatment effects on cancer cells and video surveillance. a fundamental problem of individual-cell/object tracking is to simultaneously address the cell/object appearance variations caused by intrinsic and extrinsic factors. in this paper, inspired by the architecture of deep learning, we propose a robust feature learning method for constructing discriminative appearance models without large-scale pretraining. specifically, in the initial frames, an unsupervised method is firstly used to learn the abstract feature of a target by exploiting both classic principal component analysis (pca) algorithms with recent deep learning representation architectures. we use learned pca eigenvectors as filters and develop a novel algorithm to represent a target by composing of a pca-based filter bank layer, a nonlinear layer, and a patch-based pooling layer, respectively. then, based on the feature representation, a neural network with one hidden layer is trained in a supervised mode to construct a discriminative appearance model. finally, to alleviate the tracker drifting problem, a sample update scheme is carefully designed to keep track of the most representative and diverse samples during tracking. we test the proposed tracking method on two standard individual cell/object tracking benchmarks to show our tracker's state-of-the-art performance.","['object tracking via pcanet deep network', 'robust individual', 'computer vision', 'cell', 'biomedicine']"
"over the past decade we have witnessed the increasing sophistication of machine learning algorithms applied in daily use from internet searches, voice recognition, social network software to machine vision software in cameras, phones, robots and self-driving cars. pharmaceutical research has also seen its fair share of machine learning developments. for example, applying such methods to mine the growing datasets that are created in drug discovery not only enables us to learn from the past but to predict a molecule's properties and behavior in future. the latest machine learning algorithm garnering significant attention is deep learning, which is an artificial neural network with multiple hidden layers. publications over the last 3\xa0years suggest that this algorithm may have advantages over previous machine learning methods and offer a slight but discernable edge in predictive performance. the time has come for a balanced review of this technique but also to apply machine learning methods such as deep learning across a wider array of endpoints relevant to pharmaceutical research for which the datasets are growing such as physicochemical property prediction, formulation prediction, absorption, distribution, metabolism, excretion and toxicity (adme/tox), target prediction and skin permeation, etc. we also show that there are many potential applications of deep learning beyond cheminformatics. it will be important to perform prospective testing (which has been carried out rarely to date) in order to convince skeptics that there will be benefits from investing in this technique.","['pharmaceutical research', 'next era', 'deep learning']"
"esoteric jargon and technical language are potential barriers to the teaching of science and medicine. effective teaching strategies which address these barriers are desirable. here, we created and evaluated the effectiveness of stand-alone 'equivalence-based instruction' (ebi) learning resources wherein the teaching of a small number of direct relationships between stimuli (e.g., anatomical regions, their function, and pathology) results in the learning of higher numbers of untaught relationships.","['student experience', 'neuroanatomy teaching', 'based instruction', 'applied equivalence']"
massive open online courses (moocs) have been criticized for focusing on presentation of short video clip lectures and asking theoretical multiple-choice questions. a potential way of vitalizing these educational activities in the health sciences is to introduce virtual patients. experiences from such extensions in moocs have not previously been reported in the literature.,"['behavioral medicine massive open online course', 'virtual patients', 'moo']"
"immune cell infiltration in tumor is an emerging prognostic biomarker in breast cancer. the gold standard for quantification of immune cells in tissue sections is visual assessment through a microscope, which is subjective and semi-quantitative. in this study, we propose and evaluate an approach based on antibody-guided annotation and deep learning to quantify immune cell-rich areas in hematoxylin and eosin (h&e) stained samples.","['eosin stained breast cancer samples', 'supervised deep learning', 'infiltrating immune cells', 'tumor', 'quantification', 'hematoxylin', 'antibody']"
"the physician manager role in the health care system is invaluable as they serve as role models and quality setters. the requirements from physician managers have become more demanding and the role less prestigious; yet burnout and its prevention in this group have received little attention. physician leadership development programmes have generally dealt directly with skill and knowledge acquisition. the aim of this research was to evaluate an intensive workshop designed to modify attitudes and improve skills of physician-managers of community clinics, through focus on personal well-being and empowerment.","['physician empowerment programme', 'unique workshop', 'community clinics', 'physician', 'managers']"
"neural networks have generated valuable quantitative structure-activity/property relationships (qsar/qspr) models for a wide variety of small molecules and materials properties. they have grown in sophistication and many of their initial problems have been overcome by modern mathematical techniques. qsar studies have almost always used so-called ""shallow"" neural networks in which there is a single hidden layer between the input and output layers. recently, a new and potentially paradigm-shifting type of neural network based on deep learning has appeared. deep learning methods have generated impressive improvements in image and voice recognition, and are now being applied to qsar and qsar modelling. this paper describes the differences in approach between deep and shallow neural networks, compares their abilities to predict the properties of test sets for 15 large drug data sets (the kaggle set), discusses the results in terms of the universal approximation theorem for neural networks, and describes how dnn may ameliorate or remove troublesome ""activity cliffs"" in qsar data sets.","['universal approximation theorem', 'shallow neural networks', 'activity cliffs', 'qsar', 'performance', 'deep']"
"this study aimed to examine the efficacy of semantic segmentation implemented by deep learning and to confirm whether this method is more effective than a commercially dominant auto-segmentation tool with regards to delineating normal lung excluding the trachea and main bronchi. a total of 232 non-small-cell lung cancer cases were examined. the computed tomography (ct) images of these cases were converted from digital imaging and communications in medicine (dicom) radiation therapy (rt) formats to arrays of 32\xa0×\xa0128\xa0×\xa0128 voxels and input into both 2d and 3d u-net, which are deep learning networks for semantic segmentation. the number of training, validation and test sets were 160, 40 and 32, respectively. dice similarity coefficients (dscs) of the test set were evaluated employing smart segmentationⓡ knowledge based contouring (smart segmentation is an atlas-based segmentation tool), as well as the 2d and 3d u-net. the mean dscs of the test set were 0.964 [95% confidence interval (ci), 0.960-0.96","['ci', '990', '99', '989', '95', '0']"
"crop diseases are a major threat to food security, but their rapid identification remains difficult in many parts of the world due to the lack of the necessary infrastructure. the combination of increasing global smartphone penetration and recent advances in computer vision made possible by deep learning has paved the way for smartphone-assisted disease diagnosis. using a public dataset of 54,306 images of diseased and healthy plant leaves collected under controlled conditions, we train a deep convolutional neural network to identify 14 crop species and 26 diseases (or absence thereof). the trained model achieves an accuracy of 99.35% on a held-out test set, demonstrating the feasibility of this approach. overall, the approach of training deep learning models on increasingly large and publicly available image datasets presents a clear path toward smartphone-assisted crop disease diagnosis on a massive global scale.","['based plant disease detection', 'using deep learning', 'image']"
"computer graphic images (cgi) can be manufactured very similar to natural images (ni) by state-of-the-art algorithms in computer graphic filed. thus, there are various identification algorithms proposed to detect cgi. however, the manipulation is complicated and difficult for an ultimate cgi against the forensic algorithms. further, the forensics on cgi and ni made achievements in the different aspects with the encouragement of deep learning. though the generated cgi can achieve high quality automatically by generative adversarial networks (gan), cgi generation based on gan is difficult to ensure that it cannot be detected by forensics. in this paper, we propose a brief and effective architecture based on gan for preventing the generated images being detected under the forensics on cgi and ni. the adapted characteristics will make the cgi generated by gan fools the detector and keep the end-to-end generation mode of gan.","['natural images using generative adversarial networks', 'computer graphic images', 'forensic scheme', 'anti']"
"today, the deep inferior epigastric perforator (diep) flap is considered to be the gold standard in microvascular breast reconstruction. although this procedure is known as technically demanding, novice plastic surgeons must be able to perform these procedures to meet the rising demand. the purpose of this study was to evaluate if the young junior professional is trained adequately to set up and safely perform microsurgical breast reconstructions.","['autologous breast reconstruction program', 'plastic surgical training', 'starting', 'good', 'gets']"
"this paper proposes a novel and effective approach, namely pay attention to them (pat), to general object detection, which integrates the bottom-up single-shot convolutional neural networks (cnns) and a top-down operating strategy. pat starts by routinely applying a cnn regression detector to the entire input image. it then conducts refinement, which locates a sub-region that probably contains relevant objects through an intelligent agent built with an attentional mechanism and zooms it in to launch the detector again. this refining step is repeated in a cascaded way, where all the bounding boxes produced are scaled according to the original resolution and the sub-marginal and overlapping parts are wiped out to generate the final output. due to such progressive processing, pat improves the detection accuracy, especially for the objects of small sizes. extensive experiments are conducted on the pascal voc and ms coco benchmarks, and the results show that pat is able to improve the representative baseline detectors, i.e., single shot multibox detector, yolov2, and faster regions with cnn features, with remarkable accuracy gains [about 2%-5% mean average precision (map","['based cascade object detection', 'deep reinforcement learning', 'pay attention', 'hich demonstrates', 'competency', ""'],""]"
"protein-protein interactions (ppis) are important for the study of protein functions and pathways involved in different biological processes, as well as for understanding the cause and progression of diseases. several high-throughput experimental techniques have been employed for the identification of ppis in a few model organisms, but still, there is a huge gap in identifying all possible binary ppis in an organism. therefore, ppi prediction using machine-learning algorithms has been used in conjunction with experimental methods for discovery of novel protein interactions. the two most popular supervised machine-learning techniques used in the prediction of ppis are support vector machines and random forest classifiers. bayesian-probabilistic inference has also been used but mainly for the scoring of high-throughput ppi dataset confidence measures. recently, deep-learning algorithms have been used for sequence-based prediction of ppis. several clustering methods such as hierarchical and k-means are useful as unsupervised machine-learning algorithms for the prediction of interacting protein pairs without explicit data labelling. in summary, machine-learning techniques have been widely used for the prediction of ppis thus allowing experimental researchers to study cellular ppi networks.","['learning techniques', 'protein interactions', 'protein', 'prediction', 'machine']"
"the imaging workup in acute stroke can be simplified by deriving non-contrast ct (ncct) from ct perfusion (ctp) images. this results in reduced workup time and radiation dose. to achieve this, we present a stacked bidirectional convolutional lstm (c-lstm) network to predict 3d volumes from 4d spatiotemporal data. several parameterizations of the c-lstm network were trained on a set of 17 ctp-ncct pairs to learn to derive a ncct from ctp and were subsequently quantitatively evaluated on a separate cohort of 16 cases. the results show that the c-lstm network clearly outperforms the baseline and competitive convolutional neural network methods. we show good scalability and performance of the method by continued training and testing on an independent dataset which includes pathology of 80 and 83 ctp-ncct pairs, respectively. c-lstm is, therefore, a promising general deep learning approach to learn from high-dimensional spatiotemporal medical images.","['stacked bidirectional convolutional lstms', 'deriving 3d non', 'spatiotemporal 4d ct', 'contrast ct']"
"although the cerebral cortex is thought to be composed of functionally distinct areas, the actual parcellation of area and assignment of function are still highly controversial. an example is the much-studied lateral intraparietal cortex (lip). despite the general agreement that lip plays an important role in visual-oculomotor transformation, it remains unclear whether the area is primary sensory- or motor-related (the attention-intention debate). although lip has been considered as a functionally unitary area, its dorsal (lipd) and ventral (lipv) parts differ in local morphology and long-distance connectivity. in particular, lipv has much stronger connections with two oculomotor centers, the frontal eye field and the deep layers of the superior colliculus, than does lipd. such anatomical distinctions imply that compared with lipd, lipv might be more involved in oculomotor processing. we tested this hypothesis physiologically with a memory saccade task and a gap saccade task. we found that lip neurons with persistent memory activities in memory saccade are primarily provoked either by visual stimulation (vision-related) or by both visual and saccadic events (vision-saccade-related) in gap saccade. the distribution changes from predominantly vision-related to predominantly vision-saccade-related as the recording depth increases along the dorsal-ventral dimension. consistently, the simultaneously recorded local field potential also changes from visual evoked to saccade evoked. finally, local injection of muscimol (gaba agonist) in lipv, but not in lipd, dramatically decreases the proportion of express saccades. with these results, we conclude that lipd and lipv are more involved in visual and visual-saccadic processing, respectively.","['macaque lip process visual', 'oculomotor information differently', 'two subdivisions']"
"neural networks are transforming the field of computer algorithms, yet their emulation on current computing substrates is highly inefficient. reservoir computing was successfully implemented on a large variety of substrates and gave new insight in overcoming this implementation bottleneck. despite its success, the approach lags behind the state of the art in deep learning. we therefore extend time-delay reservoirs to deep networks and demonstrate that these conceptually correspond to deep convolutional neural networks. convolution is intrinsically realized on a substrate level by generic drive-response properties of dynamical systems. the resulting novelty is avoiding vector matrix products between layers, which cause low efficiency in today's substrates. compared to singleton time-delay reservoirs, our deep network achieves accuracy improvements by at least an order of magnitude in mackey-glass and lorenz time series prediction.","['deep convolutional neural networks', 'coupled nonlinear delay systems']"
"ensemble learning has been proved to improve the generalization ability effectively in both theory and practice. in this paper, we briefly outline the current status of research on it first. then, a new deep neural network-based ensemble method that integrates filtering views, local views, distorted views, explicit training, implicit training, subview prediction, and simple average is proposed for biomedical time series classification. finally, we validate its effectiveness on the chinese cardiovascular disease database containing a large number of electrocardiogram recordings. the experimental results show that the proposed method has certain advantages compared to some well-known ensemble methods, such as bagging and adaboost.","['biomedical time series classification', 'ensemble deep learning']"
"deep learning has been immensely successful at a variety of tasks, ranging from classification to artificial intelligence. learning corresponds to fitting training data, which is implemented by descending a very high-dimensional loss function. understanding under which conditions neural networks do not get stuck in poor minima of the loss, and how the landscape of that loss evolves as depth is increased, remains a challenge. here we predict, and test empirically, an analogy between this landscape and the energy landscape of repulsive ellipses. we argue that in fully connected deep networks a phase transition delimits the over- and underparametrized regimes where fitting can or cannot be achieved. in the vicinity of this transition, properties of the curvature of the minima of the loss (the spectrum of the hessian) are critical. this transition shares direct similarities with the jamming transition by which particles form a disordered solid as the density is increased, which also occurs in certain classes of computational optimization and learning problems such as the perceptron. our analysis gives a simple explanation as to why poor minima of the loss cannot be encountered in the overparametrized regime. interestingly, we observe that the ability of fully connected networks to fit random data is independent of their depth, an independence that appears to also hold for real data. we also study a quantity δ which characterizes how well (δ<0) or badly (δ>0) a datum is learned. at the critical point it is power-law distributed on several decades, p_{+}(δ)∼δ^{θ} for δ>0 and p_{-}(δ)∼(-δ)^{-γ} for δ<0, with exponents that depend on the choice of activation function. this observation suggests that near the transition the loss landscape has a hierarchical structure and that the learning dynamics is prone to avalanche-like dynamics, with abrupt changes in the set of patterns that are learned.","['deep neural networks', 'loss landscape', 'jamming transition', 'understand', 'paradigm']"
"information hiding aims to achieve secret communication via certain carrier. however, these carrier-based methods often have different kinds of deficiencies. in order to solve the problems addressed by the traditional information hiding methods such as the difficult balance between secret embedding rate and detection rate, this paper proposes a novel approach which utilizes augmented reality (ar) to achieve secret communication. in this paper, we present an ar based information hiding architecture which combines information hiding, augmented reality, and deep learning methods altogether. the proposed architecture basically follows the idea of secret-key matching policy. the secret sender first maps the secret message to objects, images or coordinates, etc. the mapped objects, images or coordinates then serve as the secret key for further secret revealing. the secret key and concealing model are shared between two communication parties instead of direct transmitting the secret messages. different secret keys can be combined in order to generate more mapping sequences. also, deep learning based models are integrated in the architecture to extend the mapping varieties. by taking advantage of the augmented reality technique, the secret messages can be transmitted in various formats which results in higher secret embedding rate in potential. furthermore, the proposed architecture can be seen as a useful application of coverless information hiding scheme. the experimental system realizes the proposed architecture by implementing convolutional neural network (cnn) based real-time object detection, image recognition, augmented reality and secret-key matching altogether which shows great promise in practice.","['information hiding based', 'augmented reality']"
"cotton seed purity is a critical factor influencing the cotton yield. in this study, near-infrared hyperspectral imaging was used to identify seven varieties of cotton seeds. score images formed by pixel-wise principal component analysis (pca) showed that there were differences among different varieties of cotton seeds. effective wavelengths were selected according to pca loadings. a self-design convolution neural network (cnn) and a residual network (resnet) were used to establish classification models. partial least squares discriminant analysis (pls-da), logistic regression (lr) and support vector machine (svm) were used as direct classifiers based on full spectra and effective wavelengths for comparison. furthermore, pls-da, lr and svm models were used for cotton seeds classification based on deep features extracted by self-design cnn and resnet models. lr and pls-da models using deep features as input performed slightly better than those using full spectra and effective wavelengths directly. self-design cnn based models performed slightly better than resnet based models. classification models using full spectra performed better than those using effective wavelengths, with classification accuracy of calibration, validation and prediction sets all over 80% for most models. the overall results illustrated that near-infrared hyperspectral imaging with deep learning was feasible to identify cotton seed varieties.","['infrared hyperspectral imaging combined', 'identify cotton seed varieties', 'deep learning', 'near']"
"precipitation is useful information for assessing vital water resources, agriculture, ecosystems and hydrology. data-driven model predictions using deep learning algorithms are promising for these purposes. echo state network (esn) and deep echo state network (deepesn), referred to as reservoir computing (rc), are effective and speedy algorithms to process a large amount of data. in this study, we used the esn and the deepesn algorithms to analyze the meteorological hourly data from 2002 to 2014 at the tainan observatory in the southern taiwan. the results show that the correlation coefficient by using the deepesn was better than that by using the esn and commercial neuronal network algorithms (back-propagation network (bpn) and support vector regression (svr), matlab, the mathworks co.), and the accuracy of predicted rainfall by using the deepesn can be significantly improved compared with those by using esn, the bpn and the svr. in sum, the deepesn is a trustworthy and good method to predict rainfall; it could be applied to global climate forecasts which need high-volume data processing.","['southern taiwan', 'deep learning', 'rainfall', 'prediction', 'application']"
"sparse representation based classification (src), nuclear-norm matrix regression (nmr), and deep learning (dl) have achieved a great success in face recognition (fr). however, there still exist some intrinsic limitations among them. src and nmr based coding methods belong to one-step model, such that the latent discriminative information of the coding error vector cannot be fully exploited. dl, as a multi-step model, can learn powerful representation, but relies on large-scale data and computation resources for numerous parameters training with complicated back-propagation. straightforward training of deep neural networks from scratch on small-scale data is almost infeasible. therefore, in order to develop efficient algorithms that are specifically adapted for small-scale data, we propose to derive the deep models of src and nmr. specifically, in this paper, we propose an end-to-end deep cascade model (dcm) based on src and nmr with hierarchical learning, nonlinear transformation and multi-layer structure for corrupted face recognition. the contributions include four aspects. first, an end-to-end deep cascade model for small-scale data without back-propagation is proposed. second, a multi-level pyramid structure is integrated for local feature representation. third, for introducing nonlinear transformation in layer-wise learning, softmax vector coding of the errors with class discrimination is proposed. fourth, the existing representation methods can be easily integrated into our dcm framework. experiments on a number of small-scale benchmark fr datasets demonstrate the superiority of the proposed model over state-of-the-art counterparts. additionally, a perspective that deep-layered learning does not have to be convolutional neural network with back-propagation optimization is consolidated. the demo code is available in https://github.com/liuji93/dcm.","['deep cascade model based face recognition', 'layered learning meets small data', 'deep']"
"nuclei detection is often a critical initial step in the development of computer aided diagnosis and prognosis schemes in the context of digital pathology images. while over the last few years, a number of nuclei detection methods have been proposed, most of these approaches make idealistic assumptions about the staining quality of the tissue. in this paper, we present a new multi-pass adaptive voting (mpav) for nuclei detection which is specifically geared towards images with poor quality staining and noise on account of tissue preparation artifacts. the mpav utilizes the symmetric property of nuclear boundary and adaptively selects gradient from edge fragments to perform voting for a potential nucleus location. the mpav was evaluated in three cohorts with different staining methods: hematoxylin &eosin, cd31 &hematoxylin, and ki-67 and where most of the nuclei were unevenly and imprecisely stained. across a total of 47 images and nearly 17,700 manually labeled nuclei serving as the ground truth, mpav was able to achieve a superior performance, with an area under the precision-recall curve (auc) of 0.73. additionally, mpav also outperformed three state-of-the-art nuclei detection methods, a single pass voting method, a multi-pass voting method, and a deep learning based method.","['pass adaptive voting', 'nuclei detection', 'histopathological images', 'multi']"
"currently, the use of artificial intelligence (ai) in radiology, particularly machine learning (ml), has become a reality in clinical practice. since the end of the last century, several ml algorithms have been introduced for a wide range of common imaging tasks, not only for diagnostic purposes but also for image acquisition and postprocessing. ai is now recognized to be a driving initiative in every aspect of radiology. there is growing evidence of the advantages of ai in radiology creating seamless imaging workflows for radiologists or even replacing radiologists. most of the current ai methods have some internal and external disadvantages that are impeding their ultimate implementation in the clinical arena. as such, ai can be considered a portion of a business trying to be introduced in the health care market. for this reason, this review analyzes the current status of ai, and specifically ml, applied to radiology from the scope of strengths, weaknesses, opportunities, and threats (swot) analysis.","['machine learning applications', 'threats analysis', 'artificial intelligence', 'weaknesses', 'strengths', 'radiology', 'opportunities']"
"liquid chromatography-mass spectrometry (lc-ms)-based metabolomics has emerged as a valuable tool for biological discovery, capable of assaying thousands of diverse chemical entities in a single biospecimen. processing of nontargeted lc-ms spectral data requires identification and isolation of true spectral features from the random, false noise peaks that comprise a significant portion of total signals, using inexact peak selection algorithms and time-consuming visual inspection of data. to increase the fidelity and speed of data processing, herein we establish, optimize, and evaluate a machine learning pipeline employing deep neural networks as well as a simpler multiple logistic regression model for classification of spectral features from nontargeted lc-ms metabolomics data. machine learning-based approaches were found to remove up to 90% of false peaks from complex nontargeted lc-ms data sets without reducing true positive signals and exhibit excellent reproducibility across multiple data sets. application of machine learning for nontargeted lc-ms-based peak selection provides for robust and scalable peak classification and data filtering, enabling handling and processing of large scale, complex metabolomics data sets.","['ms spectral peaks', 'deep neural networks', 'lc', 'classification']"
"gene expression data is commonly available in cancer research and provides a snapshot of the molecular status of a specific tumor tissue. this high-dimensional data can be analyzed for diagnoses, prognoses, and to suggest treatment options. machine learning based methods are widely used for such analysis. recently, a set of deep learning techniques was successfully applied in different domains including bioinformatics. one of these prominent techniques are convolutional neural networks (cnn). currently, cnns are extending to non-euclidean domains like graphs. molecular networks are commonly represented as graphs detailing interactions between molecules. gene expression data can be assigned to the vertices of these graphs, and the edges can depict interactions, regulations and signal flow. in other words, gene expression data can be structured by utilizing molecular network information as prior knowledge. here, we applied graph cnn to gene expression data of breast cancer patients to predict the occurrence of metastatic events. to structure the data we utilized a protein-protein interaction network. we show that the graph cnn exploiting the prior knowledge is able to provide classification improvements for the prediction of metastatic events compared to existing methods.","['utilizing molecular network information via graph convolutional neural networks', 'predict metastatic event', 'breast cancer']"
"with the rapid adoption of machine learning techniques for large-scale applications in science and engineering comes the convergence of two grand challenges in visualization. first, the utilization of black box models (e.g., deep neural networks) calls for advanced techniques in exploring and interpreting model behaviors. second, the rapid growth in computing has produced enormous datasets that require techniques that can handle millions or more samples. although some solutions to these interpretability challenges have been proposed, they typically do not scale beyond thousands of samples, nor do they provide the high-level intuition scientists are looking for. here, we present the first scalable solution to explore and analyze high-dimensional functions often encountered in the scientific data analysis pipeline. by combining a new streaming neighborhood graph construction, the corresponding topology computation, and a novel data aggregation scheme, namely topology aware datacubes, we enable interactive exploration of both the topological and the geometric aspect of high-dimensional data. following two use cases from high-energy-density (hed) physics and computational biology, we demonstrate how these capabilities have led to crucial new insights in both applications.","['scalable topological data analysis', 'evaluating data', 'scientific applications', 'driven models', 'visualization']"
"automatic segmentation methods based on deep learning have recently demonstrated state-of-the-art performance, outperforming the ordinary methods. nevertheless, these methods are inapplicable for small datasets, which are very common in medical problems. to this end, we propose a knowledge transfer method between diseases via the generative bayesian prior network. our approach is compared to a pre-train approach and random initialization and obtains the best results in terms of dice similarity coefficient metric for the small subsets of the brain tumor segmentation 2018 database (brats2018).","['mri semantic segmentation problems', 'bayesian generative models', 'knowledge transfer']"
"as the performance of a conventional track and trigger system in a rapid response system has been unsatisfactory, we developed and implemented an artificial intelligence for predicting in-hospital cardiac arrest, denoted the deep learning-based early warning system. the purpose of this study was to compare the performance of an artificial intelligence-based early warning system with that of conventional methods in a real hospital situation.","['detecting patient deterioration using artificial intelligence', 'rapid response system']"
"in the diagnosis of neurodegenerative disorders, f-18 fluorodeoxyglucose positron emission tomography/computed tomography (18f-fdg pet/ct) is used for its ability to detect functional changes at early stages of disease process. however, anatomical information from another modality (ct or mri) is still needed to properly interpret and localize the radiotracer uptake due to its low spatial resolution. lack of structural information limits segmentation and accurate quantification of the 18f-fdg pet/ct. the correct segmentation of the brain compartment in 18f-fdg pet/ct will enable the quantitative analysis of the 18f-fdg pet/ct scan alone. in this paper, we propose a method to segment white matter in 18f-fdg pet/ct images using generative adversarial network (gan). the segmentation result of gan model was evaluated using evaluation parameters such as dice, auc-pr, precision, and recall. it was also compared with other deep learning methods. as a result, the proposed method achieves superior segmentation accuracy and reliability compared with other deep learning methods.","['pet using generative adversarial network', 'white matter', 'semantic segmentation', 'fdg']"
"drug repositioning can drastically decrease the cost and duration taken by traditional drug research and development while avoiding the occurrence of unforeseen adverse events. with the rapid advancement of high-throughput technologies and the explosion of various biological data and medical data, computational drug repositioning methods have been appealing and powerful techniques to systematically identify potential drug-target interactions and drug-disease interactions. in this review, we first summarize the available biomedical data and public databases related to drugs, diseases and targets. then, we discuss existing drug repositioning approaches and group them based on their underlying computational models consisting of classical machine learning, network propagation, matrix factorization and completion, and deep learning based models. we also comprehensively analyze common standard data sets and evaluation metrics used in drug repositioning, and give a brief comparison of various prediction methods on the gold standard data sets. finally, we conclude our review with a brief discussion on challenges in computational drug repositioning, which includes the problem of reducing the noise and incompleteness of biomedical data, the ensemble of various computation drug repositioning methods, the importance of designing reliable negative samples selection methods, new techniques dealing with the data sparseness problem, the construction of large-scale and comprehensive benchmark data sets and the analysis and explanation of the underlying mechanisms of predicted interactions.","['drug repositioning', 'computational models', 'comprehensive review', 'biomedical data']"
"endometriosis is a gynaecological disease characterised by the presence of endometriotic tissue outside of the uterus impacting a significant fraction of women of childbearing age. evidence from epidemiological studies suggests a relationship between risk of endometriosis and exposure to some organochlorine persistent organic pollutants (pops). however, these chemicals are numerous and occur in complex and highly correlated mixtures, and to date, most studies have not accounted for this simultaneous exposure. linear and logistic regression models are constrained to adjusting for multiple exposures when variables are highly intercorrelated, resulting in unstable coefficients and arbitrary findings. advanced machine learning models, of emerging use in epidemiology, today appear as a promising option to address these limitations. in this study, different machine learning techniques were compared on a dataset from a case-control study conducted in france to explore associations between mixtures of pops and deep endometriosis. the battery of models encompassed regularised logistic regression, artificial neural network, support vector machine, adaptive boosting, and partial least-squares discriminant analysis with some additional sparsity constraints. these techniques were applied to identify the biomarkers of internal exposure in adipose tissue most associated with endometriosis and to compare model classification performance. the five tested models revealed a consistent selection of most associated pops with deep endometriosis, including octachlorodibenzofuran, cis-heptachlor epoxide, polychlorinated biphenyl 77 or trans-nonachlor, among others. the high classification performance of all five models confirmed that machine learning may be a promising complementary approach in modelling highly correlated exposure biomarkers and their associations with health outcomes. regularised logistic regression provided a good compromise between the interpretability of traditional statistical approaches and the classification capacity of machine learning approaches. applying a battery of complementary algorithms may be a strategic approach to decipher complex exposome-health associations when the underlying structure is unknown.","['multipollutant assessment using machine learning algorithms', 'persistent organic pollutants', 'endometriosis', 'associations']"
"treatment planning is an essential step of the radiotherapy workflow. it has become more sophisticated over the past couple of decades with the help of computer science, enabling planners to design highly complex radiotherapy plans to minimize the normal tissue damage while persevering sufficient tumor control. as a result, treatment planning has become more labor intensive, requiring hours or even days of planner effort to optimize an individual patient case in a trial-and-error fashion. more recently, artificial intelligence has been utilized to automate and improve various aspects of medical science. for radiotherapy treatment planning, many algorithms have been developed to better support planners. these algorithms focus on automating the planning process and/or optimizing dosimetric trade-offs, and they have already made great impact on improving treatment planning efficiency and plan quality consistency. in this review, the smart planning tools in current clinical use are summarized in 3 main categories: automated rule implementation and reasoning, modeling of prior knowledge in clinical practice, and multicriteria optimization. novel artificial intelligence-based treatment planning applications, such as deep learning-based algorithms and emerging research directions, are also reviewed. finally, the challenges of artificial intelligence-based treatment planning are discussed for future works.","['radiotherapy treatment planning', 'artificial intelligence', 'present', 'future']"
"magnetic resonance fingerprinting (mrf) is an imaging technique acquiring unique time signals for different tissues. although the acquisition is highly accelerated, the reconstruction time remains a problem, as the state-of-the-art template matching compares every signal with a set of possible signals. to overcome this limitation, deep learning based approaches, e.g. convolutional neural networks (cnns) have been proposed. in this work, we investigate the applicability of recurrent neural networks (rnns) for this reconstruction problem, as the signals are correlated in time. compared to previous methods based on cnns, rnn models yield significantly improved results using in-vivo data.",['magnetic resonance fingerprinting reconstruction using recurrent neural networks']
"the important role of micrornas (mirnas) in the formation, development, diagnosis, and treatment of diseases has attracted much attention among researchers recently. in this study, we present an unsupervised deep learning model of the variational autoencoder for mirna-disease association prediction (vaemda). through combining the integrated mirna similarity and the integrated disease similarity with known mirna-disease associations, respectively, we constructed two spliced matrices. these matrices were applied to train the variational autoencoder (vae), respectively. the final predicted association scores between mirnas and diseases were obtained by integrating the scores from the two trained vae models. unlike previous models, vaemda can avoid noise introduced by the random selection of negative samples and reveal associations between mirnas and diseases from the perspective of data distribution. compared with previous methods, vaemda obtained higher area under the receiver operating characteristics curves (aucs) of 0.9118, 0.8652, and 0.9091 ± 0.0065 in global leave-one-out cross validation (loocv), local loocv, and five-fold cross validation, respectively. further, the aucs of vaemda were 0.8250 and 0.8237 in global leave-one-disease-out cross validation (lodocv), and local lodocv, respectively. in three different types of case studies on three important diseases, the results showed that most of the top 50 potentially associated mirnas were verified by databases and the literature.","['novel unsupervised deep learning framework', 'variational autoencoder', 'potential mirna', 'disease associations', 'prediction']"
"the purpose of this work is to validate the application of a deep learning-based method for pelvic synthetic ct (sct) generation that can be used for prostate proton beam therapy treatment planning. we propose to integrate dense block minimization into 3d cycle-consistent generative adversarial networks (cyclegan) framework to effectively learn the nonlinear mapping between mri and ct pairs. a cohort of 17 patients with co-registered ct and mr pairs were used to test the deep learning-based sct generation method by leave-one-out cross-validation. image quality between the sct and ct images, gamma analysis passing rate, dose-volume metrics, distal range displacement, and the individual pencil beam bragg peak shift between sct- and ct-based proton plans were evaluated. the average mean absolute error (mae) was 51.32\u2009\u2009±\u2009\u200916.91 hu. the relative differences of the statistics of the ptv dose-volume histogram (dvh) metrics in between sct and ct were generally less than 1%. mean values of dose difference, absolute dose difference (in percent of the prescribed dose) were\u2009\u2009-0.07%\u2009\u2009±\u2009\u20090.07% and 0.23%\u2009\u2009±\u2009\u20090.08%. mean gamma analysis pass rate of 1\u2009mm/1%, 2\u2009mm/2%, 3\u2009mm/3% criteria with 10% dose threshold were 92.39%\u2009\u2009±\u2009\u20095.97%, 97.95%\u2009\u2009±\u2009\u20092.95% and 98.97%\u2009\u2009±\u2009\u20091.62% respectively. the median, mean and standard deviation of absolute maximum range differences were 0.09\u2009cm and 0.23\u2009\u2009±\u2009\u20090.25\u2009cm. the median and mean bragg peak shifts among the 17 patients were 0.09\u2009cm and 0.18\u2009\u2009±\u2009\u20090.07\u2009cm. the image similarity, dosimetric and distal range agreement between sct and original ct suggests the feasibility of further development of an mri-only workflow for prostate proton radiotherapy.","['based pelvic synthetic ct generation technique', 'based prostate proton treatment planning', 'deep learning', 'mri', 'evaluation']"
"the ability to complete an operative report is a vital skill for an orthopaedic surgeon. we hypothesized that most programs do not have formal operative report teaching, that resident operative reports at our institution are incomplete, and that a formal teaching program would improve operative reports.","['orthopaedic surgery', 'operative reports', 'need', 'education', 'assessment']"
"the goal of this work is to reduce driver's range anxiety by estimating the real-time energy consumption of electric vehicles using deep convolutional neural network. the real-time estimate can be used to accurately predict the remaining range for the vehicle and hence, can reduce driver's range anxiety. in contrast to existing techniques, the non-linearity and complexity induced by the combination of influencing factors make the problem more suitable for a deep learning approach. the proposed approach requires three parameters namely, vehicle speed, tractive effort and road elevation. multiple experiments with different variants are performed to explore the impact of number of layers and input feature descriptors. the comparison of proposed approach and five of the existing techniques show that the proposed model performed consistently better than existing techniques with lowest error.","['electric vehicles using deep convolutional neural network', 'reduce driver', 'range anxiety', 'energy consumption', 'estimation']"
"histopathology image analysis serves as the gold standard for cancer diagnosis. efficient and precise diagnosis is quite critical for the subsequent therapeutic treatment of patients. so far, computer-aided diagnosis has not been widely applied in pathological field yet as currently well-addressed tasks are only the tip of the iceberg. whole slide image (wsi) classification is a quite challenging problem. first, the scarcity of annotations heavily impedes the pace of developing effective approaches. pixelwise delineated annotations on wsis are time consuming and tedious, which poses difficulties in building a large-scale training dataset. in addition, a variety of heterogeneous patterns of tumor existing in high magnification field are actually the major obstacle. furthermore, a gigapixel scale wsi cannot be directly analyzed due to the immeasurable computational cost. how to design the weakly supervised learning methods to maximize the use of available wsi-level labels that can be readily obtained in clinical practice is quite appealing. to overcome these challenges, we present a weakly supervised approach in this article for fast and effective classification on the whole slide lung cancer images. our method first takes advantage of a patch-based fully convolutional network (fcn) to retrieve discriminative blocks and provides representative deep features with high efficiency. then, different context-aware block selection and feature aggregation strategies are explored to generate globally holistic wsi descriptor which is ultimately fed into a random forest (rf) classifier for the image-level prediction. to the best of our knowledge, this is the first study to exploit the potential of image-level labels along with some coarse annotations for weakly supervised learning. a large-scale lung cancer wsi dataset is constructed in this article for evaluation, which validates the effectiveness and feasibility of the proposed method. extensive experiments demonstrate the superior performance of our method that surpasses the state-of-the-art approaches by a significant margin with an accuracy of 97.3% . in addition, our method also achieves the best performance on the public lung cancer wsis dataset from the cancer genome atlas (tcga). we highlight that a small number of coarse annotations can contribute to further accuracy improvement. we believe that weakly supervised learning methods have great potential to assist pathologists in histology image diagnosis in the near future.","['whole slide lung cancer image analysis', 'weakly supervised deep learning']"
"the purpose of this research is to exploit a weak and semi-supervised deep learning framework to segment prostate cancer in trus images, alleviating the time-consuming work of radiologists to draw the boundary of the lesions and training the neural network on the data that do not have complete annotations. a histologic-proven benchmarking dataset of 102 case images was built and 22 images were randomly selected for evaluation. some portion of the training images were strong supervised, annotated pixel by pixel. using the strong supervised images, a deep learning neural network was trained. the rest of the training images with only weak supervision, which is just the location of the lesion, were fed to the trained network to produce the intermediate pixelwise labels for the weak supervised images. then, we retrained the neural network on the all training images with the original labels and the intermediate labels and fed the training images to the retrained network to produce the refined labels. comparing the distance of the center of mass of the refined labels and the intermediate labels to the weak supervision location, the closer one replaced the previous label, which could be considered as the label updates. after the label updates, test set images were fed to the retrained network for evaluation. the proposed method shows better result with weak and semi-supervised data than the method using only small portion of strong supervised data, although the improvement may not be as much as when the fully strong supervised dataset is used. in terms of mean intersection over union (miou), the proposed method reached about 0.6 when the ratio of the strong supervised data was 40%, about 2% decreased performance compared to that of 100% strong supervised case. the proposed method seems to be able to help to alleviate the time-consuming work of radiologists to draw the boundary of the lesions, and to train the neural network on the data that do not have complete annotations.","['supervised segmentation method', 'trus images', 'prostate cancer', 'weak', 'semi']"
"the whole slide histopathology images (wsis) play a critical role in gastric cancer diagnosis. however, due to the large scale of wsis and various sizes of the abnormal area, how to select informative regions and analyze them are quite challenging during the automatic diagnosis process. the multi-instance learning based on the most discriminative instances can be of great benefit for whole slide gastric image diagnosis. in this paper, we design a recalibrated multi-instance deep learning method (rmdl) to address this challenging problem. we first select the discriminative instances, and then utilize these instances to diagnose diseases based on the proposed rmdl approach. the designed rmdl network is capable of capturing instance-wise dependencies and recalibrating instance features according to the importance coefficient learned from the fused features. furthermore, we build a large whole-slide gastric histopathology image dataset with detailed pixel-level annotations. experimental results on the constructed gastric dataset demonstrate the significant improvement on the accuracy of our proposed framework compared with other state-of-the-art multi-instance learning methods. moreover, our method is general and can be extended to other diagnosis tasks of different cancer types based on wsis.","['whole slide gastric image classification', 'instance deep learning', 'recalibrated multi', 'rmdl']"
"the 'how to …' series focuses on how to do qualitative research. but how can qualitative research enhance patient care? this paper aims to support health care practitioners, educators and researchers who are interested in bridging the gap between research and practice (both clinical and educational), to guide improvements that can ultimately benefit patients. we present action research and the change laboratory method as two approaches that typically involve qualitative research and have potential to change practice, blending scientific inquiry with social action. these approaches establish close research-practice partnerships and help answer tricky 'why' and 'how' questions that may unlock deep insights to enhance learning and patient care. …\xa0how can qualitative research enhance patient care?","['… use qualitative research', 'change practice']"
"biomedical text mining is becoming increasingly important as the number of biomedical documents rapidly grows. with the progress in natural language processing (nlp), extracting valuable information from biomedical literature has gained popularity among researchers, and deep learning has boosted the development of effective biomedical text mining models. however, directly applying the advancements in nlp to biomedical text mining often yields unsatisfactory results due to a word distribution shift from general domain corpora to biomedical corpora. in this article, we investigate how the recently introduced pre-trained language model bert can be adapted for biomedical corpora.","['trained biomedical language representation model', 'biomedical text mining', 'pre', 'biobert']"
"we present chromalignnet, a deep learning model for alignment of peaks in gas chromatography-mass spectrometry (gc-ms) data. in gc-ms data, a compound's retention time (rt) may not stay fixed across multiple chromatograms. to use gc-ms data for biomarker discovery requires alignment of identical analyte's rt from different samples. current methods of alignment are all based on a set of formal, mathematical rules. we present a solution to gc-ms alignment using deep learning neural networks, which are more adept at complex, fuzzy data sets. we tested our model on several gc-ms data sets of various complexities and analysed the alignment results quantitatively. we show the model has very good performance (auc\u202f∼\u202f1 for simple data sets and auc\u202f∼\u202f0.85 for very complex data sets). further, our model easily outperforms existing algorithms on complex data sets. compared with existing methods, chromalignnet is very easy to use as it requires no user input of reference chromatograms and parameters. this method can easily be adapted to other similar data such as those from liquid chromatography. the source code is written in python and available online.","['mass spectrometry data', 'peak alignment', 'gas chromatography', 'deep learning']"
"compared with the normal low dynamic range (ldr) images, the high dynamic range (hdr) images provide more dynamic range and image details. although the existing techniques for generating the hdr images have a good effect for static scenes, they usually produce artifacts on the hdr images for dynamic scenes. in recent years, some learning-based approaches are used to synthesize the hdr images and obtain good results. however, there are also many problems, including the deficiency of explaining and the time-consuming training process. in this article, we propose a novel approach to synthesize multiview hdr images through fuzzy broad learning system (fbls). we use a set of multiview ldr images with different exposure as input and transfer corresponding takagi-sugeno (ts) fuzzy subsystems; then, the structure is expanded in a wide sense in the ``enhancement groups'' which transfer from the ts fuzzy rules with nonlinear transformation. after integrating fuzzy subsystems and enhancement groups with the trained-well weight, the hdr image is generated. in fbls, applying the incremental learning algorithm and the pseudoinverse method to compute the weights can greatly reduce the training time. in addition, the fuzzy system has better interpretability. in the learning process, if-then fuzzy rules can effectively help the model to detect the artifacts and reject them in the final hdr result. these advantages solve the problem of existing deep-learning methods. furthermore, we set up a new dataset of multiview ldr images with corresponding hdr ground truth to train our system. our experimental results show that our system can synthesize high-quality multiview hdr images, which has a higher training speed than other learning methods.",['multiview high dynamic range image synthesis using fuzzy broad learning system']
to investigate the natural history of persistent pulmonary pure ground-glass nodules (pggns) with deep learning-assisted nodule segmentation.,"['persistent pulmonary pure ground', 'assisted nodule segmentation', 'term follow', 'glass nodules', 'deep learning', 'long']"
"occupational therapy practitioners' professional identities and distinctive contributions to health care connect essentially to their knowledge of occupation. thus, the strategies educators use to convey occupation to students and the perspectives embedded in those strategies are critical topics for researchers.","['instructional strategies used', 'teach occupation', 'signature pedagogies', 'national survey', 'learning activities', 'implications']"
"the purpose of super-resolution approaches is to overcome the hardware limitations and the clinical requirements of imaging procedures by reconstructing high-resolution images from low-resolution acquisitions using post-processing methods. super-resolution techniques could have strong impacts on structural magnetic resonance imaging when focusing on cortical surface or fine-scale structure analysis for instance. in this paper, we study deep three-dimensional convolutional neural networks for the super-resolution of brain magnetic resonance imaging data. first, our work delves into the relevance of several factors in the performance of the purely convolutional neural network-based techniques for the monomodal super-resolution: optimization methods, weight initialization, network depth, residual learning, filter size in convolution layers, number of the filters, training patch size and number of training subjects. second, our study also highlights that one single network can efficiently handle multiple arbitrary scaling factors based on a multiscale training approach. third, we further extend our super-resolution networks to the multimodal super-resolution using intermodality priors. fourth, we investigate the impact of transfer learning skills onto super-resolution performance in terms of generalization among different datasets. lastly, the learnt models are used to enhance real clinical low-resolution images. results tend to demonstrate the potential of deep neural networks with respect to practical medical image applications.","['resolution using deep 3d convolutional networks', 'multiscale brain mri super']"
"accurate segmentation of brainstem nuclei (red nucleus and substantia nigra) is very important in various neuroimaging applications such as deep brain stimulation and the investigation of imaging biomarkers for parkinson's disease (pd). due to iron deposition during aging, image contrast in the brainstem is very low in magnetic resonance (mr) images. hence, the ambiguity of patch-wise similarity makes the recently successful multi-atlas patch-based label fusion methods have difficulty to perform as competitive as segmenting cortical and sub-cortical regions from mr images. to address this challenge, we propose a novel multi-atlas brainstem nuclei segmentation method using deep hyper-graph learning. specifically, we achieve this goal in three-fold. first, we employ hyper-graph to combine the advantage of maintaining spatial coherence from graph-based segmentation approaches and the benefit of harnessing population priors from multi-atlas based framework. second, besides using low-level image appearance, we also extract high-level context features to measure the complex patch-wise relationship. since the context features are calculated on a tentatively estimated label probability map, we eventually turn our hyper-graph learning based label propagation into a deep and self-refining model. third, since anatomical labels on some voxels (usually located in uniform regions) can be identified much more reliably than other voxels (usually located at the boundary between two regions), we allow these reliable voxels to propagate their labels to the nearby difficult-to-label voxels. such hierarchical strategy makes our proposed label fusion method deep and dynamic. we evaluate our proposed label fusion method in segmenting substantia nigra (sn) and red nucleus (rn) from 3.0 t mr images, where our proposed method achieves significant improvement over the state-of-the-art label fusion methods.","['atlas based segmentation', 'mr images', 'graph learning', 'deep hyper', 'brainstem nuclei', 'multi']"
"we present a novel approach based on deep learning for decoding sensory information from non-invasively recorded electroencephalograms (eeg). it can either be used in a passive brain-computer interface (bci) to predict properties of a visual stimulus the person is viewing, or it can be used to actively control a bci application. both scenarios were tested, whereby an average information transfer rate (itr) of 701 bit/min was achieved for the passive bci approach with the best subject achieving an online itr of 1237 bit/min. further, it allowed the discrimination of 500,000 different visual stimuli based on only 2 seconds of eeg data with an accuracy of up to 100%. when using the method for an asynchronous self-paced bci for spelling, an average utility rate of 175 bit/min was achieved, which corresponds to an average of 35 error-free letters per minute. as the presented method extracts more than three times more information than the previously fastest approach, we suggest that eeg signals carry more information than generally assumed. finally, we observed a ceiling effect such that information content in the eeg exceeds that required for bci control, and therefore we discuss if bci research has reached a point where the performance of non-invasive visual bci control cannot be substantially improved anymore.","['fastest brain', 'deep learning', 'computer interface', 'combining eeg2code', 'world']"
"camera manipulation confounds the use of object recognition applications by blind people. this is exacerbated when photos from this population are also used to train models, as with teachable machines, where out-of-frame or partially included objects against cluttered backgrounds degrade performance. leveraging prior evidence on the ability of blind people to coordinate hand movements using proprioception, we propose a deep learning system that jointly models hand segmentation and object localization for object classification. we investigate the utility of hands as a natural interface for including and indicating the object of interest in the camera frame. we confirm the potential of this approach by analyzing existing datasets from people with visual impairments for object recognition. with a new publicly available egocentric dataset and an extensive error analysis, we provide insights into this approach in the context of teachable recognizers.","['hands holding clues', 'teachable machines', 'object recognition']"
"with the widespread use of deep learning methods, semantic segmentation has achieved great improvements in recent years. however, many researchers have pointed out that with multiple uses of convolution and pooling operations, great information loss would occur in the extraction processes. to solve this problem, various operations or network architectures have been suggested to make up for the loss of information. we observed a trend in many studies to design a network as a symmetric type, with both parts representing the ""encoding"" and ""decoding"" stages. by ""upsampling"" operations in the ""decoding"" stage, feature maps are constructed in a certain way that would more or less make up for the losses in previous layers. in this paper, we focus on upsampling operations, make a detailed analysis, and compare current methods used in several famous neural networks. we also combine the knowledge on image restoration and design a new upsampled layer (or operation) named the tgv upsampling algorithm. we successfully replaced upsampling layers in the previous research with our new method. we found that our model can better preserve detailed textures and edges of feature maps and can, on average, achieve 1.4-2.3% improved accuracy compared to the original models.","['tgv upsampling', 'semantic segmentation', 'operation', 'making']"
"skin cancer cases are increasing and becoming one of the main problems worldwide. skin cancer is known as a malignant type of skin lesion, and early detection and treatment are necessary. malignant melanoma and seborrheic keratosis are known as common skin lesion types. a fast and accurate medical diagnosis of these lesions is crucial. in this study, a novel gabor wavelet-based deep convolutional neural network is proposed for the detection of malignant melanoma and seborrheic keratosis. the proposed method is based on the decomposition of input images into seven directional sub-bands. seven sub-band images and the input image are used as inputs to eight parallel cnns to generate eight probabilistic predictions. decision fusion based on the sum rule is utilized to classify the skin lesion. gabor based approach provides directional decomposition where each sub-band gives isolated decisions that can be fused for improved overall performance. the results show that the proposed method outperforms alternative methods in the literature developed for skin cancer detection.","['skin lesion classification', 'based deep learning', 'gabor wavelet']"
"*: background in the search for therapeutic peptides for disease treatments, many efforts have been made to identify various functional peptides from large numbers of peptide sequence databases. in this paper, we propose an effective computational model that uses deep learning and word2vec to predict therapeutic peptides (ptpd). *: results representation vectors of all k-mers were obtained through word2vec based on k-mer co-existence information. the original peptide sequences were then divided into k-mers using the windowing method. the peptide sequences were mapped to the input layer by the embedding vector obtained by word2vec. three types of filters in the convolutional layers, as well as dropout and max-pooling operations, were applied to construct feature maps. these feature maps were concatenated into a fully connected dense layer, and rectified linear units (relu) and dropout operations were included to avoid over-fitting of ptpd. the classification probabilities were generated by a sigmoid function. ptpd was then validated using two datasets: an independent anticancer peptide dataset and a virulent protein dataset, on which it achieved accuracies of 96% and 94%, respectively. *: conclusions ptpd identified novel therapeutic peptides efficiently, and it is suitable for application as a useful tool in therapeutic peptide design.","['predicting therapeutic peptides', 'deep learning', 'word2vec', 'ptpd']"
"deep convolutional neural networks have achieved great performance on various image restoration tasks. specifically, the residual dense network (rdn) has achieved great results on image noise reduction by cascading multiple residual dense blocks (rdbs) to make full use of the hierarchical feature. however, the rdn only performs well in denoising on a single noise level, and the computational cost of the rdn increases significantly with the increase in the number of rdbs, and this only slightly improves the effect of denoising. to overcome this, we propose the dynamic residual dense network (drdn), a dynamic network that can selectively skip some rdbs based on the noise amount of the input image. moreover, the drdn allows modifying the denoising strength to manually get the best outputs, which can make the network more effective for real-world denoising. our proposed drdn can perform better than the rdn and reduces the computational cost by 40 - 50 % . furthermore, we surpass the state-of-the-art cbdnet by 1.34 db on the real-world noise benchmark.","['dynamic residual dense network', 'image denoising']"
"here we present the mendeleev-meyer force project which aims at tabulating all materials and substances in a fashion similar to the periodic table. the goal is to group and tabulate substances using nanoscale force footprints rather than atomic number or electronic configuration as in the periodic table. the process is divided into: (1) acquiring nanoscale force data from materials, (2) parameterizing the raw data into standardized input features to generate a library, (3) feeding the standardized library into an algorithm to generate, enhance or exploit a model to identify a material or property. we propose producing databases mimicking the materials genome initiative, the medical literature analysis and retrieval system online (medlars) or the proteomics identifications database (pride) and making these searchable online via search engines mimicking pubmed or the pride web interface. a prototype exploiting deep learning algorithms, i.e. multilayer neural networks, is presented.","['meyer force project', 'mendeleev']"
"short-term traffic speed prediction has become one of the most important parts of intelligent transportation systems (itss). in recent years, deep learning methods have demonstrated their superiority both in accuracy and efficiency. however, most of them only consider the temporal information, overlooking the spatial or some environmental factors, especially the different correlations between the target road and the surrounding roads. this paper proposes a traffic speed prediction approach based on temporal clustering and hierarchical attention (tcha) to address the above issues. we apply temporal clustering to the target road to distinguish the traffic environment. traffic data in each cluster have a similar distribution, which can help improve the prediction accuracy. a hierarchical attention-based mechanism is then used to extract the features at each time step. the encoder measures the importance of spatial features, and the decoder measures the temporal ones. the proposed method is evaluated over the data of a certain area in hangzhou, and experiments have shown that this method can outperform the state of the art for traffic speed prediction.","['traffic speed prediction', 'based method', 'attention']"
"near-infrared (nir) spectral sensors can deliver the spectral response of light absorbed by materials. data analysis technology based on nir sensors has been a useful tool for quality identification. in this paper, an improved deep convolutional neural network (cnn) with batch normalization and msra (microsoft research asia) initialization is proposed to discriminate the tobacco cultivation regions using data collected from nir sensors. the network structure is created with six convolutional layers and three full connection layers, and the learning rate is controlled by exponential attenuation method. one-dimensional kernel is applied as the convolution kernel to extract features. meanwhile, the methods of l2 regularization and dropout are used to avoid the overfitting problem, which improve the generalization ability of the network. experimental results show that the proposed deep network structure can effectively extract the complex characteristics inside the spectrum, which proves that it has excellent recognition performance on tobacco cultivation region discrimination, and it also demonstrates that the deep cnn is more suitable for information mining and analysis of big data.","['infrared spectroscopy sensors', 'improved deep cnn', 'parameter initialization', 'data analysis', 'near']"
"local specific absorption rate (sar) cannot be measured and is usually evaluated by offline numerical simulations using generic body models that of course will differ from the patient\'s anatomy. an additional safety margin is needed to include this intersubject variability. in this work, we present a deep learning-based method for image-based subject-specific local sar assessment. we propose to train a convolutional neural network to learn a ""surrogate sar model"" to map the relation between subject-specific b 1 +  maps and the corresponding local sar.","['specific local sar assessment', 'deep learning method', 'based subject', 'image']"
"monitoring of tool wear in machining process has found its importance to predict tool life, reduce equipment downtime, and tool costs. traditional visual methods require expert experience and human resources to obtain accurate tool wear information. with the development of charge-coupled device (ccd) image sensor and the deep learning algorithms, it has become possible to use the convolutional neural network (cnn) model to automatically identify the wear types of high-temperature alloy tools in the face milling process. in this paper, the cnn model is developed based on our image dataset. the convolutional automatic encoder (cae) is used to pre-train the network model, and the model parameters are fine-tuned by back propagation (bp) algorithm combined with stochastic gradient descent (sgd) algorithm. the established toolwearnet network model has the function of identifying the tool wear types. the experimental results show that the average recognition precision rate of the model can reach 96.20%. at the same time, the automatic detection algorithm of tool wear value is improved by combining the identified tool wear types. in order to verify the feasibility of the method, an experimental system is built on the machine tool. by matching the frame rate of the industrial camera and the machine tool spindle speed, the wear image information of all the inserts can be obtained in the machining gap. the automatic detection method of tool wear value is compared with the result of manual detection by high precision digital optical microscope, the mean absolute percentage error is 4.76%, which effectively verifies the effectiveness and practicality of the method.","['tool wear based', 'face milling process', 'convolutional neural network', 'automatic identification']"
the development of deep neural networks is facilitating more advanced digital analysis of histopathologic images. we trained a convolutional neural network for multiclass segmentation of digitized kidney tissue sections stained with periodic acid-schiff (pas).,"['based histopathologic assessment', 'kidney tissue', 'deep learning']"
"background although several deep learning (dl) calcium scoring methods have achieved excellent performance for specific ct protocols, their performance in a range of ct examination types is unknown. purpose to evaluate the performance of a dl method for automatic calcium scoring across a wide range of ct examination types and to investigate whether the method can adapt to different types of ct examinations when representative images are added to the existing training data set. materials and methods the study included 7240 participants who underwent various types of nonenhanced ct examinations that included the heart: coronary artery calcium (cac) scoring ct, diagnostic ct of the chest, pet attenuation correction ct, radiation therapy treatment planning ct, cac screening ct, and low-dose ct of the chest. cac and thoracic aorta calcification (tac) were quantified using a convolutional neural network trained with (a) 1181 low-dose chest ct examinations (baseline), (b) a small set of examinations of the respective type supplemented to the baseline (data specific), and (c) a combination of examinations of all available types (combined). supplemental training sets contained 199-568 ct images depending on the calcium burden of each population. the dl algorithm performance was evaluated with intraclass correlation coefficients (iccs) between dl and manual (agatston) cac and (volume) tac scoring and with linearly weighted κ values for cardiovascular risk categories (agatston score; cardiovascular disease risk categories: 0, 1-10, 11-100, 101-400, >400). results at baseline, the dl algorithm yielded iccs of 0.79-0.97 for cac and 0.66-0.98 for tac across the range of different types of ct examinations. iccs improved to 0.84-0.99 (cac) and 0.92-0.99 (tac) for ct protocol-specific training and to 0.85-0.99 (cac) and 0.96-0.99 (tac) for combined training. for assignment of cardiovascular disease risk category, the κ value for all test ct scans was 0.90 (95% confidence interval [c","['9', '89', '0']"
"purpose\xa0: the purpose of this paper is to present a fully automated abdominal artery segmentation method from a ct volume. three-dimensional (3d) blood vessel structure information is important for diagnosis and treatment. information about blood vessels (including arteries) can be used in patient-specific surgical planning and intra-operative navigation. since blood vessels have large inter-patient variations in branching patterns and positions, a patient-specific blood vessel segmentation method is necessary. even though deep learning-based segmentation methods provide good segmentation accuracy among large organs, small organs such as blood vessels are not well segmented. we propose a deep learning-based abdominal artery segmentation method from a ct volume. because the artery is one of small organs that is difficult to segment, we introduced an original training sample generation method and a three-plane segmentation approach to improve segmentation accuracy. method\xa0: our proposed method segments abdominal arteries from an abdominal ct volume with a fully convolutional network (fcn). to segment small arteries, we employ a 2d patch-based segmentation method and an area imbalance reduced training patch generation (airtpg) method. airtpg adjusts patch number imbalances between patches with artery regions and patches without them. these methods improved the segmentation accuracies of small artery regions. furthermore, we introduced a three-plane segmentation approach to obtain clear 3d segmentation results from 2d patch-based processes. in the three-plane approach, we performed three segmentation processes using patches generated on axial, coronal, and sagittal planes and combined the results to generate a 3d segmentation result. results\xa0: the evaluation results of the proposed method using 20 cases of abdominal ct volumes show that the averaged f-measure, precision, and recall rates were 87.1%, 85.8%, and 88.4%, respectively. this result outperformed our previous automated fcn-based segmentation method. our method offers competitive performance compared to the previous blood vessel segmentation methods from 3d volumes. conclusions\xa0: we developed an abdominal artery segmentation method using fcn. the 2d patch-based and airtpg methods effectively segmented the artery regions. in addition, the three-plane approach generated good 3d segmentation results.","['ct volumes using fully convolutional neural network', 'abdominal artery segmentation method']"
"deep neural networks (dnns) have achieved extraordinary success in numerous areas. however, dnns often carry a large number of weight parameters, leading to the challenge of heavy memory and computation costs. overfitting is another challenge for dnns when the training data are insufficient. these challenges severely hinder the application of dnns in resource-constrained platforms. in fact, many network weights are redundant and can be removed from the network without much loss of performance. in this paper, we introduce a new non-convex integrated transformed ℓ1 regularizer to promote sparsity for dnns, which removes redundant connections and unnecessary neurons simultaneously. specifically, we apply the transformed ℓ1 regularizer to the matrix space of network weights and utilize it to remove redundant connections. besides, group sparsity is integrated to remove unnecessary neurons. an efficient stochastic proximal gradient algorithm is presented to solve the new model. to the best of our knowledge, this is the first work to develop a non-convex regularizer in sparse optimization based method to simultaneously promote connection-level and neuron-level sparsity for dnns. experiments on public datasets demonstrate the effectiveness of the proposed method.","['learning sparse deep neural networks', 'transformed ℓ1 regularization']"
to test whether our proposed denoising approach with deep learning-based reconstruction (ddlr) can effectively denoise brain mr images.,"['deep learning based noise reduction', 'brain mr imaging', 'healthy volunteers', 'tests', 'phantoms']"
"a computationally fast tone mapping operator (tmo) that can quickly adapt to a wide spectrum of high dynamic range (hdr) content is quintessential for visualization on varied low dynamic range (ldr) output devices such as movie screens or standard displays. existing tmos can successfully tone-map only a limited number of hdr content and require an extensive parameter tuning to yield the best subjective-quality tone-mapped output. in this paper, we address this problem by proposing a fast, parameter-free and scene-adaptable deep tone mapping operator (deeptmo) that yields a high-resolution and high-subjective quality tone mapped output. based on conditional generative adversarial network (cgan), deeptmo not only learns to adapt to vast scenic-content (e.g., outdoor, indoor, human, structures, etc.) but also tackles the hdr related scene-specific challenges such as contrast and brightness, while preserving the fine-grained details. we explore 4 possible combinations of generator-discriminator architectural designs to specifically address some prominent issues in hdr related deep-learning frameworks like blurring, tiling patterns and saturation artifacts. by exploring different influences of scales, loss-functions and normalization layers under a cgan setting, we conclude with adopting a multi-scale model for our task. to further leverage on the large-scale availability of unlabeled hdr data, we train our network by generating targets using an objective hdr quality metric, namely tone mapping image quality index (tmqi). we demonstrate results both quantitatively and qualitatively, and showcase that our deeptmo generates high-resolution, high-quality output images over a large spectrum of real-world scenes. finally, we evaluate the perceived quality of our results by conducting a pair-wise subjective study which confirms the versatility of our method.","['high dynamic range images', 'deep tone mapping operator']"
"the inapplicability of amino acid covariation methods to small protein families has limited their use for structural annotation of whole genomes. recently, deep learning has shown promise in allowing accurate residue-residue contact prediction even for shallow sequence alignments. here we introduce dmpfold, which uses deep learning to predict inter-atomic distance bounds, the main chain hydrogen bond network, and torsion angles, which it uses to build models in an iterative fashion. dmpfold produces more accurate models than two popular methods for a test set of casp12 domains, and works just as well for transmembrane proteins. applied to all pfam domains without known structures, confident models for 25% of these so-called dark families were produced in under a week on a small 200 core cluster. dmpfold provides models for 16% of human proteome uniprot entries without structures, generates accurate models with fewer than 100 sequences in some cases, and is freely available.","['deep learning extends de novo protein modelling coverage', 'genomes using iteratively predicted structural constraints']"
"crispr/cas9 system, as the third-generation genome editing technology, has been widely applied in target gene repair and gene expression regulation. selection of appropriate sgrna can improve the on-target knockout efficacy of crispr/cas9 system with high sensitivity and specificity. however, when crispr/cas9 system is operating, unexpected cleavage may occur at some sites, known as off-target. presently, a number of prediction methods have been developed to predict the off-target propensity of sgrna at specific dna fragments. most of them use artificial feature extraction operations and machine learning techniques to obtain off-target scores. with the rapid expansion of off-target data and the rapid development of deep learning theory, the existing prediction methods can no longer satisfy the prediction accuracy at the clinical level.","['target propensity prediction', 'deep learning improves', 'sgrna', 'ability']"
"combining machine learning with neuroimaging data has a great potential for early diagnosis of mild cognitive impairment (mci) and alzheimer's disease (ad). however, it remains unclear how well the classifiers built on one population can predict mci/ad diagnosis of other populations. this study aimed to employ a spectral graph convolutional neural network (graph-cnn), that incorporated cortical thickness and geometry, to identify mci and ad based on 3089 t1-weighted mri data of the adni-2 cohort, and to evaluate its feasibility to predict ad in the adni-1 cohort (n\u202f=\u202f3602) and an asian cohort (n\u202f=\u202f347). for the adni-2 cohort, the graph-cnn showed classification accuracy of controls (cn) vs. ad at 85.8% and early mci (emci) vs. ad at 79.2%, followed by cn vs. late mci (lmci) (69.3%), lmci vs. ad (65.2%), emci vs. lmci (60.9%), and cn vs. emci (51.8%). we demonstrated the robustness of the graph-cnn among the existing deep learning approaches, such as euclidean-domain-based multilayer network and 1d cnn on cortical thickness, and 2d and 3d cnns on t1-weighted mr images of the adni-2 cohort. the graph-cnn also achieved the prediction on the conversion of emci to ad at 75% and that of lmci to ad at 92%. the find-tuned graph-cnn further provided a promising cn vs. ad classification accuracy of 89.4% on the adni-1 cohort and >90% on the asian cohort. our study demonstrated the feasibility to transfer ad/mci classifiers learned from one population to the other. notably, incorporating cortical geometry in cnn has the potential to improve classification performance.","['transfer learning across populations', 'cortical graph neural network', 'mci diagnosis', 'ad']"
"recent development of object detection mainly depends on deep learning with large-scale benchmarks. however, collecting such fully-annotated data is often difficult or expensive for real-world applications, which restricts the power of deep neural networks in practice. alternatively, humans can detect new objects with little annotation burden, since humans often use the prior knowledge to identify new objects with few elaborately-annotated examples, and subsequently generalize this capacity by exploiting objects from wild images. inspired by this procedure of learning to detect, we propose a novel progressive object transfer detection (potd) framework. specifically, we make three main contributions in this paper. first, potd can leverage various object supervision of different domains effectively into a progressive detection procedure. via such human-like learning, one can boost a target detection task with few annotations. second, potd consists of two delicate transfer stages, i.e., low-shot transfer detection (lstd), and weakly-supervised transfer detection (wstd). in lstd, we distill the implicit object knowledge of source detector to enhance target detector with few annotations. it can effectively warm up wstd later on. in wstd, we design a recurrent object labelling mechanism for learning to annotate weakly-labeled images. more importantly, we exploit the reliable object supervision from lstd, which can further enhance the robustness of target detector in the wstd stage. finally, we perform extensive experiments on a number of challenging detection benchmarks with different settings. the results demonstrate that, our potd outperforms the recent state-of-the-art approaches. the codes and models are available at https://github.com/cassie94/lstd/tree/lstd.",['progressive object transfer detection']
"scanning acoustic microscopy (sam) provides high-resolution images of biological tissues. since higher transducer frequencies limit penetration depth, image resolution enhancement techniques could help in maintaining sufficient lateral resolution without sacrificing penetration depth. compared with existing sam research, this work introduces two novelties. first, deep learning (dl) is used to improve lateral resolution of 180-mhz sam images, comparing it with two deconvolution-based approaches. second, 316-mhz images are used as ground truth in order to quantitatively evaluate image resolution enhancement. the samples used were mouse and rat brain sections. the results demonstrate that dl can closely approximate ground truth (nrmse = 0.056 and psnr = 28.4 db) even with a relatively limited training set (four images, each smaller than 1 mm ×1 mm). this study suggests the high potential of using dl as a single image superresolution method in sam.","['acoustic microscopy lateral resolution', 'two deconvolution methods', 'deep learning', 'enhancement', 'comparison']"
"visual attention prediction (vap) is a significant and imperative issue in the field of computer vision. most of the existing vap methods are based on deep learning. however, they do not fully take advantage of the low-level contrast features while generating the visual attention map. in this article, a novel vap method is proposed to generate the visual attention map via bio-inspired representation learning. the bio-inspired representation learning combines both low-level contrast and high-level semantic features simultaneously, which are developed by the fact that the human eye is sensitive to the patches with high contrast and objects with high semantics. the proposed method is composed of three main steps: 1) feature extraction; 2) bio-inspired representation learning; and 3) visual attention map generation. first, the high-level semantic feature is extracted from the refined vgg16, while the low-level contrast feature is extracted by the proposed contrast feature extraction block in a deep network. second, during bio-inspired representation learning, both the extracted low-level contrast and high-level semantic features are combined by the designed densely connected block, which is proposed to concatenate various features scale by scale. finally, the weighted-fusion layer is exploited to generate the ultimate visual attention map based on the obtained representations after bio-inspired representation learning. extensive experiments are performed to demonstrate the effectiveness of the proposed method.","['visual attention prediction', 'inspired representation learning', 'bio']"
"aiming at the problems of low efficiency and poor accuracy of traditional captcha recognition methods, we have proposed a more efficient way based on deep convolutional neural network (cnn). the dense convolutional network (densenet) has shown excellent classification performance which adopts cross-layer connection. not only it effectively alleviates the vanishing-gradient problem, but also dramatically reduce the number of parameters. however, it also has caused great memory consumption. so we improve and construct a new densenet for captcha recognition (dfcr). firstly, we reduce the number of convolutional blocks and build corresponding classifiers for different types of captcha images. secondly, we input the captcha images of tfrecords format into the dfcr for model training. finally, we test the chinese or english captchas experimentally with different numbers of characters. experiments show that the new network not only keeps the primary performance advantages of the densenets but also effectively reduces the memory consumption. furthermore, the recognition accuracy of captcha with the background noise and character adhesion is above 99.9%.","['deep convolutional neural network', 'captcha recognition based']"
"in this paper, we propose a novel deep reinforcement learning (drl) algorithm which can navigate non-holonomic robots with continuous control in an unknown dynamic environment with moving obstacles. we call the approach mk-a3c (memory and knowledge-based asynchronous advantage actor-critic) for short. as its first component, mk-a3c builds a gru-based memory neural network to enhance the robot's capability for temporal reasoning. robots without it tend to suffer from a lack of rationality in face of incomplete and noisy estimations for complex environments. additionally, robots with certain memory ability endowed by mk-a3c can avoid local minima traps by estimating the environmental model. secondly, mk-a3c combines the domain knowledge-based reward function and the transfer learning-based training task architecture, which can solve the non-convergence policies problems caused by sparse reward. these improvements of mk-a3c can efficiently navigate robots in unknown dynamic environments, and satisfy kinetic constraints while handling moving objects. simulation experiments show that compared with existing methods, mk-a3c can realize successful robotic navigation in unknown and challenging environments by outputting continuous acceleration commands.","['unknown dynamic environments based', 'deep reinforcement learning', 'navigation']"
"thin-section magnetic resonance imaging (mri) can provide higher resolution anatomical structures and more precise clinical information than thick-section images. however, thin-section mri is not always available due to the imaging cost issue. in multicenter retrospective studies, a large number of data are often in thick-section manner with different section thickness. the lack of thin-section data and the difference in section thickness bring considerable difficulties in the study based on the image big data. in this article, we introduce deepvolume, a two-step deep learning architecture to address the challenge of accurate thin-section mr image reconstruction. the first stage is the brain structure-aware network, in which the thick-section mr images in axial and sagittal planes are fused by a multitask 3-d u-net with prior knowledge of brain volume segmentation, which encourages the reconstruction result to have correct brain structure. the second stage is the spatial connection-aware network, in which the preliminary reconstruction results are adjusted slice-by-slice by a recurrent convolutional network embedding convolutional long short-term memory (lstm) block, which enhances the precision of the reconstruction by utilizing the previously unassessed sagittal information. we used 305 paired brain mri samples with thickness of 1.0 mm and 6.5 mm in this article. extensive experiments illustrate that deepvolume can produce the state-of-the-art reconstruction results by embedding more anatomical knowledge. furthermore, considering deepvolume as an intermediate step, the practical and clinical value of our method is validated by applying the brain volume estimation and voxel-based morphometry. the results show that deepvolume can provide much more reliable brain volume estimation in the normalized space based on the thick-section mr images compared with the traditional solutions.","['brain mri super', 'brain structure', 'spatial connection', 'aware network', 'resolution', 'deepvolume']"
"the research on forgery detection and localization is significant in digital forensics and has attracted increasing attention recently. traditional methods mostly use handcrafted or shallow-learning based features，but they have limited description ability and heavy computational costs. recently, deep neural networks have shown to be capable of extracting complex statistical features from high-dimensional inputs and efficiently learning their hierarchical representations. in order to capture more discriminative features between tampered and non-tampered regions，we propose an improved mask regional convolutional neural network (mask r-cnn) which attach a sobel filter to the mask branch of mask r-cnn in this paper. the sobel filter acts as an auxiliary task to encourage predicted masks to have similar image gradients to the groundtruth mask. the overall network is capable of detecting two different types of image manipulations, including copy-move and splicing. the experimental results on two standard datasets show that the proposed model outperforms some state-of-the-art methods.","['image forgeries using improved mask regional convolutional neural network', 'localization', 'detection']"
"deep reinforcement learning (rl) demonstrates excellent performance on tasks that can be solved by trained policy. it plays a dominant role among cutting-edge machine learning approaches using multi-layer neural networks (nns). at the same time, deep rl suffers from high sensitivity to noisy, incomplete, and misleading input data. following biological intuition, we involve spiking neural networks (snns) to address some deficiencies of deep rl solutions. previous studies in image classification domain demonstrated that standard nns (with relu nonlinearity) trained using supervised learning can be converted to snns with negligible deterioration in performance. in this paper, we extend those conversion results to the domain of q-learning nns trained using rl. we provide a proof of principle of the conversion of standard nn to snn. in addition, we show that the snn has improved robustness to occlusion in the input image. finally, we introduce results with converting full-scale deep q-network to snn, paving the way for future research to robust deep rl applications.","['spiking neuronal network platforms applied', 'reinforcement learning policies upon conversion', 'atari breakout game', 'improved robustness']"
"bladder urine volume has been estimated using an ellipsoid method based on triaxial measurements of the bladder extrapolated from two-dimensional ultrasound images. this study aimed to automate this process and to determine the accuracy of the automated estimation method for normal and small amounts of urine. a training set of 81 pairs of transverse and longitudinal ultrasound images were collected from healthy volunteers on a tablet-type ultrasound device, and an automatic detection tool was developed using them. the tool was evaluated using paired transverse/longitudinal ultrasound images from 27 other healthy volunteers. after imaging, the participants voided and their urine volume was measured. for determining accuracy, regression coefficients were calculated between estimated bladder volume and urine volume. further, sensitivity and specificity for 50 and 100 ml bladder volume thresholds were evaluated. data from 50 procedures were included. the regression coefficient was very similar between the automatic estimation (β = 0.99, r2 = 0.96) and manual estimation (β = 1.05, r2 = 0.97) methods. the sensitivity and specificity of the automatic estimation method were 88.5% and 100.0%, respectively, for 100 ml and were 94.1% and 100.0%, respectively, for 50 ml. the newly-developed automated tool accurately and reliably estimated bladder volume at two different volume thresholds of approximately 50 ml and 100 ml.","['automated ultrasonographic detection', 'bladder urine volume', 'bladder diameter', 'evaluation', 'estimation', 'development']"
"the emotional state of the learner is an important factor that must be taken into consideration during evaluating learning process and managing learning flows in computer based learning environments. this factor has a significant impact on the process of interaction between the learner and the learning environment. enriching this type of interaction make the learning flow more dynamic based on emotional and mental responses of the learners. this approach can manage various learning flows based on learner's capabilities which lead to enhance the learning process outcome. this article provides data on learners' emotional states during their interaction with learning environment and other data that describe their learning activities and learning flows. the learning activities data is a combination of data that represents summary of learners' emotional states and data that represents the mental responses per learning session. all of emotional states data and mental responses data are used to provide the next learning level for each learner using fuzzy rules. the datasets are hosted in the mendeley dataset repository (megahed, 2019).","['learners emotional states', 'fuzzy learning flows', 'learning environment', 'mental responses', 'interaction', 'data']"
"a prediction model for new-onset nonmelanoma skin cancer could enhance prevention measures, but few patient data-driven tools exist for more accurate prediction.","['deep learning using nonimaging information', 'sequential medical records', 'nonmelanoma skin cancer', 'prediction model', 'develop', 'assessment']"
"clinical sleep scoring involves a tedious visual review of overnight polysomnograms by a human expert, according to official standards. it could appear then a suitable task for modern artificial intelligence algorithms. indeed, machine learning algorithms have been applied to sleep scoring for many years. as a result, several software products offer nowadays automated or semi-automated scoring services. however, the vast majority of the sleep physicians do not use them. very recently, thanks to the increased computational power, deep learning has also been employed with promising results. machine learning algorithms can undoubtedly reach a high accuracy in specific situations, but there are many difficulties in their introduction in the daily routine. in this review, the latest approaches that are applying deep learning for facilitating and accelerating sleep scoring are thoroughly analyzed and compared with the state of the art methods. then the obstacles in introducing automated sleep scoring in the clinical practice are examined. deep learning algorithm capabilities of learning from a highly heterogeneous dataset, in terms both of human data and of scorers, are very promising and should be further investigated.","['automated sleep scoring', 'latest approaches', 'review']"
"the advent of deep learning has pushed medical image analysis to new levels, rapidly replacing more traditional machine learning and computer vision pipelines. however segmenting and labelling anatomical regions remains challenging owing to appearance variations, imaging artifacts, the paucity and variability of annotated data, and the difficulty of fully exploiting domain constraints such as anatomical knowledge about inter-region relationships. we address the last point, improving the network's region-labeling consistency by introducing nonadjloss, an adjacency-graph based auxiliary training loss that penalizes outputs containing regions with anatomically-incorrect adjacency relationships. nonadjloss supports both fully-supervised training and a semi-supervised extension in which it is applied to unlabeled supplementary training data. the approach substantially reduces segmentation anomalies on the miccai-2012, ibsrv2 brain mri datasets and the anatomy3 whole body ct dataset, especially when semi-supervised training is included.","['removing segmentation inconsistencies', 'supervised non', 'adjacency constraint', 'semi']"
"barrett cancer is a treatable disease when detected at an early stage. however, current screening protocols are often not effective at finding the disease early. volumetric laser endomicroscopy (vle) is a promising new imaging tool for finding dysplasia in barrett's esophagus (be) at an early stage, by acquiring cross-sectional images of the microscopic structure of be up to 3-mm deep. however, interpretation of vle scans is difficult for medical doctors due to both the size and subtlety of the gray-scale data. therefore, algorithms that can accurately find cancerous regions are very valuable for the interpretation of vle data. in this study, we propose a fully-automatic multi-step computer-aided detection (cad) algorithm that optimally leverages the effectiveness of deep learning strategies by encoding the principal dimension in vle data. additionally, we show that combining the encoded dimensions with conventional machine learning techniques further improves results while maintaining interpretability. furthermore, we train and validate our algorithm on a new histopathologically validated set of in-vivo vle snapshots. additionally, an independent test set is used to assess the performance of the model. finally, we compare the performance of our algorithm against previous state-of-the-art systems. with the encoded principal dimension, we obtain an area under the curve (auc) and f1 score of 0.93 and 87.4% on the test set respectively. we show this is a significant improvement compared to the state-of-the-art of 0.89 and 83.1%, respectively, thereby demonstrating the effectiveness of our approach.","['deep principal dimension encoding', 'volumetric laser endomicroscopy', 'early neoplasia', 'esophagus', 'classification', 'barrett']"
"parkinson's disease (pd) is an irreversible neurodegenerative disease. the diagnosis of pd based on neuroimaging is usually with low-level or deep learning features, which results in difficulties in achieving precision classification or interpreting the clinical significance. herein, we aimed to extract high-order features by using radiomics approach and achieve acceptable diagnosis accuracy in pd.","['support vector machine', 'radiomic features', 'normal controls', 'distinguish parkinson', 'disease cases', 'use']"
to compare the clinical and radiological outcomes of o-arm navigation assisted percutaneous pedicle fixation and open freehand pedicle fixation in treatment of ao type a3 thoracolumbar burst fractures (tbfs) without neurological deficit.,"['segment pedicle instrumentation assisted', 'thoracolumbar burst fractures', 'percutaneous short', 'arm navigation', 'treatment']"
"the global aging phenomenon has increased the number of individuals with age-related neurological movement disorders including parkinson's disease (pd) and essential tremor (et). pathological hand tremor (pht), which is considered among the most common motor symptoms of such disorders, can severely affect patients' independence and quality of life. to develop advanced rehabilitation and assistive technologies, accurate estimation/prediction of nonstationary pht is critical, however, the required level of accuracy has not yet been achieved. the lack of sizable datasets and generalizable modeling techniques that can fully represent the spectrotemporal characteristics of pht have been a critical bottleneck in attaining this goal. this paper addresses this unmet need through establishing a deep recurrent model to predict and eliminate the pht component of hand motion. more specifically, we propose a machine learning-based, assumption-free, and real-time pht elimination framework, the phtnet, by incorporating deep bidirectional recurrent neural networks. the phtnet is developed over a hand motion dataset of 81 et and pd patients collected systematically in a movement disorders clinic over 3 years. the phtnet is the first intelligent systems model developed on this scale for pht elimination that maximizes the resolution of estimation and allows for prediction of future and upcoming sub-movements.","['involuntary pathological hand tremor using recurrent neural network models', 'deep mining', 'phtnet', 'characterization']"
"informal caregivers often complain about missing knowledge. a knowledge-based personalized educational system is developed, which provides caregiving relatives with the information needed. yet, evaluation against domain experts indicated, that parts of the knowledge-base are incorrect. to overcome these problems the system can be extended by a learning capacity and then be trained further utilizing feedback from real informal caregivers. to extend the existing system an artificial neural network was trained to represent a large part of the knowledge-based approach. this paper describes the found artificial neural network's structure and the training process. the found neural network structure is not deep but very wide. the training terminated after 374.700 epochs with a mean squared error of 7.731 ∗ 10-8 for the end validation set. the neural network represents the parts of the knowledge-based approach and can now be retrained with user feedback, which will be collected during a system test in april and may 2019.","['learning capacity', 'based system', 'knowledge', 'extending']"
"crystalline materials exhibit long-range ordered lattice unit, within which resides nonperiodic structural features called defects. these crystallographic defects play a vital role in determining the physical and mechanical properties of a wide range of material systems. while computer vision has demonstrated success in recognizing feature patterns in images with well-defined contrast, automated identification of nanometer scale crystallographic defects in electron micrographs governed by complex contrast mechanisms is still a challenging task. here, building upon an advanced defect imaging mode that offers high feature clarity, we introduce defectsegnet - a new convolutional neural network (cnn) architecture that performs semantic segmentation of three common crystallographic defects in structural alloys: dislocation lines, precipitates and voids. results from supervised training on\xa0a small set of high-quality defect images of steels show high pixel-wise accuracy across all three types of defects: 91.60\u2009±\u20091.77% on dislocations, 93.39\u2009±\u20091.00% on precipitates, and 98.85\u2009±\u20090.56% on voids. we discuss the sources of uncertainties in cnn prediction and the training data in terms of feature density, representation and homogeneity and their effects on deep learning performance. further defect quantification using defectsegnet prediction outperforms human expert average, presenting a promising new workflow for fast and statistically meaningful quantification of materials defects.","['advanced stem images', 'semantic segmentation', 'deep learning', 'steels', 'defects']"
"the scientific, clinical, and pedagogical significance of devising methodologies to train nonprofessional subjects to recognize diagnostic visual patterns in medical images has been broadly recognized. however, systematic approaches to doing so remain poorly established. using mammography as an exemplar case, we use a series of experiments to demonstrate that deep learning (dl) techniques can, in principle, be used to train naïve subjects to reliably detect certain diagnostic visual patterns of cancer in medical images. in the main experiment, subjects were required to learn to detect statistical visual patterns diagnostic of cancer in mammograms using only the mammograms and feedback provided following the subjects' response. we found not only that the subjects learned to perform the task at statistically significant levels, but also that their eye movements related to image scrutiny changed in a learning-dependent fashion. two additional, smaller exploratory experiments suggested that allowing subjects to re-examine the mammogram in light of various items of diagnostic information may help further improve dl of the diagnostic patterns. finally, a fourth small, exploratory experiment suggested that the image information learned was similar across subjects. together, these results prove the principle that dl methodologies can be used to train nonprofessional subjects to reliably perform those aspects of medical image perception tasks that depend on visual pattern recognition expertise.","['detect diagnostic visual patterns', 'train naïve', 'principle study', 'nonprofessional observers', 'deep learning', 'certain cancers', 'used', 'proof', 'mammograms']"
"correlation of pathology reports with radiology examinations has long been of interest to radiologists and helps to facilitate peer learning. such correlation also helps meet regulatory requirements, ensures quality, and supports multidisciplinary conferences and patient care. additional offshoots of such correlation include evaluating for and ensuring concordance of pathology results with radiology interpretation and procedures as well as ensuring specimen adequacy after biopsy. for much of the history of radiology, this correlation has been done manually, which is time consuming and cumbersome and provides coverage of only a fraction of radiology examinations performed. electronic storage and indexing of radiology and pathology information laid the foundation for easier access and for the development of automated artificial intelligence methods to match pathology information with radiology reports. more recent techniques have resulted in near comprehensive coverage of radiology examinations with methods to present results and solicit feedback from end users. newer deep learning language modeling techniques will advance these methods by providing more robust automated and comprehensive radiology-pathology correlation with the ability to rapidly, flexibly, and iteratively tune models to site and user preference.","['overview including recent artificial intelligence methods', 'facilitate peer learning', 'pathology correlation', 'radiology']"
"accurate and reliable fault diagnosis for rotating machinery, especially under variable working conditions remains a great challenge. existing deep learning methods which extract features from single domain are insufficient to ensure reliable diagnosis results. in this study, a new deep learning based fault diagnosis method, which extracts features from both time and frequency domains is proposed. two sets of deep features from multiple domains are fused into intrinsic low-dimensional features by local and global principle component analysis. and a new ensemble kernel extreme learning machine is proposed for fault pattern classification based on the fused features. extensive experiments on gearbox, rotor and engine rolling bearing show that the proposed method has better diagnosis performance than state-of-the-art methods and is more adaptable to the fluctuation of working conditions.","['ensemble kernel extreme learning machine based', 'rotating machinery', 'fused multi', 'fault diagnosis', 'domain features']"
"due to both the hidden nature and the irreversibility of alzheimers disease (ad), it has become the killer of the elderly and is thus the focus of much attention in the medical field. radiologists compare the predicted brain age with the ground truth in order to provide a preliminary analysis of ad, which helps doctors diagnose ad as early in its development as possible. in this paper, a transfer learning-based method of predicting brain age using mr images and dataset of a public brain was proposed. in order to get the best transfer results, we froze different layers and only fine-tuned the remaining layers. we used three planes of brain mr images together to predict age for the first time and experiment results showed that the proposed method performs better than the state-of-the-art method under mean absolute error metric by 0.6 years. in addition, to explore the relationship between brain mr images of different planes and predicted age accuracy, we used three different planes of brain mr images to predict age respectively for the first time and found that sagittal plane mr images outperformed two other planes in age estimation. finally, our research identified, the effective regions that contribute to brain age estimation for cognitively normal individuals and for ad patients with deep learning. for ad patients, the effective region is mainly concentrated in the frontal lobe of the brain, verifying the relevant medical conclusions about ad.","['brain age estimation', 'weighted images', 'transfer learning', 't1']"
"this study aimed to design an optimal emotion recognition method using multiple physiological signal parameters acquired by bio-signal sensors for improving the accuracy of classifying individual emotional responses. multiple physiological signals such as respiration (rsp) and heart rate variability (hrv) were acquired in an experiment from 53 participants when six basic emotion states were induced. two rsp parameters were acquired from a chest-band respiration sensor, and five hrv parameters were acquired from a finger-clip blood volume pulse (bvp) sensor. a newly designed deep-learning model based on a convolutional neural network (cnn) was adopted for detecting the identification accuracy of individual emotions. additionally, the signal combination of the acquired parameters was proposed to obtain high classification accuracy. furthermore, a dominant factor influencing the accuracy was found by comparing the relativeness of the parameters, providing a basis for supporting the results of emotion classification. the users of this proposed model will soon be able to improve the emotion recognition model further based on cnn using multimodal physiological signals and their sensors.","['optimal six basic emotion classification using multiple physiological signals', 'cnn architectures', 'design']"
"staging third molar development is commonly used for age estimation in subadults. automated developmental stage allocation to the mandibular left third molar in panoramic radiographs has been examined in a pilot study. this method used an alexnet deep convolutional neural network (cnn) approach to stage lower left third molars, which had been selected by manually drawn bounding boxes around them. this method (bounding box alexnet\xa0=\xa0ba) still contained parts of surrounding structures which may have affected the automated stage allocation performance. we hypothesize that segmenting only the third molar could further improve the automated stage allocation performance. therefore, the current study aimed to determine and validate the effect of lower third molar segmentations on automated tooth development staging. retrospectively, 400 panoramic radiographs were collected, processed and segmented in three ways: bounding box (bb), rough (rs), and full (fs) tooth segmentation. a densenet201 cnn was used for automated stage allocation. automated staging results were compared with reference stages - allocated by human observers - overall and per stage. fs rendered the best results with a stage allocation accuracy of 0.61, a mean absolute difference of 0.53 stages and a cohen's linear κ of 0.84. misallocated stages were mostly neighboring stages, and densenet201 rendered better results than alexnet by increasing the percentage of correctly allocated stages by 3% (ba compared to bb). fs increased the percentage of correctly allocated stages by 7% compared to bb. in conclusion, full tooth segmentation and a densenet cnn optimize automated dental stage allocation for age estimation.","['automated tooth development staging using', 'lower third molar segmentations', 'convolutional neural network', 'effect']"
"single-channel, speaker-independent speech separation methods have recently seen great progress. however, the accuracy, latency, and computational cost of such methods remain insufficient. the majority of the previous methods have formulated the separation problem through the time-frequency representation of the mixed signal, which has several drawbacks, including the decoupling of the phase and magnitude of the signal, the suboptimality of time-frequency representation for speech separation, and the long latency of the entire system. to address these shortcomings, we propose a fully-convolutional time-domain audio separation network (conv-tasnet), a deep learning framework for end-to-end time-domain speech separation. conv-tasnet uses a linear encoder to generate a representation of the speech waveform optimized for separating individual speakers. speaker separation is achieved by applying a set of weighting functions (masks) to the encoder output. the modified encoder representations are then inverted back to the waveforms using a linear decoder. the masks are found using a temporal convolutional network (tcn) consisting of stacked 1-d dilated convolutional blocks, which allows the network to model the long-term dependencies of the speech signal while maintaining a small model size. the proposed conv-tasnet system significantly outperforms previous time-frequency masking methods in separating two- and three-speaker mixtures. additionally, conv-tasnet surpasses several ideal time-frequency magnitude masks in two-speaker speech separation as evaluated by both objective distortion measures and subjective quality assessment by human listeners. finally, conv-tasnet has a significantly smaller model size and a much shorter minimum latency, making it a suitable solution for both offline and real-time speech separation applications. this study therefore represents a major step toward the realization of speech separation systems for real-world speech processing technologies.","['surpassing ideal time', 'frequency magnitude masking', 'speech separation', 'tasnet', 'conv']"
"computing equilibrium states in condensed-matter many-body systems, such as solvated proteins, is a long-standing challenge. lacking methods for generating statistically independent equilibrium samples in ""one shot,"" vast computational effort is invested for simulating these systems in small steps, e.g., using molecular dynamics. combining deep learning and statistical mechanics, we developed boltzmann generators, which are shown to generate unbiased one-shot equilibrium samples of representative condensed-matter systems and proteins. boltzmann generators use neural networks to learn a coordinate transformation of the complex configurational equilibrium distribution to a distribution that can be easily sampled. accurate computation of free-energy differences and discovery of new configurations are demonstrated, providing a statistical mechanics tool that can avoid rare events during sampling without prior knowledge of reaction coordinates.","['sampling equilibrium states', 'deep learning', 'boltzmann generators', 'body systems', 'many']"
"with the development of the smart manufacturing, data-driven fault diagnosis has receiving more and more attentions from both academic and engineering fields. as one of the most important data-driven fault diagnosis method, deep learning (dl) has achieved remarkable applications. however, the dl based fault diagnosis methods still have the following two drawbacks: 1) one of the most major branch of deep learning is to construct the deeper structures, however the deep learning models in fault diagnosis is very shadow. 2) as stated by the no-free-lunch theorem, no single model can perform best on every dataset, and the individual deep learning model still suffers from the generalization ability. in this research, a new negative correlation ensemble transfer learning method (ncte) is proposed. firstly, the transfer learning based resnet-50 is proposed to construct a deep learning structure that has 50 layers. secondly, several fully-connected layers and softmax classifiers are trained cooperatively using negative correlation learning (ncl). thirdly, the hyper-parameters of the proposed ncte are determined by cross validation. the proposed ncte is conducted on the kat bearing dataset, and the prediction accuracy of ncte is as high as 98.73%. this results show that ncte has achieved a good results compared with other machine learning and deep learning method.","['negative correlation ensemble transfer learning method', 'fault diagnosis based', 'convolutional neural network']"
"recent years have witnessed significant progress in understanding how memories are encoded, from the molecular to the cellular and the circuit/systems levels. with a good compromise between brain complexity and behavioral sophistication, the fruit fly drosophila melanogaster is one of the preeminent animal models of learning and memory. here we review how memories are encoded in drosophila, with a focus on short-term memory and an eye toward future directions. forward genetic screens have revealed a large number of genes and transcripts necessary for learning and memory, some acting cell-autonomously. further, the relative numerical simplicity of the fly brain has enabled the reverse engineering of learning circuits with remarkable precision, in some cases ascribing behavioral phenotypes to single neurons. functional imaging and physiological studies have localized and parsed the plasticity that occurs during learning at some of the major loci. connectomics projects are significantly expanding anatomical knowledge of the nervous system, filling out the roadmap for ongoing functional/physiological and behavioral studies, which are being accelerated by simultaneous tool development. these developments have provided unprecedented insight into the fundamental neural principles of learning, and lay the groundwork for deep understanding in the near future.","['olfactory associative learning', 'circuit mechanisms', 'drosophila', 'cellular']"
"recently, deep neural network-powered quantitative susceptibility mapping (qsm), qsmnet, successfully performed ill-conditioned dipole inversion in qsm and generated high-quality susceptibility maps. in this paper, the network, which was trained by healthy volunteer data, is evaluated for hemorrhagic lesions that have substantially higher susceptibility than healthy tissues in order to test ""linearity"" of qsmnet for susceptibility. the results show that qsmnet underestimates susceptibility in hemorrhagic lesions, revealing degraded linearity of the network for the untrained susceptibility range. to overcome this limitation, a data augmentation method is proposed to generalize the network for a wider range of susceptibility. the newly trained network, which is referred to as qsmnet+, is assessed in computer-simulated lesions with an extended susceptibility range (-1.4\xa0\u200bppm to +1.4\xa0\u200bppm) and also in twelve hemorrhagic patients. the simulation results demonstrate improved linearity of qsmnet+ over qsmnet (root mean square error of qsmnet+: 0.04\xa0\u200bppm vs. qsmnet: 0.36\xa0\u200bppm). when applied to patient data, qsmnet+ maps show less noticeable artifacts to those of conventional qsm maps. moreover, the susceptibility values of qsmnet+ in hemorrhagic lesions are better matched to those of the conventional qsm method than those of qsmnet when analyzed using linear regression (qsmnet+: slope\xa0\u200b=\xa0\u200b1.05, intercept\xa0\u200b=\xa0\u200b-0.03, r2\xa0\u200b=\xa0\u200b0.93; qsmnet: slope\xa0\u200b=\xa0\u200b0.68, intercept\xa0\u200b=\xa0\u200b0.06, r2\xa0\u200b=\xa0\u200b0.86), consolidating improved linearity in qsmnet+. this study demonstrates the importance of the trained data range in deep neural network-powered parametric mapping and suggests the data augmentation approach for generalization of network. the new network can be applicable for a wide range of susceptibility quantification.","['deep neural network trained qsm', 'exploring linearity', 'qsmnet']"
"the exponential growth in population and their overall reliance on the usage of electrical and electronic devices have increased the demand for energy production. it needs precise energy management systems that can forecast the usage of the consumers for future policymaking. embedded smart sensors attached to electricity meters and home appliances enable power suppliers to effectively analyze the energy usage to generate and distribute electricity into residential areas based on their level of energy consumption. therefore, this paper proposes a clustering-based analysis of energy consumption to categorize the consumers' electricity usage into different levels. first, a deep autoencoder that transfers the low-dimensional energy consumption data to high-level representations was trained. second, the high-level representations were fed into an adaptive self-organizing map (som) clustering algorithm. afterward, the levels of electricity energy consumption were established by conducting the statistical analysis on the obtained clustered data. finally, the results were visualized in graphs and calendar views, and the predicted levels of energy consumption were plotted over the city map, providing a compact overview to the providers for energy utilization analysis.",['deep learning assisted buildings energy consumption profiling using smart meter data']
"adversarial networks were developed to complete powerful image-processing tasks on the basis of example images provided to train the networks. these networks are relatively new in the field of deep learning and have proved to have unique strengths that can potentially benefit radiology. specifically, adversarial networks have the potential to decrease radiation exposure to patients through minimizing repeat imaging due to artifact, decreasing acquisition time, and generating higher quality images from low-dose or no-dose studies. the authors provide an overview of a specific type of adversarial network called a ""generalized adversarial network"" and review its uses in current medical imaging research.","['generative adversarial networks', 'radiation reduction', 'medical imaging', 'artifact correction', 'role']"
"we present a joint model based on deep learning that is designed to inpaint the missing-wedge sinogram of electron tomography and reduce the residual artifacts in the reconstructed tomograms. traditional methods, such as weighted back projection (wbp) and simultaneous algebraic reconstruction technique (sart), lack the ability to recover the unacquired project information as a result of the limited tilt range; consequently, the tomograms reconstructed using these methods are distorted and contaminated with the elongation, streaking, and ghost tail artifacts. to tackle this problem, we first design a sinogram filling model based on the use of residual-in-residual dense blocks in a generative adversarial network (gan). then, we use a u-net structured generative adversarial network to reduce the residual artifacts. we build a two-step model to perform information recovery and artifacts removal in their respective suitable domain. compared with the traditional methods, our method offers superior peak signal to noise ratio (psnr) and the structural similarity index (ssim) to wbp and sart; even with a missing wedge of 45°, our method offers reconstructed images that closely resemble the ground truth with nearly no artifacts. in addition, our model has the advantage of not needing inputs from human operators or setting hyperparameters such as iteration steps and relaxation coefficient used in tv-based methods, which highly relies on human experience and parameter fine turning.","['joint deep learning model', 'wedge sinograms', 'reduce artifacts', 'recover information', 'electron tomography', 'missing', 'beyond']"
"dicom header information is frequently used to classify medical image types; however, if a header is missing fields or contains incorrect data, the utility is limited. to expedite image classification, we trained convolutional neural networks (cnns) in two classification tasks for thoracic radiographic views obtained from dual-energy studies: (a)\xa0distinguishing between frontal, lateral, soft tissue, and bone images and (b)\xa0distinguishing between posteroanterior (pa) or anteroposterior (ap) chest radiographs. cnns with alexnet architecture were trained from scratch. 1910 manually classified radiographs were used for training the network to accomplish task (a), then tested with an independent test set (3757 images). frontal radiographs from the two datasets were combined to train a network to accomplish task (b); tested using an independent test set of 1000 radiographs. roc analysis was performed for each trained cnn with area under the curve (auc) as a performance metric. classification between frontal images (ap/pa) and other image types yielded an auc of 0.997 [95% confidence interval (ci): 0.996, 0.99","['ap radiographs resulted', 'pa', 'lassification', 'ci', 'auc', '98', '973', '961', '95', '0']"
"rice lodging severely affects harvest yield. traditional evaluation methods and manual on-site measurement are found to be time-consuming, labor-intensive, and cost-intensive. in this study, a new method for rice lodging assessment based on a deep learning unet (u-shaped network) architecture was proposed. the uav (unmanned aerial vehicle) equipped with a high-resolution digital camera and a three-band multispectral camera synchronously was used to collect lodged and non-lodged rice images at an altitude of 100 m. after splicing and cropping the original images, the datasets with the lodged and non-lodged rice image samples were established by augmenting for building a unet model. the research results showed that the dice coefficients in rgb (red, green and blue) image and multispectral image test set were 0.9442 and 0.9284, respectively. the rice lodging recognition effect using the rgb images without feature extraction is better than that of multispectral images. the findings of this study are useful for rice lodging investigations by different optical sensors, which can provide an important method for large-area, high-efficiency, and low-cost rice lodging monitoring research.","['unmanned aerial vehicle imagery', 'extract rice lodging', 'deep learning unet', 'use']"
"diabetes is a global eye health issue. given the rising in diabetes prevalence and ageing population, this poses significant challenge to perform diabetic retinopathy (dr) screening for these patients. artificial intelligence (ai) using machine learning and deep learning have been adopted by various groups to develop automated dr detection algorithms. this article aims to describe the state-of-art ai dr screening technologies that have been described in the literature, some of which are already commercially available. all these technologies were designed using different training datasets and technical methodologies. although many groups have published robust diagnostic performance of the ai algorithms for dr screening, future research is required to address several challenges, for examples medicolegal implications, ethics, and clinical deployment model in order to expedite the translation of these novel technologies into the healthcare setting.","['diabetic retinopathy screening', 'artificial intelligence', 'review']"
"image-based deep learning systems, such as convolutional neural networks (cnns), have recently been applied to cell classification, producing impressive results; however, application of cnns has been confined to classification of the current cell state from the image. here, we focused on cell movement where current and/or past cell shape can influence the future cell movement. we demonstrate that cnns prospectively predicted the future direction of cell movement with high accuracy from a single image patch of a cell at a certain time. furthermore, by visualizing the image features that were learned by the cnns, we could identify morphological features, e.g., the protrusions and trailing edge that have been experimentally reported to determine the direction of cell movement. our results indicate that cnns have the potential to predict the future direction of cell movement from current cell shape, and can be used to automatically identify those morphological features that influence future cell movement.","['convolutional neural networks', 'future direction', 'cell movement', 'predicting']"
"the incidence of pathological gambling in parkinson's patients is significantly greater than in the general population. a correlation has been observed between dopamine agonist medication and the development of pathological gambling. however, scientists conjecture that the affected patients have underlying risk factors. studies analysing parkinson's patients have detected that patients who developed pathological gambling are younger, score higher on novelty-seeking tests, are more impulsive and are more likely to have a personal or family history of alcohol addiction. in addition, some genetic variations have been associated with the susceptibility of developing pathological gambling, which include mutations of drd3, 5-httlpr and grin2b. studies focusing on neurofunctional discrepancies between parkinson's patients with and without pathological gambling have found increased functional activation and dopamine release in regions associated with the mesolimbic reward system. furthermore, there is also evidence showing increased processing of reward and decreased activation elicited by punishment, suggesting altered learning processes. furthermore, the role of deep brain stimulation of the nucleus subthalamicus (stn dbs) is controversial. in most parkinson's patients, pathological gambling resolved after the initiation of the stn dbs, which might be explained by discontinuation or decrease in dopamine agonist medication. however, it has been also shown that some patients are more impulsive while the stn dbs is activated. these differences may depend on the dbs localization in the more limbic or motor part of the stn and their regulative effects on impulsivity. further research is needed to clarify susceptibility factors for the development of pathological gambling in parkinson's patients.","['risk factors', 'pathological gambling', 'role', 'parkinson', 'impulsivity', 'disease']"
the objective of this study is to assess the performance of a computer-aided diagnosis (cad) system (intact system) for the automatic classification of high-resolution computed tomography images into 4 radiological diagnostic categories and to compare this with the performance of radiologists on the same task.,"['pulmonary fibrosis using deep learning', 'ct images', 'aided diagnosis', 'computer']"
"ultrasound is the most commonly used imaging modality in clinical practice because it is a nonionizing, low-cost, and portable point-of-care imaging tool that provides real-time images. artificial intelligence (ai)-powered ultrasound is becoming more mature and getting closer to routine clinical applications in recent times because of an increased need for efficient and objective acquisition and evaluation of ultrasound images. because ultrasound images involve operator-, patient-, and scanner-dependent variations, the adaptation of classical machine learning methods to clinical applications becomes challenging. with their self-learning ability, deep-learning (dl) methods are able to harness exponentially growing graphics processing unit computing power to identify abstract and complex imaging features. this\xa0has given rise to tremendous opportunities such as providing robust and generalizable ai models for improving image acquisition, real-time assessment of image quality, objective diagnosis and detection of diseases, and optimizing ultrasound clinical workflow. in this report, the authors review current dl approaches and research directions in rapidly advancing ultrasound technology and present their outlook on future directions and trends for dl techniques to further improve diagnosis, reduce health care cost, and optimize ultrasound clinical workflow.","['improving clinical workflow', 'learning applications', 'artificial intelligence', 'powered ultrasound', 'ultrasound', 'survey', 'deep']"
"more than 8,000 genes are turned on or off as progenitor cells produce the 7 classes of retinal cell types during development. thousands of enhancers are also active in the developing retinae, many having features of cell- and developmental stage-specific activity. we studied dynamic changes in the 3d chromatin landscape important for precisely orchestrated changes in gene expression during retinal development by ultra-deep in situ hi-c analysis on murine retinae. we identified developmental-stage-specific changes in chromatin compartments and enhancer-promoter interactions. we developed a machine learning-based algorithm to map euchromatin and heterochromatin domains genome-wide and overlaid it with chromatin compartments identified by hi-c. single-cell atac-seq and rna-seq were integrated with our hi-c and previous chip-seq data to identify cell- and developmental-stage-specific super-enhancers (ses). we identified a bipolar neuron-specific core regulatory circuit se upstream of vsx2, whose deletion in mice led to the loss of bipolar neurons.","['retinal development', 'nucleome dynamics']"
"nuclear magnetic resonance (nmr) spectroscopy serves as an indispensable tool in chemistry and biology but often suffers from long experimental times. we present a proof-of-concept of the application of deep learning and neural networks for high-quality, reliable, and very fast nmr spectra reconstruction from limited experimental data. we show that the neural network training can be achieved using solely synthetic nmr signals, which lifts the prohibiting demand for a large volume of realistic training data usually required for a deep learning approach.","['accelerated nuclear magnetic resonance spectroscopy', 'deep learning']"
"manual delineation of clinical target volumes (ctvs) and organs at risk (oars) is time-consuming, and automatic contouring tools lack clinical validation. we aimed to construct and validate the use of convolutional neural networks (cnns) to set better contouring standards for rectal cancer radiotherapy.","['rectal cancer postoperative radiotherapy', 'clinical target volume', 'deep learning', 'automatic delineation', 'risk', 'organs']"
"convolutional neural networks (cnns) have become one of the state-of-the-art methods for various computer vision and pattern recognition tasks including facial affective computing. although impressive results have been obtained in facial affective computing using cnns, the computational complexity of cnns has also increased significantly. this means high performance hardware is typically indispensable. most existing cnns are thus not generalizable enough for mobile devices, where the storage, memory and computational power are limited. in this paper, we focus on the design and implementation of cnns on mobile devices for real-time facial affective computing tasks. we propose a light-weight cnn architecture which well balances the performance and computational complexity. the experimental results show that the proposed architecture achieves high performance while retaining the low computational complexity compared with state-of-the-art methods. we demonstrate the feasibility of a cnn architecture in terms of speed, memory and storage consumption for mobile devices by implementing a real-time facial affective computing application on an actual mobile device.","['time facial affective computing', 'mobile devices', 'real']"
"identified genetic variants from genome wide association studies frequently show only modest effects on the disease risk, leading to the ""missing heritability"" problem. an avenue, to account for a part of this ""missingness"" is to evaluate gene-gene interactions (epistasis) thereby elucidating their effect on complex diseases. this can potentially help with identifying gene functions, pathways, and drug targets. however, the exhaustive evaluation of all possible genetic interactions among millions of single nucleotide polymorphisms (snps) raises several issues, otherwise known as the ""curse of dimensionality"". the dimensionality involved in the epistatic analysis of such exponentially growing snps diminishes the usefulness of traditional, parametric statistical methods. with the immense popularity of multifactor dimensionality reduction (mdr), a non-parametric method, proposed in 2001, that classifies multi-dimensional genotypes into one- dimensional binary approaches, led to the emergence of a fast-growing collection of methods that were based on the mdr approach. moreover, machine-learning (ml) methods such as random forests and neural networks (nns), deep-learning (dl) approaches, and hybrid approaches have also been applied profusely, in the recent years, to tackle this dimensionality issue associated with whole genome gene-gene interaction studies. however, exhaustive searching in mdr based approaches or variable selection in ml methods, still pose the risk of missing out on relevant snps. furthermore, interpretability issues are a major hindrance for dl methods. to minimize this loss of information, python based tools such as pyspark can potentially take advantage of distributed computing resources in the cloud, to bring back smaller subsets of data for further local analysis. parallel computing can be a powerful resource that stands to fight this ""curse"". pyspark supports all standard python libraries and c extensions thus making it convenient to write codes to deliver dramatic improvements in processing speed for extraordinarily large sets of data.","['gene interaction', 'gene', 'dimensionality', 'curse']"
"annotation of surgical videos is a time-consuming task which requires specific knowledge. in this paper, we present and evaluate a deep learning-based method that includes pre-annotation of the phases and steps in surgical videos and user assistance in the annotation process.","['surgical videos', 'step annotation', 'assisted phase']"
"a 73-year-old man was admitted with sudden onset of dyspnea. contrast-enhanced computed tomography showed acute pulmonary thromboembolism and deep vein thrombosis. he was started on the direct oral anticoagulant rivaroxaban (factor xa inhibitor) and this resolved the thrombus. serological analysis revealed that his risk of thrombosis was primary antiphospholipid syndrome (aps). he has remained free of recurrent venous thromboembolism (vte) for two years while under rivaroxaban. we present a case with vte due to aps for whom direct oral anticoagulant was effective. <learning objective: direct oral anticoagulants (doac) have become agents of first choice in the treatment of acute to chronic period pulmonary thromboembolism for most patients. however, the effects of doac on acute pulmonary thromboembolism (apte) in patients with antiphospholipid syndrome (aps) remain obscure. the standard treatment for thrombotic aps is initial anticoagulation with unfractionated heparin or a low-molecular-weight heparin followed by warfarin. doac may be useful for some apte patients with aps.>.","['primary antiphospholipid antibody syndrome', 'acute pulmonary thromboembolism', 'successful treatment', 'rivaroxaban', 'patient']"
"predicting rna-binding protein (rbp) specificity is important for understanding gene expression regulation and rna-mediated enzymatic processes. it is widely believed that rbp binding specificity is determined by both the sequence and structural contexts of rnas. existing approaches, including traditional machine learning algorithms and more recently, deep learning models, have been extensively applied to integrate rna sequence and its predicted or experimental rna structural probabilities for improving the accuracy of rbp binding prediction. such models were trained mostly on the large-scale in vitro datasets, such as the rnacompete dataset. however, in rnacompete, most synthetic rnas are unstructured, which makes machine learning methods not effectively extract rbp-binding structural preferences. furthermore, rna structure may be variable or multi-modal according to both theoretical and experimental evidence. in this work, we propose thermonet, a thermodynamic prediction model by integrating a new sequence-embedding convolutional neural network model over a thermodynamic ensemble of rna secondary structures. first, the sequence-embedding convolutional neural network generalizes the existing k-mer based methods by jointly learning convolutional filters and k-mer embeddings to represent rna sequence contexts. second, the thermodynamic average of deep-learning predictions is able to explore structural variability and improves the prediction, especially for the structured rnas. extensive experiments demonstrate that our method significantly outperforms existing approaches, including rck, deepbind and several other recent state-of-the-art methods for predictions on both in vitro and in vivo data. the implementation of thermonet is available at https://github.com/suyufeng/thermonet.","['sequence contexts improves protein', 'rna binding prediction', 'integrating thermodynamic']"
"monitoring the activity of elderly individuals in nursing homes is key, as it has been shown that physical activity leads to significant health improvement. in this work, we introduce nursenet, a system that combines an unobtrusive, affordable, and robust piezoelectric floor sensor with a convolutional neural network algorithm, which aims at measuring elderly physical activity. our algorithm is trained using signal embedding based on atoms of a pre-learned dictionary and focuses the network's attention on step-related signals. we show that nursenet is able to avoid the main limitation of floor sensors by recognizing relevant signals (i.e., signals produced by patients) and ignoring events related to the medical staff, offering a new tool to monitor elderly activity in nursing homes efficiently.","['monitoring elderly levels', 'piezoelectric floor', 'nursenet', 'activity']"
"uncontrolled proliferation is a hallmark of cancer and can be assessed by labelling breast tissue using immunohistochemistry for ki67, a protein associated with cell proliferation. accurate measurement of ki67-positive tumour nuclei is of critical importance, but requires annotation of the tumour regions by a pathologist. this manual annotation process is highly subjective, time-consuming and subject to inter- and intra-annotator experience. to address this challenge, we have developed proliferation tumour marker network (ptm-net), a deep learning model that objectively annotates the tumour regions in ki67-labelled breast cancer digital pathology images using a convolution neural network. our custom designed deep learning model was trained on 45 immunohistochemical ki67-labelled whole slide images to classify tumour and non-tumour regions and was validated on 45 whole slide images from two different sources that were stained using different protocols. our results show a dice coefficient of 0.74, positive predictive value of 70% and negative predictive value of 88.3% against the manual ground truth annotation for the combined dataset. there were minimal differences between the images from different sources and the model was further tested in oestrogen receptor and progesterone receptor-labelled images. finally, using an extension of the model, we could identify possible hotspot regions of high proliferation within the tumour. in the future, this approach could be useful in identifying tumour regions in biopsy samples and tissue microarray images.","['proliferation tumour marker network', 'ptm', 'ne']"
"neural networks enjoy widespread success in both research and industry and, with the advent of quantum technology, it is a crucial challenge to design quantum neural networks for fully quantum learning tasks. here we propose a truly quantum analogue of classical neurons, which form quantum feedforward neural networks capable of universal quantum computation. we describe the efficient training of these networks using the fidelity as a cost function, providing both classical and efficient quantum implementations. our method allows for fast optimisation with reduced memory requirements: the number of qudits required scales with only the width, allowing deep-network optimisation. we benchmark our proposal for the quantum task of learning an unknown unitary and find remarkable generalisation behaviour and a striking robustness to noisy training data.",['training deep quantum neural networks']
"g protein-coupled receptors (gpcrs) are one of the most important drug targets, accounting for ∼34% of drugs on the market. for drug discovery, accurate modeling and explanation of bioactivities of ligands is critical for the screening and optimization of hit compounds. homologous gpcrs are more likely to interact with chemically similar ligands, and they tend to share common binding modes with ligand molecules. the inclusion of homologous gpcrs in learning bioactivities of ligands potentially enhances the accuracy and interpretability of models due to utilizing increased training sample size and the existence of common ligand substructures that control bioactivities. accurate modeling and interpretation of bioactivities of ligands by combining homologous gpcrs can be formulated as multitask learning with joint feature learning problem and naturally matched with the group lasso learning algorithm. thus, we proposed a multitask regression learning with group lasso (mtr-gl) implemented by l2,1-norm regularization to model bioactivities of ligand molecules and then tested the algorithm on a series of thirty-five representative gpcrs datasets that cover nine subfamilies of human gpcrs. the results show that mtr-gl is overall superior to single-task learning methods and classic multitask learning with joint feature learning methods. moreover, mtr-gl achieves better performance than state-of-the-art deep multitask learning based methods of predicting ligand bioactivities on most datasets (31/35), where mtr-gl obtained an average improvement of 38% on correlation coefficient (r2) and 29% on root-mean-square error over the deepneuralnet-qsar predictors.","['homologous g protein', 'coupled receptors boost', 'ligand molecules', 'modeling', 'interpretation', 'bioactivities']"
"the conformation of a protein largely depends on the interactions between peptides. specific and intrinsic sequence peptide patterns, such as dna double helix backbones, may be present in proteins. a computational statistical deep learning method has supported this assumption, but it has not been experimentally proven. mass spectrometry, as a fast and accurate experimental method, could be used to evaluate the interaction of biomolecules. the results would be of great value for further study of the mechanism of protein folding.","['potential intrinsic sequence patterns', 'noncovalent interactions', 'mass spectrometry', 'peptides', 'investigation']"
"spatiotemporal problems are ubiquitous and of vital importance in many research fields. despite the potential already demonstrated by deep learning methods in modeling spatiotemporal data, typical approaches tend to focus solely on conditional expectations of the output variables being modeled. in this article, we propose a multioutput multiquantile deep learning approach for jointly modeling several conditional quantiles together with the conditional expectation as a way to provide a more complete ``picture'' of the predictive density in spatiotemporal problems. using two large-scale data sets from the transportation domain, we empirically demonstrate that, by approaching the quantile regression problem from a multitask learning perspective, it is possible to solve the embarrassing quantile crossings problem while simultaneously significantly outperforming state-of-the-art quantile regression methods. moreover, we show that jointly modeling the mean and several conditional quantiles not only provides a rich description about the predictive density that can capture heteroscedastic properties at a neglectable computational overhead but also leads to improved predictions of the conditional expectation due to the extra information and the regularization effect induced by the added quantiles.","['deep joint mean', 'spatiotemporal problems', 'quantile regression', 'beyond expectation']"
"segmentation of organs from chest x-ray images is an essential task for an accurate and reliable diagnosis of lung diseases and chest organ morphometry. in this study, we investigated the benefits of augmenting state-of-the-art deep convolutional neural networks (cnns) for image segmentation with organ contour information and evaluated the performance of such augmentation on segmentation of lung fields, heart, and clavicles from chest x-ray images.","['ray organ segmentation', 'label chest x', 'aware multi', 'contour']"
"precisely labeling teeth on digitalized 3d dental surface models is the precondition for tooth position rearrangements in orthodontic treatment planning. however, it is a challenging task primarily due to the abnormal and varying appearance of patients' teeth. the emerging utilization of intraoral scanners (ioss) in clinics further increases the difficulty in automated tooth labeling, as the raw surfaces acquired by ios are typically low-quality at gingival and deep intraoral regions. in recent years, some pioneering end-to-end methods (e.g., pointnet) have been proposed in the communities of computer vision and graphics to consume directly raw surface for 3d shape segmentation. although these methods are potentially applicable to our task, most of them fail to capture fine-grained local geometric context that is critical to the identification of small teeth with varying shapes and appearances. in this paper, we propose an end-to-end deep-learning method, called meshsegnet, for automated tooth labeling on raw dental surfaces. using multiple raw surface attributes as inputs, meshsegnet integrates a series of graph-constrained learning modules along its forward path to hierarchically extract multi-scale local contextual features. then, a dense fusion strategy is applied to combine local-to-global geometric features for the learning of higher-level features for mesh cell annotation. the predictions produced by our meshsegnet are further post-processed by a graph-cut refinement step for final segmentation. we evaluated meshsegnet using a real-patient dataset consisting of raw maxillary surfaces acquired by 3d ios. experimental results, performed 5-fold cross-validation, demonstrate that meshsegnet significantly outperforms state-of-the-art deep learning methods for 3d shape segmentation.","['scale mesh feature learning', 'raw dental surfaces', '3d intraoral scanners', 'deep multi', 'automated labeling']"
"this chapter proposes a method to detect metastatic liver cancer from x-ray ct images using a convolutional neural network (cnn). the proposed method generates various lesion images by the combination of three kinds of generation methods: (1) synthesis using poisson blending, (2) generation based on ct value distributions, and (3) generation using deep convolutional generative adversarial networks (dcgans). the proposed method constructs two kinds of detectors by using synthetic (fake) lesion images generated by the methods as well as real ones. one of the detectors is a 2d cnn for detecting candidate regions in a ct image, and the other is a 3d cnn for validating the candidate regions. experimental results showed that the proposed method gave 0.30 improvement from 0.65 to 0.95 in terms of the detection rate, and 0.70 improvement from 0.90 to 0.20 in terms of the number of false detections per case. from the results, we confirmed the effectiveness of the proposed method.","['lesion image synthesis using dcgans', 'metastatic liver cancer detection']"
generative adversarial networks (gans) are deep learning models aimed at generating fake realistic looking images. these novel models made a great impact on the computer vision field. our study aims to review the literature on gans applications in radiology.,"['radiology applications using generative adversarial networks', 'creating artificial images', 'gan']"
"at medical checkups or mass screenings, the fundus examination is effective for early detection of systemic hypertension, arteriosclerosis, diabetic retinopathy, etc. in most cases, ophthalmologists and physicians grade retinal images by the condition of the blood vessels, lesions. however, human observation does not provide quantitative results, thus blood vessel analysis is an important process in determining hypertension and arteriosclerosis, quantitatively. this chapter describes the latest automated blood vessel extraction using the deep convolution neural network (dcnn). diabetic retinopathy is a common cardiovascular disease and a major factor in blindness. therefore, early detection of diabetic retinopathy is very important to preventing blindness. a microaneurysm is an initial sign of diabetic retinopathy, and much research has been conducted for microaneurysm detection. this chapter also describes diabetic retinopathy detection and automated microaneurysm detection using the dcnn.","['deep convolution neural network', 'retinopathy analysis based']"
"radio-frequency dosimetry is an important process in assessments for human exposure safety and for compliance of related products. recently, computational human models generated from medical images have often been used for such assessment, especially to consider the inter-subject variability. however, a common procedure to develop personalized models is time consuming because it involves excessive segmentation of several components that represent different biological tissues, which is a major obstacle in the inter-subject variability assessment of radiation safety. deep learning methods have been shown to be a powerful approach for pattern recognition and signal analysis. convolutional neural networks with deep architecture are proven robust for feature extraction and image mapping in several biomedical applications. in this study, we develop a learning-based approach for fast and accurate estimation of the dielectric properties and density of tissues directly from magnetic resonance images in a single shot. the smooth distribution of the dielectric properties in head models, which is realized using a process without tissue segmentation, improves the smoothness of the specific absorption rate (sar) distribution compared with that in the commonly used procedure. the estimated sar distributions, as well as that averaged over 10\u2009g of tissue in a cubic shape, are found to be highly consistent with those computed using the conventional methods that employ segmentation.","['tissue density', 'personalized radio', 'head models', 'frequency dosimetry', 'dielectric properties', 'based estimation', 'learning']"
"a novel adversarial attack methodology for fooling deep neural network classifiers in image classification tasks is proposed, along with a novel defense mechanism to counter such attacks. two concepts are introduced, namely the k-anonymity-inspired adversarial attack (k-a3) and the multiple support vector data description defense (m-svdd-d). the proposed k-a3 introduces novel optimization criteria to standard adversarial attack methodologies, inspired by the k-anonymity principles. its generated adversarial examples are not only misclassified by the neural network classifier, but are uniformly spread along k different ranked output positions. the proposed m-svdd-d consists of a deep neural architecture layer consisting of multiple non-linear one-class classifiers based on support vector data description that can be used to replace the final linear classification layer of a deep neural architecture, and an additional class verification mechanism. its application decreases the effectiveness of adversarial attacks, by increasing the noise energy required to deceive the protected model, attributed to the introduced non-linearity. in addition, m-svdd-d can be used to prevent adversarial attacks in black-box attack settings.","['anonymity inspired adversarial attack', 'class classification defense', 'multiple one', 'k']"
computer automated diagnosis of various skin lesions through medical dermoscopy images remains a challenging task.,"['multiple skin lesions diagnostics via integrated deep convolutional networks', 'segmentation', 'classification']"
"medical images have been widely used in clinics, providing visual representations of under-skin tissues in human body. by applying different imaging protocols, diverse modalities of medical images with unique characteristics of visualization can be produced. considering the cost of scanning high-quality single modality images or homogeneous multiple modalities of images, medical image synthesis methods have been extensively explored for clinical applications. among them, deep learning approaches, especially convolutional neural networks (cnns) and generative adversarial networks (gans), have rapidly become dominating for medical image synthesis in recent years. in this chapter, based on a general review of the medical image synthesis methods, we will focus on introducing typical cnns and gans models for medical image synthesis. especially, we will elaborate our recent work about low-dose to high-dose pet image synthesis, and cross-modality mr image synthesis, using these models.",['medical image synthesis via deep learning']
"the rise of neuroimaging in research and clinical practice, together with the development of new machine learning techniques has strongly encouraged the computer aided diagnosis (cad) of different diseases and disorders. however, these algorithms are often tested in proprietary datasets to which the access is limited and, therefore, a direct comparison between cad procedures is not possible. furthermore, the sample size is often small for developing accurate machine learning methods. multi-center initiatives are currently a very useful, although limited, tool in the recruitment of large populations and standardization of cad evaluation. conversely, we propose a brain image synthesis procedure intended to generate a new image set that share characteristics with an original one. our system focuses on nuclear imaging modalities such as pet or spect brain images. we analyze the dataset by applying pca to the original dataset, and then model the distribution of samples in the projected eigenbrain space using a probability density function (pdf) estimator. once the model has been built, we can generate new coordinates on the eigenbrain space belonging to the same class, which can be then projected back to the image space. the system has been evaluated on different functional neuroimaging datasets assessing the: resemblance of the synthetic images with the original ones, the differences between them, their generalization ability and the independence of the synthetic dataset with respect to the original. the synthetic images maintain the differences between groups found at the original dataset, with no significant differences when comparing them to real-world samples. furthermore, they featured a similar performance and generalization capability to that of the original dataset. these results prove that these images are suitable for standardizing the evaluation of cad pipelines, and providing data augmentation in machine learning systems -e.g. in deep learning-, or even to train future professionals at medical school.","['functional brain imaging synthesis based', 'neurodegenerative diseases', 'kernel modeling', 'image decomposition', 'application']"
"characteristic or classic phenotype of cornelia de lange syndrome (cdls) is associated with a recognisable facial pattern. however, the heterogeneity in causal genes and the presence of overlapping syndromes have made it increasingly difficult to diagnose only by clinical features. deepgestalt technology, and its app face2gene, is having a growing impact on the diagnosis and management of genetic diseases by analysing the features of affected individuals. here, we performed a phenotypic study on a cohort of 49 individuals harbouring causative variants in known cdls genes in order to evaluate face2gene utility and sensitivity in the clinical diagnosis of cdls. based on the profile images of patients, a diagnosis of cdls was within the top five predicted syndromes for 97.9% of our cases and even listed as first prediction for 83.7%. the age of patients did not seem to affect the prediction accuracy, whereas our results indicate a correlation between the clinical score and affected genes. furthermore, each gene presents a different pattern recognition that may be used to develop new neural networks with the goal of separating different genetic subtypes in cdls. overall, we conclude that computer-assisted image analysis based on deep learning could support the clinical diagnosis of cdls.","['identify cornelia de lange syndrome', 'facial phenotypes', 'evaluating face2gene', 'tool']"
"for computer-aided diagnosis (cad), detection, segmentation, and classification from medical imagery are three key components to efficiently assist physicians for accurate diagnosis. in this chapter, a completely integrated cad system based on deep learning is presented to diagnose breast lesions from digital x-ray mammograms involving detection, segmentation, and classification. to automatically detect breast lesions from mammograms, a regional deep learning approach called you-only-look-once (yolo) is used. to segment breast lesions, full resolution convolutional network (frcn), a novel segmentation model of deep network, is implemented and used. finally, three conventional deep learning models including regular feedforward cnn, resnet-50, and inceptionresnet-v2 are separately adopted and used to classify or recognize the detected and segmented breast lesion as either benign or malignant. to evaluate the integrated cad system for detection, segmentation, and classification, the publicly available and annotated inbreast database is used over fivefold cross-validation tests. the evaluation results of the yolo-based detection achieved detection accuracy of 97.27%, matthews's correlation coefficient (mcc) of 93.93%, and f1-score of 98.02%. moreover, the results of the breast lesion segmentation via frcn achieved an overall accuracy of 92.97%, mcc of 85.93%, dice (f1-score) of 92.69%, and jaccard similarity coefficient of 86.37%. the detected and segmented breast lesions are classified via cnn, resnet-50, and inceptionresnet-v2 achieving an average overall accuracies of 88.74%, 92.56%, and 95.32%, respectively. the performance evaluation results through all stages of detection, segmentation, and classification show that the integrated cad system outperforms the latest conventional deep learning methodologies. we conclude that our cad system could be used to assist radiologists over all stages of detection, segmentation, and classification for diagnosis of breast lesions.","['deep learning computer', 'digital mammogram', 'breast lesion', 'aided diagnosis']"
"as a result of the worldwide health care system digitalization trend, the produced healthcare data is estimated to reach as much as 2314 exabytes of new data generated in 2020. the ongoing development of intelligent systems aims to provide better reasoning and to more efficiently use the data collected. this use is not restricted retrospective interpretation, that is, to provide diagnostic conclusions. it can also be extended to prospective interpretation providing early prognosis. that said, physicians who could be assisted by these systems find themselves standing in the gap between clinical case and deep technical reviews. what they lack is a clear starting point from which to approach the world of machine learning in medicine.","['machine learning', 'artificial intelligence', 'service', 'potentiality', 'necessity', 'medicine']"
"image-based computer-aided diagnosis (cad) algorithms by the use of convolutional neural network (cnn) which do not require the image-feature extractor are powerful compared with conventional feature-based cad algorithms which require the image-feature extractor for classification of lung abnormalities. moreover, computer-aided detection and segmentation algorithms by the use of cnn are useful for analysis of lung abnormalities. deep learning will improve the performance of cad systems dramatically. therefore, they will change the roles of radiologists in the near future. in this article, we introduce development and evaluation of such image-based cad algorithms for various kinds of lung abnormalities such as lung nodules and diffuse lung diseases.","['pulmonary image analysis', 'deep learning', 'segmentation', 'detection', 'classification']"
"biomedical event extraction is a fundamental and in-demand technology that has attracted substantial interest from many researchers. previous works have heavily relied on manual designed features and external nlp packages in which the feature engineering is large and complex. additionally, most of the existing works use the pipeline process that breaks down a task into simple sub-tasks but ignores the interaction between them. to overcome these limitations, we propose a novel event combination strategy based on hybrid deep neural networks to settle the task in a joint end-to-end manner.","['novel combination strategy based', 'hybrid deep neural networks', 'biomedical event extraction']"
"understanding the genetic background of complex diseases and disorders plays an essential role in the promising precision medicine. the evaluation of candidate genes, however, requires time-consuming and expensive experiments given a large number of possibilities. thus, computational methods have seen increasing applications in predicting gene-disease associations. we proposed a bioinformatics framework, prioritization of autism-genes using network-based deep-learning approach (panda). our approach aims to identify autism-genes across the human genome based on patterns of gene-gene interactions and topological similarity of genes in the interaction network. panda trains a graph deep learning classifier using the input of the human molecular interaction network and predicts and ranks the probability of autism association of every node (gene) in the network. panda was able to achieve a high classification accuracy of 89%, outperforming three other commonly used machine learning algorithms. moreover, the gene prioritization ranking list produced by panda was evaluated and validated using an independent large-scale exome-sequencing study. the top 10% of panda-ranked genes were found significantly enriched for autism association.","['genes using network', 'learning approach', 'based deep', 'prioritization', 'panda', 'autism']"
"with the global climate change and the rapid urbanization process, there is an increase in the risk of urban floods. therefore, undertaking risk studies of urban floods, especially the depth prediction of urban flood is very important for urban flood control. in this study, an urban flood data warehouse was established with available structured and unstructured urban flood data. in this study, an urban flood data warehouse was established with available structured and unstructured urban flood data. based on this, a regression model to predict the depth of urban flooded areas was constructed with deep learning algorithm, named gradient boosting decision tree (gbdt). the flood condition factors used in modeling were rainfall, rainfall duration, peak rainfall, evaporation, land use (the proportion of roads, woodlands, grasslands, water bodies and building), permeability, catchment area, and slope. based on the rainfall data of different rainfall return periods, flood condition maps were produced using gis. in addition, the feature importance of these conditioning factors was determined based on the regression model. the results demonstrated that the growth rate of the number and depth of the water accumulation points increased significantly after the rainfall return period of 'once in every two years' in zhengzhou city, and the flooded areas mainly occurred in the old urban areas and parts of southern zhengzhou. the relative error of prediction results was 11.52%, which verifies the applicability and validity of the method in the depth prediction of urban floods. the results of this study can provide a scientific basis for urban flood control and drainage.","['different rainfall return periods based', 'urban flood', 'depth prediction', 'deep learning', 'data warehouse']"
"the skin is the largest organ of our body. skin disease abnormalities which occur within the skin layers are difficult to examine visually and often require biopsies to make a confirmation on a suspected condition. such invasive methods are not well-accepted by children and women due to the possibility of scarring. optical coherence tomography (oct) is a non-invasive technique enabling in vivo examination of sub-surface skin tissue without the need for excision of tissue. however, one of the challenges in oct imaging is the interpretation and analysis of oct images. in this review, we discuss the various methodologies in skin layer segmentation and how it could potentially improve the management of skin diseases. we also present a review of works which use advanced machine learning techniques to achieve layers segmentation and detection of skin diseases. lastly, current challenges in analysis and applications are also discussed.","['skin oct analysis', 'techniques', 'applications']"
"recent advances in scanning transmission electron and scanning probe microscopies have opened exciting opportunities in probing the materials structural parameters and various functional properties in real space with angstrom-level precision. this progress has been accompanied by an exponential increase in the size and quality of data sets produced by microscopic and spectroscopic experimental techniques. these developments necessitate adequate methods for extracting relevant physical and chemical information from the large data sets, for which a priori information on the structures of various atomic configurations and lattice defects is limited or absent. here we demonstrate an application of deep neural networks to extract information from atomically resolved images including location of the atomic species and type of defects. we develop a ""weakly supervised"" approach that uses information on the coordinates of all atomic species in the image, extracted via a deep neural network, to identify a rich variety of defects that are not part of an initial training set. we further apply our approach to interpret complex atomic and defect transformation, including switching between different coordination of silicon dopants in graphene as a function of time, formation of peculiar silicon dimer with mixed 3-fold and 4-fold coordination, and the motion of molecular ""rotor"". this deep learning-based approach resembles logic of a human operator, but can be scaled leading to significant shift in the way of extracting and analyzing information from raw experimental data.","['atomically resolved scanning transmission electron microscopy images', 'tracking local transformations', 'deep learning', 'chemical identification']"
"metabolism of drugs affects their absorption, distribution, efficacy, excretion, and toxicity profiles. metabolism is routinely assessed experimentally using recombinant enzymes, human liver microsome, and animal models. unfortunately, these experiments are expensive, time-consuming, and often extrapolate poorly to humans because they fail to capture the full breadth of metabolic reactions observed in vivo. as a result, metabolic pathways leading to the formation of toxic metabolites are often missed during drug development, giving rise to costly failures. to address some of these limitations, computational metabolism models can rapidly and cost-effectively predict sites of metabolism-the atoms or bonds which undergo enzymatic modifications-on thousands of drug candidates, thereby improving the likelihood of discovering metabolic transformations forming toxic metabolites. however, current computational metabolism models are often unable to predict the specific metabolites formed by metabolism at certain sites. identification of reaction type is a key step toward metabolite prediction. phase i enzymes, which are responsible for the metabolism of more than 90% of fda approved drugs, catalyze highly diverse types of reactions and produce metabolites with substantial structural variability. without knowledge of potential metabolite structures, medicinal chemists cannot differentiate harmful metabolic transformations from beneficial ones. to address this shortcoming, we propose a system for simultaneously labeling sites of metabolism and reaction types, by classifying them into five key reaction classes: stable and unstable oxidations, dehydrogenation, hydrolysis, and reduction. these classes unambiguously identify 21 types of phase i reactions, which cover 92.3% of known reactions in our database. we used this labeling system to train a neural network model of phase i metabolism on a literature-derived data set encompassing 20\u202f736 human phase i metabolic reactions. our model, rainbow xenosite, was able to identify reaction-type specific sites of metabolism with a cross-validated accuracy of 97.1% area under the receiver operator curve. rainbow xenosite with five-color and combined output is available for use free and online through our secure server at http://swami.wustl.edu/xenosite/p/phase1_rainbow.","['deep learning phase', 'metabolic rainbow', 'five colors', 'metabolism']"
"computer-assisted interventions (cai) aim to increase the effectiveness, precision and repeatability of procedures to improve surgical outcomes. the presence and motion of surgical tools is a key information input for cai surgical phase recognition algorithms. vision-based tool detection and recognition approaches are an attractive solution and can be designed to take advantage of the powerful deep learning paradigm that is rapidly advancing image recognition and classification. the challenge for such algorithms is the availability and quality of labelled data used for training. in this letter, surgical simulation is used to train tool detection and segmentation based on deep convolutional neural networks and generative adversarial networks. the authors experiment with two network architectures for image segmentation in tool classes commonly encountered during cataract surgery. a commercially-available simulator is used to create a simulated cataract dataset for training models prior to performing transfer learning on real surgical data. to the best of authors' knowledge, this is the first attempt to train deep learning models for surgical instrument detection on simulated data while demonstrating promising results to generalise on real data. results indicate that simulated data does have some potential for training advanced classification methods for cai systems.","['train detection', 'surgical simulation', 'neural networks', 'used', 'classification']"
to evaluate the ability of deep learning (dl) models to detect obstructive meibomian gland dysfunction (mgd) using in vivo laser confocal microscopy images.,"['detecting obstructive meibomian gland dysfunction', 'vivo laser confocal microscopy', 'deep neural network', 'based method']"
"this letter presents a stable polyp-scene classification method with low false positive (fp) detection. precise automated polyp detection during colonoscopies is essential for preventing colon-cancer deaths. there is, therefore, a demand for a computer-assisted diagnosis (cad) system for colonoscopies to assist colonoscopists. a high-performance cad system with spatiotemporal feature extraction via a three-dimensional convolutional neural network (3d cnn) with a limited dataset achieved about 80% detection accuracy in actual colonoscopic videos. consequently, further improvement of a 3d cnn with larger training data is feasible. however, the ratio between polyp and non-polyp scenes is quite imbalanced in a large colonoscopic video dataset. this imbalance leads to unstable polyp detection. to circumvent this, the authors propose an efficient and balanced learning technique for deep residual learning. the authors' method randomly selects a subset of non-polyp scenes whose number is the same number of still images of polyp scenes at the beginning of each epoch of learning. furthermore, they introduce post-processing for stable polyp-scene classification. this post-processing reduces the fps that occur in the practical application of polyp-scene classification. they evaluate several residual networks with a large polyp-detection dataset consisting of 1027 colonoscopic videos. in the scene-level evaluation, their proposed method achieves stable polyp-scene classification with 0.86 sensitivity and 0.97 specificity.","['scene classification via subsampling', 'imbalanced large dataset', 'stable polyp', 'residual learning']"
"in cancer, the primary tumour's organ of origin and histopathology are the strongest determinants of its clinical behaviour, but in 3% of cases a patient presents with a\xa0metastatic tumour and no obvious primary. here, as part of the icgc/tcga pan-cancer analysis of whole genomes (pcawg) consortium, we train a deep learning classifier to predict cancer type based on patterns of somatic passenger mutations detected in whole genome sequencing (wgs) of 2606 tumours representing 24 common cancer types produced by the pcawg consortium. our classifier achieves an accuracy of 91% on held-out tumor samples and 88% and 83% respectively on independent primary and metastatic samples, roughly double the accuracy of trained pathologists when presented with a metastatic tumour without knowledge of the primary. surprisingly, adding information on driver mutations reduced accuracy. our results have clinical applicability, underscore how patterns of somatic passenger mutations encode the state of the cell of origin, and can inform future strategies to detect the source of circulating tumour dna.","['metastatic cancers using passenger mutation patterns', 'deep learning system accurately classifies primary']"
"a novel deep learning based model called multi-planar spatial convolutional neural network (mps-cnn) is proposed for effective, automated segmentation of different sub-regions viz. peritumoral edema (ed), necrotic core (ncr), enhancing and non-enhancing tumor core (et/net), from multi-modal mr images of the brain. an encoder-decoder type cnn model is designed for pixel-wise segmentation of the tumor along three anatomical planes (axial, sagittal, and coronal) at the slice level. these are then combined, by incorporating a consensus fusion strategy with a fully connected conditional random field (crf) based post-refinement, to produce the final volumetric segmentation of the tumor and its constituent sub-regions. concepts, such as spatial-pooling and unpooling are used to preserve the spatial locations of the edge pixels, for reducing segmentation error around the boundaries. a new aggregated loss function is also developed for effectively handling data imbalance. the mps-cnn is trained and validated on the recent multimodal brain tumor segmentation challenge (brats) 2018 dataset. the dice scores obtained for the validation set for whole tumor (wt :ncr/ne +et +ed), tumor core (tc:ncr/net +et), and enhancing tumor (et) are 0.90216, 0.87247, and 0.82445. the proposed mps-cnn is found to perform the best (based on leaderboard scores) for et and tc segmentation tasks, in terms of both the quantitative measures (viz. dice and hausdorff). in case of the wt segmentation it also achieved the second highest accuracy, with a score which was only 1% less than that of the best performing method.","['novel volumetric sub', 'region segmentation', 'brain tumors']"
"the service quality and system dependability of real-time communication networks strongly depends on the analysis of monitored data, to identify concrete problems and their causes. many of these can be described by either their structural or temporal properties, or a combination of both. as current research is short of approaches sufficiently addressing both properties simultaneously, we propose a new feature space specifically suited for this task, which we analyze for its theoretical properties and its practical relevance. we evaluate its classification performance when used on real-world data sets of structural-temporal mobile communication data, and compare it to the performance achieved of feature representations used in related work. for this purpose we propose a system which allows the automatic detection and prediction of classes of pre-defined sequence behavior, greatly reducing costs caused by the otherwise required manual analysis. with our proposed feature spaces this system achieves a precision of more than 93% at recall values of 100%, with an up to 6.7% higher effective recall than otherwise similarly performing alternatives, notably outperforming alternative deep learning, kernel learning and ensemble learning approaches of related work. furthermore the supported system calibration allows separating reliable from unreliable predictions more effectively, which is highly relevant for any practical application.","['time communication network validation data', 'temporal data', 'use case', 'learning system', 'features spaces', 'structural', 'real', 'application']"
"radiomics, artificial intelligence, and deep learning figure amongst recent buzzwords in current medical imaging research and technological development. analysis of medical big data in assessment and follow-up of personalised treatments has also become a major research topic in the area of precision medicine. in this review, current research trends in radiomics are analysed, from handcrafted radiomics feature extraction and statistical analysis to deep learning. radiomics algorithms now include genomics and immunomics data to improve patient stratification and prediction of treatment response. several applications have already shown conclusive results demonstrating the potential of including other ""omics"" data to existing imaging features. we also discuss further challenges of data harmonisation and management infrastructure to shed a light on the much-needed integration of radiomics and all other ""omics"" into clinical workflows. in particular, we point to the emerging paradigm shift in the implementation of big data infrastructures to facilitate databanks growth, data extraction and the development of expert software tools. secured access, sharing, and integration of all health data, called ""holomics"", will accelerate the revolution of personalised medicine and oncology as well as expand the role of imaging specialists.","['personalised oncology', 'integrating radiomics', 'holomics', 'bedside', 'algorithms']"
"breast density is one of the most significant factors that is associated with cancer risk. in this study, our purpose was to develop a supervised deep learning approach for automated estimation of percentage density (pd) on digital mammograms (dms). the input 'for processing' dms was first log-transformed, enhanced by a multi-resolution preprocessing scheme, and subsampled to a pixel size of 800 µm\u2009\u2009×\u2009\u2009800 µm from 100 µm\u2009\u2009×\u2009\u2009100 µm. a deep convolutional neural network (dcnn) was trained to estimate a probability map of breast density (pmd) by using a domain adaptation resampling method. the pd was estimated as the ratio of the dense area to the breast area based on the pmd. the dcnn approach was compared to a feature-based statistical learning approach. gray level, texture and morphological features were extracted and a least absolute shrinkage and selection operator was used to combine the features into a feature-based pmd. with approval of the institutional review board, we retrospectively collected a training set of 478 dms and an independent test set of 183 dms from patient files in our institution. two experienced mammography quality standards act radiologists interactively segmented pd as the reference standard. ten-fold cross-validation was used for model selection and evaluation with the training set. with cross-validation, dcnn obtained a dice's coefficient (dc) of 0.79\u2009\u2009±\u2009\u20090.13 and pearson's correlation (r) of 0.97, whereas feature-based learning obtained dc\u2009\u2009=\u2009\u20090.72\u2009\u2009±\u2009\u20090.18 and r\u2009\u2009=\u2009\u20090.85. for the independent test set, dcnn achieved dc\u2009\u2009=\u2009\u20090.76\u2009\u2009±\u2009\u20090.09 and r\u2009\u2009=\u2009\u20090.94, while feature-based learning achieved dc\u2009\u2009=\u2009\u20090.62\u2009\u2009±\u2009\u20090.21 and r\u2009\u2009=\u2009\u20090.75. our dcnn approach was significantly better and more robust than the feature-based learning approach for automated pd estimation on dms, demonstrating its potential use for automated density reporting as well as for model-based risk prediction.","['supervised deep learning', 'based statistical learning', 'breast density', 'aided assessment', 'feature', 'computer', 'comparison']"
contouring of organs at risk (oars) is an important but time consuming part of radiotherapy treatment planning. the aim of this study was to investigate whether using institutional created software-generated contouring will save time if used as a starting point for manual oar contouring for lung cancer patients.,"['deep learning based automatic contouring', 'lung cancer', 'clinical evaluation', 'atlas']"
"this chapter focuses on modern deep learning techniques that are proposed for automatically recognizing and segmenting multiple organ regions on three-dimensional (3d) computed tomography (ct) images. ct images are widely used to visualize 3d anatomical structures composed of multiple organ regions inside the human body in clinical medicine. automatic recognition and segmentation of multiple organs on ct images is a fundamental processing step of computer-aided diagnosis, surgery, and radiation therapy systems, which aim to achieve precision and personalized medicines. in this chapter, we introduce our recent works on addressing the issue of multiple organ segmentation on 3d ct images by using deep learning, a completely novel approach, instead of conventional segmentation methods originated from traditional digital image processing techniques. we evaluated and compared the segmentation performances of two different deep learning approaches based on 2d- and 3d deep convolutional neural networks (cnns) without and with a pre-processing step. a conventional method based on a probabilistic atlas algorithm, which presented the best performance within the conventional approaches, was also adopted as a baseline for performance comparison. a dataset containing 240 ct scans of different portions of human bodies was used for training the cnns and validating the segmentation performance of the learning results. a maximum number of 17 types of organ regions in each ct scan were segmented automatically and validated with the human annotations by using ratio of intersection over union (iou) as the criterion. our experimental results showed that the ious of the segmentation results had a mean value of 79% and 67% by averaging 17 types of organs that were segmented by the proposed 3d and 2d deep cnns, respectively. all results using the deep learning approaches showed better accuracy and robustness than the conventional segmentation method that used the probabilistic atlas algorithm. the effectiveness and usefulness of deep learning approaches were demonstrated for multiple organ segmentation on 3d ct images.","['using deep learning approaches', '3d ct images', 'multiple organs', 'automatic segmentation']"
"the aim of this review is to present an up-to-date overview of the application of machine learning methods in heart failure including diagnosis, classification, readmissions and medication adherence.","['prime time', 'machine learning', 'heart failure', 'ready']"
"an important component of processing medical texts is the identification of synonymous words or phrases. synonyms can inform learned representations of patients or improve linking mentioned concepts to medical ontologies. however, medical synonyms can be lexically similar (""dilated ra"" and ""dilated rv"") or dissimilar (""cerebrovascular accident"" and ""stroke""); contextual information can determine if 2 strings are synonymous. medical professionals utilize extensive variation of medical terminology, often not evidenced in structured medical resources. therefore, the ability to discover synonyms, especially without reliance on training data, is an important component in processing training notes. the ability to discover synonyms from models trained on large amounts of unannotated data removes the need to rely on annotated pairs of similar words. models relying solely on non-annotated data can be trained on a wider variety of texts without the cost of annotation, and thus may capture a broader variety of language.","['learning unsupervised contextual representations', 'medical synonym discovery']"
"cardiac imaging plays an important role in the diagnosis of cardiovascular disease (cvd). until now, its role has been limited to visual and quantitative assessment of cardiac structure and function. however, with the advent of big data and machine learning, new opportunities are emerging to build artificial intelligence tools that will directly assist the clinician in the diagnosis of cvds. this paper presents a thorough review of recent works in this field and provide the reader with a detailed presentation of the machine learning methods that can be further exploited to enable more automated, precise and early diagnosis of most cvds.","['based cardiac diagnosis', 'machine learning', 'review', 'image']"
to train a generic deep learning software (dls) to classify breast cancer on ultrasound images and to compare its performance to human readers with variable breast imaging experience.,"['generic deep learning analysis software', 'ultrasound imaging using', 'pilot study', 'breast cancer', 'classification']"
"the authors present a deep learning algorithm for the automatic centroid localisation of out-of-plane us needle reflections to produce a semi-automatic ultrasound (us) probe calibration algorithm. a convolutional neural network was trained on a dataset of 3825 images at a 6 cm imaging depth to predict the position of the centroid of a needle reflection. applying the automatic centroid localisation algorithm to a test set of 614 annotated images produced a root mean squared error of 0.62 and 0.74 mm (6.08 and 7.62 pixels) in the axial and lateral directions, respectively. the mean absolute errors associated with the test set were 0.50 ± 0.40 mm and 0.51 ± 0.54 mm (4.9 ± 3.96 pixels and 5.24 ± 5.52 pixels) for the axial and lateral directions, respectively. the trained model was able to produce visually validated us probe calibrations at imaging depths on the range of 4-8 cm, despite being solely trained at 6 cm. this work has automated the pixel localisation required for the guided-us calibration algorithm producing a semi-automatic implementation available open-source through 3d slicer. the automatic needle centroid localisation improves the usability of the algorithm and has the potential to decrease the fiducial localisation and target registration errors associated with the guided-us calibration method.","['automatic ultrasound probe calibration', 'plane needle localisation', 'deep learning approach', 'automatic', 'semi']"
"this paper presents trustsign, a novel, trusted automatic malware signature generation method based on high-level deep features transferred from a vgg-19 neural network model pretrained on the imagenet dataset. while traditional automatic malware signature generation techniques rely on static or dynamic analysis of the malware's executable, our method overcomes the limitations associated with these techniques by producing signatures based on the presence of the malicious process in the volatile memory. by leveraging the cloud's virtualization technology, trustsign analyzes the malicious process in a trusted manner, since the malware is unaware and cannot interfere with the inspection procedure. additionally, by removing the dependency on the malware's executable, our method is fully capable of signing fileless malware as well. trustsign's signature generation process does not require feature engineering or any additional model training, and it is done in a completely unsupervised manner, eliminating the need for a human expert. because of this, our method has the advantage of dramatically reducing signature generation and distribution time. in fact, in this paper we rethink the typical use of deep convolutional neural networks and use the vgg-19 model as a topological feature extractor for a vastly different task from the one it was trained for. the results of our experimental evaluation demonstrate trustsign's ability to generate signatures impervious to the process state over time. by using the signatures generated by trustsign as input for various supervised classifiers, we achieved up to 99.5% classification accuracy.","['deep feature transfer learning', 'automated malware signature generation', 'private cloud environments', 'trusted']"
"positron emission tomography (pet) is an essential technique in many clinical applications such as tumor detection and brain disorder diagnosis. in order to obtain high-quality pet images, a standard-dose radioactive tracer is needed, which inevitably causes the risk of radiation exposure damage. for reducing the patient's exposure to radiation and maintaining the high quality of pet images, in this paper, we propose a deep learning architecture to estimate the high-quality standard-dose pet (spet) image from the combination of the low-quality low-dose pet (lpet) image and the accompanying t1-weighted acquisition from magnetic resonance imaging (mri). specifically, we adapt the convolutional neural network (cnn) to account for the two channel inputs of lpet and t1, and directly learn the end-to-end mapping between the inputs and the spet output. then, we integrate multiple cnn modules following the auto-context strategy, such that the tentatively estimated spet of an early cnn can be iteratively refined by subsequent cnns. validations on real human brain pet/mri data show that our proposed method can provide competitive estimation quality of the pet images, compared to the state-of-the-art methods. meanwhile, our method is highly efficient to test on a new subject, e.g., spending ~2 seconds for estimating an entire spet image in contrast to ~16 minutes by the state-of-the-art method. the results above demonstrate the potential of our method in real clinical applications.","['context convolutional neural networks', 'dose pet image estimation', 'dose pet', 'deep auto', 'standard', 'mri', 'low']"
"cancer is a complex genetic disease that develops from the accumulation of genomic alterations in which germline variations predispose individuals to cancer and somatic alterations initiate and trigger the progression of cancer. for the past 2 decades, genomic research has advanced remarkably, evolving from single-gene to whole-genome screening by using genome-wide association study and next-generation sequencing that contributes to big genomic data. international collaborative efforts have contributed to curating these data to identify clinically significant alterations that could be used in clinical settings. focusing on breast cancer, the present review summarizes the identification of genomic alterations with high-throughput screening as well as the use of genomic information in clinical trials that match cancer patients to therapies, which further leads to cancer precision medicine. furthermore, cancer screening and monitoring were enhanced greatly by the use of liquid biopsies. with the growing data complexity and size, there is much anticipation in exploiting deep machine learning and artificial intelligence to curate integrative ""-omics"" data to refine the current medical practice to be applied in the near future.","['big genomic data', 'cancer precision medicine', 'breast cancer', 'translation']"
"deep learning is the state-of-the-art machine learning approach. the success of deep learning in many pattern recognition applications has brought excitement and high expectations that deep learning, or artificial intelligence (ai), can bring revolutionary changes in health care. early studies of deep learning applied to lesion detection or classification have reported superior performance compared to those by conventional techniques or even better than radiologists in some tasks. the potential of applying deep-learning-based medical image analysis to computer-aided diagnosis (cad), thus providing decision support to clinicians and improving the accuracy and efficiency of various diagnostic and treatment processes, has spurred new research and development efforts in cad. despite the optimism in this new era of machine learning, the development and implementation of cad or ai tools in clinical practice face many challenges. in this chapter, we will discuss some of these issues and efforts needed to develop robust deep-learning-based cad tools and integrate these tools into the clinical workflow, thereby advancing towards the goal of providing reliable intelligent aids for patient care.","['medical image analysis', 'deep learning']"
"survival prediction is very important in medical treatment. however, recent leading research is challenged by two factors: 1) the datasets usually come with multi-modality; and 2) sample sizes are relatively small. to solve the above challenges, we developed a deep survival learning model to predict patients' survival outcomes by integrating multi-view data. the proposed network contains two sub-networks, one view-specific and one common sub-network. we designated one cnn-based and one fcn-based sub-network to efficiently handle pathological images and molecular profiles, respectively. our model first explicitly maximizes the correlation among the views and then transfers feature hierarchies from view commonality and specifically fine-tunes on the survival prediction task. we evaluate our method on real lung and brain tumor data sets to demonstrate the effectiveness of the proposed model using data with multiple modalities across different tumor types.","['deep integrative analysis', 'survival prediction']"
"establishing a solid theoretical foundation for structured deep neural networks is greatly desired due to the successful applications of deep learning in various practical domains. this paper aims at an approximation theory of deep convolutional neural networks whose structures are induced by convolutions. to overcome the difficulty in theoretical analysis of the networks with linearly increasing widths arising from convolutions, we introduce a downsampling operator to reduce the widths. we prove that the downsampled deep convolutional neural networks can be used to approximate ridge functions nicely, which hints some advantages of these structured networks in terms of approximation or modeling. we also prove that the output of any multi-layer fully-connected neural network can be realized by that of a downsampled deep convolutional neural network with free parameters of the same order, which shows that in general, the approximation ability of deep convolutional neural networks is at least as good as that of fully-connected networks. finally, a theorem for approximating functions on riemannian manifolds is presented, which demonstrates that deep convolutional neural networks can be used to learn manifold features of data.","['deep convolutional neural networks', 'theory', 'downsampling']"
the purpose of this study is to investigate the effect of different magnetic resonance (mr) sequences on the accuracy of deep learning-based synthetic computed tomography (sct) generation in the complex head and neck region.,"['based synthetic ct generation using', 'sequence mr image', 'generative adversarial network', 'neck mri', 'radiotherapy', 'multi', 'head']"
"with the rapid development of deep sequencing techniques in the recent years, enhancers have been systematically identified in such projects as fantom and encode, forming genome-wide landscapes in a series of human cell lines. nevertheless, experimental approaches are still costly and time consuming for large scale identification of enhancers across a variety of tissues under different disease status, making computational identification of enhancers indispensable.","['deep convolutional neural networks', 'predicting enhancers']"
"retinal fundus images are often corrupted by non-uniform and/or poor illumination that occur due to overall imperfections in the image acquisition process. this unwanted variation in brightness limits the pathological information that can be gained from the image. studies have shown that poor illumination can impede human grading in about 10~15% of retinal images. for automated grading, the effect can be even higher. in this perspective, we propose a novel method for illumination correction in the context of retinal imaging. the method splits the color image into luminosity and chroma (i.e., color) components and performs illumination correction in the luminosity channel based on a novel background estimation technique. extensive subjective and objective experiments were conducted on publicly available diaretdb1 and eyepacs images to justify the performance of the proposed method. the subjective experiment has confirmed that the proposed method does not create false color/artifacts and at the same time performs better than the traditional method in 84 out of 89 cases. the objective experiment shows an accuracy improvement of 4% in automated disease grading when illumination correction is performed by the proposed method than the traditional method.","['color fundus photographs', 'poor illumination', 'novel method', 'correcting non', 'uniform']"
"type 2 diabetes (t2d) is a complex disease characterized by pancreatic islet dysfunction, insulin resistance, and disruption of blood glucose levels. genome-wide association studies (gwas) have identified\xa0>\xa0400 independent signals that encode genetic predisposition. more than 90% of associated single-nucleotide polymorphisms (snps) localize to non-coding regions and are enriched in chromatin-defined islet enhancer elements, indicating a strong transcriptional regulatory component to disease susceptibility. pancreatic islets are a mixture of cell types that express distinct hormonal programs, so each cell type may contribute differentially to the underlying regulatory processes that modulate t2d-associated transcriptional circuits. existing chromatin profiling methods such as atac-seq and dnase-seq, applied to islets in bulk, produce aggregate profiles that mask important cellular and regulatory heterogeneity.","['specific type 2 diabetes regulatory signatures', 'rare cells reveals cell', 'human pancreatic islets', 'deep learning upscaling', 'cell atac', 'single', 'seq']"
"the basal ganglia (bg) is a collection of nuclei located deep beneath the cerebral cortex that is involved in learning and selection of rewarded actions. here, we analyzed bg mechanisms that enable these functions. we implemented a rate model of a bg-thalamo-cortical loop and simulated its performance in a standard action selection task. we have shown that potentiation of corticostriatal synapses enables learning of a rewarded option. however, these synapses became redundant later as direct connections between prefrontal and premotor cortices (pfc-pmc) were potentiated by hebbian learning. after we switched the reward to the previously unrewarded option (reversal), the bg was again responsible for switching to the new option. due to the potentiated direct cortical connections, the system was biased to the previously rewarded choice, and establishing the new choice required a greater number of trials. guided by physiological research, we then modified our model to reproduce pathological states of mild parkinson's and huntington's diseases. we found that in the parkinsonian state pmc activity levels become extremely variable, which is caused by oscillations arising in the bg-thalamo-cortical loop. the model reproduced severe impairment of learning and predicted that this is caused by these oscillations as well as a reduced reward prediction signal. in the huntington state, the potentiation of the pfc-pmc connections produced better learning, but altered bg output disrupted expression of the rewarded choices. this resulted in random switching between rewarded and unrewarded choices resembling an exploratory phase that never ended. along with other computational studies, our results further reconcile the apparent contradiction between the critical involvement of the bg in execution of previously learned actions and yet no impairment of these actions after bg output is ablated by lesions or deep brain stimulation. we predict that the cortico-bg-thalamo-cortical loop conforms to previously learned choice in healthy conditions, but impedes those choices in disease states.","['executing previously learned choices', 'learning rewarded actions', 'basal ganglia role', 'diseased states', 'healthy']"
"surgical instrument detection in robot-assisted surgery videos is an import vision component for these systems. most of the current deep learning methods focus on single-tool detection and suffer from low detection speed. to address this, the authors propose a novel frame-by-frame detection method using a cascading convolutional neural network (cnn) which consists of two different cnns for real-time multi-tool detection. an hourglass network and a modified visual geometry group (vgg) network are applied to jointly predict the localisation. the former cnn outputs detection heatmaps representing the location of tool tip areas, and the latter performs bounding-box regression for tool tip areas on these heatmaps stacked with input rgb image frames. the authors' method is tested on the publicly available endovis challenge dataset and the atlas dione dataset. the experimental results show that their method achieves better performance than mainstream detection methods in terms of detection accuracy and speed.","['time surgical instrument detection', 'convolutional neural network cascade', 'assisted surgery using', 'robot', 'real']"
"in-line holographic microscopy provides an unparalleled wealth of information about the properties of colloidal dispersions. analyzing one colloidal particle's hologram with the lorenz-mie theory of light scattering yields the particle's three-dimensional position with nanometer precision while simultaneously reporting its size and refractive index with part-per-thousand resolution. analyzing a few thousand holograms in this way provides a comprehensive picture of the particles that make up a dispersion, even for complex multicomponent systems. all of this valuable information comes at the cost of three computationally expensive steps: (1) identifying and localizing features of interest within recorded holograms, (2) estimating each particle's properties based on characteristics of the associated features, and finally (3) optimizing those estimates through pixel-by-pixel fits to a generative model. here, we demonstrate an end-to-end implementation that is based entirely on machine-learning techniques. characterizing and tracking colloids holographically (catch) with deep convolutional neural networks is fast enough for real-time applications and otherwise outperforms conventional analytical algorithms, particularly for heterogeneous and crowded samples. we demonstrate this system's capabilities with experiments on free-flowing and holographically trapped colloidal spheres.","['tracking colloids holographically using deep neural networks', 'characterizing', 'catch']"
the aim of the study was to realign how nurses view simulation in nursing education as a means of facilitating fluency in knowledge and action to promote expertise in practice.,"['nursing education', 'concept analysis', 'simulation', 'fluency']"
"alzheimer's disease (ad) may cause damage to the memory cells permanently, which results in the form of dementia. the diagnosis of alzheimer's disease at an early stage is a problematic task for researchers. for this, machine learning and deep convolutional neural network (cnn) based approaches are readily available to solve various problems related to brain image data analysis. in clinical research, magnetic resonance imaging (mri) is used to diagnose ad. for accurate classification of dementia stages, we need highly discriminative features obtained from mri images. recently advanced deep cnn-based models successfully proved their accuracy. however, due to a smaller number of image samples available in the datasets, there exist problems of over-fitting hindering the performance of deep learning approaches. in this research, we developed a siamese convolutional neural network (scnn) model inspired by vgg-16 (also called oxford net) to classify dementia stages. in our approach, we extend the insufficient and imbalanced data by using augmentation approaches. experiments are performed on a publicly available dataset open access series of imaging studies (oasis), by using the proposed approach, an excellent test accuracy of 99.05% is achieved for the classification of dementia stages. we compared our model with the state-of-the-art models and discovered that the proposed model outperformed the state-of-the-art models in terms of performance, efficiency, and accuracy.","['deep siamese convolution neural network', 'class classification', 'alzheimer disease', 'multi']"
"crop yield prediction is extremely challenging due to its dependence on multiple factors such as crop genotype, environmental factors, management practices, and their interactions. this paper presents a deep learning framework using convolutional neural networks (cnns) and recurrent neural networks (rnns) for crop yield prediction based on environmental data and management practices. the proposed cnn-rnn model, along with other popular methods such as random forest (rf), deep fully connected neural networks (dfnn), and lasso, was used to forecast corn and soybean yield across the entire corn belt (including 13 states) in the united states for years 2016, 2017, and 2018 using historical data. the new model achieved a root-mean-square-error (rmse) 9% and 8% of their respective average yields, substantially outperforming all other methods that were tested. the cnn-rnn has three salient features that make it a potentially useful method for other crop yield prediction studies. (1) the cnn-rnn model was designed to capture the time dependencies of environmental factors and the genetic improvement of seeds over time without having their genotype information. (2) the model demonstrated the capability to generalize the yield prediction to untested environments without significant drop in the prediction accuracy. (3) coupled with the backpropagation method, the model could reveal the extent to which weather conditions, accuracy of weather predictions, soil conditions, and management practices were able to explain the variation in the crop yields.","['crop yield prediction', 'rnn framework', 'cnn']"
"a growing body of evidence now suggests that precision psychiatry, an interdisciplinary field of psychiatry, precision medicine, and pharmacogenomics, serves as an indispensable foundation of medical practices by offering the accurate medication with the accurate dose at the accurate time to patients with psychiatric disorders. in light of the latest advancements in artificial intelligence and machine learning techniques, numerous biomarkers and genetic loci associated with psychiatric diseases and relevant treatments are being discovered in precision psychiatry research by employing neuroimaging and multi-omics. in this review, we focus on the latest developments for precision psychiatry research using artificial intelligence and machine learning approaches, such as deep learning and neural network algorithms, together with multi-omics and neuroimaging data. firstly, we review precision psychiatry and pharmacogenomics studies that leverage various artificial intelligence and machine learning techniques to assess treatment prediction, prognosis prediction, diagnosis prediction, and the detection of potential biomarkers. in addition, we describe potential biomarkers and genetic loci that have been discovered to be associated with psychiatric diseases and relevant treatments. moreover, we outline the limitations in regard to the previous precision psychiatry and pharmacogenomics studies. finally, we present a discussion of directions and challenges for future research.","['precision psychiatry applications', 'machine learning approaches', 'artificial intelligence', 'pharmacogenomics']"
"advancements in musculoskeletal analysis have been achieved by adopting deep learning technology in image recognition and analysis. unlike musculoskeletal modeling based on computational anatomy, deep learning-based methods can obtain muscle information automatically. through analysis of image features, both approaches can obtain muscle characteristics such as shape, volume, and area, and derive additional information by analyzing other image textures. in this chapter, we first discuss the necessity of musculoskeletal analysis and the required image processing technology. then, the limitations of skeletal muscle recognition based on conventional handcrafted features are discussed, and developments in skeletal muscle recognition using machine learning and deep learning technology are described. next, a technique for analyzing musculoskeletal systems using whole-body computed tomography (ct) images is shown. this study aims to achieve automatic recognition of skeletal muscles throughout the body and automatic classification of atrophic muscular disease using only image features, to demonstrate an application of whole-body musculoskeletal analysis driven by deep learning. finally, we discuss future development of musculoskeletal analysis that effectively combines deep learning with handcrafted feature-based modeling techniques.","['deep learning technique', 'musculoskeletal analysis']"
"deep brain stimulation of the subthalamic nucleus (stn-dbs) has become an effective treatment strategy for patients with parkinson's disease. however, the biological mechanism underlying dbs treatment remains poorly understood.","['functional magnetic resonance imaging', 'bimodal positron emission tomography', 'deep brain stimulation', 'subthalamic nucleus', 'effective network', 'parkinson', 'disease']"
"structural mr images concomitantly acquired with pet images can provide crucial anatomic information for precise quantitative analysis. however, in the clinical setting, not all the subjects have corresponding mr images. here, we developed a model to generate structural mr images from amyloid pet using deep generative networks. we applied our model to quantification of cortical amyloid load without structural mr. methods: we used florbetapir pet and structural mr data from the alzheimer disease neuroimaging initiative database. the generative network was trained to generate realistic structural mr images from florbetapir pet images. after the training, the model was applied to the quantification of cortical amyloid load. pet images were spatially normalized to the template space using the generated mr, and then suv ratio (suvr) of the target regions was measured by predefined regions of interest. a real mr-based quantification was used as the gold standard to measure the accuracy of our approach. other mr-less methods-a normal pet template-based, a multiatlas pet template-based, and a pet segmentation-based normalization/quantification-were also tested. we compared the performance of quantification methods using generated mr with that of mr-based and mr-less quantification methods. results: generated mr images from florbetapir pet showed signal patterns that were visually similar to the real mr. the structural similarity index between real and generated mr was 0.91 ± 0.04. the mean absolute error of suvr of cortical composite regions estimated by the generated mr-based method was 0.04 ± 0.03, which was significantly smaller than other mr-less methods (0.29 ± 0.12 for the normal pet template, 0.12 ± 0.07 for the multiatlas pet template, and 0.08 ± 0.06 for the pet segmentation-based methods). bland-altman plots revealed that the generated mr-based suvr quantification was the closest to the suvrs estimated by the real mr-based method. conclusion: structural mr images were successfully generated from amyloid pet images using deep generative networks. generated mr images could be used as templates for accurate and precise amyloid quantification. this generative method might be used to generate multimodal images of various organs for further quantitative analyses.","['structural mr images', 'less quantification', 'amyloid pet', 'mr', 'generation', 'application']"
"in the last decades, large datasets of fundus photographs have been collected in diabetic retinopathy (dr) screening networks. through deep learning, these datasets were used to train automatic detectors for dr and a few other frequent pathologies, with the goal to automate screening. one challenge limits the adoption of such systems so far: automatic detectors ignore rare conditions that ophthalmologists currently detect, such as papilledema or anterior ischemic optic neuropathy. the reason is that standard deep learning requires too many examples of these conditions. however, this limitation can be addressed with few-shot learning, a machine learning paradigm where a classifier has to generalize to a new category not seen in training, given only a few examples of this category. this paper presents a new few-shot learning framework that extends convolutional neural networks (cnns), trained for frequent conditions, with an unsupervised probabilistic model for rare condition detection. it is based on the observation that cnns often perceive photographs containing the same anomalies as similar, even though these cnns were trained to detect unrelated conditions. this observation was based on the t-sne visualization tool, which we decided to incorporate in our probabilistic model. experiments on a dataset of 164,660 screening examinations from the ophdiat screening network show that 37 conditions, out of 41, can be detected with an area under the roc curve (auc) greater than 0.8 (average auc: 0.938). in particular, this framework significantly outperforms other frameworks for detecting rare conditions, including multitask learning, transfer learning and siamese networks, another few-shot learning solution. we expect these richer predictions to trigger the adoption of automated eye pathology screening, which will revolutionize clinical practice in ophthalmology.","['fundus photographs using', 'shot learning', 'rare pathologies', 'automatic detection']"
"lung cancer is the most common cancer among men and the third most common among women in the world. many diagnostic techniques have been introduced to diagnose lung cancer. positron emission tomography (pet)/computed tomography (ct) examination is an image diagnostic method that performs automatic detection and distinction of lung lesions. in addition, pathological examination by biopsy is performed for lesions that are suspected of being malignant, and appropriate treatment methods are applied according to the diagnosis results. currently, lung cancer diagnosis is performed through coordination between respiratory, radiation, and pathological diagnosis experts, but there are some tasks, such as image diagnosis, that require a large amount of time and effort to complete. therefore, we developed a decision support system using pet/ct and microscopic images at the time of image diagnosis, which leads to appropriate treatment. in this chapter, we introduce the proposed system using deep learning and radiomic techniques.","['lung cancer using pet', 'decision support system', 'microscopic images', 'ct']"
"in patients with coronary artery stenoses of intermediate severity, the functional significance needs to be determined. fractional flow reserve (ffr) measurement, performed during invasive coronary angiography (ica), is most often used in clinical practice. to reduce the number of ica procedures, we present a method for automatic identification of patients with functionally significant coronary artery stenoses, employing deep learning analysis of the left ventricle (lv) myocardium in rest coronary ct angiography (ccta). the study includes consecutively acquired ccta scans of 166 patients who underwent invasive ffr measurements. to identify patients with a functionally significant coronary artery stenosis, analysis is performed in several stages. first, the lv myocardium is segmented using a multiscale convolutional neural network (cnn). to characterize the segmented lv myocardium, it is subsequently encoded using unsupervised convolutional autoencoder (cae). as ischemic changes are expected to appear locally, the lv myocardium is divided into a number of spatially connected clusters, and statistics of the encodings are computed as features. thereafter, patients are classified according to the presence of functionally significant stenosis using an svm classifier based on the extracted features. quantitative evaluation of lv myocardium segmentation in 20 images resulted in an average dice coefficient of 0.91 and an average mean absolute distance between the segmented and reference lv boundaries of 0.7\xa0mm. twenty ccta images were used to train the lv myocardium encoder. classification of patients was evaluated in the remaining 126 ccta scans in 50 10-fold cross-validation experiments and resulted in an area under the receiver operating characteristic curve of 0.74\u202f±\u202f0.02. at sensitivity levels 0.60, 0.70 and 0.80, the corresponding specificity was 0.77, 0.71 and 0.59, respectively. the results demonstrate that automatic analysis of the lv myocardium in a single ccta scan acquired at rest, without assessment of the anatomy of the coronary arteries, can be used to identify patients with functionally significant coronary artery stenosis. this might reduce the number of patients undergoing unnecessary invasive ffr measurements.","['functionally significant coronary artery stenosis', 'coronary ct angiography', 'deep learning analysis', 'patients', 'myocardium', 'identification']"
"tropical cyclone intensity estimation is a challenging task as it required domain knowledge while extracting features, significant pre-processing, various sets of parameters obtained from satellites, and human intervention for analysis. the inconsistency of results, significant pre-processing of data, complexity of the problem domain, and problems on generalizability are some of the issues related to intensity estimation. in this study, we design a deep convolutional neural network architecture for categorizing hurricanes based on intensity using graphics processing unit. our model has achieved better accuracy and lower root-mean-square error by just using satellite images than 'state-of-the-art' techniques. visualizations of learned features at various layers and their deconvolutions are also presented for understanding the learning process.","['tropical cyclone intensity estimation using', 'deep convolutional neural network']"
"interest for deep learning in radiology has increased tremendously in the past decade due to the high achievable performance for various computer vision tasks such as detection, segmentation, classification, monitoring, and prediction. this article provides step-by-step practical guidance for conducting a project that involves deep learning in radiology, from defining specifications, to deployment and scaling. specifically, the objectives of this article are to provide an overview of clinical use cases of deep learning, describe the composition of multi-disciplinary team, and summarize current approaches to patient, data, model, and hardware selection. key ideas will be illustrated by examples from a prototypical project on imaging of colorectal liver metastasis. this article illustrates the workflow for liver lesion detection, segmentation, classification, monitoring, and prediction of tumor recurrence and patient survival. challenges are discussed, including ethical considerations, cohorting, data collection, anonymization, and availability of expert annotations. the practical guidance may be adapted to any project that requires automated medical image analysis.","['deep learning workflow', 'radiology', 'primer']"
"movement screens are used to assess the overall movement quality of an athlete. however, these rely on visual observation of a series of movements and subjective scoring. data-driven methods to provide objective scoring of these movements are being developed. these currently use optical motion capture and require manual pre-processing of data to identify the start and end points of each movement. therefore, we aimed to use deep learning techniques to automatically identify movements typically found in movement screens and assess the feasibility of performing the classification based on wearable sensor data. optical motion capture data were collected on 417 athletes performing 13 athletic movements. we trained an existing deep neural network architecture that combines convolutional and recurrent layers on a subset of 278 athletes. a validation subset of 69 athletes was used to tune the hyperparameters and the final network was tested on the remaining 70 athletes. simulated inertial measurement data were generated based on the optical motion capture data and the network was trained on this data for different combinations of body segments. classification accuracy was similar for networks trained using the optical and full-body simulated inertial measurement unit data at 90.1 and 90.2%, respectively. a good classification accuracy of 85.9% was obtained using as few as three simulated sensors placed on the torso and shanks. however, using three simulated sensors on the torso and upper arms or fewer than three sensors resulted in poor accuracy. these results for simulated sensor data indicate the feasibility of classifying athletic movements using a small number of wearable sensors. this could facilitate objective data-driven methods that automatically score overall movement quality using wearable sensors to be easily implemented in the field.","['athletic tasks using deep neural networks', 'sensor data required', 'automatic recognition']"
deep learning-based computer-aided diagnosis (cad) is an important method in aiding diagnosis for radiologists. we investigated the accuracy of a deep learning-based cad in classifying breast lesions with different histological types.,"['different pathological types', 'deep learning framework', 'aided diagnosis system', 'classification accuracy', 'breast lesions', 'based computer', 'investigation']"
"management of thyroid nodules in the era of precision medicine is continuously changing. neck ultrasound plays a pivotal role in the diagnosis and several ultrasound stratification systems have been proposed in order to predict malignancy and help clinicians in therapeutic and follow-up decision. ultrasound elastosonography is another powerful diagnostic technique and can be an added value to stratify the risk of malignancy of thyroid nodules. moreover, the development of new techniques in the era of ""deep learning,"" has led to a creation of machine-learning algorithms based on ultrasound examinations that showed similar accuracy to that obtained by expert radiologists. despite new technologies in thyroid imaging, diagnostic surgery in 50-70% of patients with indeterminate cytology is still performed. molecular tests can increase accuracy in diagnosis when performed on ""indeterminate"" nodules. however, the more updated tools that can be used to this purpose in order to ""rule out"" (afirma gsc) or ""rule in"" (thyroseq v3) malignancy, have a main limitation: the high costs. in the last years various image-guided procedures have been proposed as alternative and less invasive approaches to surgery for symptomatic thyroid nodules. these minimally invasive techniques (laser and radio-frequency ablation, high intensity focused ultrasound and percutaneous microwave ablation) results in nodule shrinkage and improvement of local symptoms, with a lower risk of complications and minor costs compared to surgery. finally, ultrasound-guided ablation therapy was introduced with promising results as a feasible treatment for low-risk papillary thyroid microcarcinoma or cervical lymph node metastases.","['nodular thyroid disease', 'precision medicine', 'era']"
"microscopic interpretation of stained smears is one of the most operator-dependent and time-intensive activities in the clinical microbiology laboratory. here, we investigated application of an automated image acquisition and convolutional neural network (cnn)-based approach for automated gram stain classification. using an automated microscopy platform, uncoverslipped slides were scanned with a 40× dry objective, generating images of sufficient resolution for interpretation. we collected 25,488 images from positive blood culture gram stains prepared during routine clinical workup. these images were used to generate 100,213 crops containing gram-positive cocci in clusters, gram-positive cocci in chains/pairs, gram-negative rods, or background (no cells). these categories were targeted for proof-of-concept development as they are associated with the majority of bloodstream infections. our cnn model achieved a classification accuracy of 94.9% on a test set of image crops. receiver operating characteristic (roc) curve analysis indicated a robust ability to differentiate between categories with an area under the curve of >0.98 for each. after training and validation, we applied the classification algorithm to new images collected from 189 whole slides without human intervention. sensitivity and specificity were 98.4% and 75.0% for gram-positive cocci in chains and pairs, 93.2% and 97.2% for gram-positive cocci in clusters, and 96.3% and 98.1% for gram-negative rods. taken together, our data support a proof of concept for a fully automated classification methodology for blood-culture gram stains. importantly, the algorithm was highly adept at identifying image crops with organisms and could be used to present prescreened, classified crops to technologists to accelerate smear review. this concept could potentially be extended to all gram stain interpretive activities in the clinical laboratory.","['deep convolutional neural network', 'blood culture gram stains', 'automated interpretation', 'use']"
schizophrenia is a severe psychiatric disorder associated with iq deficits. rare copy number variations (cnvs) have been established to play an important role in the etiology of schizophrenia. several of the large rare cnvs associated with schizophrenia have been shown to negatively affect iq in population-based controls where no major neuropsychiatric disorder is reported. the aim of this study was to examine the diagnostic yield of microarray testing and the functional impact of genome-wide rare cnvs in a community ascertained cohort of adults with schizophrenia and low (<\u200985) or average (≥\u200985) iq.,"['diagnostic yield', 'community sample', 'chromosomal microarray', 'schizophrenia', 'iq', 'impact', 'adults']"
"the accurate and automated determination of small earthquake (ml\u2009<\u20093.0) locations is still a challenging endeavor due to low signal-to-noise ratio in data. however, such information is critical for monitoring seismic activity and assessing potential hazards. in particular, earthquakes caused by industrial injection have become a public concern, and regulators need a solid capability for estimating small earthquakes that may trigger the action requirements for operators to follow in real time. in this study, we develop a fully convolutional network and locate earthquakes induced during oil and gas operations in oklahoma with data from 30 network stations. the network is trained by 1,013 cataloged events (ml\u2009≥\u20093.0) as base data along with augmented data accounting for smaller events (3.0\u2009>\u2009ml\u2009≥\u20090.5), and the output is a 3d volume of the event location probability in the earth. the prediction results suggest that the mean epicenter errors of the testing events (ml\u2009≥\u20091.5) vary from 3.7 to 6.4\u2009km, meeting the need of the traffic light system in oklahoma, but smaller events (ml\u2009=\u20091.0, 0.5) show errors larger than 11\u2009km. synthetic tests suggest that the accuracy of ground truth from catalog affects the prediction results. correct ground truth leads to a mean epicenter error of 2.0\u2009km in predictions, but adding a mean location error of 6.3\u2009km to ground truth causes a mean epicenter error of 4.9\u2009km. the automated system is able to distinguish certain interfered events or events out of the monitoring zone based on the output probability estimate. it requires approximately one hundredth of a second to locate an event without the need for any velocity model or human interference.","['locating induced earthquakes', 'deep learning method', 'seismic stations', 'oklahoma via', 'network']"
"the goals of this workshop are to discuss challenges in explainability of current machine leaning and deep analytics (mlda) used in biocomputing and to start the discussion on ways to improve it. we define explainability in mlda as easy to use information explaining why and how the mlda approach made its decisions. we believe that much greater effort is needed to address the issue of mlda explainability because of: 1) the ever increasing use and dependence on mlda in biocomputing including the need for increased adoption by non-mld experts; 2) the diversity, complexity and scale of biocomputing data and mlda algorithms; 3) the emerging importance of mlda-based decisions in patient care, in daily research, as well as in the development of new costly medical procedures and drugs. this workshop aims to: a) analyze and challenge the current level of explainability of mlda methods and practices in biocomputing; b) explore benefits of improvements in this area; and c) provide useful and practical guidance to the biocomputing community on how to address these challenges and how to develop improvements. the workshop format is designed to encourage a lively discussion with panelists to first motivate and understand the problem and then to define next steps and solutions needed to improve mlda explainability.","['machine learning', 'deep analytics', 'better explainability', 'call', 'biocomputing']"
recognition of human behavioral activities using local field potential (lfp) signals recorded from the subthalamic nuclei (stn) has applications in developing the next generation of deep brain stimulation (dbs) systems. dbs therapy is often used for patients with parkinson's disease (pd) when medication cannot effectively tackle patients' motor symptoms. a dbs system capable of adaptively adjusting its parameters based on patients' activities may optimize therapy while reducing the stimulation side effects and improving the battery life.,"['recognize human behavioral activities using brain stn', 'deep learning framework', 'lfp signals', 'lfp', 'net']"
"dental schools seek to educate students to become inclined toward self-directed, lifelong learning, an important mindset for healthcare professionals that may be linked to deep versus surface learning approaches. students using a deep learning approach are more intrinsically motivated and actively engage in higher-order thinking, while those using a surface learning approach are more extrinsically motivated and aim for passive learning.","['dental student learning approaches', 'surface learning', 'third year', 'implications', 'curriculum', 'assessment']"
"cardiovascular conditions remain the leading cause of mortality and morbidity worldwide, with genotype being a significant influence on disease risk. cardiac imaging-genetics aims to identify and characterize the genetic variants that influence functional, physiological, and anatomical phenotypes derived from cardiovascular imaging. high-throughput dna sequencing and genotyping have greatly accelerated genetic discovery, making variant interpretation one of the key challenges in contemporary clinical genetics. heterogeneous, low-fidelity phenotyping and difficulties integrating and then analyzing large-scale genetic, imaging and clinical datasets using traditional statistical approaches have impeded process. artificial intelligence (ai) methods, such as deep learning, are particularly suited to tackle the challenges of scalability and high dimensionality of data and show promise in the field of cardiac imaging-genetics. here we review the current state of ai as applied to imaging-genetics research and discuss outstanding methodological challenges, as the field moves from pilot studies to mainstream applications, from one dimensional global descriptors to high-resolution models of whole-organ shape and function, from univariate to multivariate analysis and from candidate gene to genome-wide approaches. finally, we consider the future directions and prospects of ai imaging-genetics for ultimately helping understand the genetic and environmental underpinnings of cardiovascular health and disease.","['genetics research', 'cardiac imaging', 'artificial intelligence']"
"the wide spread usage of wearable sensors such as in smart watches has provided continuous access to valuable user generated data such as human motion that could be used to identify an individual based on his/her motion patterns such as, gait. several methods have been suggested to extract various heuristic and high-level features from gait motion data to identify discriminative gait signatures and distinguish the target individual from others. however, the manual and hand crafted feature extraction is error prone and subjective. furthermore, the motion data collected from inertial sensors have complex structure and the detachment between manual feature extraction module and the predictive learning models might limit the generalization capabilities. in this paper, we propose a novel approach for human gait identification using time-frequency (tf) expansion of human gait cycles in order to capture joint 2 dimensional (2d) spectral and temporal patterns of gait cycles. then, we design a deep convolutional neural network (dcnn) learning to extract discriminative features from the 2d expanded gait cycles and jointly optimize the identification model and the spectro-temporal features in a discriminative fashion. we collect raw motion data from five inertial sensors placed at the chest, lower-back, right hand wrist, right knee, and right ankle of each human subject synchronously in order to investigate the impact of sensor location on the gait identification performance. we then present two methods for early (input level) and late (decision score level) multi-sensor fusion to improve the gait identification generalization performance. we specifically propose the minimum error score fusion (mesf) method that discriminatively learns the linear fusion weights of individual dcnn scores at the decision level by minimizing the error rate on the training data in an iterative manner. 10 subjects participated in this study and hence, the problem is a 10-class identification task. based on our experimental results, 91% subject identification accuracy was achieved using the best individual imu and 2dtf-dcnn. we then investigated our proposed early and late sensor fusion approaches, which improved the gait identification accuracy of the system to 93.36% and 97.06%, respectively.","['based gait recognition using convolutional neural networks', 'sensor fusion', 'multi', 'imu']"
"diabetic macular edema (dme) is an advanced stage of diabetic retinopathy (dr) and can lead to permanent vision loss. currently, it affects 26.7 million people globally and on account of such a huge number of dme cases and the limited number of ophthalmologists, it is desirable to automate the diagnosis process. computer-assisted, deep learning based diagnosis could help in early detection, following which precision medication can help to mitigate the vision loss.","['diabetic macular edema diagnosis using hierarchical ensemble', 'dmenet', 'cnns']"
"as the interaction between clinicians and computational processes increases in complexity, more nuanced mechanisms are required to describe how their communication is mediated. medical image segmentation in particular affords a large number of distinct loci for interaction which can act on a deep, knowledge-driven level which complicates the naive interpretation of the computer as a symbol processing machine. using the perspective of the computer as dialogue partner, we can motivate the semiotic understanding of medical image segmentation. taking advantage of peircean semiotic traditions and new philosophical inquiry into the structure and quality of metaphors, we can construct a unified framework for the interpretation of medical image segmentation as a sign exchange in which each sign acts as an interface metaphor. this allows for a notion of finite semiosis, described through a schematic medium, that can rigorously describe how clinicians and computers interpret the signs mediating their interaction. altogether, this framework provides a unified approach to the understanding and development of medical image segmentation interfaces.","['medical image segmentation', 'semiotics']"
"the grading of glioma has clinical significance in determining a treatment strategy and evaluating prognosis to investigate a novel set of radiomic features extracted from the fractional anisotropy (fa) and mean diffusivity (md) maps of brain diffusion tensor imaging (dti) sequences for computer-aided grading of gliomas. this retrospective study included 108 patients who had pathologically confirmed brain gliomas and dti scanned during 2012-2018. this cohort included 43 low-grade gliomas (lggs; all grade ii) and 65 high-grade gliomas (hggs; grade iii or iv). we extracted a set of radiomic features, including traditional texture, morphological, and novel deep features derived from pre-trained convolutional neural network models, in the manually-delineated tumor regions. we employed support vector machine and these radiomic features for two classification tasks: lggs vs hggs, and grade iii vs iv. the area under the receiver operating characteristic (roc) curve (auc), accuracy, sensitivity, and specificity was reported as the performance metrics using the leave-one-out cross-validation method. when combining fa+md, auc\u2009=\u20090.93, accuracy\u2009=\u20090.94, sensitivity\u2009=\u20090.98, and specificity\u2009=\u20090.86 in classifying lggs from hggs, while auc\u2009=\u20090.99, accuracy\u2009=\u20090.98, sensitivity\u2009=\u20090.98, and specificity\u2009=\u20091.00 in classifying grade iii from iv. the auc and accuracy remain close when features were extracted from only the solid tumor or additionally including necrosis, cyst, and peritumoral edema. still, the effects in terms of sensitivity and specificity are mixed. deep radiomic features derived from pre-trained convolutional neural networks showed higher prediction ability than the traditional texture and shape features in both classification experiments. radiomic features extracted on the fa and md maps of brain dti images are useful for noninvasively classification/grading of lggs vs hggs, and grade iii vs iv.","['deep convolutional radiomic features', 'diffusion tensor images', 'glioma grades', 'classification']"
"accurate identification of compound-protein interactions (cpis) in silico may deepen our understanding of the underlying mechanisms of drug action and thus remarkably facilitate drug discovery and development. conventional similarity- or docking-based computational methods for predicting cpis rarely exploit latent features from currently available large-scale unlabeled compound and protein data and often limit their usage to relatively small-scale datasets. in the present study, we propose deepcpi, a novel general and scalable computational framework that combines effective feature embedding (a technique of representation learning) with powerful deep learning methods to accurately predict cpis at a large scale. deepcpi automatically learns the implicit yet expressive low-dimensional features of compounds and proteins from a massive amount of unlabeled data. evaluations of the measured cpis in large-scale databases, such as chembl and bindingdb, as well as of the known drug-target interactions from drugbank, demonstrated the superior predictive performance of deepcpi. furthermore, several interactions among small-molecule compounds and three g protein-coupled receptor targets (glucagon-like peptide-1 receptor, glucagon receptor, and vasoactive intestinal peptide receptor) predicted using deepcpi were experimentally validated. the present study suggests that deepcpi is a useful and powerful tool for drug discovery and repositioning. the source code of deepcpi can be downloaded from https://github.com/fangpingwan/deepcpi.","['silico drug screening', 'deep learning', 'based framework', 'scale', 'large', 'deepcpi']"
"the reconstruction of gene regulatory network (grn) from gene expression data can discover regulatory relationships among genes and gain deep insights into the complicated regulation mechanism of life. however, it is still a great challenge in systems biology and bioinformatics. during the past years, numerous computational approaches have been developed for this goal, and bayesian network (bn) methods draw most of attention among these methods because of its inherent probability characteristics. however, bayesian network methods are time consuming and cannot handle large-scale networks due to their high computational complexity, while the mutual information-based methods are highly effective but directionless and have a high false-positive rate.","['reconstructing gene regulatory network based', 'improved bayesian network method', 'candidate auto selection']"
"early detection of glaucoma is important to slow down progression of the disease and to prevent total vision loss. retinal fundus photography is frequently obtained for various eye disease diagnosis and record and is a suitable screening exam for its simplicity and low cost. however, the number of ophthalmologists who are specialized in glaucoma diagnosis is limited. we have been studying automated schemes for detection of nerve fiber layer defects and analysis of optic disc deformation, two major signs of glaucoma, in assisting ophthalmologists' accurate and efficient diagnosis. in this chapter, our recent progress in computerized methods is discussed.","['retinal fundus images using deep learning', 'nerve fiber layer defect', 'optic disc analysis', 'glaucoma', 'diagnosis', 'detection']"
to develop and evaluate deep learning (dl) risk assessment models for predicting the progression of radiographic medial joint space loss using baseline knee x-rays.,"['radiographic medial joint space loss', 'deep learning risk assessment models', 'predicting progression', 'month follow', 'period', '48']"
"stimuli are represented in the brain by the collective population responses of sensory neurons, and an object presented under varying conditions gives rise to a collection of neural population responses called an 'object manifold'. changes in the object representation along a hierarchical sensory system are associated with changes in the geometry of those manifolds, and recent theoretical progress connects this geometry with 'classification capacity', a quantitative measure of the ability to support object classification. deep neural networks trained on object classification tasks are a natural testbed for the applicability of this relation. we show how classification capacity improves along the hierarchies of deep neural networks with different architectures. we demonstrate that changes in the geometry of the associated object manifolds underlie this improved capacity, and shed light on the functional roles different levels in the hierarchy play to achieve it, through orchestrated reduction of manifolds' radius, dimensionality and inter-manifold correlations.","['deep neural networks', 'object manifolds', 'separability', 'geometry']"
"quality assessment of diffusion mri (dmri) data is essential prior to any analysis, so that appropriate pre-processing can be used to improve data quality and ensure that the presence of mri artifacts do not affect the results of subsequent image analysis. manual quality assessment of the data is subjective, possibly error-prone, and infeasible, especially considering the growing number of consortium-like studies, underlining the need for automation of the process. in this paper, we have developed a deep-learning-based automated quality control (qc) tool, qc-automator, for dmri data, that can handle a variety of artifacts such as motion, multiband interleaving, ghosting, susceptibility, herringbone, and chemical shifts. qc-automator uses convolutional neural networks along with transfer learning to train the automated artifact detection on a labeled dataset of ∼332,000 slices of dmri data, from 155 unique subjects and 5 scanners with different dmri acquisitions, achieving a 98% accuracy in detecting artifacts. the method is fast and paves the way for efficient and effective artifact detection in large datasets. it is also demonstrated to be replicable on other datasets with different acquisition parameters.","['based automated quality control', 'diffusion mr images', 'deep learning', 'qc', 'automator']"
to develop a deep learning algorithm that can rule out significant rotator cuff tear based on conventional shoulder radiographs in patients suspected of rotator cuff tear.,"['shoulder radiograph series using deep learning', 'rotator cuff tear', 'conventional radiograph', 'ruling', 'role', 'redefining']"
"material informatics (mi) is a promising approach to liberate us from the time-consuming edisonian (trial and error) process for material discoveries, driven by machine-learning algorithms. several descriptors, which are encoded material features to feed computers, were proposed in the last few decades. especially to solid systems, however, their insufficient representations of three dimensionality of field quantities such as electron distributions and local potentials have critically hindered broad and practical successes of the solid-state mi. we develop a simple, generic 3d voxel descriptor that compacts any field quantities, in such a suitable way to implement convolutional neural networks (cnns). we examine the 3d voxel descriptor encoded from the electron distribution by a regression test with 680 oxides data. the present scheme outperforms other existing descriptors in the prediction of hartree energies that are significantly relevant to the long-wavelength distribution of the valence electrons. the results indicate that this scheme can forecast any functionals of field quantities just by learning sufficient amount of data, if there is an explicit correlation between the target properties and field quantities. this 3d descriptor opens a way to import prominent cnns-based algorithms of supervised, semi-supervised and reinforcement learnings into the solid-state mi.","['universal 3d voxel descriptor', 'deep convolutional neural networks', 'state material informatics', 'solid']"
"goodness of pronunciation (gop) is the most widely used method for automatic mispronunciation detection. in this paper, a transfer learning approach to gop based mispronunciation detection when applying maximum f1-score criterion (mfc) training to deep neural network (dnn)-hidden markov model based acoustic models is proposed. rather than train the whole network using mfc, a dnn is used, whose hidden layers are borrowed from native speech recognition with only the softmax layer trained according to the mfc objective function. as a result, significant mispronunciation detection improvement is obtained. in light of this, the two-stage transfer learning based gop is investigated in depth. the first stage exploits the hidden layer(s) to extract phonetic-discriminating features. the second stage uses a trainable softmax layer to learn the human standard for judgment. the validation is carried out by experimenting with different mispronunciation detection architectures using acoustic models trained by different criteria. it is found that it is preferable to use frame-level cross-entropy to train the hidden layer parameters. classifier based mispronunciation detection is further experimented with using features computed by transfer learning based gop and it is shown that it also helps to achieve better results.","['pronunciation based automatic mispronunciation detection', 'transfer learning approach', 'goodness']"
"electronic health records (ehrs) contain a wealth of patient data useful to biomedical researchers. at present, both the extraction of data and methods for analyses are frequently designed to work with a single snapshot of a patient's record. health care providers often perform and record actions in small batches over time. by extracting these care events, a sequence can be formed providing a trajectory for a patient's interactions with the health care system. these care events also offer a basic heuristic for the level of attention a patient receives from health care providers. we show that is possible to learn meaningful embeddings from these care events using two deep learning techniques, unsupervised autoencoders and long short-term memory networks. we compare these methods to traditional machine learning methods which require a point in time snapshot to be extracted from an ehr.","['mapping patient trajectories using longitudinal extraction', 'iii critical care database', 'deep learning', 'mimic']"
"although laparoscopic resection for colon cancer has been proven safe and feasible when compared with open resection, currently no clear evidence is available regarding minimally invasive surgery for rectal cancer. this type of surgery may benefit patients by allowing fast recovery of normal dietary intake and bowel function, reduced postoperative pain, and shorter hospitalization. therefore, minimally invasive surgeries such as laparoscopic or robot surgery have become the predominant treatment option for colon cancer. specifically, the proportion of laparoscopic colorectal cancer surgery in korea increased from 42.6 to 64.7% until 2013. however, laparoscopic surgery for rectal cancer is more difficult and technically demanding. in addition, the procedure requires a prolonged learning curve to achieve equivalent outcomes relative to open surgery. it is very challenging to approach the deep and narrow pelvis using laparoscopic instruments. however, robotic surgery provides better vision with a high definition three-dimensional view, exceptional ergonomics, endowrist technology, enhanced dexterity of movement, and a lack of physiologic tremor, facilitated by the use of an assistant in the narrow and deep pelvis. recently, an increasing number of reports have compared the outcomes of laparoscopic and open surgery for colon cancer. such reports have prompted a discussion of the outcomes of minimally invasive surgery, including robotic surgery, for rectal cancer. the aim of this review is to summarize current data regarding the clinical outcomes, including oncologic outcomes, of minimally invasive surgery for rectal cancer.","['minimally invasive surgery', 'rectal cancer', 'future perspectives', 'current status']"
the aim of the study was to assess entry-level competency and practice readiness of newly graduated nurses.,"['assessing new graduate nurses', 'ethical imperative', 'clinical reasoning', 'strategic', 'crisis', 'competency']"
"surgical tool tracking has a variety of applications in different surgical scenarios. electromagnetic (em) tracking can be utilised for tool tracking, but the accuracy is often limited by magnetic interference. vision-based methods have also been suggested; however, tracking robustness is limited by specular reflection, occlusions, and blurriness observed in the endoscopic image. recently, deep learning-based methods have shown competitive performance on segmentation and tracking of surgical tools. the main bottleneck of these methods lies in acquiring a sufficient amount of pixel-wise, annotated training data, which demands substantial labour costs. to tackle this issue, the authors propose a weakly supervised method for surgical tool segmentation and tracking based on hybrid sensor systems. they first generate semantic labellings using em tracking and laparoscopic image processing concurrently. they then train a light-weight deep segmentation network to obtain a binary segmentation mask that enables tool tracking. to the authors' knowledge, the proposed method is the first to integrate em tracking and laparoscopic image processing for generation of training labels. they demonstrate that their framework achieves accurate, automatic tool segmentation (i.e. without any manual labelling of the surgical tool to be tracked) and robust tool tracking in laparoscopic image sequences.","['time surgical tool tracking', 'weakly supervised segmentation', 'real']"
"prefrontal cortex in frontal lobe (fl) is the center of executive functions (ef). fl damage can lead to executive dysfunction by influencing frontal-subcortical circuits (dorsolateral, orbitofrontal, ventromedial). damage to the dorsolateral prefrontal cortex (dlpfc) can lead to deterioration in ef, whereas damage to the orbitofrontal cortex (ofc) can lead to personality changes with the characteristic of disinhibition and irritability. in addition, damage to the anterior cingulate cortex/medial prefrontal cortex (acc/mpfc) can result in decreased spontaneity. neuropsychological tests are important components in the assessment of ef including goal-directed behavior, decision-making, risk assessment, making plans for the future, setting of priorities and order of our actions. clinical conditions affecting frontal-subcortical connections outside of the fl can also lead to executive dysfunctions and frontal lobe syndrome (fls). this case report is about an adolescent patient diagnosed as fls. the clinical symptoms, assessment and treatment processes of this case are discussed in this report. the case is a 15-year-old boy that was admitted to our clinic with behavioral problems, which began after a car accident three years ago. magnetic resonance imaging (mri) of the brain indicated hyperintense signal increase in periventricular deep white matter that is associated with traumatic brain damage. neuropsychological tests results (stroop, wisconsin card sorting test, serial digit learning test, line orientation test, verbal memory processes scale) have demonstrated impairment in cognitive flexibility, verbal fluency, setting priority, inappropriate response inhibition, sustained attention, planning, problem solving, organization skills and subcortical memory functions. we thought that cognitive and behavioral symptoms of this case were associated with the dysfunctions of frontal-subcortical circuits, independent of an obvious frontal lesion. fls for the patients with sudden-onset behavioral and cognitive problems after head traumas should be kept in mind in differential diagnosis, even in the absence of an obvious frontal lesion.","['frontal lob syndrome', 'case report ].', 'executive functions']"
"natural history collections contain data that are critical for many scientific endeavors. recent efforts in mass digitization are generating large datasets from these collections that can provide unprecedented insight. here, we present examples of how deep convolutional neural networks can be applied in analyses of imaged herbarium specimens. we first demonstrate that a convolutional neural network can detect mercury-stained specimens across a collection with 90% accuracy. we then show that such a network can correctly distinguish two morphologically similar plant families 96% of the time. discarding the most challenging specimen images increases accuracy to 94% and 99%, respectively. these results highlight the importance of mass digitization and deep learning approaches and reveal how they can together deliver powerful new investigative tools.","['digitized natural history collections', 'deep convolutional neural networks', 'applications']"
"whilst exaggerated bursts of beta frequency band oscillatory synchronization in the subthalamic nucleus have been associated with motor impairment in parkinson's disease, a plausible mechanism linking the two phenomena has been lacking. here we test the hypothesis that increased synchronization denoted by beta bursting might compromise information coding capacity in basal ganglia networks. to this end we recorded local field potential activity in the subthalamic nucleus of 18 patients with parkinson's disease as they executed cued upper and lower limb movements. we used the accuracy of local field potential-based classification of the limb to be moved on each trial as an index of the information held by the system with respect to intended action. machine learning using the naïve bayes conditional probability model was used for classification. local field potential dynamics allowed accurate prediction of intended movements well ahead of their execution, with an area under the receiver operator characteristic curve of 0.80 ± 0.04 before imperative cues when the demanded action was known ahead of time. the presence of bursts of local field potential activity in the alpha, and even more so, in the beta frequency band significantly compromised the prediction of the limb to be moved. we conclude that low frequency bursts, particularly those in the beta band, restrict the capacity of the basal ganglia system to encode physiologically relevant information about intended actions. the current findings are also important as they suggest that local subthalamic activity may potentially be decoded to enable effector selection, in addition to force control in restorative brain-machine interface applications.","['subthalamic nucleus activity dynamics', 'limb movement prediction', 'parkinson', 'disease']"
"we propose a new paradigm for target detection in high resolution aerial remote sensing images under small target priors. previous remote sensing target detection methods frame the detection as learning of detection model + inference of class-label and bounding-box coordinates. instead, we formulate it from a bayesian view that at inference stage, the detection model is adaptively updated to maximize its posterior that is determined by both training and observation. we call this paradigm ""random access memories (ram)."" in this paradigm, ""memories"" can be interpreted as any model distribution learned from training data and ""random access"" means accessing memories and randomly adjusting the model at detection phase to obtain better adaptivity to any unseen distribution of test data. by leveraging some latest detection techniques e.g., deep convolutional neural networks and multi-scale anchors, experimental results on a public remote sensing target detection data set show our method outperforms several other state of the art methods. we also introduce a new data set ""learning, vision and remote sensing laboratory (levir)"", which is one order of magnitude larger than other data sets of this field. levir consists of a large set of google earth images, with over 22 k images and 10 k independently labeled targets. ram gives noticeable upgrade of accuracy (an mean average precision improvement of 1% ~ 4%) of our baseline detectors with acceptable computational overhead.","['high resolution aerial remote sensing images', 'random access memories', 'target detection', 'new paradigm']"
"rice panicle phenotyping is important in rice breeding, and rice panicle segmentation is the first and key step for image-based panicle phenotyping. because of the challenge of illumination differentials, panicle shape deformations, rice accession variations, different reproductive stages and the field's complex background, rice panicle segmentation in the field is a very large challenge.","['robust image segmentation method', 'superpixel optimization', 'rice panicles', 'field based', 'deep learning', 'seg', 'panicle']"
"accurate prediction of non-small cell lung cancer (nsclc) prognosis after surgery remains challenging. the cox proportional hazard (ph) model is widely used, however, there are some limitations associated with it. in this study, we developed novel neural network models called binned time survival analysis (deepbts) models using 30 clinico-pathological features of surgically resected nsclc patients (training cohort, n\u2009=\u20091,022; external validation cohort, n\u2009=\u2009298). we employed the root-mean-square error (in the supervised learning model, s- deepbts) or negative log-likelihood (in the semi-unsupervised learning model, su-deepbts) as the loss function. the su-deepbts algorithm achieved better performance (c-index\u2009=\u20090.7306; auc\u2009=\u20090.7677) than the other models (cox ph: c-index\u2009=\u20090.7048 and auc\u2009=\u20090.7390; s-deepbts: c-index\u2009=\u20090.7126 and auc\u2009=\u20090.7420). the top 14 features were selected using su-deepbts model as a selector and could distinguish the low- and high-risk groups in the training cohort (p\u2009=\u20091.86\u2009×\u200910-11) and validation cohort (p\u2009=\u20091.04\u2009×\u200910-10). when trained with the optimal feature set for each model, the su-deepbts model could predict the prognoses of nsclc better than the traditional model, especially in stage i patients. follow-up studies using combined radiological, pathological imaging, and genomic data to enhance the performance of our model are ongoing.","['small cell lung cancer using', 'binned deep neural network', 'free survival', 'time', 'recurrence', 'prediction', 'non', 'deepbts']"
"computational chemistry is currently a synergistic assembly between ab initio calculations, simulation, machine learning (ml) and optimization strategies for describing, solving and predicting chemical data and related phenomena. these include accelerated literature searches, analysis and prediction of physical and quantum chemical properties, transition states, chemical structures, chemical reactions, and also new catalysts and drug candidates. the generalization of scalability to larger chemical problems, rather than specialization, is now the main principle for transforming chemical tasks in multiple fronts, for which systematic and cost-effective solutions have benefited from ml approaches, including those based on deep learning (e.g. quantum chemistry, molecular screening, synthetic route design, catalysis, drug discovery). the latter class of ml algorithms is capable of combining raw input into layers of intermediate features, enabling bench-to-bytes designs with the potential to transform several chemical domains. in this review, the most exciting developments concerning the use of ml in a range of different chemical scenarios are described. a range of different chemical problems and respective rationalization, that have hitherto been inaccessible due to the lack of suitable analysis tools, is thus detailed, evidencing the breadth of potential applications of these emerging multidimensional approaches. focus is given to the models, algorithms and methods proposed to facilitate research on compound design and synthesis, materials design, prediction of binding, molecular activity, and soft matter behavior. the information produced by pairing chemistry and ml, through data-driven analyses, neural network predictions and monitoring of chemical systems, allows (i) prompting the ability to understand the complexity of chemical data, (ii) streamlining and designing experiments, (ii) discovering new molecular targets and materials, and also (iv) planning or rethinking forthcoming chemical challenges. in fact, optimization engulfs all these tasks directly.","['deep learning', 'deep chemistry', 'chemical patterns', 'prediction', 'optimizing']"
"kidney stones are a common urologic condition with a high amount of recurrence. recurrence depends on a multitude of factors the incidence of precursors to kidney stones, plugs, and plaques. one method of characterising the stone precursors is endoscopic assessment, though it is manual and time-consuming. deep learning has become a popular technique for semantic segmentation because of the high accuracy that has been demonstrated. the present letter examined the efficacy of deep learning to segment the renal papilla, plaque, and plugs. a u-net model with resnet-34 encoder was tested; the letter examined dropout (to avoid overtraining) and two different loss functions (to address the class imbalance problem. the models were then trained in 1666 images and tested on 185 images. the jaccard-cross-entropy loss function was more effective than the focal loss function. the model with the dropout rate 0.4 was found to be more effective due to its generalisability. the model was largely successful at delineating the papilla. the model was able to correctly detect the plaques and plugs; however, small plaques were challenging. deep learning was found to be applicable for segmentation of an endoscopic image for the papilla, plaque, and plug, with room for improvement.","['calcium phosphate deposit plugs', 'terminal ends', 'kidney tubules', 'automatic detection']"
"in recent years, with the rapid development of mobile internet and its business applications, mobile advertising click-through rate (ctr) estimation has become a hot research direction in the field of computational advertising, which is used to achieve accurate advertisement delivery for the best benefits in the three-side game between media, advertisers, and audiences. current research on the estimation of ctr mainly uses the methods and models of machine learning, such as linear model or recommendation algorithms. however, most of these methods are insufficient to extract the data features and cannot reflect the nonlinear relationship between different features. in order to solve these problems, we propose a new model based on deep belief nets to predict the ctr of mobile advertising, which combines together the powerful data representation and feature extraction capability of deep belief nets, with the advantage of simplicity of traditional logistic regression models. based on the training dataset with the information of over 40 million mobile advertisements during a period of 10 days, our experiments show that our new model has better estimation accuracy than the classic logistic regression (lr) model by 5.57% and support vector regression (svr) model by 5.80%.","['rate estimation based', 'mobile advertising click', 'deep belief nets', 'new approach']"
"the progesterone receptor (pr) is important therapeutic target for many malignancies and endocrine disorders due to its role in controlling ovulation and pregnancy via the reproductive cycle. therefore, the modulation of pr activity using its agonists and antagonists is receiving increasing interest as novel treatment strategy. however, clinical trials using the pr modulators have not yet been found conclusive evidences. recently, increasing evidence from several fields shows that the classification of chemical compounds, including agonists and antagonists, can be done with recent improvements in deep learning (dl) using deep neural network. therefore, we recently proposed a novel dl-based quantitative structure-activity relationship (qsar) strategy using transfer learning to build prediction models for agonists and antagonists. by employing this novel approach, referred as deepsnap-dl method, which uses images captured from 3-dimension (3d) chemical structure with multiple angles as input data into the dl classification, we constructed prediction models of the pr antagonists in this study. here, the deepsnap-dl method showed a high performance prediction of the pr antagonists by optimization of some parameters and image adjustment from 3d-structures. furthermore, comparison of the prediction models from this approach with conventional machine learnings (mls) indicated the deepsnap-dl method outperformed these mls. therefore, the models predicted by deepsnap-dl would be powerful tool for not only qsar field in predicting physiological and agonist/antagonist activities, toxicity, and molecular bindings; but also for identifying biological or pathological phenomena.","['deep learning approach predicts progesterone receptor antagonist activity', 'high performance', 'deepsnap']"
"cancer is one of the most difficult diseases to treat owing to the drug resistance of tumour cells. recent studies have revealed that drug responses are closely associated with genomic alterations in cancer cells. numerous state-of-the-art machine learning models have been developed for prediction of drug responses using various genomic data and diverse drug molecular information, but those methods are ineffective to predict drug response to untrained drugs and gene expression patterns, which is known as the cold-start problem. in this study, we present a novel deep neural network model, termed refdnn, for improved prediction of drug resistance and identification of biomarkers related to drug response. refdnn exploits a collection of drugs, called reference drugs, to learn representations for a high-dimensional gene expression vector and a molecular structure vector of a drug and predicts drug response labels using the reference drug-based representations. these calculations come from the observation that similar chemicals have similar effects. the proposed model not only outperformed existing computational prediction models in most comparative experiments, but also showed more robust prediction for untrained drugs and cancer types than traditional machine learning models. refdnn exploits the elasticnet regularization to deal with high-dimensional gene expression data, which allows identification of gene markers associated with drug resistance. lastly, we described an application of refdnn in exploring a new candidate drug for liver cancer. as the proposed model can guarantee good prediction of drug responses to untrained drugs for given gene expression patterns, it may be of potential benefit in drug repositioning and personalized medicine.","['reference drug based neural network', 'anticancer drug resistance', 'accurate prediction', 'refdnn']"
": dental panoramic radiographs (dprs) provide information required to potentially evaluate bone density changes through a textural and morphological feature analysis on a mandible. this study aims to evaluate the discriminating performance of deep convolutional neural networks (cnns), employed with various transfer learning strategies, on the classification of specific features of osteoporosis in dprs. for objective labeling, we collected a dataset containing 680 images from different patients who underwent both skeletal bone mineral density and digital panoramic radiographic examinations at the korea university ansan hospital between 2009 and 2018. four study groups were used to evaluate the impact of various transfer learning strategies on deep cnn models as follows: a basic cnn model with three convolutional layers (cnn3), visual geometry group deep cnn model (vgg-16), transfer learning model from vgg-16 (vgg-16_tf), and fine-tuning with the transfer learning model (vgg-16_tf_ft). the best performing model achieved an overall area under the receiver operating characteristic of 0.858. in this study, transfer learning and fine-tuning improved the performance of a deep cnn for screening osteoporosis in dpr images. in addition, using the gradient-weighted class activation mapping technique, a visual interpretation of the best performing deep cnn model indicated that the model relied on image features in the lower left and right border of the mandibular. this result suggests that deep learning-based assessment of dpr images could be useful and reliable in the automated screening of osteoporosis patients.","['deep convolutional neural networks', 'dental panoramic radiographs', 'transfer learning', 'screening osteoporosis', 'evaluation']"
"deep learning has led to significant advances in artificial intelligence, in part, by adopting strategies motivated by neurophysiology. however, it is unclear whether deep learning could occur in the real brain. here, we show that a deep learning algorithm that utilizes multi-compartment neurons might help us to understand how the neocortex optimizes cost functions. like neocortical pyramidal neurons, neurons in our model receive sensory information and higher-order feedback in electrotonically segregated compartments. thanks to this segregation, neurons in different layers of the network can coordinate synaptic weight updates. as a result, the network learns to categorize images better than a single layer network. furthermore, we show that our algorithm takes advantage of multilayer architectures to identify useful higher-order representations-the hallmark of deep learning. this work demonstrates that deep learning can be achieved using segregated dendritic compartments, which may help to explain the morphology of neocortical pyramidal neurons.","['towards deep learning', 'segregated dendrites']"
"background: lymph node (ln) metastasis is the most important prognostic factor in esophageal squamous cell carcinoma (escc). traditional clinical factor and existing methods based on ct images are insufficiently effective in diagnosing ln metastasis. a more efficient method to predict ln status based on ct image is needed. methods: in this multicenter retrospective study, 411 patients with pathologically confirmed escc were registered from two hospitals. quantitative image features including handcrafted-, computer vision-(cv-), and deep-features were extracted from preoperative arterial phase ct images for each patient. a handcrafted-, cv-, and deep-radiomics signature were built, respectively. then, multiple radiomics models were constructed by merging independent clinical risk factor into radiomics signatures. the performance of models were evaluated with respect to the discrimination, calibration, and clinical usefulness. finally, an independent external validation cohort was used to validate the model's predictive performance. results: five, seven, and nine features were selected for building handcrafted-, cv-, and deep-radiomics signatures from extracted features, respectively. those signatures were statistically significant different between ln-positive and ln-negative patients in all cohorts (p < 0.001). the developed multiple level ct radiomics model that integrates multiple radiomics signatures with clinical risk factor, was superior to traditional clinical factors and the results reported by existing methods, and achieved satisfactory discrimination performance with c-statistic of 0.875 in development cohort, 0.874 in internal validation cohort and 0.840 in independent external validation cohort. nomogram and decision curve analysis (dca) further confirmed our method may serve as an effective tool for clinicians to evaluate the risk of ln metastasis in patients with escc and further choose treatment strategy. conclusions: the proposed multiple level ct radiomics model which integrate multiple level radiomics features into clinical risk factor can be used for preoperative predicting ln metastasis of patients with escc.","['multiple level ct radiomics features preoperatively predict lymph node metastasis', 'multicentre retrospective study', 'esophageal cancer']"
"knee arthritis is a common joint disease that usually requires a total knee arthroplasty. there are multiple surgical variables that have a direct impact on the correct positioning of the implants, and an optimal combination of all these variables is the most challenging aspect of the procedure. usually, preoperative planning using a computed tomography scan or magnetic resonance imaging helps the surgeon in deciding the most suitable resections to be made. this work is a proof of concept for a navigation system that supports the surgeon in following a preoperative plan. existing solutions require costly sensors and special markers, fixed to the bones using additional incisions, which can interfere with the normal surgical flow. in contrast, the authors propose a computer-aided system that uses consumer rgb and depth cameras and do not require additional markers or tools to be tracked. they combine a deep learning approach for segmenting the bone surface with a recent registration algorithm for computing the pose of the navigation sensor with respect to the preoperative 3d model. experimental validation using ex-vivo data shows that the method enables contactless pose estimation of the navigation sensor with the preoperative model, providing valuable information for guiding the surgeon during the medical procedure.","['deep segmentation leverages geometric pose estimation', 'aided total knee arthroplasty', 'computer']"
"metabolism of xenobiotics (greek xenos: exogenous substances) plays an essential role in the prediction of biological activity and testing for the subsequent research and development of new drug candidates. integration of various methods and techniques using different computational and experimental approaches is one of the keys to a successful metabolism prediction. while multiple structure-based and ligand-based approaches to metabolism prediction exist, the most important problem arises at the first stage of metabolism prediction: detection of the sites of metabolism (soms). in this paper, we describe the application of quantitative neighborhoods of atoms (qna) descriptors for prediction of the soms using potential function method, as well as several different machine learning techniques: naïve bayes, random forest classifier, multilayer perceptron with back propagation and convolutional neural networks, and deep neural networks.","['based prediction', 'sites', 'qna', 'metabolism']"
"for single-cell experiments, it is important to accurately count the number of viable cells in a nanoliter well. we used a deep learning-based convolutional neural network (cnn) on a large amount of digital data obtained as microscopic images. the training set consisted of 103 019 samples, each representing a microscopic grayscale image. after extensive training, the cnn was able to classify the samples into four categories, i.e., 0, 1, 2, and more than 2 cells per well, with an accuracy of 98.3% when compared to determination by two trained technicians. by analyzing the samples for which judgments were discordant, we found that the judgment by technicians was relatively correct although cell counting was often difficult by the images of discordant samples. based on the results, the system was further enhanced by introducing a new algorithm in which the highest outputs from cnn were used, increasing the accuracy to higher than 99%. our system was able to classify the data even from wells with a different shape. no other tested machine learning algorithm showed a performance higher than that of our system. the presented cnn system is expected to be useful for various single-cell experiments, and for high-throughput and high-content screening.","['deep learning algorithm', 'count cell numbers', 'cell experiments', 'viable single', 'system using', 'nanoliter wells', 'construction']"
"nanopore sequencing is promising because of its long read length and high speed. during sequencing, a strand of dna/rna passes through a biological nanopore, which causes the current in the pore to fluctuate. during basecalling, context-dependent current measurements are translated into the base sequence of the dna/rna strand. accurate and fast basecalling is vital for downstream analyses such as genome assembly and detecting single-nucleotide polymorphisms and genomic structural variants. however, owing to the various changes in dna/rna molecules, noise during sequencing, and limitations of basecalling methods, accurate basecalling remains a challenge. in this paper, we propose causalcall, which uses an end-to-end temporal convolution-based deep learning model for accurate and fast nanopore basecalling. developed on a temporal convolutional network (tcn) and a connectionist temporal classification decoder, causalcall directly identifies base sequences of varying lengths from current measurements in long time series. in contrast to the basecalling models using recurrent neural networks (rnns), the convolution-based model of causalcall can speed up basecalling by matrix computation. experiments on multiple species have demonstrated the great potential of the tcn-based model to improve basecalling accuracy and speed when compared to an rnn-based model. besides, experiments on genome assembly indicate the utility of causalcall in reference-based genome assembly.","['temporal convolutional network', 'nanopore basecalling using', 'causalcall']"
"image segmentation is one of the most important methods for animal phenome research. since the advent of deep learning, many researchers have looked at multilayer convolutional neural networks to solve the problems of image segmentation. a network simplifies the task of image segmentation with automatic feature extraction. many networks struggle to output accurate details when dealing with pixel-level segmentation. in this paper, we propose a new concept: depth density. based on a depth image, produced by a kinect system, we design a new function to calculate the depth density value of each pixel and bring this value back to the result of semantic segmentation for improving the accuracy. in the experiment, we choose simmental cattle as the target of image segmentation and fully convolutional networks (fcn) as the verification networks. we proved that depth density can improve four metrics of semantic segmentation (pixel accuracy, mean accuracy, mean intersection over union, and frequency weight intersection over union) by 2.9%, 0.3%, 11.4%, and 5.02%, respectively. the result shows that depth information produced by kinect can improve the accuracy of the semantic segmentation of fcn. this provides a new way of analyzing the phenotype information of animals.","['depth density achieves', 'semantic segmentation', 'kinect system', 'better result']"
"the cancer genome atlas (tcga) has profiled over 10,000 tumors across 33 different cancer-types for many genomic features, including gene expression levels. gene expression measurements capture substantial information about the state of each tumor. certain classes of deep neural network models are capable of learning a meaningful latent space. such a latent space could be used to explore and generate hypothetical gene expression profiles under various types of molecular and genetic perturbation. for example, one might wish to use such a model to predict a tumor\'s response to specific therapies or to characterize complex gene expression activations existing in differential proportions in different tumors. variational autoencoders (vaes) are a deep neural network approach capable of generating meaningful latent spaces for image and text data. in this work, we sought to determine the extent to which a vae can be trained to model cancer gene expression, and whether or not such a vae would capture biologically-relevant features. in the following report, we introduce a vae trained on tcga pan-cancer rna-seq data, identify specific patterns in the vae encoded features, and discuss potential merits of the approach. we name our method ""tybalt"" after an instigative, cat-like character who sets a cascading chain of events in motion in shakespeare\'s ""romeo and juliet"". from a systems biology perspective, tybalt could one day aid in cancer stratification or predict specific activated expression patterns that would result from genetic changes or treatment effects.","['biologically relevant latent space', 'variational autoencoders', 'cancer transcriptomes', 'extracting']"
"augmented reality (ar) is becoming increasingly popular due to its numerous applications. this is especially evident in games, medicine, education, and other areas that support our everyday activities. moreover, this kind of computer system not only improves our vision and our perception of the world that surrounds us, but also adds additional elements, modifies existing ones, and gives additional guidance. in this article, we focus on interpreting a reality-based real-time environment evaluation for informing the user about impending obstacles. the proposed solution is based on a hybrid architecture that is capable of estimating as much incoming information as possible. the proposed solution has been tested and discussed with respect to the advantages and disadvantages of different possibilities using this type of vision.","['deep learning techniques', 'augmented reality models', 'safety alert', 'obstacle detection', 'use']"
"gene expression is a key intermediate level that genotypes lead to a particular trait. gene expression is affected by various factors including genotypes of genetic variants. with an aim of delineating the genetic impact on gene expression, we build a deep auto-encoder model to assess how good genetic variants will contribute to gene expression changes. this new deep learning model is a regression-based predictive model based on the multilayer perceptron and stacked denoising auto-encoder (mlp-sae). the model is trained using a stacked denoising auto-encoder for feature selection and a multilayer perceptron framework for backpropagation. we further improve the model by introducing dropout to prevent overfitting and improve performance.","['gene expression prediction', 'encoder model', 'deep auto']"
"convolutional neural networks (cnns), the state of the art in image classification, have proven to be as effective as an ophthalmologist, when detecting referable diabetic retinopathy. having a size of [formula: see tex","['receiver operating characteristics curve', 'powerful image preprocessing procedure', 'different input image sizes', 'small local features', 'includes two cnns', 'see text ].', 'see text ],', 'fundus retina images', 'total image', 'see text', 'input model', 'trained using', 'messidor datasets', 'images based', 'feedback method', 'false positives', 'early lesions', 'diaretdb1 dataset', 'diabetic retinopathy', 'complete images']"
"deformable image registration is a fundamental problem in the field of medical image analysis. during the last years, we have witnessed the advent of deep learning-based image registration methods which achieve state-of-the-art performance, and drastically reduce the required computational time. however, little work has been done regarding how can we encourage our models to produce not only accurate, but also anatomically plausible results, which is still an open question in the field. in this work, we argue that incorporating anatomical priors in the form of global constraints into the learning process of these models, will further improve their performance and boost the realism of the warped images after registration. we learn global non-linear representations of image anatomy using segmentation masks, and employ them to constraint the registration process. the proposed ac-regnet architecture is evaluated in the context of chest x-ray image registration using three different datasets, where the high anatomical variability makes the task extremely challenging. our experiments show that the proposed anatomically constrained registration model produces more realistic and accurate results than state-of-the-art methods, demonstrating the potential of this approach.","['learning deformable registration', 'medical images', 'anatomical constraints']"
"glioblastoma multiforme (gbm), a malignant brain tumor, is among the most lethal of all cancers. temozolomide is the primary chemotherapy treatment for patients diagnosed with gbm. the methylation status of the promoter or the enhancer regions of the o6-methylguanine methyltransferase (mgmt) gene may impact the efficacy and sensitivity of temozolomide, and hence may affect overall patient survival. microscopic genetic changes may manifest as macroscopic morphological changes in the brain tumors that can be detected using magnetic resonance imaging (mri), which can serve as noninvasive biomarkers for determining methylation of mgmt regulatory regions. in this research, we use a compendium of brain mri scans of gbm patients collected from the cancer imaging archive (tcia) combined with methylation data from the cancer genome atlas (tcga) to predict the methylation state of the mgmt regulatory regions in these patients. our approach relies on a bi-directional convolutional recurrent neural network architecture (crnn) that leverages the spatial aspects of these 3-dimensional mri scans. our crnn obtains an accuracy of 67% on the validation data and 62% on the test data, with precision and recall both at 67%, suggesting the existence of mri features that may complement existing markers for gbm patient stratification and prognosis. we have additionally presented our model via a novel neural network visualization platform, which we have developed to improve interpretability of deep learning mri-based classification models.","['glioblastoma patients using convolutional recurrent neural networks', 'predicting methylation status', 'mri', 'mgmt']"
"vehicle detection in aerial images is an important and challenging task. traditionally, many target detection models based on sliding-window fashion were developed and achieved acceptable performance, but these models are time-consuming in the detection phase. recently, with the great success of convolutional neural networks (cnns) in computer vision, many state-of-the-art detectors have been designed based on deep cnns. however, these cnn-based detectors are inefficient when applied in aerial image data due to the fact that the existing cnn-based models struggle with small-size object detection and precise localization. to improve the detection accuracy without decreasing speed, we propose a cnn-based detection model combining two independent convolutional neural networks, where the first network is applied to generate a set of vehicle-like regions from multi-feature maps of different hierarchies and scales. because the multi-feature maps combine the advantage of the deep and shallow convolutional layer, the first network performs well on locating the small targets in aerial image data. then, the generated candidate regions are fed into the second network for feature extraction and decision making. comprehensive experiments are conducted on the vehicle detection in aerial imagery (vedai) dataset and munich vehicle dataset. the proposed cascaded detection model yields high performance, not only in detection accuracy but also in detection speed.","['cascaded convolutional neural networks', 'robust vehicle detection', 'aerial images based']"
"nowadays proper detection of cognitive impairment has become a challenge for the scientific community. alzheimer's disease (ad), the most common cause of dementia, has a high prevalence that is increasing at a fast pace towards epidemic level. in the not-so-distant future this fact could have a dramatic social and economic impact. in this scenario, an early and accurate diagnosis of ad could help to decrease its effects on patients, relatives and society. over the last decades there have been useful advances not only in classic assessment techniques, but also in novel non-invasive screening methodologies.","['automatic speech analysis', 'task approach', 'linear multi', 'early detection', 'alzheimer disease', 'non', 'advances']"
"diabetic retinopathy (dr) is one of the leading causes of preventable blindness in the world. its earliest sign are red lesions, a general term that groups both microaneurysms (mas) and hemorrhages (hes). in daily clinical practice, these lesions are manually detected by physicians using fundus photographs. however, this task is tedious and time consuming, and requires an intensive effort due to the small size of the lesions and their lack of contrast. computer-assisted diagnosis of dr based on red lesion detection is being actively explored due to its improvement effects both in clinicians consistency and accuracy. moreover, it provides comprehensive feedback that is easy to assess by the physicians. several methods for detecting red lesions have been proposed in the literature, most of them based on characterizing lesion candidates using hand crafted features, and classifying them into true or false positive detections. deep learning based approaches, by contrast, are scarce in this domain due to the high expense of annotating the lesions manually.","['ensemble deep learning based approach', 'red lesion detection', 'fundus images']"
"molecular docking, scoring, and virtual screening play an increasingly important role in computer-aided drug discovery. scoring functions (sfs) are typically employed to predict the binding conformation (docking task), binding affinity (scoring task), and binary activity level (screening task) of ligands against a critical protein target in a disease's pathway. in most molecular docking software packages available today, a generic binding affinity-based (ba-based) sf is invoked for all three tasks to solve three different, but related, prediction problems. the limited predictive accuracies of such sfs in these three tasks has been a major roadblock toward cost-effective drug discovery. therefore, in this work, we develop bt-score, an ensemble machine-learning (ml) sf of boosted decision trees and thousands of predictive descriptors to estimate ba. bt-score reproduced ba of out-of-sample test complexes with correlation of 0.825. even with this high accuracy in the scoring task, we demonstrate that the docking and screening performance of bt-score and other ba-based sfs is far from ideal. this has motivated us to build two task-specific ml sfs for the docking and screening problems. we propose bt-dock, a boosted-tree ensemble model trained on a large number of native and computer-generated ligand conformations and optimized to predict binding poses explicitly. this model has shown an average improvement of 25% over its ba-based counterparts in different ligand pose prediction scenarios. similar improvement has also been obtained by our screening-based sf, bt-screen, which directly models the ligand activity labeling task as a classification problem. bt-screen is trained on thousands of active and inactive protein-ligand complexes to optimize it for finding real actives from databases of ligands not seen in its training set. in addition to the three task-specific sfs, we propose a novel multi-task deep neural network (mt-net) that is trained on data from the three tasks to simultaneously predict binding poses, affinities, and activity levels. we show that the performance of mt-net is superior to conventional sfs and on a par with or better than models based on single-task neural networks.","['predicting ligand binding poses', 'specific scoring functions', 'screening enrichment', 'task', 'affinity']"
"machine learning classifiers are shown to outperform conventional matched field processing for a deep water (600\u2009m depth) ocean acoustic-based ship range estimation problem in the santa barbara channel experiment when limited environmental information is known. recordings of three different ships of opportunity on a vertical array were used as training and test data for the feed-forward neural network and support vector machine classifiers, demonstrating the feasibility of machine learning methods to locate unseen sources. the classifiers perform well up to 10\u2009km range whereas the conventional matched field processing fails at about 4\u2009km range without accurate environmental information.","['santa barbara channel using machine learning classifiers', 'ship localization']"
"cancer is a complex worldwide health problem associated with high mortality. with the rapid development of the high-throughput sequencing technology and the application of various machine learning methods that have emerged in recent years, progress in cancer prediction has been increasingly made based on gene expression, providing insight into effective and accurate treatment decision making. thus, developing machine learning methods, which can successfully distinguish cancer patients from healthy persons, is of great current interest. however, among the classification methods applied to cancer prediction so far, no one method outperforms all the others.","['model ensemble method', 'deep learning', 'cancer prediction', 'based multi']"
"we propose a deep-learning-based classification of data pages used in holographic memory. we numerically investigated the classification performance of a conventional multilayer perceptron (mlp) and a deep neural network, under the condition that reconstructed page data are contaminated by some noise and are randomly laterally shifted. when data pages are randomly laterally shifted, the mlp was found to have a classification accuracy of 93.02%, whereas the deep neural network was able to classify data pages at an accuracy of 99.98%. the accuracy of the deep neural network is 2 orders of magnitude better than the mlp.","['based data page classification', 'convolutional neural network', 'holographic memory']"
"conventional methods of matrix completion are linear methods that are not effective in handling data of nonlinear structures. recently a few researchers attempted to incorporate nonlinear techniques into matrix completion but there still exists considerable limitations. in this paper, a novel method called deep matrix factorization (dmf) is proposed for nonlinear matrix completion. different from conventional matrix completion methods that are based on linear latent variable models, dmf is on the basis of a nonlinear latent variable model. dmf is formulated as a deep-structure neural network, in which the inputs are the low-dimensional unknown latent variables and the outputs are the partially observed variables. in dmf, the inputs and the parameters of the multilayer neural network are simultaneously optimized to minimize the reconstruction errors for the observed entries. then the missing entries can be readily recovered by propagating the latent variables to the output layer. dmf is compared with state-of-the-art methods of linear and nonlinear matrix completion in the tasks of toy matrix completion, image inpainting and collaborative filtering. the experimental results verify that dmf is able to provide higher matrix completion accuracy than existing methods do and dmf is applicable to large matrices.","['deep matrix factorization', 'matrix completion']"
"the contrast-enhanced ultrasound (ceus) has been a widely accepted imaging modality for diagnosis of liver cancers. in clinical practice, several typical images selected from enhancement patterns of the arterial, portal venous and late phases can provide reliable information basis for diagnosis. in this work, we propose to develop a ceus-based computer-aided diagnosis (cad) for liver cancers with only three typical ceus images selected from three phases, which simulates the clinical diagnosis mode of radiologists. in the proposed cad, the deep canonical correlation analysis (dcca) is first performed on three ceus pairs between arterial and portal venous phases, arterial and late phases, respectively, due to the effectiveness of multi-view fusion of dcca. the generated six-view features are then fed to a multiple kernel learning (mkl) classifier to further promote the predictive diagnosis result. the experimental results indicate that the proposed dcca-mkl algorithm achieves best performance for discriminating benign liver tumors from malignant liver cancers.","['deep canonical correlation analysis', 'liver tumors', 'kernel learning', 'based classification', 'multi', 'ceus']"
our purpose was to use deep learning for the automated detection of age-related macular degeneration (amd) in spectral domain optical coherence tomography (sd-oct).,"['spectral domain optical coherence tomography using deep learning', 'related macular degeneration', 'exudative age', 'automated detection']"
"happiness is a universal fundamental human goal. since the emergence of positive psychology, a major focus in psychological research has been to study the role of certain factors in the prediction of happiness. the conventional methodologies are based on linear relationships, such as the commonly used multivariate linear regression (mlr), which may suffer from the lack of representative capacity to the varied psychological features. using deep neural networks (dnn), we define a happiness degree predictor (h-dp) based on the answers to five psychometric standardized questionnaires.","['happiness degree predictor using', 'deep learning architectures', 'conceptual data structure']"
"conventional decoding pipeline for brain-machine interfaces (bmis) consists of chained different stages of feature extraction, time-frequency analysis and statistical learning models. each of these stages uses a different algorithm trained in a sequential manner, which makes it difficult to make the whole system adaptive. the goal was to create an adaptive online system with a single objective function and a single learning algorithm so that the whole system can be trained in parallel to increase the decoding performance. here, we used deep neural networks consisting of convolutional neural networks (cnn) and a special kind of recurrent neural network (rnn) called long short term memory (lstm) to address these needs.","['ecog using deep learning', 'finger trajectory', 'decoding']"
"heart transplantations have made it possible to extend the median survival time to 12 years for patients with end-stage heart diseases. this operation is unfortunately limited by the availability of donor organs and patients have to wait on average about 200 days in a waiting list before being operated. this waiting time varies considerably across the patients. in this paper, we studied the outcome for patients entering a transplantation waiting list using deep learning techniques. we implemented a model in the form of two-layer neural networks and we predicted the outcome as still waiting, transplanted or dead in the waiting list, at three different time points: 180 days, 365 days, and 730 days. as data source, we used the united network for organ sharing (unos) registry, where we extracted adult patients (>17 years) from january 2000 to december 2011. we trained our model using the keras framework, and we report f1 macro scores of respectively 0.674, 0.680, and 0.680 compared to a baseline of 0.271. we also applied a backward elimination procedure, using our neural network, to extract the 10 most significant parameters predicting the patient status for the three different time points.","['heart transplantation queue using deep learning', 'predicting', 'patients', 'outcome']"
"learning and memory are among the executive functions attributed to intelligent forms of life. unfortunately, there is a lack of clear understanding regarding the underlying mechanisms governing these functions. most of the modern day scientists attribute these functions solely to brain. however, in the latter half of last century, a number of reports suggested existence of extra-cranial memory and potential of its transfer between animals. some have linked this phenomenon to rna while others believed that peptides were responsible. the terms like ""educated rna"" and ""scotophobin"" were coined. this atypical work involving flatworms, yeast rna and scotophobin was received with deep skepticism and ultimately disregarded. however, the recent reproduction of some of this earlier work by scientists at tufts university has reignited the debate on the mechanisms of learning and memory. keeping this in view, we believe it is high time to summarize this historical work and discuss the possibilities to delineate these atypical claims. the objective is to incite the present day researchers to explore this opportunity under the perspective of newer advancements in science.","['memory exist outside', 'ways forward', 'historical review', 'transferred', 'issues', 'brain']"
"biomarkers are a class of measurable and evaluable indicators with the potential to predict disease initiation and progression. in contrast to disease-associated factors, biomarkers hold the promise to capture the changeable signatures of biological states. with methodological advances, computer-aided biomarker discovery has now become a burgeoning paradigm in the field of biomedical science. in recent years, the 'big data' term has accumulated for the systematical investigation of complex biological phenomena and promoted the flourishing of computational methods for systems-level biomarker screening. compared with routine wet-lab experiments, bioinformatics approaches are more efficient to decode disease pathogenesis under a holistic framework, which is propitious to identify biomarkers ranging from single molecules to molecular networks for disease diagnosis, prognosis and therapy. in this review, the concept and characteristics of typical biomarker types, e.g. single molecular biomarkers, module/network biomarkers, cross-level biomarkers, etc., are explicated on the guidance of systems biology. then, publicly available data resources together with some well-constructed biomarker databases and knowledge bases are introduced. biomarker identification models using mathematical, network and machine learning theories are sequentially discussed. based on network substructural and functional evidences, a novel bioinformatics model is particularly highlighted for microrna biomarker discovery. this article aims to give deep insights into the advantages and challenges of current computational approaches for biomarker detection, and to light up the future wisdom toward precision medicine and nation-wide healthcare.","['aided biomarker discovery', 'precision medicine', 'data resources', 'models', 'computer', 'applications']"
we explored how a deep learning (dl) approach based on hierarchical attention networks (hans) can improve model performance for multiple information extraction tasks from unstructured cancer pathology reports compared to conventional methods that do not sufﬁciently capture syntactic and semantic contexts from free-text documents.,"['hierarchical attention networks', 'cancer pathology reports', 'information extraction']"
"previous state-of-the-art systems on drug name recognition (dnr) and clinical concept extraction (cce) have focused on a combination of text ""feature engineering"" and conventional machine learning algorithms such as conditional random fields and support vector machines. however, developing good features is inherently heavily time-consuming. conversely, more modern machine learning approaches such as recurrent neural networks (rnns) have proved capable of automatically learning effective features from either random assignments or automated word ""embeddings"".","['specialized word embeddings', 'recurrent neural networks', 'entity recognition', 'domain named', 'health']"
"vision research has been shaped by the seminal insight that we can understand the higher-tier visual cortex from the perspective of multiple functional pathways with different goals. in this paper, we try to give a computational account of the functional organization of this system by reasoning from the perspective of multi-task deep neural networks. machine learning has shown that tasks become easier to solve when they are decomposed into subtasks with their own cost function. we hypothesize that the visual system optimizes multiple cost functions of unrelated tasks and this causes the emergence of a ventral pathway dedicated to vision for perception, and a dorsal pathway dedicated to vision for action. to evaluate the functional organization in multi-task deep neural networks, we propose a method that measures the contribution of a unit towards each task, applying it to two networks that have been trained on either two related or two unrelated tasks, using an identical stimulus set. results show that the network trained on the unrelated tasks shows a decreasing degree of feature representation sharing towards higher-tier layers while the network trained on related tasks uniformly shows high degree of sharing. we conjecture that the method we propose can be used to analyze the anatomical and functional organization of the visual system and beyond. we predict that the degree to which tasks are related is a good descriptor of the degree to which they share downstream cortical-units.","['task deep neural networks', 'visual pathways', 'cost functions', 'perspective', 'multi']"
"much attention has been given to machine learning and its perceived impact in radiology, particularly in light of recent success with image classification in international competitions. however, machine learning is likely to impact radiology outside of image interpretation long before a fully functional ""machine radiologist"" is implemented in practice. here, we describe an overview of machine learning, its application to radiology and other domains, and many cases of use that do not involve image interpretation. we hope that better understanding of these potential applications will help radiology practices prepare for the future and realize performance improvement and efficiency gains.","['applications beyond image interpretation', 'machine learning', 'radiology']"
"a long-standing goal of artificial intelligence is an algorithm that learns, tabula rasa, superhuman proficiency in challenging domains. recently, alphago became the first program to defeat a world champion in the game of go. the tree search in alphago evaluated positions and selected moves using deep neural networks. these neural networks were trained by supervised learning from human expert moves, and by reinforcement learning from self-play. here we introduce an algorithm based solely on reinforcement learning, without human data, guidance or domain knowledge beyond game rules. alphago becomes its own teacher: a neural network is trained to predict alphago's own move selections and also the winner of alphago's games. this neural network improves the strength of the tree search, resulting in higher quality move selection and stronger self-play in the next iteration. starting tabula rasa, our new program alphago zero achieved superhuman performance, winning 100-0 against the previously published, champion-defeating alphago.","['go without human knowledge', 'mastering', 'game']"
"tumor specimens contain a variety of healthy cells as well as cancerous cells, and this heterogeneity underlies resistance to various cancer therapies. but this problem has not been thoroughly investigated until recently. meanwhile, technological breakthroughs in imaging have led to an explosion of molecular and cellular profiling data from large numbers of samples, and modern machine learning approaches including deep learning have been shown to produce encouraging results by finding hidden structures and make accurate predictions. in this paper, we propose a deep learning based nucleus classification (deepnc) approach using paired histopathology and immunofluorescence images (for label), and demonstrate its classification prediction power. this method can solve current issue on discrepancy between genomic- or transcriptomic-based and pathology-based tumor purity estimates by improving histological evaluation. we also explain challenges in training a deep learning model for huge dataset.","['deep learning based nucleus classification', 'pancreas histological images']"
"white blood cells (wbcs) differential counting yields valued information about human health and disease. the current developed automated cell morphology equipments perform differential count which is based on blood smear image analysis. previous identification systems for wbcs consist of successive dependent stages; pre-processing, segmentation, feature extraction, feature selection, and classification. there is a real need to employ deep learning methodologies so that the performance of previous wbcs identification systems can be increased. classifying small limited datasets through deep learning systems is a major challenge and should be investigated.","['white blood cells identification system based', 'convolutional deep neural learning networks']"
"purpose: isocitrate dehydrogenase (idh) mutations in glioma patients confer longer survival and may guide treatment decision making. we aimed to predict the idh status of gliomas from mr imaging by applying a residual convolutional neural network to preoperative radiographic data.experimental design: preoperative imaging was acquired for 201 patients from the hospital of university of pennsylvania (hup), 157 patients from brigham and women's hospital (bwh), and 138 patients from the cancer imaging archive (tcia) and divided into training, validation, and testing sets. we trained a residual convolutional neural network for each mr sequence (flair, t2, t1 precontrast, and t1 postcontrast) and built a predictive model from the outputs. to increase the size of the training set and prevent overfitting, we augmented the training set images by introducing random rotations, translations, flips, shearing, and zooming.results: with our neural network model, we achieved idh prediction accuracies of 82.8% (auc = 0.90), 83.0% (auc = 0.93), and 85.7% (auc = 0.94) within training, validation, and testing sets, respectively. when age at diagnosis was incorporated into the model, the training, validation, and testing accuracies increased to 87.3% (auc = 0.93), 87.6% (auc = 0.95), and 89.1% (auc = 0.95), respectively.conclusions: we developed a deep learning technique to noninvasively predict idh genotype in grade ii-iv glioma using conventional mr imaging using a multi-institutional data set. clin cancer res; 24(5); 1073-81. ©2017 aacr.","['residual convolutional neural network', 'mr imaging', 'idh status', 'grade gliomas', 'low', 'high', 'determination']"
"automatic identification of specific osseous landmarks on the spinal radiograph can be used to automate calculations for correcting ligament instability and injury, which affect 75% of patients injured in motor vehicle accidents. in this work, we propose to use deep learning based object detection method as the first step towards identifying landmark points in lateral lumbar x-ray images. the significant breakthrough of deep learning technology has made it a prevailing choice for perception based applications, however, the lack of large annotated training dataset has brought challenges to utilizing the technology in medical image processing field. in this work, we propose to fine tune a deep network, faster-rcnn, a state-of-the-art deep detection network in natural image domain, using small annotated clinical datasets. in the experiment we show that, by using only 81 lateral lumbar x-ray training images, one can achieve much better performance compared to traditional sliding window detection method on hand crafted features. furthermore, we fine-tuned the network using 974 training images and tested on 108 images, which achieved average precision of 0.905 with average computation time of 3 second per image, which greatly outperformed traditional methods in terms of accuracy and efficiency.","['ray images using faster r', 'intervertebral disc detection', 'x', 'cnn']"
to present research models based on artificial intelligence and discuss the concept of cognitive computing and escience as disruptive factors in health and life science research methodologies.,"['obesity intervention programs', 'life science research', 'cognitive computing', 'artificial intelligence', 'health', 'escience']"
"regulatory sequences are not solely defined by their nucleic acid sequence but also by their relative distances to genomic landmarks such as transcription start site, exon boundaries or polyadenylation site. deep learning has become the approach of choice for modeling regulatory sequences because of its strength to learn complex sequence features. however, modeling relative distances to genomic landmarks in deep neural networks has not been addressed.","['spline transformations increases prediction accuracy', 'modeling positional effects', 'deep neural networks', 'regulatory sequences']"
"in this paper, we propose a novel medical image segmentation using iterative deep learning framework. we have combined an iterative learning approach and an encoder-decoder network to improve segmentation results, which enables to precisely localize the regions of interest (rois) including complex shapes or detailed textures of medical images in an iterative manner. the proposed iterative deep convolutional encoder-decoder network consists of two main paths: convolutional encoder path and convolutional decoder path with iterative learning. experimental results show that the proposed iterative deep learning framework is able to yield excellent medical image segmentation performances for various medical images. the effectiveness of the proposed method has been proved by comparing with other state-of-the-art medical image segmentation methods.","['iterative deep convolutional encoder', 'medical image segmentation', 'decoder network']"
"in this study, the super-resolution convolutional neural network (srcnn) scheme, which is the emerging deep-learning-based super-resolution method for enhancing image resolution in chest ct images, was applied and evaluated using the post-processing approach. for evaluation, 89 chest ct cases were sampled from the cancer imaging archive. the 89 ct cases were divided randomly into 45 training cases and 44 external test cases. the srcnn was trained using the training dataset. with the trained srcnn, a high-resolution image was reconstructed from a low-resolution image, which was down-sampled from an original test image. for quantitative evaluation, two image quality metrics were measured and compared to those of the conventional linear interpolation methods. the image restoration quality of the srcnn scheme was significantly higher than that of the linear interpolation methods (p\xa0<\xa00.001 or p\xa0<\xa00.05). the high-resolution image reconstructed by the srcnn scheme was highly restored and comparable to the original reference image, in particular, for a ×2 magnification. these results indicate that the srcnn scheme significantly outperforms the linear interpolation methods for enhancing image resolution in chest ct images. the results also suggest that srcnn may become a potential solution for generating high-resolution ct images from standard ct images.","['resolution convolutional neural network', 'enhancing image resolution', 'chest ct', 'super', 'application']"
"electromyogram (emg) signals contain useful information of the neuromuscular diseases like amyotrophic lateral sclerosis (als). als is a well-known brain disease, which can progressively degenerate the motor neurons. in this paper, we propose a deep learning based method for efficient classification of als and normal emg signals. spectrogram, continuous wavelet transform (cwt), and smoothed pseudo wigner-ville distribution (spwvd) have been employed for time-frequency (t-f) representation of emg signals. a convolutional neural network is employed to classify these features. in it, two convolution layers, two pooling layer, a fully connected layer and a lost function layer is considered in cnn architecture. the cnn architecture is trained with the reinforcement sample learning strategy. the efficiency of the proposed implementation is tested on publicly available emg dataset. the dataset contains 89 als and 133 normal emg signals with 24\xa0khz sampling frequency. experimental results show 96.80% accuracy. the obtained results are also compared with other methods, which show the superiority of the proposed method.","['amyotrophic lateral sclerosis disease based', 'reinforcement sample learning algorithm', 'convolutional neural network', 'classification']"
"existing summary statistics based upon optical coherence tomographic (oct) scans and/or visual fields (vfs) are suboptimal for distinguishing between healthy and glaucomatous eyes in the clinic. this study evaluates the extent to which a hybrid deep learning method (hdlm), combined with a single wide-field oct protocol, can distinguish eyes previously classified as either healthy suspects or mild glaucoma.","['field optical coherence tomography scans accurately classifies glaucoma suspects', 'hybrid deep learning', 'single wide']"
"artificial intelligence (ai), machine learning, and deep learning are terms now seen frequently, all of which refer to computer algorithms that change as they are exposed to more data. many of these algorithms are surprisingly good at recognizing objects in images. the combination of large amounts of machine-consumable digital data, increased and cheaper computing power, and increasingly sophisticated statistical models combine to enable machines to find patterns in data in ways that are not only cost-effective but also potentially beyond humans' abilities. building an ai algorithm can be surprisingly easy. understanding the associated data structures and statistics, on the other hand, is often difficult and obscure. converting the algorithm into a sophisticated product that works consistently in broad, general clinical use is complex and incompletely understood. to show how these ai products reduce costs and improve outcomes will require clinical translation and industrial-grade integration into routine workflow. radiology has the chance to leverage ai to become a center of intelligently aggregated, quantitative, diagnostic information. centaur radiologists, formed as a synergy of human plus computer, will provide interpretations using data extracted from images by humans and image-analysis computer algorithms, as well as the electronic health record, genomics, and other disparate sources. these interpretations will form the foundation of precision health care, or care customized to an individual patient. © rsna, 2017.","['next frontier', 'machines think', 'radiology']"
"tessellation in fundus is not only a visible feature for aged-related and myopic maculopathy but also confuse retinal vessel segmentation. the detection of tessellated images is an inevitable processing in retinal image analysis. in this work, we propose a model using convolutional neural network for detecting tessellated images. the input to the model is pre-processed fundus image, and the output indicate whether this photograph has tessellation or not. a database with 12,000 colour retinal images is collected to evaluate the classification performance. the best tessellation classifier achieves accuracy of 97.73% and auc value of 0.9659 using pretrained googlenet and transfer learning technique.",['deep tessellated retinal image detection using convolutional neural networks']
"the quality of input images significantly affects the outcome of automated diabetic retinopathy (dr) screening systems. unlike the previous methods that only consider simple low-level features such as hand-crafted geometric and structural features, in this paper we propose a novel method for retinal image quality classification (iqc) that performs computational algorithms imitating the working of the human visual system. the proposed algorithm combines unsupervised features from saliency map and supervised features coming from convolutional neural networks (cnn), which are fed to an svm to automatically detect high quality vs poor quality retinal fundus images. we demonstrate the superior performance of our proposed algorithm on a large retinal fundus image dataset and the method could achieve higher accuracy than other methods. although retinal images are used in this study, the methodology is applicable to the image quality assessment and enhancement of other types of medical images.","['dr screening using deep learning', 'image quality classification']"
"objective assessments of parkinson's disease (pd) patients' motor state using motion capture techniques are still rarely used in clinical practice, even though they may improve clinical management. one major obstacle relates to the large dimensionality of motor abnormalities in pd. we aimed to extract global motor performance measures covering different everyday motor tasks, as a function of a clinical intervention, i.e., deep brain stimulation (dbs) of the subthalamic nucleus.","['quantified via random forest feature classification', 'motor symptoms across different motor tasks', 'parkinson', 'disease', 'correlations']"
"prostate cancer (pca) is a major cause of death since ancient time documented in egyptian ptolemaic mummy imaging. pca detection is critical to personalized medicine and varies considerably under an mri scan. 172 patients with 2,602 morphologic images (axial 2d t2-weighted imaging) of the prostate were obtained. a deep learning with deep convolutional neural network (dcnn) and a non-deep learning with sift image feature and bag-of-word (bow), a representative method for image recognition and analysis, were used to distinguish pathologically confirmed pca patients from prostate benign conditions (bcs) patients with prostatitis or prostate benign hyperplasia (bph). in fully automated detection of pca patients, deep learning had a statistically higher area under the receiver operating characteristics curve (auc) than non-deep learning (p\u2009=\u20090.0007\u2009<\u20090.001). the aucs were 0.84 (95% ci 0.78-0.89) for deep learning method and 0.70 (95% ci 0.63-0.77) for non-deep learning method, respectively. our results suggest that deep learning with dcnn is superior to non-deep learning with sift image feature and bow model for fully automated pca patients differentiation from prostate bcs patients. our deep learning method is extensible to image modalities such as mr imaging, ct and pet of other organs.","['fully automated magnetic resonance imaging classification', 'deep learning versus non', 'deep learning', 'prostate cancer', 'searching']"
"purpose to evaluate the performance of a deep learning convolutional neural network (cnn) model compared with a traditional natural language processing (nlp) model in extracting pulmonary embolism (pe) findings from thoracic computed tomography (ct) reports from two institutions. materials and methods contrast material-enhanced ct examinations of the chest performed between january 1, 1998, and january 1, 2016, were selected. annotations by two human radiologists were made for three categories: the presence, chronicity, and location of pe. classification of performance of a cnn model with an unsupervised learning algorithm for obtaining vector representations of words was compared with the open-source application pefinder. sensitivity, specificity, accuracy, and f1 scores for both the cnn model and pefinder in the internal and external validation sets were determined. results the cnn model demonstrated an accuracy of 99% and an area under the curve value of 0.97. for internal validation report data, the cnn model had a statistically significant larger f1 score (0.938) than did pefinder (0.867) when classifying findings as either pe positive or pe negative, but no significant difference in sensitivity, specificity, or accuracy was found. for external validation report data, no statistical difference between the performance of the cnn model and pefinder was found. conclusion a deep learning cnn model can classify radiology free-text reports with accuracy equivalent to or beyond that of an existing traditional nlp model. © rsna, 2017 online supplemental material is available for this article.","['classify radiology free', 'text reports', 'deep learning']"
"precision oncology involves identifying drugs that will effectively treat a tumor and then prescribing an optimal clinical treatment regimen. however, most first-line chemotherapy drugs do not have biomarkers to guide their application. for molecularly targeted drugs, using the genomic status of a drug target as a therapeutic indicator has limitations. in this study, machine learning methods (e.g., deep learning) were used to identify informative features from genome-scale omics data and to train classifiers for predicting the effectiveness of drugs in cancer cell lines. the methodology introduced here can accurately predict the efficacy of drugs, regardless of whether they are molecularly targeted or nonspecific chemotherapy drugs. this approach, on a per-drug basis, can identify sensitive cancer cells with an average sensitivity of 0.82 and specificity of 0.82; on a per-cell line basis, it can identify effective drugs with an average sensitivity of 0.80 and specificity of 0.82. this report describes a data-driven precision medicine approach that is not only generalizable but also optimizes therapeutic efficacy. the framework detailed herein, when successfully translated to clinical environments, could significantly broaden the scope of precision oncology beyond targeted therapies, benefiting an expanded proportion of cancer patients. mol cancer res; 16(2); 269-78. ©2017 aacr.","['precision oncology beyond targeted therapy', 'machine learning matches', 'combining omics data', 'effective therapeutics', 'cancer cells', 'majority']"
"indoor air quality analysis is of interest to understand the abnormal atmospheric phenomena and external factors that affect air quality. by recording and analyzing quality measurements, we are able to observe patterns in the measurements and predict the air quality of near future. we designed a microchip made out of sensors that is capable of periodically recording measurements, and proposed a model that estimates atmospheric changes using deep learning. in addition, we developed an efficient algorithm to determine the optimal observation period for accurate air quality prediction. experimental results with real-world data demonstrate the feasibility of our approach.","['indoor air quality analysis using deep learning', 'sensor data']"
"sequence classification is crucial in predicting the function of newly discovered sequences. in recent years, the prediction of the incremental large-scale and diversity of sequences has heavily relied on the involvement of machine-learning algorithms. to improve prediction accuracy, these algorithms must confront the key challenge of extracting valuable features. in this work, we propose a feature-enhanced protein classification approach, considering the rich generation of multiple sequence alignment algorithms, n-gram probabilistic language model and the deep learning technique. the essence behind the proposed method is that if each group of sequences can be represented by one feature sequence, composed of homologous sites, there should be less loss when the sequence is rebuilt, when a more relevant sequence is added to the group. on the basis of this consideration, the prediction becomes whether a query sequence belonging to a group of sequences can be transferred to calculate the probability that the new feature sequence evolves from the original one. the proposed work focuses on the hierarchical classification of g-protein coupled receptors (gpcrs), which begins by extracting the feature sequences from the multiple sequence alignment results of the gpcrs sub-subfamilies. the n-gram model is then applied to construct the input vectors. finally, these vectors are imported into a convolutional neural network to make a prediction. the experimental results elucidate that the proposed method provides significant performance improvements. the classification error rate of the proposed method is reduced by at least 4.67% (family level i) and 5.75% (family level ii), in comparison with the current state-of-the-art methods. the implementation program of the proposed work is freely available at: https://github.com/alanfchina/cnn .","['protein coupled receptors based', 'multiple sequence alignments', 'convolutional neural network', 'rich generation', 'gram transformation', 'n', 'g', 'classification']"
"with the latest development in the design and fabrication of high-density multi-electrode arrays (mea) for in-vivo neural recordings, the spatiotemporal information in the recorded signals allows for refined estimation of a neuron's location around the probe. in parallel, advances in computational models for neural activity enables simulation of recordings from neurons with detailed morphology. our approach uses deep learning algorithms on a large set of such simulation data to extract the 3d position of the neuronal somata. multi-compartment models from 13 different neural morphologies in layer 5 (l5) of the rat's neocortex are placed at random locations and with different alignments with respect to the mea. the sodium trough and repolarisation peak images on the mea serve as input features for a convolutional neural network (cnn), which predicts the neural location robustly and with low error rates. the forward modeling/machine learning approach yields very accurate results for the different morphologies and is able to cope with different neuron alignments.","['vivo recordings using deep learning', 'localizing neuronal somata', 'electrode array', 'multi']"
"the purpose of this paper is to explore group work assessment underpinned by constructive alignment theory to develop a new assessment pedagogy. a review was undertaken of an existing module 'mental health nursing 1', with student nurses participating in the bsc (hons) nursing programme. constructive alignment theory requires teachers to adopt a deep approach to learning where module learning outcomes are aligned with the teaching environment and modes of assessment. as the module progressed, reviewing the mental health nursing 1 module became an excellent opportunity to begin to understand how constructive alignment theory can inform a group work assessment pedagogy. working using a constructively aligned assessment process became a valuable learning experience for the module leader whilst at the same time revealed a gap in the research around the impact of constructively aligned teaching and group work assessment.","['group work assessment pedagogy using constructive alignment theory', 'development']"
"the medical subdomain of a clinical note, such as cardiology or neurology, is useful content-derived metadata for developing machine learning downstream applications. to classify the medical subdomain of a note accurately, we have constructed a machine learning-based natural language processing (nlp) pipeline and developed medical subdomain classifiers based on the content of the note.","['based natural language processing approach', 'medical subdomain classification', 'clinical notes using', 'machine learning']"
"deep learning and analysis of heavy metal concentration are very crucial to our life, for it plays an essential role in both environmental and human health. in this paper, we developed a new cu (ii) ions sensor made by all organic material with bending and stretching properties. the new sensor consists of chlorophyll-a extracted from fresh leaves of common garcinia, plant fiber and with the use of pdms as a substrate. fluorescence spectra study shows that chlorophyll-a is significantly much more sensitive to cu (ii) ions than any other heavy metal ions and the device sensitivity outperforms all the cu (ii) ions sensors ever reported. the result fully shows the selectivity of chlorophyll-a toward cu (ii) ions. bending and stretching tests show that the sensor has an outstanding durability, which can be used to develop accompanying applications, such as real-time sampling and the analysis of cu (ii) concentration specified in athlete's sweat or patients with brain death and parkinson's disease.","['organic label', 'like copper']"
"convolutional neural network (cnn) driven by image recognition has been shown to be able to explain cortical responses to static pictures at ventral-stream areas. here, we further showed that such cnn could reliably predict and decode functional magnetic resonance imaging data from humans watching natural movies, despite its lack of any mechanism to account for temporal dynamics or feedback processing. using separate data, encoding and decoding models were developed and evaluated for describing the bi-directional relationships between the cnn and the brain. through the encoding models, the cnn-predicted areas covered not only the ventral stream, but also the dorsal stream, albeit to a lesser degree; single-voxel response was visualized as the specific pixel pattern that drove the response, revealing the distinct representation of individual cortical location; cortical activation was synthesized from natural images with high-throughput to map category representation, contrast, and selectivity. through the decoding models, fmri signals were directly decoded to estimate the feature representations in both visual and semantic spaces, for direct visual reconstruction and semantic categorization, respectively. these results corroborate, generalize, and extend previous findings, and highlight the value of using deep learning, as an all-in-one model of the visual cortex, to understand and decode natural vision.","['dynamic natural vision', 'neural encoding', 'deep learning', 'decoding']"
"we present a novel model for timing behavior. this model is based on the firing property of neurons in the superficial layers of the posterior cingulate granular retrosplenial cortex (grs) and does not require a unit-time clock. suppose that event b occurs n seconds after event a and triggers behavior c. by our behavioral, physiological and anatomical experiments, we found the following facts. 1) thalamic input carrying sensory information, a, is provided to the superficial layers of the grs and delayed by the lateral cascading connection within the layers. 2) hippocampal input (recall information, b) is provided to the deep layers of the grs. 3) the grs neurons show timing behavior that is dependent on the trial cycle. 4) lesioning the grs impaired the acquisition of trace fear memory and the production of fear-induced freezing behavior, c. thus we would propose that neural circuits in the grs play a crucial role in the animal behaviors requiring time discrimination. the question of whether hebbian learning occurs at the convergent neurons that integrates thalamic and hippocampal information remains unanswered.","['posterior cingulate cascading delay model', 'timing behavior ].']"
"segmentation is the first and most important task in computer-based diagnosis of skin cancer since other tasks are relied mainly on accurately segmented lesions. recently, deep learning as a mainstream method in machine learning has shown promising results on semantic image segmentation. in this paper, we demonstrate applying deep convolutional networks to two main segmentation tasks in melanoma diagnosis, a lesion segmentation task followed by a lesion dermoscopic feature segmentation task. the proposed method is evaluated on a database from isbi challenge 2016. by using a hybrid model, computation load for the second task decreases and masks provided by lesion segmentation have been used to enhance the results for the feature segmentation task as well. the results are close to the best results of isbi challenge 2016. the proposed model yields quite promising results although it is based on very initial hybrid model without an aggressive fine-tuning that is heavily required in deep learning implementations. therefore, there is a room for further improvements.","['skin cancer analysis', 'dermoscopic feature segmentation', 'automated lesion segmentation']"
"speech signal is usually degraded by room reverberation and additive noises in real environments. this paper focuses on separating target speech signal in reverberant conditions from binaural inputs. binaural separation is formulated as a supervised learning problem, and we employ deep learning to map from both spatial and spectral features to a training target. with binaural inputs, we first apply a fixed beamformer and then extract several spectral features. a new spatial feature is proposed and extracted to complement the spectral features. the training target is the recently suggested ideal ratio mask. systematic evaluations and comparisons show that the proposed system achieves very good separation performance and substantially outperforms related algorithms under challenging multi-source and reverberant environments.","['deep learning based binaural speech separation', 'reverberant environments']"
"in the early 1900s, breed society herdbooks had been established and milk-recording programs were in their infancy. farmers wanted to improve the productivity of their cattle, but the foundations of population genetics, quantitative genetics, and animal breeding had not been laid. early animal breeders struggled to identify genetically superior families using performance records that were influenced by local environmental conditions and herd-specific management practices. daughter-dam comparisons were used for more than 30 yr and, although genetic progress was minimal, the attention given to performance recording, genetic theory, and statistical methods paid off in future years. contemporary (herdmate) comparison methods allowed more accurate accounting for environmental factors and genetic progress began to accelerate when these methods were coupled with artificial insemination and progeny testing. advances in computing facilitated the implementation of mixed linear models that used pedigree and performance data optimally and enabled accurate selection decisions. sequencing of the bovine genome led to a revolution in dairy cattle breeding, and the pace of scientific discovery and genetic progress accelerated rapidly. pedigree-based models have given way to whole-genome prediction, and bayesian regression models and machine learning algorithms have joined mixed linear models in the toolbox of modern animal breeders. future developments will likely include elucidation of the mechanisms of genetic inheritance and epigenetic modification in key biological pathways, and genomic data will be used with data from on-farm sensors to facilitate precision management on modern dairy farms.","['deep learning algorithms', 'year review', 'genetic selection', 'dam comparisons', 'dairy cattle', 'methods', 'impact', 'daughter', '100']"
"recent progress in biosensor technology and wearable devices has created a formidable opportunity for remote healthcare monitoring systems as well as real-time diagnosis and disease prevention. the use of data mining techniques is indispensable for analysis of the large pool of data generated by the wearable devices. deep learning is among the promising methods for analyzing such data for healthcare applications and disease diagnosis. however, the conventional deep neural networks are computationally intensive and it is impractical to use them in real-time diagnosis with low-powered on-body devices. we propose staged inference using conditional deep learning (sicdl), as an energy efficient approach for creating healthcare monitoring systems. for smart diagnostics, we observe that all diagnoses are not equally challenging. the proposed approach thus decomposes the diagnoses into preliminary analysis (such as healthy vs unhealthy) and detailed analysis (such as identifying the specific type of cardio disease). the preliminary diagnosis is conducted real-time with a low complexity neural network realized on the resource-constrained on-body device. the detailed diagnosis requires a larger network that is implemented remotely in cloud and is conditionally activated only for detailed diagnosis (unhealthy individuals). we evaluated the proposed approach using available physiological sensor data from physionet databases, and achieved 38% energy reduction in comparison to the conventional deep learning approach.","['staged inference using conditional deep learning', 'time smart diagnosis', 'energy efficient real']"
"the hippocampus is a particularly interesting target for neuroscience research studies due to its essential role within the human brain. in large human cohort studies, bilateral hippocampal structures are frequently identified and measured to gain insight into human behaviour or genomic variability in neuropsychiatric disorders of interest. automatic segmentation is performed using various algorithms, with freesurfer being a popular option. in this manuscript, we present a method to segment the bilateral hippocampus using a deep-learned appearance model. deep convolutional neural networks (convnets) have shown great success in recent years, due to their ability to learn meaningful features from a mass of training data. our method relies on the following key novelties: (i) we use a wide and variable training set coming from multiple cohorts (ii) our training labels come in part from the output of the freesurfer algorithm, and (iii) we include synthetic data and use a powerful data augmentation scheme. our method proves to be robust, and it has fast inference (<30s total per subject), with trained model available online (https://github.com/bthyreau/hippodeep). we depict illustrative results and show extensive qualitative and quantitative cohort-wide comparisons with freesurfer. our work demonstrates that deep neural-network methods can easily encode, and even improve, existing anatomical knowledge, even when this knowledge exists in algorithmic form.","['transferring algorithmic knowledge', 'large cohort processing', 'segmentation', 'hippocampus']"
"this paper explores the effectiveness of applying a deep learning based method to segment the amniotic fluid and fetal tissues in fetal ultrasound (us) images. the deeply learned model firstly encodes the input image into down scaled feature maps by convolution and pooling structures, then up-scale the feature maps to confidence maps by corresponded un-pooling and convolution layers. additional convolution layers with 1×1 sized kernels are adopted to enhance the feature representations, which could be used to further improve the discriminative learning of our model. we effectively update the weights of the network by fine-tuning on part of the layers from a pre-trained model. by conducting experiments using clinical data, the feasibility of our proposed approach is compared and discussed. the result proves that this work achieves satisfied results for segmentation of specific anatomical structures from us images.","['fetal ultrasound images', 'automatic fetal body', 'amniotic fluid segmentation', 'inner layers', 'decoder network', 'encoder']"
"tracing the use of computers in the radiology department from administrative functions through image acquisition, storage, and reporting, to early attempts at improved diagnosis, we begin to imagine possible new frontiers for their use in exam interpretation. given their initially slow but ultimately substantial progress in the noninterpretive areas, we are left desiring and even expecting more in the interpretation realm. new technological advances may provide the next wave of progress and radiologists should be early adopters. several potential applications are discussed and hopefully will serve to inspire future progress.","['next frontier', 'deep learning', 'artificial intelligence', 'radiology']"
"breast cancer is the most common malignant disease in women worldwide. in recent decades, earlier diagnosis and better adjuvant therapy have substantially improved patient outcome. diagnosis by histopathology has proven to be instrumental to guide breast cancer treatment, but new challenges have emerged as our increasing understanding of cancer over the years has revealed its complex nature. as patient demand for personalized breast cancer therapy grows, we face an urgent need for more precise biomarker assessment and more accurate histopathologic breast cancer diagnosis to make better therapy decisions. the digitization of pathology data has opened the door to faster, more reproducible, and more precise diagnoses through computerized image analysis. software to assist diagnostic breast pathology through image processing techniques have been around for years. but recent breakthroughs in artificial intelligence (ai) promise to fundamentally change the way we detect and treat breast cancer in the near future. machine learning, a subfield of ai that applies statistical methods to learn from data, has seen an explosion of interest in recent years because of its ability to recognize patterns in data with less need for human instruction. one technique in particular, known as deep learning, has produced groundbreaking results in many important problems including image classification and speech recognition. in this review, we will cover the use of ai and deep learning in diagnostic breast pathology, and other recent developments in digital image analysis.","['image processing techniques', 'digital image analysis', 'breast pathology', 'artificial intelligence']"
"the study of phenomes or phenomics has been a central part of biology. the field of automatic phenotype acquisition technologies based on images has seen an important advance in the last years. as with other high-throughput technologies, it addresses a common set of problems, including data acquisition and analysis. in this review, we give an overview of the main systems developed to acquire images. we give an in-depth analysis of image processing with its major issues and the algorithms that are being used or emerging as useful to obtain data out of images in an automatic fashion.","['image data analysis algorithms', 'image acquisition technologies', 'plant phenomics', 'overview']"
"in our preliminary study, the reflectance signatures obtained from hyperspectral imaging (hsi) of normal and abnormal corneal epithelium tissues of porcine show similar morphology with subtle differences. here we present image enhancement algorithms that can be used to improve the interpretability of data into clinically relevant information to facilitate diagnostics. a total of 25 corneal epithelium images without the application of eye staining were used. three image feature extraction approaches were applied for image classification: (i) image feature classification from histogram using a support vector machine with a gaussian radial basis function (svm-grbf); (ii) physical image feature classification using deep-learning convolutional neural networks (cnns) only; and (iii) the combined classification of cnns and svm-linear. the performance results indicate that our chosen image features from the histogram and length-scale parameter were able to classify with up to 100% accuracy; particularly, at cnns and cnns-svm, by employing 80% of the data sample for training and 20% for testing. thus, in the assessment of corneal epithelium injuries, hsi has high potential as a method that could surpass current technologies regarding speed, objectivity, and reliability.","['hyperspectral image enhancement', 'corneal epithelium injuries', 'mixture deep', 'learning classification']"
"in this paper a new method for continuous pain detection is proposed. one approach to detect the presence of pain is by processing images taken from the face. it has been reported that expression of pain from the face can be detected utilizing action units (aus). in this manner, each action units must be detected separately and then combined together through a linear expression. also, pain detection can be directly done from a painful face. there are different methods to extract features of both shape and appearance. shape and appearance features must be extracted separately, and then used to train a classifier. here, a hierarchical unsupervised feature learning approach is proposed in order to extract the features needed for pain detection from facial images. in this work, features are extracted using convolutional deep belief network (cdbn). the extracted features include different properties of painful images such as head movements, shape and appearance information. the proposed model was tested on the publicly available unbc macmaster shoulder pain archive database and we achieved near 95% for the area under roc curve metric that is prominent with respect to the other reported results.","['facial images using unsupervised feature learning approach', 'pain detection']"
"mammographic breast density is an established risk marker for breast cancer and is visually assessed by radiologists in routine mammogram image reading, using four qualitative breast imaging and reporting data system (bi-rads) breast density categories. it is particularly difficult for radiologists to consistently distinguish the two most common and most variably assigned bi-rads categories, i.e., ""scattered density"" and ""heterogeneously dense"". the aim of this work was to investigate a deep learning-based breast density classifier to consistently distinguish these two categories, aiming at providing a potential computerized tool to assist radiologists in assigning a bi-rads category in current clinical workflow.","['classifying mammographic breast density categories', 'deep learning method']"
downward causation is the controversial idea that 'higher' levels of organization can causally influence behaviour at 'lower' levels of organization. here i propose that we can gain traction on downward causation by being operational and examining how adaptive systems identify regularities in evolutionary or learning time and use these regularities to guide behaviour. i suggest that in many adaptive systems components collectively compute their macroscopic worlds through coarse-graining. i further suggest we move from simple feedback to downward causation when components tune behaviour in response to estimates of collectively computed macroscopic properties. i introduce a weak and strong notion of downward causation and discuss the role the strong form plays in the origins of new organizational levels. i illustrate these points with examples from the study of biological and social systems and deep neural networks.this article is part of the themed issue 'reconceptualizing the origins of life'.,"['downward causation mechanism', 'graining', 'coarse']"
"stress management is related to public healthcare and quality of life; an accurate stress classification method is necessary for the design of stress monitoring systems. therefore, the goal of this study was to design a novel stress classification model using a deep learning method.","['stress classification model using deep belief networks', 'stress monitoring', 'development']"
"although there have been impressive strides in detector development for time-of-flight positron emission tomography, most detectors still make use of simple signal processing methods to extract the time-of-flight information from the detector signals. in most cases, the timing pick-off for each waveform is computed using leading edge discrimination or constant fraction discrimination, as these were historically easily implemented with analog pulse processing electronics. however, now with the availability of fast waveform digitizers, there is opportunity to make use of more of the timing information contained in the coincident detector waveforms with advanced signal processing techniques. here we describe the application of deep convolutional neural networks (cnns), a type of machine learning, to estimate time-of-flight directly from the pair of digitized detector waveforms for a coincident event. one of the key features of this approach is the simplicity in obtaining ground-truth-labeled data needed to train the cnn: the true time-of-flight is determined from the difference in path length between the positron emission and each of the coincident detectors, which can be easily controlled experimentally. the experimental setup used here made use of two photomultiplier tube-based scintillation detectors, and a point source, stepped in 5\u2009mm increments over a 15\u2009cm range between the two detectors. the detector waveforms were digitized at 10 gs s-1 using a bench-top oscilloscope. the results shown here demonstrate that cnn-based time-of-flight estimation improves timing resolution by 20% compared to leading edge discrimination (231\u2009ps versus 185\u2009ps), and 23% compared to constant fraction discrimination (242\u2009ps versus 185\u2009ps). by comparing several different cnn architectures, we also showed that cnn depth (number of convolutional and fully connected layers) had the largest impact on timing resolution, while the exact network parameters, such as convolutional filter size and number of feature maps, had only a minor influence.","['using convolutional neural networks', 'pet detector waveforms', 'estimate time', 'flight']"
"for deep learning on image data, a common approach is to augment the training data by artificial new images, using techniques like moving windows, scaling, affine distortions, and elastic deformations. in contrast to image data, electroencephalographic (eeg) data suffers even more from the lack of sufficient training data.","['rotational data augmentation', 'electroencephalographic data']"
"nuclei detection in histology images is an essential part of computer aided diagnosis of cancers and tumors. it is a challenging task due to diverse and complicated structures of cells. in this work, we present an automated technique for detection of cellular nuclei in hematoxylin and eosin stained histopathology images. our proposed approach is based on kernelized correlation filters. correlation filters have been widely used in object detection and tracking applications but their strength has not been explored in the medical imaging domain up till now. our experimental results show that the proposed scheme gives state of the art accuracy and can learn complex nuclear morphologies. like deep learning approaches, the proposed filters do not require engineering of image features as they can operate directly on histopathology images without significant preprocessing. however, unlike deep learning methods, the large-margin correlation filters developed in this work are interpretable, computationally efficient and do not require specialized or expensive computing hardware.","['histopathology images', 'correlation filters', 'cellular nuclei', 'detection']"
"cephalopods exhibit unique behaviors such as camouflage and tactile learning. the brain functions correlated to these behaviors have long been analyzed through behavioral observations of animals subject to surgical manipulation or electrical stimulation of brain lobes. however, physiological methods have rarely been introduced to investigate the functions of each individual lobe, though physiological work on giant axons and slices of the vertical lobe system of the cephalopods have provided deep insights into ion conductance of nerves and long-term synaptic plasticity. the lack of in vivo physiological work is partly due to difficulties in immobilizing the brain which is contained within the soft body and applying calcium indicators to the cephalopod central nervous system.","['central nervous system', 'calcium imaging method', 'spatial patterns', 'pygmy squid', 'neural responses', 'idiosepius paradoxus', 'visualize']"
"this paper describes three coarse image description strategies, which are meant to promote a rough perception of surrounding objects for visually impaired individuals, with application to indoor spaces. the described algorithms operate on images (grabbed by the user, by means of a chest-mounted camera), and provide in output a list of objects that likely exist in his context across the indoor scene. in this regard, first, different colour, texture, and shape-based feature extractors are generated, followed by a feature learning step by means of autoencoder (ae) models. second, the produced features are fused and fed into a multilabel classifier in order to list the potential objects. the conducted experiments point out that fusing a set of ae-learned features scores higher classification rates with respect to using the features individually. furthermore, with respect to reference works, our method: (i) yields higher classification accuracies, and (ii) runs (at least four times) faster, which enables a potential full real-time application.","['visually impaired using autoencoder fusion strategies', 'time indoor scene description', 'visible cameras', 'real']"
"the malignancy risk differentiation of pulmonary nodule is one of the most challenge tasks of computer-aided diagnosis (cadx). most recently reported cadx methods or schemes based on texture and shape estimation have shown relatively satisfactory on differentiating the risk level of malignancy among the nodules detected in lung cancer screening. however, the existing cadx schemes tend to detect and analyze characteristics of pulmonary nodules from a statistical perspective according to local features only. enlightened by the currently prevailing learning ability of convolutional neural network (cnn), which simulates human neural network for target recognition and our previously research on texture features, we present a hybrid model that takes into consideration of both global and local features for pulmonary nodule differentiation using the largest public database founded by the lung image database consortium and image database resource initiative (lidc-idri). by comparing three types of cnn models in which two of them were newly proposed by us, we observed that the multi-channel cnn model yielded the best discrimination in capacity of differentiating malignancy risk of the nodules based on the projection of distributions of extracted features. moreover, cadx scheme using the new multi-channel cnn model outperformed our previously developed cadx scheme using the 3d texture feature analysis method, which increased the computed area under a receiver operating characteristic curve (auc) from 0.9441 to 0.9702.","['pulmonary nodule malignancy risk differentiation', 'hybrid cnn feature model']"
"what can artificial intelligence learn from neuroscience, and vice versa?","['branching', 'brains']"
"inspired by recent advances in deep learning, we propose a framework for reconstructing dynamic sequences of 2-d cardiac magnetic resonance (mr) images from undersampled data using a deep cascade of convolutional neural networks (cnns) to accelerate the data acquisition process. in particular, we address the case where data are acquired using aggressive cartesian undersampling. first, we show that when each 2-d image frame is reconstructed independently, the proposed method outperforms state-of-the-art 2-d compressed sensing approaches, such as dictionary learning-based mr image reconstruction, in terms of reconstruction error and reconstruction speed. second, when reconstructing the frames of the sequences jointly, we demonstrate that cnns can learn spatio-temporal correlations efficiently by combining convolution and data sharing approaches. we show that the proposed method consistently outperforms state-of-the-art methods and is capable of preserving anatomical structure more faithfully up to 11-fold undersampling. moreover, reconstruction is very fast: each complete dynamic sequence can be reconstructed in less than 10 s and, for the 2-d case, each image frame can be reconstructed in 23 ms, enabling real-time applications.","['dynamic mr image reconstruction', 'convolutional neural networks', 'deep cascade']"
"the united states spends more than $250 million each year on the american community survey (acs), a labor-intensive door-to-door study that measures statistics relating to race, gender, education, occupation, unemployment, and other demographic factors. although a comprehensive source of data, the lag between demographic changes and their appearance in the acs can exceed several years. as digital imagery becomes ubiquitous and machine vision techniques improve, automated data analysis may become an increasingly practical supplement to the acs. here, we present a method that estimates socioeconomic characteristics of regions spanning 200 us cities by using 50 million images of street scenes gathered with google street view cars. using deep learning-based computer vision techniques, we determined the make, model, and year of all motor vehicles encountered in particular neighborhoods. data from this census of motor vehicles, which enumerated 22 million automobiles in total (8% of all automobiles in the united states), were used to accurately estimate income, race, education, and voting patterns at the zip code and precinct level. (the average us precinct contains ∼1,000 people.) the resulting associations are surprisingly simple and powerful. for instance, if the number of sedans encountered during a drive through a city is higher than the number of pickup trucks, the city is likely to vote for a democrat during the next presidential election (88% chance); otherwise, it is likely to vote republican (82%). our results suggest that automated systems for monitoring demographics may effectively complement labor-intensive approaches, with the potential to measure demographics with fine spatial resolution, in close to real time.","['using deep learning', 'google street view', 'united states', 'neighborhoods across', 'demographic makeup', 'estimate']"
"in this study, we report the evaluation of the residue-residue contacts predicted by our three different methods in the casp12 experiment, focusing on studying the impact of multiple sequence alignment, residue coevolution, and machine learning on contact prediction. the first method (multicom-novel) uses only traditional features (sequence profile, secondary structure, and solvent accessibility) with deep learning to predict contacts and serves as a baseline. the second method (multicom-construct) uses our new alignment algorithm to generate deep multiple sequence alignment to derive coevolution-based features, which are integrated by a neural network method to predict contacts. the third method (multicom-cluster) is a consensus combination of the predictions of the first two methods. we evaluated our methods on 94 casp12 domains. on a subset of 38 free-modeling domains, our methods achieved an average precision of up to 41.7% for top l/5 long-range contact predictions. the comparison of the three methods shows that the quality and effective depth of multiple sequence alignments, coevolution-based features, and machine learning integration of coevolution-based features and traditional features drive the quality of predicted protein contacts. on the full casp12 dataset, the coevolution-based features alone can improve the average precision from 28.4% to 41.6%, and the machine learning integration of all the features further raises the precision to 56.3%, when top l/5 predicted long-range contacts are evaluated. and the correlation between the precision of contact prediction and the logarithm of the number of effective sequences in alignments is 0.66.","['integrating deep multiple sequence alignments', 'protein contact prediction', 'machine learning', 'coevolution']"
"this study aimed to compare shallow and deep learning of classifying the patterns of interstitial lung diseases (ilds). using high-resolution computed tomography images, two experienced radiologists marked 1200 regions of interest (rois), in which 600 rois were each acquired using a ge or siemens scanner and each group of 600 rois consisted of 100 rois for subregions that included normal and five regional pulmonary disease patterns (ground-glass opacity, consolidation, reticular opacity, emphysema, and honeycombing). we employed the convolution neural network (cnn) with six learnable layers that consisted of four convolution layers and two fully connected layers. the classification results were compared with the results classified by a shallow learning of a support vector machine (svm). the cnn classifier showed significantly better performance for accuracy compared with that of the svm classifier by 6-9%. as the convolution layer increases, the classification accuracy of the cnn showed better performance from 81.27 to 95.12%. especially in the cases showing pathological ambiguity such as between normal and emphysema cases or between honeycombing and reticular opacity cases, the increment of the convolution layer greatly drops the misclassification rate between each case. conclusively, the cnn classifier showed significantly greater accuracy than the svm classifier, and the results implied structural characteristics that are inherent to the specific ild patterns.","['diffuse lung disease', 'deep learning methods', 'regional pattern', 'shallow', 'comparison', 'classifying']"
"purpose to investigate diagnostic performance by using a deep learning method with a convolutional neural network (cnn) for the differentiation of liver masses at dynamic contrast agent-enhanced computed tomography (ct). materials and methods this clinical retrospective study used ct image sets of liver masses over three phases (noncontrast-agent enhanced, arterial, and delayed). masses were diagnosed according to five categories (category a, classic hepatocellular carcinomas [hcc","['rare benign liver masses', 'malignant liver tumors', 'including early hccs', 'indeterminate masses', 'early hccs', 'like lesions', 'dysplastic nodules', 'ategory b', 'category e', 'category c', 'category', 'mass', 'hemangiomas', 'cysts', 'cyst', 'classic']"
"automated glaucoma detection is an important application of retinal image analysis. compared with segmentation based approaches, image classification based approaches have a potential of better performance. however, it still remains a challenging problem for two reasons. firstly, due to insufficient sample size, learning effective features is difficult. secondly, the shape variations of optic disc introduce misalignment. to address these problem, a new classification based approach for glaucoma detection is proposed, in which deep convolutional networks derived from large-scale generic dataset is used to representing the visual appearance and holistic and local features are combined to mitigate the influence of misalignment. the proposed method achieves an area under the receiver operating characteristic curve of 0.8384 on the origa dataset, which clearly demonstrates its effectiveness.","['local deep features', 'integrating holistic', 'glaucoma classification']"
"machine learning methods have found many applications in raman spectroscopy, especially for the identification of chemical species. however, almost all of these methods require non-trivial preprocessing such as baseline correction and/or pca as an essential step. here we describe our unified solution for the identification of chemical species in which a convolutional neural network is trained to automatically identify substances according to their raman spectrum without the need for preprocessing. we evaluated our approach using the rruff spectral database, comprising mineral sample data. superior classification performance is demonstrated compared with other frequently used machine learning algorithms including the popular support vector machine method.","['deep convolutional neural networks', 'raman spectrum recognition', 'unified solution']"
"using deep-learning methodologies to analyze multimodal physiological signals becomes increasingly attractive for recognizing human emotions. however, the conventional deep emotion classifiers may suffer from the drawback of the lack of the expertise for determining model structure and the oversimplification of combining multimodal feature abstractions.","['emotions using multimodal physiological signals', 'ensemble deep learning model', 'recognition']"
"information of the proteins\' subcellular localization is crucially important for revealing their biological functions in a cell, the basic unit of life. with the avalanche of protein sequences generated in the postgenomic age, it is highly desired to develop computational tools for timely identifying their subcellular locations based on the sequence information alone. the current study is focused on the gram-negative bacterial proteins. although considerable efforts have been made in protein subcellular prediction, the problem is far from being solved yet. this is because mounting evidences have indicated that many gram-negative bacterial proteins exist in two or more location sites. unfortunately, most existing methods can be used to deal with single-location proteins only. actually, proteins with multi-locations may have some special biological functions important for both basic research and drug design. in this study, by using the multi-label theory, we developed a new predictor called ""ploc-mgneg"" for predicting the subcellular localization of gram-negative bacterial proteins with both single and multiple locations. rigorous cross-validation on a high quality benchmark dataset indicated that the proposed predictor is remarkably superior to ""iloc-gneg"", the state-of-the-art predictor for the same purpose. for the convenience of most experimental scientists, a user-friendly web-server for the novel predictor has been established at http://www.jci-bioinfo.cn/ploc-mgneg/, by which users can easily get their desired results without the need to go through the complicated mathematics involved.","['deep gene ontology learning via general pseaac', 'predict subcellular localization', 'negative bacterial proteins', 'ploc', 'mgneg', 'gram']"
"aging is now at the forefront of major challenges faced globally, creating an immediate need for safe, widescale interventions to reduce the burden of chronic disease and extend human healthspan. metformin and rapamycin are two fda-approved mtor inhibitors proposed for this purpose, exhibiting significant anti-cancer and anti-aging properties beyond their current clinical applications. however, each faces issues with approval for off-label, prophylactic use due to adverse effects. here, we initiate an effort to identify nutraceuticals-safer, naturally-occurring compounds-that mimic the anti-aging effects of metformin and rapamycin without adverse effects. we applied several bioinformatic approaches and deep learning methods to the library of integrated network-based cellular signatures (lincs) dataset to map the gene- and pathway-level signatures of metformin and rapamycin and screen for matches among over 800 natural compounds. we then predicted the safety of each compound with an ensemble of deep neural network classifiers. the analysis revealed many novel candidate metformin and rapamycin mimetics, including allantoin and ginsenoside (metformin), epigallocatechin gallate and isoliquiritigenin (rapamycin), and withaferin a (both). four relatively unexplored compounds also scored well with rapamycin. this work revealed promising candidates for future experimental validation while demonstrating the applications of powerful screening methods for this and similar endeavors.","['towards natural mimetics', 'rapamycin', 'metformin']"
"cassava is the third largest source of carbohydrates for human food in the world but is vulnerable to virus diseases, which threaten to destabilize food security in sub-saharan africa. novel methods of cassava disease detection are needed to support improved control which will prevent this crisis. image recognition offers both a cost effective and scalable technology for disease detection. new deep learning models offer an avenue for this technology to be easily deployed on mobile devices. using a dataset of cassava disease images taken in the field in tanzania, we applied transfer learning to train a deep convolutional neural network to identify three diseases and two types of pest damage (or lack thereof). the best trained model accuracies were 98% for brown leaf spot (bls), 96% for red mite damage (rmd), 95% for green mite damage (gmd), 98% for cassava brown streak disease (cbsd), and 96% for cassava mosaic disease (cmd). the best model achieved an overall accuracy of 93% for data not used in the training process. our results show that the transfer learning approach for image recognition of field images offers a fast, affordable, and easily deployable strategy for digital plant disease detection.","['based cassava disease detection', 'deep learning', 'image']"
our purpose was to evaluate the clinical safety and efficacy of co2 laser-assisted sclerectomy surgery (class) with mitomycin c (mmc) in open angle glaucoma (oag).,"['assisted sclerectomy surgery', 'prospective evaluation', 'co2 laser', 'clas']"
"cardiovascular diseases are one of the top causes of deaths worldwide. in developing nations and rural areas, difficulties with diagnosis and treatment are made worse due to the deficiency of healthcare facilities. a viable solution to this issue is telemedicine, which involves delivering health care and sharing medical knowledge at a distance. additionally, mhealth, the utilization of mobile devices for medical care, has also proven to be a feasible choice. the integration of telemedicine, mhealth and computer-aided diagnosis systems with the fields of machine and deep learning has enabled the creation of effective services that are adaptable to a multitude of scenarios. the objective of this review is to provide an overview of heart disease diagnosis and management, especially within the context of rural healthcare, as well as discuss the benefits, issues and solutions of implementing deep learning algorithms to improve the efficacy of relevant medical applications.","['deep learning', 'cardiac computer', 'aided diagnosis', 'solutions', 'issues', 'benefits']"
"a fundamental question is how the cerebral neocortex operates functionally, computationally. the cerebral neocortex with its superficial and deep layers and highly developed recurrent collateral systems that provide a basis for memory-related processing might perform somewhat different computations in the superficial and deep layers. here we take into account the quantitative connectivity within and between laminae. using integrate-and-fire neuronal network simulations that incorporate this connectivity, we first show that attractor networks implemented in the deep layers that are activated by the superficial layers could be partly independent in that the deep layers might have a different time course, which might because of adaptation be more transient and useful for outputs from the neocortex. in contrast the superficial layers could implement more prolonged firing, useful for slow learning and for short-term memory. second, we show that a different type of computation could in principle be performed in the superficial and deep layers, by showing that the superficial layers could operate as a discrete attractor network useful for categorisation and feeding information forward up a cortical hierarchy, whereas the deep layers could operate as a continuous attractor network useful for providing a spatially and temporally smooth output to output systems in the brain. a key advance is that we draw attention to the functions of the recurrent collateral connections between cortical pyramidal cells, often omitted in canonical models of the neocortex, and address principles of operation of the neocortex by which the superficial and deep layers might be specialized for different types of attractor-related memory functions implemented by the recurrent collaterals.","['deep vs superficial layers', 'cerebral cortex', 'computations']"
"visual information in the visual cortex is processed in a hierarchical manner. recent studies show that higher visual areas, such as v2, v3, and v4, respond more vigorously to images with naturalistic higher-order statistics than to images lacking them. this property is a functional signature of higher areas, as it is much weaker or even absent in the primary visual cortex (v1). however, the mechanism underlying this signature remains elusive. we studied this problem using computational models. in several typical hierarchical visual models including the alexnet, vggnet, and shmax, this signature was found to be prominent in higher layers but much weaker in lower layers. by changing both the model structure and experimental settings, we found that the signature strongly correlated with sparse firing of units in higher layers but not with any other factors, including model structure, training algorithm (supervised or unsupervised), receptive field size, and property of training stimuli. the results suggest an important role of sparse neuronal activity underlying this special feature of higher visual areas.","['deep learning predicts correlation', 'higher visual areas', 'sparse firing', 'functional signature', 'neurons']"
"cryptography is not only a science of applying complex mathematics and logic to design strong methods to hide data called as encryption, but also to retrieve the original data back, called decryption. the purpose of cryptography is to transmit a message between a sender and receiver such that an eavesdropper is unable to comprehend it. to accomplish this, not only we need a strong algorithm, but a strong key and a strong concept for encryption and decryption process. we have introduced a concept of dna deep learning cryptography which is defined as a technique of concealing data in terms of dna sequence and deep learning. in the cryptographic technique, each alphabet of a letter is converted into a different combination of the four bases, namely; adenine (a), cytosine (c), guanine (g) and thymine (t), which make up the human deoxyribonucleic acid (dna). actual implementations with the dna don't exceed laboratory level and are expensive. to bring dna computing on a digital level, easy and effective algorithms are proposed in this paper. in proposed work we have introduced firstly, a method and its implementation for key generation based on the theory of natural selection using genetic algorithm with needleman-wunsch (nw) algorithm and secondly, a method for implementation of encryption and decryption based on dna computing using biological operations transcription, translation, dna sequencing and deep learning.","['deep learning using genetic algorithm', 'nw algorithm', 'key generation', 'dna cryptography']"
"automatic and accurate lumbar vertebrae detection is an essential step of image-guided minimally invasive spine surgery (ig-miss). however, traditional methods still require human intervention due to the similarity of vertebrae, abnormal pathological conditions and uncertain imaging angle. in this paper, we present a novel convolutional neural network (cnn) model to automatically detect lumbar vertebrae for c-arm x-ray images. training data is augmented by drr and automatic segmentation of roi is able to reduce the computational complexity. furthermore, a feature fusion deep learning (ffdl) model is introduced to combine two types of features of lumbar vertebrae x-ray images, which uses sobel kernel and gabor kernel to obtain the contour and texture of lumbar vertebrae, respectively. comprehensive qualitative and quantitative experiments demonstrate that our proposed model performs more accurate in abnormal cases with pathologies and surgical implants in multi-angle views.","['automatic lumbar vertebrae detection based', 'feature fusion deep learning', 'partial occluded c', 'ray images', 'arm x']"
"melanoma, most threatening type of skin cancer, is on the rise. in this paper an implementation of a deep-learning system on a computer server, equipped with graphic processing unit (gpu), is proposed for detection of melanoma lesions. clinical (non-dermoscopic) images are used in the proposed system, which could assist a dermatologist in early diagnosis of this type of skin cancer. in the proposed system, input clinical images, which could contain illumination and noise effects, are preprocessed in order to reduce such artifacts. afterward, the enhanced images are fed to a pre-trained convolutional neural network (cnn) which is a member of deep learning models. the cnn classifier, which is trained by large number of training samples, distinguishes between melanoma and benign cases. experimental results show that the proposed method is superior in terms of diagnostic accuracy in comparison with the state-of-the-art methods.","['clinical images using convolutional neural network', 'melanoma detection', 'analysis']"
"for many pedestrian detectors, background vs. foreground errors heavily influence the detection quality. our main contribution is to design semantic regions of interest that extract the foreground target roughly to reduce the background vs. foreground errors of detectors. first, we generate a pedestrian heat map from the input image with a full convolutional neural network trained on the caltech pedestrian dataset. next, semantic regions of interest are extracted from the heat map by morphological image processing. finally, the semantic regions of interest divide the whole image into foreground and background to assist the decision-making of detectors. we test our approach on the caltech pedestrian detection benchmark. with the help of our semantic regions of interest, the effects of the detectors have varying degrees of improvement. the best one exceeds the state-of-the-art.","['semantic regions', 'pedestrian detection', 'interest']"
"coronary artery disease (cad) is the most common type of heart disease which is the leading cause of death all over the world. x-ray angiography is currently the gold standard imaging technique for cad diagnosis. these images usually suffer from low quality and presence of noise. therefore, vessel enhancement and vessel segmentation play important roles in cad diagnosis. in this paper a deep learning approach using convolutional neural networks (cnn) is proposed for detecting vessel regions in angiography images. initially, an input angiogram is preprocessed to enhance its contrast. afterward, the image is evaluated using patches of pixels and the network determines the vessel and background regions. a set of 1,040,000 patches is used in order to train the deep cnn. experimental results on angiography images of a dataset show that our proposed method has a superior performance in extraction of vessel regions.","['ray angiograms using deep learning', 'vessel extraction', 'x']"
"domain adaptation nowadays attracts increasing interests in pattern recognition and computer vision field, since it is an appealing technique in fighting off weakly labeled or even totally unlabeled target data by leveraging knowledge from external well-learned sources. conventional domain adaptation assumes that target data are still accessible in the training stage. however, we would always confront such cases in reality that the target data are totally blind in the training stage. this is extremely challenging since we have no prior knowledge of the target. in this paper, we develop a deep domain generalization framework with structured low-rank constraint to facilitate the unseen target domain evaluation by capturing consistent knowledge across multiple related source domains. specifically, multiple domain-specific deep neural networks are built to capture the rich information within multiple sources. meanwhile, a domain-invariant deep neural network is jointly designed to uncover most consistent and common knowledge across multiple sources so that we can generalize it to unseen target domains in the test stage. moreover, structured low-rank constraint is exploited to align multiple domain-specific networks and the domain-invariant one in order to better transfer knowledge from multiple sources to boost the learning problem in unseen target domains. extensive experiments are conducted on several cross-domain benchmarks and the experimental results show the superiority of our algorithm by comparing it with state-of-the-art domain generalization approaches.","['deep domain generalization', 'structured low', 'rank constraint']"
"automatic detection and classification of the masses in mammograms are still a big challenge and play a crucial role to assist radiologists for accurate diagnosis. in this paper, we propose a novel computer-aided diagnose (cad) system based on one of the regional deep learning techniques: a roi-based convolutional neural network (cnn) which is called you only look once (yolo). our proposed yolo-based cad system contains four main stages: mammograms preprocessing, feature extraction utilizing multi convolutional deep layers, mass detection with confidence model, and finally mass classification using fully connected neural network (fc-nn). a set of training mammograms with the information of roi masses and their types are used to train yolo. the trained yolo-based cad system detects the masses and classifies their types into benign or malignant. our results show that the proposed yolo-based cad system detects the mass location with an overall accuracy of 96.33%. the system also distinguishes between benign and malignant lesions with an overall accuracy of 85.52%. our proposed system seems to be feasible as a cad system capable of detection and classification at the same time. it also overcomes some challenging breast cancer cases such as the mass existing in the pectoral muscles or dense regions.","['digital mammograms via regional convolutional neural network', 'breast abnormalities', 'detection', 'classification']"
"data measuring airborne pollutants, public health and environmental factors are increasingly being stored and merged. these big datasets offer great potential, but also challenge traditional epidemiological methods. this has motivated the exploration of alternative methods to make predictions, find patterns and extract information. to this end, data mining and machine learning algorithms are increasingly being applied to air pollution epidemiology.","['air pollution epidemiology', 'systematic review', 'machine learning', 'data mining']"
"median lethal death, ld50, is a general indicator of compound acute oral toxicity (aot). various in silico methods were developed for aot prediction to reduce costs and time. in this study, we developed an improved molecular graph encoding convolutional neural networks (mge-cnn) architecture to construct three types of high-quality aot models: regression model (deepaot-r), multiclassification model (deepaot-c), and multitask model (deepaot-cr). these predictive models highly outperformed previously reported models. for the two external data sets containing 1673 (test set i) and 375 (test set ii) compounds, the r2 and mean absolute errors (maes) of deepaot-r on the test set i were 0.864 and 0.195, and the prediction accuracies of deepaot-c were 95.5% and 96.3% on test sets i and ii, respectively. the two external prediction accuracies of deepaot-cr are 95.0% and 94.1%, while the r2 and mae are 0.861 and 0.204 for test set i, respectively. we then performed forward and backward exploration of deepaot models for deep fingerprints, which could support shallow machine learning methods more efficiently than traditional fingerprints or descriptors. we further performed automatic feature learning, a key essence of deep learning, to map the corresponding activation values into fragment space and derive aot-related chemical substructures by reverse mining of the features. our deep learning architecture for aot is generally applicable in predicting and exploring other toxicity or property end points of chemical compounds. the two deepaot models are freely available at http://repharma.pku.edu.cn/dlaot/dlaothome.php or http://www.pkumdl.cn/dlaot/dlaothome.php .","['deep learning based regression', 'automatic chemical feature extraction', 'acute oral toxicity prediction', 'multiclass models']"
"hemodynamic instability and cardiovascular events heavily affect the prognosis of traumatic brain injury. physiological signals are monitored to detect these events. however, the signals are often riddled with faulty readings, which jeopardize the reliability of the clinical parameters obtained from the signals. a machine-learning model for the elimination of artifactual events shows promising results for improving signal quality. however, the actual impact of the improvements on the performance of the clinical parameters after the elimination of the artifacts is not well studied.","['traumatic brain injury predict outcome', 'deep belief network analysis', 'hemodynamic instability', 'cardiovascular events', 'artifact removal']"
"this paper proposes the relit spectral angle-stacked autoencoder, a novel unsupervised feature learning approach for mapping pixel reflectances to illumination invariant encodings. this work extends the spectral angle-stacked autoencoder so that it can learn a shadow-invariant mapping. the method is inspired by a deep learning technique, denoising autoencoders, with the incorporation of a physics-based model for illumination such that the algorithm learns a shadow invariant mapping without the need for any labelled training data, additional sensors, a priori knowledge of the scene or the assumption of planckian illumination. the method is evaluated using datasets captured from several different cameras, with experiments to demonstrate the illumination invariance of the features and how they can be used practically to improve the performance of high-level perception algorithms that operate on images acquired outdoors.","['based deep learning approach', 'shadow invariant representations', 'hyperspectral images', 'physics']"
"crystal structures of neurolysin, a zinc metallopeptidase, do not show a significant conformational change upon the binding of an allosteric inhibitor. neurolysin has a deep channel where it hydrolyzes a short neuropeptide neurotensin to create inactive fragments and thus controls its level in the tissue. neurolysin is of interest as a therapeutic target since changes in neurotensin level have been implicated in cardiovascular disorders, neurological disorders, and cancer, and inhibitors of neurolysin have been developed. an understanding of the dynamical and structural differences between apo and inhibitor-bound neurolysin will aid in further design of potent inhibitors and activators. for this purpose, we performed several molecular dynamics (md) simulations for both apo and inhibitor-bound neurolysin. a machine learning method (linear discriminant analysis) is applied to reveal differences between the apo and inhibitor-bound ensembles in an automated way, and large differences are observed on residues that are far from both the active site and the inhibitor binding site. the effects of inhibitor binding on the collective motions of neurolysin are extensively analyzed and compared using both principal component analysis and elastic network model calculations. we find that inhibitor binding induces additional low-frequency motions that are not observed in the apo form. enm also reveals changes in inter- and intradomain communication upon binding. furthermore, differences are observed in the inhibitor-bound neurolysin contact network that are far from the active site, revealing long-range allosteric behavior. this study also provides insight into the allosteric modulation of other neuropeptidases with similar folds.","['neurolysin dynamics upon inhibitor binding', 'range changes', 'long']"
"methods available for assessing the learning curve, such as a predefined number of procedures or direct mentoring are lacking. our aim was to describe the use of a statistical method to identify the minimal training length of an experienced sonographer, newly trained in deep infiltrating endometriosis (die) mapping by evaluating the learning curve of transvaginal ultrasound (tvus) in the preoperative assessment of endometriosis.","['learning curve cumulative summation test', 'transvaginal ultrasound training', 'statistical method', 'lessons', 'lc', 'cusu', 'applying']"
"lifelong learning is fundamental in autonomous robotics for the acquisition and fine-tuning of knowledge through experience. however, conventional deep neural models for action recognition from videos do not account for lifelong learning but rather learn a batch of training data with a predefined number of action classes and samples. thus, there is the need to develop learning systems with the ability to incrementally process available perceptual cues and to adapt their responses over time. we propose a self-organizing neural architecture for incrementally learning to classify human actions from video sequences. the architecture comprises growing self-organizing networks equipped with recurrent neurons for processing time-varying patterns. we use a set of hierarchically arranged recurrent networks for the unsupervised learning of action representations with increasingly large spatiotemporal receptive fields. lifelong learning is achieved in terms of prediction-driven neural dynamics in which the growth and the adaptation of the recurrent networks are driven by their capability to reconstruct temporally ordered input sequences. experimental results on a classification task using two action benchmark datasets show that our model is competitive with state-of-the-art methods for batch learning also when a significant number of sample labels are missing or corrupted during training sessions. additional experiments show the ability of our model to adapt to non-stationary input avoiding catastrophic interference.","['deep neural network self', 'lifelong learning', 'human actions', 'organization']"
"electronic health record phenotyping is the use of raw electronic health record data to assert characterizations about patients. researchers have been doing it since the beginning of biomedical informatics, under different names. phenotyping will benefit from an increasing focus on fidelity, both in the sense of increasing richness, such as measured levels, degree or severity, timing, probability, or conceptual relationships, and in the sense of reducing bias. research agendas should shift from merely improving binary assignment to studying and improving richer representations. the field is actively researching new temporal directions and abstract representations, including deep learning. the field would benefit from research in nonlinear dynamics, in combining mechanistic models with empirical data, including data assimilation, and in topology. the health care process produces substantial bias, and studying that bias explicitly rather than treating it as merely another source of noise would facilitate addressing it.","['fidelity phenotyping', 'richness', 'high', 'freedom', 'bias']"
"malignant melanoma is one of the most deadly forms of skin cancer, which is one of the world's fastest-growing cancers. early diagnosis and treatment is critical. in this study, a neural network structure is utilized to construct a broad and accurate basis for the diagnosis of skin cancer, thereby reducing screening errors. the technique is able to improve the efficacy for identification of normally indistinguishable lesions (such as pigment spots) versus clinically unknown lesions, and to ultimately improve the diagnostic accuracy. in the field of medical imaging, in general, using neural networks for image segmentation is relatively rare. the existing traditional machine-learning neural network algorithms still cannot completely solve the problem of information loss, nor detect the precise division of the boundary area. we use an improved neural network framework, described herein, to achieve efficacious feature learning, and satisfactory segmentation of melanoma images. the architecture of the network includes multiple convolution layers, dropout layers, softmax layers, multiple filters, and activation functions. the number of data sets can be increased via rotation of the training set. a non-linear activation function (such as relu and elu) is employed to alleviate the problem of gradient disappearance, and rmsprop/adam are incorporated to optimize the loss algorithm. a batch normalization layer is added between the convolution layer and the activation layer to solve the problem of gradient disappearance and explosion. experiments, described herein, show that our improved neural network architecture achieves higher accuracy for segmentation of melanoma images as compared with existing processes.","['melanoma segmentation based', 'deep learning']"
"predicting disease-associated genes is helpful for understanding the molecular mechanisms during the disease progression. since the pathological mechanisms of neurodegenerative diseases are very complex, traditional statistic-based methods are not suitable for identifying key genes related to the disease development. recent studies have shown that the computational models with deep structure can learn automatically the features of biological data, which is useful for exploring the characteristics of gene expression during the disease progression.","['disease associated genes based', 'restricted boltzmann machine', 'seq data', 'identify huntington', 'rna']"
"the development of wearable sensors has opened the door for long-term assessment of movement disorders. however, there is still a need for developing methods suitable to monitor motor symptoms in and outside the clinic. the purpose of this paper was to investigate deep learning as a method for this monitoring. deep learning recently broke records in speech and image classification, but it has not been fully investigated as a potential approach to analyze wearable sensor data. we collected data from ten patients with idiopathic parkinson's disease using inertial measurement units. several motor tasks were expert-labeled and used for classification. we specifically focused on the detection of bradykinesia. for this, we compared standard machine learning pipelines with deep learning based on convolutional neural networks. our results showed that deep learning outperformed other state-of-the-art machine learning algorithms by at least 4.6 % in terms of classification rate. we contribute a discussion of the advantages and disadvantages of deep learning for sensor-based movement assessment and conclude that deep learning is a promising method for this field.","['recent machine learning advancements', 'based mobility analysis', 'deep learning', 'disease assessment', 'sensor', 'parkinson']"
"a large number of protein sequences are becoming available through the application of novel high-throughput sequencing technologies. experimental functional characterization of these proteins is time-consuming and expensive, and is often only done rigorously for few selected model organisms. computational function prediction approaches have been suggested to fill this gap. the functions of proteins are classified using the gene ontology (go), which contains over 40\u2009000 classes. additionally, proteins have multiple functions, making function prediction a large-scale, multi-class, multi-label problem.","['predicting protein functions', 'interactions using', 'deep ontology', 'aware classifier', 'sequence', 'deepgo']"
"artificial intelligence has seen several breakthroughs in recent years, with games often serving as milestones. a common feature of these games is that players have perfect information. poker, the quintessential game of imperfect information, is a long-standing challenge problem in artificial intelligence. we introduce deepstack, an algorithm for imperfect-information settings. it combines recursive reasoning to handle information asymmetry, decomposition to focus computation on the relevant decision, and a form of intuition that is automatically learned from self-play using deep learning. in a study involving 44,000 hands of poker, deepstack defeated, with statistical significance, professional poker players in heads-up no-limit texas hold'em. the approach is theoretically sound and is shown to produce strategies that are more difficult to exploit than prior approaches.","['level artificial intelligence', 'limit poker', 'heads', 'expert', 'deepstack']"
"deep brain stimulation (dbs) of the human entorhinal area using 50 hz pulses has revealed conflicting results regarding memory performance. moreover, its impact on memory-related hippocampal potentials has not yet been investigated.","['related anterior hippocampal potentials', 'deep brain stimulation', 'memory encoding', 'entorhinal area', 'modulated']"
"burn debridement is a challenging technique that requires significant skill to identify regions requiring excision and appropriate excision depth. a machine learning tool is being developed in order to assist surgeons by providing a quantitative assessment of burn-injured tissue. three noninvasive optical imaging techniques capable of distinguishing between four kinds of tissue-healthy skin, viable wound bed, deep burn, and shallow burn-during serial burn debridement in a porcine model are presented in this paper. the combination of all three techniques considerably improves the accuracy of tissue classification, from 0.42 to almost 0.77.","['invasive optical imaging techniques', 'injured tissue detection', 'debridement surgery', 'non', 'burn']"
"an encephalogram (eeg) is a commonly used ancillary test to aide in the diagnosis of epilepsy. the eeg signal contains information about the electrical activity of the brain. traditionally, neurologists employ direct visual inspection to identify epileptiform abnormalities. this technique can be time-consuming, limited by technical artifact, provides variable results secondary to reader expertise level, and is limited in identifying abnormalities. therefore, it is essential to develop a computer-aided diagnosis (cad) system to automatically distinguish the class of these eeg signals using machine learning techniques. this is the first study to employ the convolutional neural network (cnn) for analysis of eeg signals. in this work, a 13-layer deep convolutional neural network (cnn) algorithm is implemented to detect normal, preictal, and seizure classes. the proposed technique achieved an accuracy, specificity, and sensitivity of 88.67%, 90.00% and 95.00%, respectively.","['seizure using eeg signals', 'deep convolutional neural network', 'automated detection', 'diagnosis']"
"computer aided classification of skin cancer images is an active area of research and different classification methods has been proposed so far. however, the supervised classification models based on insufficient labeled training data can badly influence the diagnosis process. to deal with the problem of limited labeled data availability this paper presents a semi advised learning model for automated recognition of skin cancer using histopathalogical images. deep belief architecture is constructed using unlabeled data by making efficient use of limited labeled data for fine tuning done the classification model. in parallel an advised svm algorithm is used to enhance classification results by counteracting the effect of misclassified data using advised weights. to increase generalization capability of the model, advised svm and deep belief network are trained in parallel. then the results are aggregated using least square estimation weighting. the proposed model is tested on a collection of 300 histopathalogical images taken from biopsy samples. the classification performance is compared with some popular methods and the proposed model outperformed most of the popular techniques including knn, ann, svm and semi supervised algorithms like expectation maximization algorithm and transductive svm based classification model.","['skin cancer diagnosis based', 'advised learning model', 'histopathalogical images', 'semi']"
"a peripherally inserted central catheter (picc) is a thin catheter that is inserted via arm veins and threaded near the heart, providing intravenous access. the final catheter tip position is always confirmed on a chest radiograph (cxr) immediately after insertion since malpositioned piccs can cause potentially life-threatening complications. although radiologists interpret picc tip location with high accuracy, delays in interpretation can be significant. in this study, we proposed a fully-automated, deep-learning system with a cascading segmentation ai system containing two fully convolutional neural networks for detecting a picc line and its tip location. a preprocessing module performed image quality and dimension normalization, and a post-processing module found the picc tip accurately by pruning false positives. our best model, trained on 400 training cases and selectively tuned on 50 validation cases, obtained absolute distances from ground truth with a mean of 3.10\xa0mm, a standard deviation of 2.03\xa0mm, and a root mean squares error (rmse) of 3.71\xa0mm on 150 held-out test cases. this system could help speed confirmation of picc position and further be generalized to include other types of vascular access and therapeutic support devices.","['automated peripherally inserted central catheter', 'learning system', 'pic', 'fully', 'deep']"
"identifying interactions between known drugs and targets is a major challenge in drug repositioning. in silico prediction of drug-target interaction (dti) can speed up the expensive and time-consuming experimental work by providing the most potent dtis. in silico prediction of dti can also provide insights about the potential drug-drug interaction and promote the exploration of drug side effects. traditionally, the performance of dti prediction depends heavily on the descriptors used to represent the drugs and the target proteins. in this paper, to accurately predict new dtis between approved drugs and targets without separating the targets into different classes, we developed a deep-learning-based algorithmic framework named deepdtis. it first abstracts representations from raw input descriptors using unsupervised pretraining and then applies known label pairs of interaction to build a classification model. compared with other methods, it is found that deepdtis reaches or outperforms other state-of-the-art methods. the deepdtis can be further used to predict whether a new drug targets to some existing targets or whether a new target interacts with some existing drugs.","['target interaction prediction', 'based drug', 'learning', 'deep']"
"we present a deep neural network-based approach to image quality assessment (iqa). the network is trained end-to-end and comprises ten convolutional layers and five pooling layers for feature extraction, and two fully connected layers for regression, which makes it significantly deeper than related iqa models. unique features of the proposed architecture are that: 1) with slight adaptations it can be used in a no-reference (nr) as well as in a full-reference (fr) iqa setting and 2) it allows for joint learning of local quality and local weights, i.e., relative importance of local quality to the global quality estimate, in an unified framework. our approach is purely data-driven and does not rely on hand-crafted features or other types of prior domain knowledge about the human visual system or image statistics. we evaluate the proposed approach on the live, cisq, and tid2013 databases as well as the live in the wild image quality challenge database and show superior performance to state-of-the-art nr and fr iqa methods. finally, cross-database evaluation shows a high ability to generalize between different databases, indicating a high robustness of the learned features.","['reference image quality assessment', 'deep neural networks', 'reference', 'full']"
"in this paper we applied transfer learning techniques for image recognition, automatic categorization, and labeling of nanoscience images obtained by scanning electron microscope (sem). roughly 20,000 sem images were manually classified into 10 categories to form a labeled training set, which can be used as a reference set for future applications of deep learning enhanced algorithms in the nanoscience domain. the categories chosen spanned the range of 0-dimensional (0d) objects such as particles, 1d nanowires and fibres, 2d films and coated surfaces, and 3d patterned surfaces such as pillars. the training set was used to retrain on the sem dataset and to\xa0compare many convolutional neural network models (inception-v3, inception-v4, resnet). we obtained compatible results by performing a feature extraction of the different models on the same dataset. we performed additional analysis of the classifier on a second test set to further investigate the results both on particular cases and from a statistical point of view. our algorithm was able to successfully classify around 90% of a test dataset consisting of sem images, while reduced accuracy was found in the case of images at the boundary between two categories or containing elements of multiple categories. in these cases, the image classification did not identify a predominant category with a high score. we used the statistical outcomes from testing to deploy a semi-automatic workflow able to classify and label images generated by the sem. finally, a separate training was performed to determine the volume fraction of coherently aligned nanowires in sem images. the results were compared with what was obtained using the local gradient orientation method. this example demonstrates the versatility and the potential of transfer learning to address specific tasks of interest in nanoscience applications.","['nanoscience scanning electron microscope image recognition', 'neural network']"
"image-based salient object detection (sod) has been extensively studied in past decades. however, video-based sod is much less explored due to the lack of large-scale video datasets within which salient objects are unambiguously defined and annotated. toward this end, this paper proposes a video-based sod dataset that consists of 200 videos. in constructing the dataset, we manually annotate all objects and regions over 7650 uniformly sampled keyframes and collect the eye-tracking data of 23 subjects who free-view all videos. from the user data, we find that salient objects in a video can be defined as objects that consistently pop-out throughout the video, and objects with such attributes can be unambiguously annotated by combining manually annotated object/region masks with eye-tracking data of multiple subjects. to the best of our knowledge, it is currently the largest dataset for video-based salient object detection. based on this dataset, this paper proposes an unsupervised baseline approach for video-based sod by using saliency-guided stacked autoencoders. in the proposed approach, multiple spatiotemporal saliency cues are first extracted at the pixel, superpixel, and object levels. with these saliency cues, stacked autoencoders are constructed in an unsupervised manner that automatically infers a saliency score for each pixel by progressively encoding the high-dimensional saliency cues gathered from the pixel and its spatiotemporal neighbors. in experiments, the proposed unsupervised approach is compared with 31 state-of-the-art models on the proposed dataset and outperforms 30 of them, including 19 image-based classic (unsupervised or non-deep learning) models, six image-based deep learning models, and five video-based unsupervised models. moreover, benchmarking results show that the proposed dataset is very challenging and has the potential to boost the development of video-based sod.","['based salient object detection', 'guided stacked autoencoders', 'benchmark dataset', 'video', 'saliency']"
"from 1999 onwards, deep brain stimulation (dbs) has been proposed as an alternative to capsulotomy in refractory cases of obsessive-compulsive disorder (ocd). although rechargeable implantable pulse generators (ripgs) have been used extensively in dbs for movement disorders, there are no reports on ripgs in patients with a psychiatric dbs indication, and even possible objections to their use.","['prospective interventional cohort study', 'deep brain stimulation', 'rechargeable stimulators', 'compulsive disorder', 'obsessive']"
to investigate deep reinforcement learning (drl) based on historical treatment plans for developing automated radiation adaptation protocols for nonsmall cell lung cancer (nsclc) patients that aim to maximize tumor local control at reduced rates of radiation pneumonitis grade 2 (rp2).,"['deep reinforcement learning', 'automated radiation adaptation', 'lung cancer']"
"receptors for glucocorticoid (gr) and corticotropin-releasing hormone (crh) are largely found in brain sensorimotor structures, particularly in cerebellum, underlining a potential role of stress hormones in the regulation of motor function. since crh is involved in neuroplasticity, known for its trophic effect on synapses, we investigated how manipulations in corticosterone serum levels can modulate the crh system in the cerebellum and affect motor coordination. corticosterone at doses of either 15 or 30mg/kg was injected in mice and the status of hormonal expression evaluated in cerebellum, hippocampus, and hypothalamus in undisturbed housing conditions or after different behavioral tests. under both conditions, metabolic activity in numerous brain regions involved in motor functions and emotion was measured by means of cytochrome oxidase (cox) activity labeling. after six consecutive days of corticosterone administration, crh-r1 transcription was downregulated in hypothalamic and cerebellar regions and hypometabolic changes were observed in mice treated with the higher dose for several limbic and sensorimotor circuitries, notably basal ganglia, deep cerebellar nuclei, and red nucleus. corticosterone did not modify motor activity, anxiety, and spatial orientation, but decreased latencies before falling from the rotorod and prevented mice from reaching targets in the coat-hanger test. in addition, cox activities were similar to control mice except in ventromedial thalamus and dorsal neostriatum, possibly indicating that physical activity protected brain energy metabolism against the stress hormone. the present findings showed that the crh/crh-r1 system might play a role in mediating the effects of stress on cerebellar function, affecting especially motor learning tasks.","['adult mice alter stress hormonal receptor expression', 'motor coordination without affecting spatial learning', 'repeated corticosterone injections', 'cerebellum']"
"poly-metallic nodules are a marine resource considered for deep sea mining. assessing nodule abundance is of interest for mining companies and to monitor potential environmental impact. optical seafloor imaging allows quantifying poly-metallic nodule abundance at spatial scales from centimetres to square kilometres. towed cameras and diving robots acquire high-resolution imagery that allow detecting individual nodules and measure their sizes. spatial abundance statistics can be computed from these size measurements, providing e.g. seafloor coverage in percent and the nodule size distribution. detecting nodules requires segmentation of nodule pixels from pixels showing sediment background. semi-supervised pattern recognition has been proposed to automate this task. existing nodule segmentation algorithms employ machine learning that trains a classifier to segment the nodules in a high-dimensional feature space. here, a rapid nodule segmentation algorithm is presented. it omits computation-intense feature-based classification and employs image processing only. it exploits a nodule compactness heuristic to delineate individual nodules. complex machine learning methods are avoided to keep the algorithm simple and fast. the algorithm has successfully been applied to different image datasets. these data sets were acquired by different cameras, camera platforms and in varying illumination conditions. their successful analysis shows the broad applicability of the proposed method.","['metallic nodule delineation', 'based poly', 'morphology', 'compact']"
"a fault diagnosis approach based on multi-sensor data fusion is a promising tool to deal with complicated damage detection problems of mechanical systems. nevertheless, this approach suffers from two challenges, which are (1) the feature extraction from various types of sensory data and (2) the selection of a suitable fusion level. it is usually difficult to choose an optimal feature or fusion level for a specific fault diagnosis task, and extensive domain expertise and human labor are also highly required during these selections. to address these two challenges, we propose an adaptive multi-sensor data fusion method based on deep convolutional neural networks (dcnn) for fault diagnosis. the proposed method can learn features from raw data and optimize a combination of different fusion levels adaptively to satisfy the requirements of any fault diagnosis task. the proposed method is tested through a planetary gearbox test rig. handcraft features, manual-selected fusion levels, single sensory data, and two traditional intelligent models, back-propagation neural networks (bpnn) and a support vector machine (svm), are used as comparisons in the experiment. the results demonstrate that the proposed method is able to detect the conditions of the planetary gearbox effectively with the best diagnosis accuracy among all comparative methods in the experiment.","['sensor data fusion method based', 'deep convolutional neural networks', 'planetary gearbox', 'fault diagnosis', 'adaptive multi']"
"epilepsy being one of the most prevalent neurological disorders, affecting approximately 50 million people worldwide, and with almost 30-40% of patients experiencing partial epilepsy being nonresponsive to medication, epilepsy surgery is widely accepted as an effective therapeutic option. presurgical evaluation has advanced significantly using noninvasive techniques based on video monitoring, neuroimaging, and electrophysiological and neuropsychological tests; however, certain clinical settings call for invasive intracranial recordings such as stereoelectroencephalography (seeg), aiming to accurately map the eloquent brain networks involved during a seizure. most of the current presurgical evaluation procedures focus on semiautomatic techniques, where surgery diagnosis relies immensely on neurologists' experience and their time-consuming subjective interpretation of semiology or the manifestations of epilepsy and their correlation with the brain's electrical activity. because surgery misdiagnosis reaches a rate of 30%, and more than one-third of all epilepsies are poorly understood, there is an evident keen interest in improving diagnostic precision using computer-based methodologies that in the past few years have shown near-human performance. among them, deep learning has excelled in many biological and medical applications, but has advanced insufficiently in epilepsy evaluation and automated understanding of neural bases of semiology. in this paper, we systematically review the automatic applications in epilepsy for human motion analysis, brain electrical activity, and the anatomoelectroclinical correlation to attribute anatomical localization of the epileptogenic network to distinctive epilepsy patterns. notably, recent advances in deep learning techniques will be investigated in the contexts of epilepsy to address the challenges exhibited by traditional machine learning techniques. finally, we discuss and propose future research on epilepsy surgery assessment that can jointly learn across visually observed semiologic patterns and recorded brain electrical activity.","['brain electrical activity', 'seizure semiology', 'presurgery evaluation', 'focused survey', 'automated analysis', 'epilepsy']"
"identifying robust survival subgroups of hepatocellular carcinoma (hcc) will significantly improve patient care. currently, endeavor of integrating multi-omics data to explicitly predict hcc survival from multiple patient cohorts is lacking. to fill this gap, we present a deep learning (dl)-based model on hcc that robustly differentiates survival subpopulations of patients in six cohorts. we built the dl-based, survival-sensitive model on 360 hcc patients' data using rna sequencing (rna-seq), mirna sequencing (mirna-seq), and methylation data from the cancer genome atlas (tcga), which predicts prognosis as good as an alternative model where genomics and clinical data are both considered. this dl-based model provides two optimal subgroups of patients with significant survival differences (p = 7.13e-6) and good model fitness [concordance index (c-index) = 0.6","['frequent tp53 inactivation mutations', 'ore aggressive subtype', 'stemness markers', 'higher expression', 'krt19', 'epca', 'associated']"
"deep neural network architectures such as convolutional and long short-term memory networks have become increasingly popular as machine learning tools during the recent years. the availability of greater computational resources, more data, new algorithms for training deep models and easy to use libraries for implementation and training of neural networks are the drivers of this development. the use of deep learning has been especially successful in image recognition; and the development of tools, applications and code examples are in most cases centered within this field rather than within biology.","['biological sequence data', 'deep learning', 'solutions', 'introduction', 'examples']"
"transfer learning in deep convolutional neural networks (dcnns) is an important step in its application to medical imaging tasks. we propose a multi-task transfer learning dcnn with the aim of translating the 'knowledge' learned from non-medical images to medical diagnostic tasks through supervised training and increasing the generalization capabilities of dcnns by simultaneously learning auxiliary tasks. we studied this approach in an important application: classification of malignant and benign breast masses. with institutional review board (irb) approval, digitized screen-film mammograms (sfms) and digital mammograms (dms) were collected from our patient files and additional sfms were obtained from the digital database for screening mammography. the data set consisted of 2242 views with 2454 masses (1057 malignant, 1397 benign). in single-task transfer learning, the dcnn was trained and tested on sfms. in multi-task transfer learning, sfms and dms were used to train the dcnn, which was then tested on sfms. n-fold cross-validation with the training set was used for training and parameter optimization. on the independent test set, the multi-task transfer learning dcnn was found to have significantly (p\u2009\u2009=\u2009\u20090.007) higher performance compared to the single-task transfer learning dcnn. this study demonstrates that multi-task transfer learning may be an effective approach for training dcnn in medical imaging applications when training samples from a single modality are limited.","['task transfer learning deep convolutional neural network', 'breast cancer', 'aided diagnosis', 'multi', 'mammograms', 'computer', 'application']"
"accurate and automatic brain metastases target delineation is a key step for efficient and effective stereotactic radiosurgery (srs) treatment planning. in this work, we developed a deep learning convolutional neural network (cnn) algorithm for segmenting brain metastases on contrast-enhanced t1-weighted magnetic resonance imaging (mri) datasets. we integrated the cnn-based algorithm into an automatic brain metastases segmentation workflow and validated on both multimodal brain tumor image segmentation challenge (brats) data and clinical patients' data. validation on brats data yielded average dice coefficients (dcs) of 0.75±0.07 in the tumor core and 0.81±0.04 in the enhancing tumor, which outperformed most techniques in the 2015 brats challenge. segmentation results of patient cases showed an average of dcs 0.67±0.03 and achieved an area under the receiver operating characteristic curve of 0.98±0.01. the developed automatic segmentation strategy surpasses current benchmark levels and offers a promising tool for srs treatment planning for multiple brain metastases.","['multiple brain metastases stereotactic radiosurgery', 'deep convolutional neural network', 'based automatic delineation strategy']"
"dopaminergic degeneration is a pathologic hallmark of parkinson's disease (pd), which can be assessed by dopamine transporter imaging such as fp-cit spect. until now, imaging has been routinely interpreted by human though it can show interobserver variability and result in inconsistent diagnosis. in this study, we developed a deep learning-based fp-cit spect interpretation system to refine the imaging diagnosis of parkinson's disease. this system trained by spect images of pd patients and normal controls shows high classification accuracy comparable with the experts' evaluation referring quantification results. its high accuracy was validated in an independent cohort composed of patients with pd and nonparkinsonian tremor. in addition, we showed that some patients clinically diagnosed as pd who have scans without evidence of dopaminergic deficit (swedd), an atypical subgroup of pd, could be reclassified by our automated system. our results suggested that the deep learning-based model could accurately interpret fp-cit spect and overcome variability of human evaluation. it could help imaging diagnosis of patients with uncertain parkinsonism and provide objective patient group classification, particularly for swedd, in further clinical studies.","['dopamine transporter imaging', 'refining diagnosis', 'deep learning', 'based interpretation', 'parkinson', 'disease']"
"protein remote homology detection plays a vital role in studies of protein structures and functions. almost all of the traditional machine leaning methods require fixed length features to represent the protein sequences. however, it is never an easy task to extract the discriminative features with limited knowledge of proteins. on the other hand, deep learning technique has demonstrated its advantage in automatically learning representations. it is worthwhile to explore the applications of deep learning techniques to the protein remote homology detection.","['protein remote homology detection based', 'bidirectional long short', 'term memory']"
"the synthesis of glycans and the sorting of proteins are critical functions of the golgi apparatus and depend on its highly complex and compartmentalized architecture. high-content image analysis coupled to rna interference screening offers opportunities to explore this organelle organization and the gene network underlying it. to date, image-based golgi screens have based on a single parameter or supervised analysis with predefined golgi structural classes. here, we report the use of multiparametric data extracted from a single marker and a computational unsupervised analysis framework to explore golgi phenotypic diversity more extensively. in contrast with the three visually definable phenotypes, our framework reproducibly identified 10 golgi phenotypes. they were used to quantify and stratify phenotypic similarities among genetic perturbations. the derived phenotypic network partially overlaps previously reported protein-protein interactions as well as suggesting novel functional interactions. our workflow suggests the existence of multiple stable golgi organizational states and provides a proof of concept for the classification of drugs and genes using fine-grained phenotypic information.","['unsupervised machine learning', 'golgi phenotypic diversity', 'digging deep']"
"the ability to predict epitopes plays an enormous role in vaccine development in terms of our ability to zero in on where to do a more thorough in-vivo analysis of the protein in question. though for the past decade there have been numerous advancements and improvements in epitope prediction, on average the best benchmark prediction accuracies are still only around 60%. new machine learning algorithms have arisen within the domain of deep learning, text mining, and convolutional networks. this paper presents a novel analytically trained and string kernel using deep neural network, which is tailored for continuous epitope prediction, called: deep ridge regressed epitope predictor (drrep).","['deep ridge regressed epitope predictor', 'drrep']"
"cardiac left ventricle (lv) quantification is among the most clinically important tasks for identification and diagnosis of cardiac disease. however, it is still a task of great challenge due to the high variability of cardiac structure across subjects and the complexity of temporal dynamics of cardiac sequences. full quantification, i.e., to simultaneously quantify all lv indices including two areas (cavity and myocardium), six regional wall thicknesses (rwt), three lv dimensions, and one phase (diastole or systole), is even more challenging since the ambiguous correlations existing among these indices may impinge upon the convergence and generalization of the learning procedure. in this paper, we propose a deep multitask relationship learning network (dmtrl) for full lv quantification. the proposed dmtrl first obtains expressive and robust cardiac representations with a deep convolution neural network (cnn); then models the temporal dynamics of cardiac sequences effectively with two parallel recurrent neural network (rnn) modules. after that, it estimates the three types of lv indices under a bayesian framework that is capable of learning multitask relationships automatically, and estimates the cardiac phase with a softmax classifier. the cnn representation, rnn temporal modeling, bayesian multitask relationship learning, and softmax classifier establish an effective and integrated network which can be learned in an end-to-end manner. the obtained task covariance matrix captures the correlations existing among these indices, therefore leads to accurate estimation of lv indices and cardiac phase. experiments on mr sequences of 145 subjects show that dmtrl achieves high accurate prediction, with average mean absolute error of 180\u202fmm2, 1.39\u202fmm, 2.51\u202fmm for areas, rwt, dimensions and error rate of 8.2% for the phase classification. this endows our method a great potential in comprehensive clinical assessment of global, regional and dynamic cardiac function.",['full left ventricle quantification via deep multitask relationships learning']
"vehicle detection is a challenging problem in autonomous driving systems, due to its large structural and appearance variations. in this paper, we propose a novel vehicle detection scheme based on multi-task deep convolutional neural networks (cnns) and region-of-interest (roi) voting. in the design of cnn architecture, we enrich the supervised information with subcategory, region overlap, bounding-box regression, and category of each training roi as a multi-task learning framework. this design allows the cnn model to share visual knowledge among different vehicle attributes simultaneously, and thus, detection robustness can be effectively improved. in addition, most existing methods consider each roi independently, ignoring the clues from its neighboring rois. in our approach, we utilize the cnn model to predict the offset direction of each roi boundary toward the corresponding ground truth. then, each roi can vote those suitable adjacent bounding boxes, which are consistent with this additional information. the voting results are combined with the score of each roi itself to find a more accurate location from a large number of candidates. experimental results on the real-world computer vision benchmarks kitti and the pascal2007 vehicle data set show that our approach achieves superior performance in vehicle detection compared with other existing published works.","['task vehicle detection', 'interest voting', 'region', 'multi']"
"the basis of this study was to explore the impact of the initiation of a problem-base learning (pbl) approach within a second-year pharmaceutics degree on a master of pharmacy programme, introduced as a way of improving deep learning and to foster independent learning.","['based learning approach', 'problem', 'pharmaceutics', 'exploring']"
"prediction of the spatial structure or function of biological macromolecules based on their sequences remains an important challenge in bioinformatics. when modeling biological sequences using traditional sequencing models, long-range interaction, complicated and variable output of labeled structures, and variable length of biological sequences usually lead to different solutions on a case-by-case basis. this study proposed a unified deep learning architecture based on long short-term memory or a gated recurrent unit to capture long-range interactions. the architecture designs the optional reshape operator to adapt to the diversity of the output labels and implements a training algorithm to support the training of sequence models capable of processing variable-length sequences. the merging and pooling operators enhances the ability of capturing short-range interactions between basic units of biological sequences. the proposed deep-learning architecture and its training algorithm might be capable of solving currently variable biological sequence-modeling problems under a unified framework. we validated the model on one of the most difficult biological sequence-modeling problems, protein residue interaction prediction. the results indicate that the accuracy of obtaining the residue interactions of the model exceeded popular approaches by 10 percent on multiple widely-used benchmarks.","['unified deep learning architecture', 'modeling biology sequence']"
"melanoma is a fatal form of skin cancer when left undiagnosed. computer-aided diagnosis systems powered by convolutional neural networks (cnns) can improve diagnostic accuracy and save lives. cnns have been successfully used in both skin lesion segmentation and classification. for reasons heretofore unclear, previous works have found image segmentation to be, conflictingly, both detrimental and beneficial to skin lesion classification. we investigate the effect of expanding the segmentation border to include pixels surrounding the target lesion. ostensibly, segmenting a target skin lesion will remove inessential information, non-lesion skin, and artifacts to aid in classification. our results indicate that segmentation border enlargement produces, to a certain degree, better results across all metrics of interest when using a convolutional based classifier built using the transfer learning paradigm. consequently, preprocessing methods which produce borders larger than the actual lesion can potentially improve classifier performance, more than both perfect segmentation, using dermatologist created ground truth masks, and no segmentation altogether.","['rethinking skin lesion segmentation', 'convolutional classifier']"
"narrow-band imaging is an image-enhanced form of endoscopy used to observed microstructures and capillaries of the mucosal epithelium which allows for real-time prediction of histologic features of colorectal polyps. however, narrow-band imaging expertise is required to differentiate hyperplastic from neoplastic polyps with high levels of accuracy. we developed and tested a system of computer-aided diagnosis with a deep neural network (dnn-cad) to analyze narrow-band images of diminutive colorectal polyps.","['diminutive colorectal polyps using computer', 'aided analysis', 'accurate classification']"
"this paper presents a novel method for learning the cyclic contents of stochastic time series: the deep time-growing neural network (dtgnn). the dtgnn combines supervised and unsupervised methods in different levels of learning for an enhanced performance. it is employed by a multiscale learning structure to classify cyclic time series (cts), in which the dynamic contents of the time series are preserved in an efficient manner. this paper suggests a systematic procedure for finding the design parameter of the classification method for a one-versus-multiple class application. a novel validation method is also suggested for evaluating the structural risk, both in a quantitative and a qualitative manner. the effect of the dtgnn on the performance of the classifier is statistically validated through the repeated random subsampling using different sets of cts, from different medical applications. the validation involves four medical databases, comprised of 108 recordings of the electroencephalogram signal, 90 recordings of the electromyogram signal, 130 recordings of the heart sound signal, and 50 recordings of the respiratory sound signal. results of the statistical validations show that the dtgnn significantly improves the performance of the classification and also exhibits an optimal structural risk.","['deep machine learning method', 'classifying cyclic time series', 'biological signals using time', 'growing neural network']"
"accurate and reliable brain tumor segmentation is a critical component in cancer diagnosis, treatment planning, and treatment outcome evaluation. build upon successful deep learning techniques, a novel brain tumor segmentation method is developed by integrating fully convolutional neural networks (fcnns) and conditional random fields (crfs) in a unified framework to obtain segmentation results with appearance and spatial consistency. we train a deep learning based segmentation model using 2d image patches and image slices in following steps: 1) training fcnns using image patches; 2) training crfs as recurrent neural networks (crf-rnn) using image slices with parameters of fcnns fixed; and 3) fine-tuning the fcnns and the crf-rnn using image slices. particularly, we train 3 segmentation models using 2d image patches and slices obtained in axial, coronal and sagittal views respectively, and combine them to segment brain tumors using a voting based fusion strategy. our method could segment brain images slice-by-slice, much faster than those based on image patches. we have evaluated our method based on imaging data provided by the multimodal brain tumor image segmentation challenge (brats) 2013, brats 2015 and brats 2016. the experimental results have demonstrated that our method could build a segmentation model with flair, t1c, and t2 scans and achieve competitive performance as those built with flair, t1, t1c, and t2 scans.","['deep learning model integrating fcnns', 'brain tumor segmentation', 'crfs']"
"the medial entorhinal cortex (mec) is important in spatial navigation and memory formation and its layers have distinct neuronal subtypes, connectivity, spatial properties, and disease susceptibility. as little is known about the molecular basis for the development of these laminar differences, we analyzed microrna (mirna) and messenger rna (mrna) expression differences between rat mec layer ii and layers iii-vi during postnatal development. we identified layer and age-specific regulation of gene expression by mirnas, which included processes related to neuron specialization and locomotor behavior. further analyses by retrograde labeling and expression profiling of layer ii stellate neurons and in situ hybridization revealed that the mirna most up-regulated in layer ii, mir-143, was enriched in stellate neurons, whereas the mirna most up-regulated in deep layers, mir-219-5p, was expressed in ependymal cells, oligodendrocytes and glia. bioinformatics analyses of predicted mrna targets with negatively correlated expression patterns to mir-143 found that mir-143 likely regulates the lmo4 gene, which is known to influence hippocampal-based spatial learning.","['rat medial entorhinal cortex', 'postnatal development', 'neuronal subtypes', 'micrornas contribute', 'laminar differences']"
"automated segmentation of retinal blood vessels in label-free fundus images entails a pivotal role in computed aided diagnosis of ophthalmic pathologies, viz., diabetic retinopathy, hypertensive disorders and cardiovascular diseases. the challenge remains active in medical image analysis research due to varied distribution of blood vessels, which manifest variations in their dimensions of physical appearance against a noisy background. in this paper we formulate the segmentation challenge as a classification task. specifically, we employ unsupervised hierarchical feature learning using ensemble of two level of sparsely trained denoised stacked autoencoder. first level training with bootstrap samples ensures decoupling and second level ensemble formed by different network architectures ensures architectural revision. we show that ensemble training of auto-encoders fosters diversity in learning dictionary of visual kernels for vessel segmentation. softmax classifier is used for fine tuning each member autoencoder and multiple strategies are explored for 2-level fusion of ensemble members. on drive dataset, we achieve maximum average accuracy of 95.33% with an impressively low standard deviation of 0.003 and kappa agreement coefficient of 0.708. comparison with other major algorithms substantiates the high efficacy of our model.","['fundus images towards achieving label', 'retinal vessel segmentation', 'deep neural ensemble', 'free angiography']"
"high-density surface electromyography (hd-semg) is to record muscles' electrical activity from a restricted area of the skin by using two dimensional arrays of closely spaced electrodes. this technique allows the analysis and modelling of semg signals in both the temporal and spatial domains, leading to new possibilities for studying next-generation muscle-computer interfaces (mcis). semg-based gesture recognition has usually been investigated in an intra-session scenario, and the absence of a standard benchmark database limits the use of hd-semg in real-world mci. to address these problems, we present a benchmark database of hd-semg recordings of hand gestures performed by 23 participants, based on an 8 × 16 electrode array, and propose a deep-learning-based domain adaptation framework to enhance semg-based inter-session gesture recognition. experiments on ninapro, csl-hdemg and our capgmyo dataset validate that our approach outperforms state-of-the-arts methods on intra-session and effectively improved inter-session gesture recognition.","['session gesture recognition enhanced', 'deep domain adaptation', 'surface emg', 'based inter']"
"contrary to forward biomechanical functions, which are deterministic, inverse biomechanical functions are generally not. calculating an inverse biomechanical function is an ill-posed problem, which has no unique solution for a manipulator with several degrees of freedom. studies of the command and control of biological movements suggest that the cerebellum takes part in the computation of approximate inverse functions, and this ability can control fast movements by predicting the consequence of current motor command. limb movements toward a goal are defined as fast if they last less than the total duration of the processing and transmission delays in the motor and sensory pathways. because of these delays, fast movements cannot be continuously controlled in a closed loop by use of sensory signals. thus, fast movements must be controlled by some open loop controller, of which cerebellar pathways constitute an important part. this article presents a system-level fuzzy neuronal motor control circuit, inspired by the cerebellar pathways. the cerebellar cortex (cc) is assumed to embed internal models of the biomechanical functions of the limb segments. such neural models are able to predict the consequences of motor commands and issue predictive signals encoding movement variables, which are sent to the controller via internal feedback loops. differences between desired and expected values of variables of movements are calculated in the deep cerebellar nuclei (dcn). after motor learning, the whole circuit can approximate the inverse function of the biomechanical function of a limb and acts as a controller. in this research, internal models of direct biomechanical functions are learned and embedded in the connectivity of the cerebellar pathways. two fuzzy neural networks represent the two parts of the cerebellum, and an online gradual learning drives the acquisition of the internal models in cc and the controlling rules in dcn. as during real learning, exercise and repetition increase skill and speed. the learning procedure is started by a simple and slow movement, controlled in the presence of delays by a simple closed loop controller comparable to the spinal reflexes. the speed of the movements is then increased gradually, and output error signals are used to compute teaching signals and drive learning. repetition of movements at each speed level allows to properly set the two neural networks, and progressively learn the movement. finally, conditions of stability of the proposed model as an inverter are identified. next, the control of a single segment arm, moved by two muscles, is simulated. after proper setting by motor learning, the circuit is able to reject perturbations.","['gradually learn inverse biomechanical functions', 'motor control inspired', 'fuzzy neuronal model', 'cerebellar pathways', 'presence', 'online', 'delay']"
"addressing deleterious effects of noncoding mutations is an essential step towards the identification of disease-causal mutations of gene regulatory elements. several methods for quantifying the deleteriousness of noncoding mutations using artificial intelligence, deep learning and other approaches have been recently proposed. although the majority of the proposed methods have demonstrated excellent accuracy on different test sets, there is rarely a consensus. in addition, advanced statistical and artificial learning approaches used by these methods make it difficult porting these methods outside of the labs that have developed them. to address these challenges and to transform the methodological advances in predicting deleterious noncoding mutations into a practical resource available for the broader functional genomics and population genetics communities, we developed snpdelscore, which uses a panel of proposed methods for quantifying deleterious effects of noncoding mutations to precompute and compare the deleteriousness scores of all common snps in the human genome in 44 cell lines. the panel of deleteriousness scores of a snp computed using different methods is supplemented by functional information from the gwas catalog, libraries of transcription factor-binding sites, and genic characteristics of mutations. snpdelscore comes with a genome browser capable of displaying and comparing large sets of snps in a genomic locus and rapidly identifying consensus snps with the highest deleteriousness scores making those prime candidates for phenotype-causal polymorphisms.","['score deleterious effects', 'combining multiple methods', 'noncoding mutations', 'human genome', 'snpdelscore']"
"one approach to improving the personalized treatment of cancer is to understand the cellular signaling transduction pathways that cause cancer at the level of the individual patient. in this study, we used unsupervised deep learning to learn the hierarchical structure within cancer gene expression data. deep learning is a group of machine learning algorithms that use multiple layers of hidden units to capture hierarchically related, alternative representations of the input data. we hypothesize that this hierarchical structure learned by deep learning will be related to the cellular signaling system.","['unsupervised deep learning reveals prognostically relevant subtypes', 'glioblastoma']"
"age-related macular degeneration (amd) affects millions of people throughout the world. the intermediate stage may go undetected, as it typically is asymptomatic. however, the preferred practice patterns for amd recommend identifying individuals with this stage of the disease to educate how to monitor for the early detection of the choroidal neovascular stage before substantial vision loss has occurred and to consider dietary supplements that might reduce the risk of the disease progressing from the intermediate to the advanced stage. identification, though, can be time-intensive and requires expertly trained individuals.","['color fundus images using deep convolutional neural networks', 'related macular degeneration', 'automated grading', 'age']"
"acceptance of a learning technology affects students' intention to use that technology, but the influence of the acceptance of a learning technology on learning approaches has not been investigated in the literature. a deep learning approach is important in the field of health, where links must be created between skills, knowledge, and habits. our hypothesis was that acceptance of a hybrid learning model would affect students' way of learning.","['hybrid learning affect learning approaches', 'france', 'acceptance']"
"delineation of the clinical target volume (ctv) and organs at risk (oars) is very important for radiotherapy but is time-consuming and prone to inter-observer variation. here, we proposed a novel deep dilated convolutional neural network (ddcnn)-based method for fast and consistent auto-segmentation of these structures.","['rectal cancer using deep dilated convolutional neural networks', 'clinical target volume', 'planning ct', 'automatic segmentation', 'risk', 'organs']"
"in humans, efficient recognition of written symbols is thought to rely on a hierarchical processing system, where simple features are progressively combined into more abstract, high-level representations. here, we present a computational model of persian character recognition based on deep belief networks, where increasingly more complex visual features emerge in a completely unsupervised manner by fitting a hierarchical generative model to the sensory data. crucially, high-level internal representations emerging from unsupervised deep learning can be easily read out by a linear classifier, achieving state-of-the-art recognition accuracy. furthermore, we tested the hypothesis that handwritten digits and letters share many common visual features: a generative model that captures the statistical structure of the letters distribution should therefore also support the recognition of written digits. to this aim, deep networks trained on persian letters were used to build high-level representations of persian digits, which were indeed read out with high accuracy. our simulations show that complex visual features, such as those mediating the identification of persian symbols, can emerge from unsupervised learning in multilayered neural networks and can support knowledge transfer across related domains.","['unsupervised deep learning', 'sharing visual features', 'persian character recognition', 'learning representation hierarchies', 'computational investigation']"
"we present a rare complication of deep venous thrombosis with pulmonary embolism that threatened the patient with systemic embolization. a 36-year-old female was referred to the hospital after five days of progressive shortness of breath and chest pain. preceding onset of symptoms, she had undergone surgery leading to reduced physical activity and had just returned from vacation by a long flight. investigations with transthoracic and transesophageal echocardiography revealed a thromboembolism-in-transit across a patent foramen ovale. thoracic ct showed submassive bilateral pulmonary embolism. hemodynamic parameters were stable. the patient was treated surgically with extraction of the thrombus, closure of the foramen ovale and removal of the bilateral pulmonary emboli. she was discharged after an uneventful hospital stay.","['pulmonary embolism', 'transit', 'thromboembolism', 'management']"
"automated surface inspection (asi) is a challenging task in industry, as collecting training dataset is usually costly and related methods are highly dataset-dependent. in this paper, a generic approach that requires small training data for asi is proposed. first, this approach builds classifier on the features of image patches, where the features are transferred from a pretrained deep learning network. next, pixel-wise prediction is obtained by convolving the trained classifier over input image. an experiment on three public and one industrial data set is carried out. the experiment involves two tasks: 1) image classification and 2) defect segmentation. the results of proposed algorithm are compared against several best benchmarks in literature. in the classification tasks, the proposed method improves accuracy by 0.66%-25.50%. in the segmentation tasks, the proposed method reduces error escape rates by 6.00%-19.00% in three defect types and improves accuracies by 2.29%-9.86% in all seven defect types. in addition, the proposed method achieves 0.0% error escape rate in the segmentation task of industrial data.","['automated surface inspection', 'generic deep', 'based approach', 'learning']"
"in this study, to advance smart health applications which have increasing security/privacy requirements, we propose a novel highly wearable ecg-based user identification system, empowered by both non-standard convenient ecg lead configurations and deep learning techniques. specifically, to achieve a super wearability, we suggest situating all the ecg electrodes on the left upper-arm, or behind the ears, and successfully obtain weak but distinguishable ecg waveforms. afterwards, to identify individuals from weak ecg, we further present a two-stage framework, including ecg imaging and deep feature learning/identification. in the former stage, the ecg heartbeats are projected to a 2d state space, to reveal heartbeats' trajectory behaviors and produce 2d images by a split-then-hit method. in the second stage, a convolutional neural network is introduced to automatically learn the intricate patterns directly from the ecg image representations without heavy feature engineering, and then perform user identification. experimental results on two acquired datasets using our wearable prototype, show a promising identification rate of 98.4% (single-arm-ecg) and 91.1% (ear-ecg), respectively. to the best of our knowledge, it is the first study on the feasibility of using single-arm-ecg/ear-ecg for user identification purpose, which is expected to contribute to pervasive ecg-based user identification in smart health applications.","['highly wearable biometric human identification', 'ecg image learning', 'deep arm', 'ear']"
"worldwide, polypoidal choroidal vasculopathy (pcv) is a common vision-threatening exudative maculopathy, and pigment epithelium detachment (ped) is an important clinical characteristic. thus, precise and efficient ped segmentation is necessary for pcv clinical diagnosis and treatment. we propose a dual-stage learning framework via deep neural networks (dnn) for automated ped segmentation in pcv patients to avoid issues associated with manual ped segmentation (subjectivity, manual segmentation errors, and high time consumption).the optical coherence tomography scans of fifty patients were quantitatively evaluated with different algorithms and clinicians. dual-stage dnn outperformed existing ped segmentation methods for all segmentation accuracy parameters, including true positive volume fraction (85.74 ± 8.69%), dice similarity coefficient (85.69 ± 8.08%), positive predictive value (86.02 ± 8.99%) and false positive volume fraction (0.38 ± 0.18%). dual-stage dnn achieves accurate ped quantitative information, works with multiple types of peds and agrees well with manual delineation, suggesting that it is a potential automated assistant for pcv management.","['stage deep learning framework', 'pigment epithelium detachment segmentation', 'polypoidal choroidal vasculopathy', 'dual']"
"the hippocampus places us both in time and space. it does so over remarkably large spans: milliseconds to years, and centimeters to kilometers. this works for sensory representations, for memory, and for behavioral context. how does it fit in such wide ranges of time and space scales, and keep order among the many dimensions of stimulus context? a key organizing principle for a wide sweep of scales and stimulus dimensions is that of order in time, or sequences. sequences of neuronal activity are ubiquitous in sensory processing, in motor control, in planning actions, and in memory. against this strong evidence for the phenomenon, there are currently more models than definite experiments about how the brain generates ordered activity. the flip side of sequence generation is discrimination. discrimination of sequences has been extensively studied at the behavioral, systems, and modeling level, but again physiological mechanisms are fewer. it is against this backdrop that i discuss two recent developments in neural sequence computation, that at face value share little beyond the label ""neural."" these are dendritic sequence discrimination, and deep learning. one derives from channel physiology and molecular signaling, the other from applied neural network theory - apparently extreme ends of the spectrum of neural circuit detail. i suggest that each of these topics has deep lessons about the possible mechanisms, scales, and capabilities of hippocampal sequence computation.","['deep learning', 'sequences', 'hippocampus', 'dendrites']"
"the possibility of using deep brain stimulation (dbs) for memory enhancement has recently been reported, but the precise underlying mechanisms of its effects remain unknown. our previous study suggested that spatial memory improvement by medial septum (ms)-dbs may be associated with cholinergic regulation and neurogenesis. however, the affected stage of memory could not be distinguished because the stimulation was delivered during the execution of all memory processes. therefore, this study was performed to determine the stage of memory affected by ms-dbs. rats were administered 192 igg-saporin to lesion cholinergic neurons. stimulation was delivered at different times in different groups of rats: 5\xa0days before the morris water maze test (pre-stimulation), 5\xa0days during the training phase of the morris water maze test (training-stimulation), and 2\xa0h before the morris water maze probe test (probe-stimulation). a fourth group of rats was lesioned but received no stimulation. these four groups were compared with a normal (control) group.","['achieve spatial memory improvement', 'morris water maze', 'deep brain stimulation', 'appropriate time', 'identifying']"
"misdosing medications with sensitive therapeutic windows, such as heparin, can place patients at unnecessary risk, increase length of hospital stay, and lead to wasted hospital resources. in this work, we present a clinician-in-the-loop sequential decision making framework, which provides an individualized dosing policy adapted to each patient's evolving clinical phenotype. we employed retrospective data from the publicly available mimic ii intensive care unit database, and developed a deep reinforcement learning algorithm that learns an optimal heparin dosing policy from sample dosing trails and their associated outcomes in large electronic medical records. using separate training and testing datasets, our model was observed to be effective in proposing heparin doses that resulted in better expected outcomes than the clinical guidelines. our results demonstrate that a sequential modeling approach, learned from retrospective data, could potentially be used at the bedside to derive individualized patient dosing policies.","['deep reinforcement learning approach', 'suboptimal clinical examples', 'optimal medication dosing']"
"deep brain stimulation (dbs) has gained increasing attention as an effective method to mitigate parkinson's disease (pd) disorders. existing dbs systems are open-loop such that the system parameters are not adjusted automatically based on patient's behavior. classification of human behavior is an important step in the design of the next generation of dbs systems that are closed-loop. this paper presents a classification approach to recognize such behavioral tasks using the subthalamic nucleus (stn) local field potential (lfp) signals. in our approach, we use the time-frequency representation (spectrogram) of the raw lfp signals recorded from left and right stns as the feature vectors. then these features are combined together via support vector machines (svm) with multiple kernel learning (mkl) formulation. the mkl-based classification method is utilized to classify different tasks: button press, mouth movement, speech, and arm movement. our experiments show that the lp-norm mkl significantly outperforms single kernel svm-based classifiers in classifying behavioral tasks of five subjects even using signals acquired with a low sampling rate of 10 hz. this leads to a lower computational cost.","['human behavioral task classification using stn', 'multiple kernel learning approach', 'lfp signal']"
"early debridement and/or eschar removal is regarded as a significant step in the treatment of deep partial and full thickness burns. it aims to control wound bioburden and allows early wound closure by conservative treatment or skin grafting. preservation of viable dermis accompanied by early wound closure, is regarded as a necessary step to reduce scar related complication, e.g. functional limitations and/or unaesthetic scar formation. aside from the classical techniques of surgical excision as tangential excision for eschar removal, hydro-surgery, maggot therapy, laser, enzymatic debridement have been described as additional techniques in the burn surgeon's armamentarium. it is widely accepted that early eschar removal within 72h improves the outcome of burn wound treatment by reducing bacterial wound colonization, infection and length of hospital stay. in contrast, the right technique for eschar removal is still a matter of debate. there is increasing evidence that enzymatic debridement is a powerful tool to remove eschar in burn wounds, reducing blood loss, the need for autologous skin grafting and the number of wounds requiring surgical excision. in order to assess the role and clinical advantages of enzymatic debridement by a mixture of proteolytic enzymes enriched in bromelain (nexobrid®) beyond the scope of the literature and in view of users' experience, a european consensus meeting was scheduled. the aim was to provide statements for application, based on the mutual experience of applying enzymatic debridement in more than 500 adult and pediatric patients by the consensus panelists. issues to be addressed were: indications, pain management and anesthesia, timing of application, technique of application, after-intervention care, skin grafting after enzymatic debridement, blood loss, training strategies and learning curve and areas of future research needs. sixty-eight (68) consensus statements were provided for the use of enzymatic debridement. the degree of consensus was remarkably high, with a unanimous consensus in 88.2% of statements, and lowest degree of consensus of 70% in only 3 statements. this consensus document may serve as preliminary guideline for the use of enzymatic debridement with user-oriented recommendations until further evidence and systematic guidelines are available.","['bromelain based enzymatic debridement', 'eschar removal', 'nexobrid']"
"deep learning and unsupervised feature learning have received great attention in past years for their ability to transform input data into high level representations using machine learning techniques. such interest has been growing steadily in the field of medical image diagnosis, particularly in melanoma classification. in this paper, a novel application of deep learning (stacked sparse auto-encoders) is presented for skin lesion classification task. the stacked sparse auto-encoder discovers latent information features in input images (pixel intensities). these high-level features are subsequently fed into a classifier for classifying dermoscopy images. in addition, we proposed a new deep neural network architecture based on bag-of-features (bof) model, which learns high-level image representation and maps images into bof space. then, we examine how using this deep representation of bof, compared with pixel intensities of images, can improve the classification accuracy. the proposed method is evaluated on a test set of 244 skin images. to test the performance of the proposed method, the area under the receiver operating characteristics curve (auc) is utilized. the proposed method is found to achieve 95% accuracy.","['features model', 'dermoscopy images', 'deep bag', 'melanomas', 'classification']"
"the prediction of eukaryotic protein subcellular localization is a well-studied topic in bioinformatics due to its relevance in proteomics research. many machine learning methods have been successfully applied in this task, but in most of them, predictions rely on annotation of homologues from knowledge databases. for novel proteins where no annotated homologues exist, and for predicting the effects of sequence variants, it is desirable to have methods for predicting protein properties from sequence information only.","['protein subcellular localization using deep learning', 'prediction', 'deeploc']"
"automated segmentation of the portal vein (pv) for liver radiotherapy planning is a challenging task due to potentially low vasculature contrast, complex pv anatomy and image artifacts originated from fiducial markers and vasculature stents. in this paper, we propose a novel framework for automated segmentation of the pv from computed tomography (ct) images. we apply convolutional neural networks (cnns) to learn the consistent appearance patterns of the pv using a training set of ct images with reference annotations and then enhance the pv in previously unseen ct images. markov random fields (mrfs) were further used to smooth the results of the enhancement of the cnn enhancement and remove isolated mis-segmented regions. finally, cnn-mrf-based enhancement was augmented with pv centerline detection that relied on pv anatomical properties such as tubularity and branch composition. the framework was validated on a clinical database with 72 ct images of patients scheduled for liver stereotactic body radiation therapy. the obtained accuracy of the segmentation was [formula: see tex","['mean symmetric surface distance', 'liver radiation therapy planning', 'liver sbrt planning', 'obtained results indicate', 'median dice coefficient', 'combining deep learning', 'see text', 'potentially integrated', 'portal vein', 'anatomical analysis', 'pv region', 'accurate segmentation', 'segmentation', 'pv', 'used', 'u2009mm', 'terms', 'respectively', 'interest', 'formula']"
"understanding the cell-specific binding patterns of transcription factors (tfs) is fundamental to studying gene regulatory networks in biological systems, for which chip-seq not only provides valuable data but is also considered as the gold standard. despite tremendous efforts from the scientific community to conduct tf chip-seq experiments, the available data represent only a limited percentage of chip-seq experiments, considering all possible combinations of tfs and cell lines. in this study, we demonstrate a method for accurately predicting cell-specific tf binding for tf-cell line combinations based on only a small fraction (4%) of the combinations using available chip-seq data. the proposed model, termed tfimpute, is based on a deep neural network with a multi-task learning setting to borrow information across transcription factors and cell lines. compared with existing methods, tfimpute achieves comparable accuracy on tf-cell line combinations with chip-seq data; moreover, tfimpute achieves better accuracy on tf-cell line combinations without chip-seq data. this approach can predict cell line specific enhancer activities in k562 and hepg2 cell lines, as measured by massively parallel reporter assays, and predicts the impact of snps on tf binding.","['transcription factor binding predictions based', 'deep learning', 'imputation']"
"falls of individuals with dementia are frequent, dangerous, and costly. early detection and access to the history of a fall is crucial for efficient care and secondary prevention in cognitively impaired individuals. however, most falls remain unwitnessed events. furthermore, understanding why and how a fall occurred is a challenge. video capture and secure transmission of real-world falls thus stands as a promising assistive tool.","['video incident review', 'dementia managed care', 'pilot study', 'fall rate', 'reduction']"
"we present a general purpose graphics processing unit (gpgpu) based real-time traffic sign detection and recognition method that is robust against illumination changes. there have been many approaches to traffic sign recognition in various research fields; however, previous approaches faced several limitations when under low illumination or wide variance of light conditions. to overcome these drawbacks and improve processing speeds, we propose a method that 1) is robust against illumination changes, 2) uses gpgpu-based real-time traffic sign detection, and 3) performs region detecting and recognition using a hierarchical model. this method produces stable results in low illumination environments. both detection and hierarchical recognition are performed in real-time, and the proposed method achieves 0.97 f1-score on our collective dataset, which uses the vienna convention traffic rules (germany and south korea).","['time traffic sign recognition based', 'general purpose gpu', 'real', 'learning', 'deep']"
"finger-vein recognition, a new and advanced biometrics recognition method, is attracting the attention of researchers because of its advantages such as high recognition performance and lesser likelihood of theft and inaccuracies occurring on account of skin condition defects. however, as reported by previous researchers, it is possible to attack a finger-vein recognition system by using presentation attack (fake) finger-vein images. as a result, spoof detection, named as presentation attack detection (pad), is necessary in such recognition systems. previous attempts to establish pad methods primarily focused on designing feature extractors by hand (handcrafted feature extractor) based on the observations of the researchers about the difference between real (live) and presentation attack finger-vein images. therefore, the detection performance was limited. recently, the deep learning framework has been successfully applied in computer vision and delivered superior results compared to traditional handcrafted methods on various computer vision applications such as image-based face recognition, gender recognition and image classification. in this paper, we propose a pad method for near-infrared (nir) camera-based finger-vein recognition system using convolutional neural network (cnn) to enhance the detection ability of previous handcrafted methods. using the cnn method, we can derive a more suitable feature extractor for pad than the other handcrafted methods using a training procedure. we further process the extracted image features to enhance the presentation attack finger-vein image detection ability of the cnn method using principal component analysis method (pca) for dimensionality reduction of feature space and support vector machine (svm) for classification. through extensive experimental results, we confirm that our proposed method is adequate for presentation attack finger-vein image detection and it can deliver superior detection results compared to cnn-based methods and other previous handcrafted methods.","['vein recognition system using nir camera', 'spoof detection', 'finger']"
"several factors play a role in academic achievement, individual's excellence and capability to do actions and tasks that the learner is in charge of in learning areas. the main goal of this study was to present academic achievement causal model based on the dimensions of goal orientation and learning approaches among the students of medical science and dentistry courses in guilan university of medical sciences in 2013.","['academic achievement causal model based', 'goal orientation', 'students', 'presenting']"
"artificial intelligence (ai), a computer system aiming to mimic human intelligence, is gaining increasing interest and is being incorporated into many fields, including medicine. stroke medicine is one such area of application of ai, for improving the accuracy of diagnosis and the quality of patient care. for stroke management, adequate analysis of stroke imaging is crucial. recently, ai techniques have been applied to decipher the data from stroke imaging and have demonstrated some promising results. in the very near future, such ai techniques may play a pivotal role in determining the therapeutic methods and predicting the prognosis for stroke patients in an individualized manner. in this review, we offer a glimpse at the use of ai in stroke imaging, specifically focusing on its technical principles, clinical application, and future perspectives.","['stroke imaging', 'artificial intelligence', 'deep', 'brain']"
"the goal of the present study was to apply deep learning algorithms to identify autism spectrum disorder (asd) patients from large brain imaging dataset, based solely on the patients brain activation patterns. we investigated asd patients brain imaging data from a world-wide multi-site database known as abide (autism brain imaging data exchange). asd is a brain-based disorder characterized by social deficits and repetitive behaviors. according to recent centers for disease control data, asd affects one in 68 children in the united states. we investigated patterns of functional connectivity that objectively identify asd participants from functional brain imaging data, and attempted to unveil the neural patterns that emerged from the classification. the results improved the state-of-the-art by achieving 70% accuracy in identification of asd versus control patients in the dataset. the patterns that emerged from the classification show an anticorrelation of brain function between anterior and posterior areas of the brain; the anticorrelation corroborates current empirical evidence of anterior-posterior disruption in brain connectivity in asd. we present the results and identify the areas of the brain that contributed most to differentiating asd from typically developing controls as per our deep learning model.","['autism spectrum disorder using deep learning', 'abide dataset', 'identification']"
"deep learning has achieved remarkable results in the areas of computer vision, speech recognition, natural language processing and most recently, even playing go. the application of deep-learning to problems in healthcare, however, has gained attention only in recent years, and it's ultimate place at the bedside remains a topic of skeptical discussion. while there is a growing academic interest in the application of machine learning (ml) techniques to clinical problems, many in the clinical community see little incentive to upgrade from simpler methods, such as logistic regression, to deep learning. logistic regression, after all, provides odds ratios, p-values and confidence intervals that allow for ease of interpretation, while deep nets are often seen as `black-boxes' which are difficult to understand and, as of yet, have not demonstrated performance levels far exceeding their simpler counterparts. if deep learning is to ever take a place at the bedside, it will require studies which (1) showcase the performance of deep-learning methods relative to other approaches and (2) interpret the relationships between network structure, model performance, features and outcomes. we have chosen these two requirements as the goal of this study. in our investigation, we utilized a publicly available emr dataset of over 32,000 intensive care unit patients and trained a deep belief network (dbn) to predict patient mortality at discharge. utilizing an evolutionary algorithm, we demonstrate automated topology selection for dbns. we demonstrate that with the correct topology selection, dbns can achieve better prediction performance compared to several bench-marking methods.","['deep network topology', 'mortality prediction', 'effects']"
"computational methods for phosphorylation site prediction play important roles in protein function studies and experimental design. most existing methods are based on feature extraction, which may result in incomplete or biased features. deep learning as the cutting-edge machine learning method has the ability to automatically discover complex representations of phosphorylation patterns from the raw sequences, and hence it provides a powerful tool for improvement of phosphorylation site prediction.","['specific phosphorylation site prediction', 'learning framework', 'musitedeep', 'kinase', 'general', 'deep']"
"segmentation of histopathology sections is a necessary preprocessing step for digital pathology. due to the large variability of biological tissue, machine learning techniques have shown superior performance over conventional image processing methods. here we present our deep neural network-based approach for segmentation and classification of glands in tissue of benign and malignant colorectal cancer, which was developed to participate in the glas@miccai2015 colon gland segmentation challenge. we use two distinct deep convolutional neural networks (cnn) for pixel-wise classification of hematoxylin-eosin stained images. while the first classifier separates glands from background, the second classifier identifies gland-separating structures. in a subsequent step, a figure-ground segmentation based on weighted total variation produces the final segmentation result by regularizing the cnn predictions. we present both quantitative and qualitative segmentation results on the recently released and publicly available warwick-qu colon adenocarcinoma dataset associated with the glas@miccai2015 challenge and compare our approach to the simultaneously developed other approaches that participated in the same challenge. on two test sets, we demonstrate our segmentation performance and show that we achieve a tissue classification accuracy of 98% and 95%, making use of the inherent capability of our system to distinguish between benign and malignant tissue. our results show that deep learning approaches can yield highly accurate and reproducible results for biomedical image analysis, with the potential to significantly improve the quality and speed of medical diagnoses.","['deep convolutional neural networks', 'total variation regularization', 'colon glands', 'segmentation', 'classification']"
"mass cytometry or cytof is an emerging technology for high-dimensional multiparameter single cell analysis that overcomes many limitations of fluorescence-based flow cytometry. new methods for analyzing cytof data attempt to improve automation, scalability, performance and interpretation of data generated in large studies. assigning individual cells into discrete groups of cell types (gating) involves time-consuming sequential manual steps, untenable for larger studies.","['gating mass cytometry data', 'deep learning']"
"human behavior modeling is a key component in application domains such as healthcare and social behavior research. in addition to accurate prediction, having the capacity to understand the roles of human behavior determinants and to provide explanations for the predicted behaviors is also important. having this capacity increases trust in the systems and the likelihood that the systems actually will be adopted, thus driving engagement and loyalty. however, most prediction models do not provide explanations for the behaviors they predict. in this paper, we study the research problem, human behavior prediction with explanations, for healthcare intervention systems in health social networks. we propose an ontology-based deep learning model (orbm+) for human behavior prediction over undirected and nodes-attributed graphs. we first propose a bottom-up algorithm to learn the user representation from health ontologies. then the user representation is utilized to incorporate self-motivation, social influences, and environmental events together in a human behavior prediction model, which extends a well-known deep learning method, the restricted boltzmann machine. orbm+ not only predicts human behaviors accurately, but also, it generates explanations for each predicted behavior. experiments conducted on both real and synthetic health social networks have shown the tremendous effectiveness of our approach compared with conventional methods.","['human behavior prediction', 'health social networks', 'based deep learning', 'ontology', 'explanations']"
"the accurate recognition of fetal facial standard plane (ffsp) (i.e., axial, coronal and sagittal plane) from ultrasound (us) images is quite essential for routine us examination. since the labor-intensive and subjective measurement is too time-consuming and unreliable, the development of the automatic ffsp recognition method is highly desirable. different from the previous methods, we leverage a general framework to recognize the ffsp from us images automatically. specifically, instead of using the previous hand-crafted visual features, we utilize the recent developed deep learning approach via very deep convolutional networks (dcnn) architecture to represent fine-grained details of us image. also, very small (3×3) convolution filters are adopted to improve the performance. the evaluation of our ffsp dataset shows the superiority of our method over the previous studies and achieves the state-of-the-art ffsp recognition results.","['fetal facial standard plane recognition via', 'deep convolutional networks']"
"automatic segmentation of brain tissues and white matter hyperintensities of presumed vascular origin (wmh) in mri of older patients is widely described in the literature. although brain abnormalities and motion artefacts are common in this age group, most segmentation methods are not evaluated in a setting that includes these items. in the present study, our tissue segmentation method for brain mri was extended and evaluated for additional wmh segmentation. furthermore, our method was evaluated in two large cohorts with a realistic variation in brain abnormalities and motion artefacts. the method uses a multi-scale convolutional neural network with a t1-weighted image, a t2-weighted fluid attenuated inversion recovery (flair) image and a t1-weighted inversion recovery (ir) image as input. the method automatically segments white matter (wm), cortical grey matter (cgm), basal ganglia and thalami (bgt), cerebellum (cb), brain stem (bs), lateral ventricular cerebrospinal fluid (lvcsf), peripheral cerebrospinal fluid (pcsf), and wmh. our method was evaluated quantitatively with images publicly available from the mrbrains13 challenge (n\xa0=\xa020), quantitatively and qualitatively in relatively healthy older subjects (n\xa0=\xa096), and qualitatively in patients from a memory clinic (n\xa0=\xa0110). the method can accurately segment wmh (overall dice coefficient in the mrbrains13 data of 0.67) without compromising performance for tissue segmentations (overall dice coefficients in the mrbrains13 data of 0.87 for wm, 0.85 for cgm, 0.82 for bgt, 0.93 for cb, 0.92 for bs, 0.93 for lvcsf, 0.76 for pcsf). furthermore, the automatic wmh volumes showed a high correlation with manual wmh volumes (spearman's ρ\xa0=\xa00.83 for relatively healthy older subjects). in both cohorts, our method produced reliable segmentations (as determined by a human observer) in most images (relatively healthy/memory clinic: tissues 88%/77% reliable, wmh 85%/84% reliable) despite various degrees of brain abnormalities and motion artefacts. in conclusion, this study shows that a convolutional neural network-based segmentation method can accurately segment brain tissues and wmh in mr images of older patients with varying degrees of brain abnormalities and motion artefacts.","['white matter hyperintensities', 'presumed vascular origin', 'deep learning approach', 'brain tissues', 'xa0mri', 'segmentation', 'evaluation']"
"in plant phenotyping, it has become important to be able to measure many features on large image sets in order to aid genetic discovery. the size of the datasets, now often captured robotically, often precludes manual inspection, hence the motivation for finding a fully automated approach. deep learning is an emerging field that promises unparalleled results on many data analysis problems. building on artificial neural networks, deep approaches have many more hidden layers in the network, and hence have greater discriminative and predictive power. we demonstrate the use of such approaches as part of a plant phenotyping pipeline. we show the success offered by such techniques when applied to the challenging problem of image-based plant phenotyping and demonstrate state-of-the-art results (>97% accuracy) for root and shoot feature identification and localization. we use fully automated trait identification using deep learning to identify quantitative trait loci in root architecture datasets. the majority (12 out of 14) of manually identified quantitative trait loci were also discovered using our automated approach based on deep learning detection to locate plant features. we have shown deep learning-based phenotyping to have very good detection and localization accuracy in validation and testing image sets. we have shown that such features can be used to derive meaningful biological traits, which in turn can be used in quantitative trait loci discovery pipelines. this process can be completely automated. we predict a paradigm shift in image-based phenotyping bought about by such deep learning approaches, given sufficient training sets.","['deep machine learning provides state', 'based plant phenotyping', 'art performance', 'image']"
"numerous studies have implicated the hippocampus in the encoding and storage of declarative and spatial memories. several models have considered the hippocampus and its distinct subfields to contain homogeneous pyramidal cell populations. yet, recent studies have led to a consensus that the dorso-ventral and proximo-distal axes have different connectivities and physiologies. the remaining deep-superficial axis of the pyramidal layer, however, remains relatively unexplored due to a lack of techniques that can record from neurons simultaneously at different depths. recent advances in transgenic mice, two-photon imaging and dense multisite recording have revealed extensive disparities between the pyramidal cells located in the deep and the superficial layers. here, we summarize differences between the two populations in terms of gene expression and connectivity with other intra-hippocampal subregions and local interneurons that underlie distinct learning processes and spatial representations. a unified picture will emerge to describe how such local segregations can increase the capacity of the hippocampus to compute and process numerous tasks in parallel.","['segregated cell populations enable distinct parallel encoding within', 'ca1 pyramidal layer', 'radial axis']"
"pedestrian detection is among the most frequently-used preprocessing tasks in many surveillance application fields, from low-level people counting to high-level scene understanding. even though many approaches perform well in the daytime with sufficient illumination, pedestrian detection at night is still a critical and challenging problem for video surveillance systems. to respond to this need, in this paper, we provide an affordable solution with a near-infrared stereo network camera, as well as a novel three-dimensional foreground pedestrian detection model. specifically, instead of using an expensive thermal camera, we build a near-infrared stereo vision system with two calibrated network cameras and near-infrared lamps. the core of the system is a novel voxel surface model, which is able to estimate the dynamic changes of three-dimensional geometric information of the surveillance scene and to segment and locate foreground pedestrians in real time. a free update policy for unknown points is designed for model updating, and the extracted shadow of the pedestrian is adopted to remove foreground false alarms. to evaluate the performance of the proposed model, the system is deployed in several nighttime surveillance scenes. experimental results demonstrate that our method is capable of nighttime pedestrian segmentation and detection in real time under heavy occlusion. in addition, the qualitative and quantitative comparison results show that our work outperforms classical background subtraction approaches and a recent rgb-d method, as well as achieving comparable performance with the state-of-the-art deep learning pedestrian detection method even with a much lower hardware cost.","['nighttime foreground pedestrian detection based', 'dimensional voxel surface model', 'three']"
"we investigate the addition of symmetry and temporal context information to a deep convolutional neural network (cnn) with the purpose of detecting malignant soft tissue lesions in mammography. we employ a simple linear mapping that takes the location of a mass candidate and maps it to either the contralateral or prior mammogram, and regions of interest (rois) are extracted around each location. two different architectures are subsequently explored: (1)\xa0a fusion model employing two datastreams where both rois are fed to the network during training and testing and (2)\xa0a stagewise approach where a single roi cnn is trained on the primary image and subsequently used as a feature extractor for both primary and contralateral or prior rois. a ""shallow"" gradient boosted tree classifier is then trained on the concatenation of these features and used to classify the joint representation. the baseline yielded an auc of 0.87 with confidence interval [0.853, 0.89","['mammography using deep neural networks', 'temporal data become available', 'see text ].', 'analyze temporal change', 'classifying symmetrical differences', 'temporal change', 'symmetrical differences', '9 ].', 'temporal analysis', 'training obtained', 'suspect performance', 'second setting', 'second architecture', 'results show', 'proposed method', 'new classifier', 'malignant masses', 'high specificity', 'first architecture', 'contralateral patches']"
"drug-drug interactions (ddis) are known to be responsible for nearly a third of all adverse drug reactions. hence several current efforts focus on extracting signal from emrs to prioritize ddis that need further exploration. to this end, being able to extract explicit mentions of ddis in free text narratives is an important task. in this paper, we explore recurrent neural network (rnn) architectures to detect and classify ddis from unstructured text using the ddiextraction dataset from the semeval 2013 (task 9) shared task. our methods are in line with those used in other recent deep learning efforts for relation extraction including ddi extraction. however, to our knowledge, we are the first to investigate the potential of character-level rnns (char-rnns) for ddi extraction (and relation extraction in general). furthermore, we explore a simple but effective model bootstrapping method to (a). build model averaging ensembles, (b). derive confidence intervals around mean micro-f scores (mmf), and (c). assess the average behavior of our methods. without any rule based filtering of negative examples, a popular heuristic used by most earlier efforts, we achieve an mmf of 69.13. by adding simple replicable heuristics to filter negative instances we are able to achieve an mmf of 70.38. furthermore, our best ensembles produce micro f-scores of 70.81 (without filtering) and 72.13 (with filtering), which are superior to metrics reported in published results. although char-rnns turnout to be inferior to regular word based rnn models in overall comparisons, we find that ensembling models from both architectures results in nontrivial gains over simply using either alone, indicating that they complement each other.","['level recurrent neural networks', 'extracting drug', 'drug interactions', 'word', 'character']"
"alternative splicing (as) is a genetically and epigenetically regulated pre-mrna processing to increase transcriptome and proteome diversity. comprehensively decoding these regulatory mechanisms holds promise in getting deeper insights into a variety of biological contexts involving in as, such as development and diseases. we assembled splicing (epi)genetic code, deepcode, for human embryonic stem cell (hesc) differentiation by integrating heterogeneous features of genomic sequences, 16 histone modifications with a multi-label deep neural network. with the advantages of epigenetic features, deepcode significantly improves the performance in predicting the splicing patterns and their changes during hesc differentiation. meanwhile, deepcode reveals the superiority of epigenomic features and their dominant roles in decoding as patterns, highlighting the necessity of including the epigenetic properties when assembling a more comprehensive splicing code. moreover, deepcode allows the robust predictions across cell lineages and datasets. especially, we identified a putative h3k36me3-regulated as event leading to a nonsense-mediated mrna decay of bard1. reduced bard1 expression results in the attenuation of atm/atr signalling activities and further the hesc differentiation. these results suggest a novel candidate mechanism linking histone modifications to hesc fate decision. in addition, when trained in different contexts, deepcode can be expanded to a variety of biological and biomedical fields.","['deep learning', 'splicing', 'ep']"
"response to prescribed analgesic drugs varies between individuals, and choosing the right drug/dose often involves a lengthy, iterative process of trial and error. furthermore, a significant portion of patients experience adverse events such as post-operative urinary retention (pour) during inpatient management of acute postoperative pain. to better forecast analgesic responses, we compared conventional machine learning methods with modern neural network architectures to gauge their effectiveness at forecasting temporal patterns of postoperative pain and analgesic use, as well as predicting the risk of pour. our results indicate that simpler machine learning approaches might offer superior results; however, all of these techniques may play a promising role for developing smarter post-operative pain management strategies.","['deep neural network architectures', 'forecasting analgesic response']"
"we introduce deepnat, a 3d deep convolutional neural network for the automatic segmentation of neuroanatomy in t1-weighted magnetic resonance images. deepnat is an end-to-end learning-based approach to brain segmentation that jointly learns an abstract feature representation and a multi-class classification. we propose a 3d patch-based approach, where we do not only predict the center voxel of the patch but also neighbors, which is formulated as multi-task learning. to address a class imbalance problem, we arrange two networks hierarchically, where the first one separates foreground from background, and the second one identifies 25 brain structures on the foreground. since patches lack spatial context, we augment them with coordinates. to this end, we introduce a novel intrinsic parameterization of the brain volume, formed by eigenfunctions of the laplace-beltrami operator. as network architecture, we use three convolutional layers with pooling, batch normalization, and non-linearities, followed by fully connected layers with dropout. the final segmentation is inferred from the probabilistic output of the network with a 3d fully connected conditional random field, which ensures label agreement between close voxels. the roughly 2.7million parameters in the network are learned with stochastic gradient descent. our results show that deepnat compares favorably to state-of-the-art methods. finally, the purely learning-based method may have a high potential for the adaptation to young, old, or diseased brains by fine-tuning the pre-trained network with a small training sample on the target application, where the availability of larger datasets with manual annotations may boost the overall segmentation accuracy in the future.","['deep convolutional neural network', 'segmenting neuroanatomy', 'deepnat']"
computer vision may aid in melanoma detection.,"['2016 international skin imaging collaboration international symposium', 'biomedical imaging challenge', 'dermoscopic images', 'computer algorithms', 'results', 'melanoma', 'diagnosis', 'dermatologists', 'comparison', 'accuracy']"
"unsupervised feature extractors are known to perform an efficient and discriminative representation of data. insight into the mappings they perform and human ability to understand them, however, remain very limited. this is especially prominent when multilayer deep learning architectures are used. this paper demonstrates how to remove these bottlenecks within the architecture of non-negativity constrained autoencoder. it is shown that using both l1 and l2 regularizations that induce non-negativity of weights, most of the weights in the network become constrained to be non-negative, thereby resulting into a more understandable structure with minute deterioration in classification accuracy. also, this proposed approach extracts features that are more sparse and produces additional output layer sparsification. the method is analyzed for accuracy and feature interpretation on the mnist data, the norb normalized uniform object data, and the reuters text categorization data set.","['enhanced understanding', 'deep learning', 'constrained autoencoders', 'data']"
"an accurate characterization of transcription factor (tf)-dna affinity landscape is crucial to a quantitative understanding of the molecular mechanisms underpinning endogenous gene regulation. while recent advances in biotechnology have brought the opportunity for building binding affinity prediction methods, the accurate characterization of tf-dna binding affinity landscape still remains a challenging problem.","['modeling transcription factor binding affinity landscape', 'novel embedding approach', 'sequence2vec']"
"due to the potential risk of inducing cancer, radiation exposure by x-ray ct devices should be reduced for routine patient scanning. however, in low-dose x-ray ct, severe artifacts typically occur due to photon starvation, beam hardening, and other causes, all of which decrease the reliability of the diagnosis. thus, a high-quality reconstruction method from low-dose x-ray ct data has become a major research topic in the ct community. conventional model-based de-noising approaches are, however, computationally very expensive, and image-domain de-noising approaches cannot readily remove ct-specific noise patterns. to tackle these problems, we want to develop a new low-dose x-ray ct algorithm based on a deep-learning approach.","['deep convolutional neural network using directional wavelets', 'ray ct reconstruction', 'dose x', 'low']"
"highly accurate classification of biomedical images is an essential task in the clinical diagnosis of numerous medical diseases identified from those images. traditional image classification methods combined with hand-crafted image feature descriptors and various classifiers are not able to effectively improve the accuracy rate and meet the high requirements of classification of biomedical images. the same also holds true for artificial neural network models directly trained with limited biomedical images used as training data or directly used as a black box to extract the deep features based on another distant dataset. in this study, we propose a highly reliable and accurate end-to-end classifier for all kinds of biomedical images via deep learning and transfer learning.","['end classifier using domain transferred deep convolutional neural networks', 'novel end', 'biomedical images']"
"in many computerized methods for cell detection, segmentation, and classification in digital histopathology that have recently emerged, the task of cell segmentation remains a chief problem for image processing in designing computer-aided diagnosis (cad) systems. in research and diagnostic studies on cancer, pathologists can use cad systems as second readers to analyze high-resolution histopathological images. since cell detection and segmentation are critical for cancer grade assessments, cellular and extracellular structures should primarily be extracted from histopathological images. in response, we sought to identify a useful cell segmentation approach with histopathological images that uses not only prominent deep learning algorithms (i.e., convolutional neural networks, stacked autoencoders, and deep belief networks), but also spatial relationships, information of which is critical for achieving better cell segmentation results. to that end, we collected cellular and extracellular samples from histopathological images by windowing in small patches with various sizes. in experiments, the segmentation accuracies of the methods used improved as the window sizes increased due to the addition of local spatial and contextual information. once we compared the effects of training sample size and influence of window size, results revealed that the deep learning algorithms, especially convolutional neural networks and partly stacked autoencoders, performed better than conventional methods in cell segmentation.","['utilizing spatial relationships', 'deep learning algorithms', 'histopathological images', 'cell segmentation']"
adopcion internacional de niños de etiopia y lenguaje: un estudio piloto.,"['pilot study ].', 'international adoption', 'language', 'ethiopia', 'children']"
"while urban systems demonstrate high spatial heterogeneity, many urban planning, economic and political decisions heavily rely on a deep understanding of local neighborhood contexts. we show that the structure of 311 service requests enables one possible way of building a unique signature of the local urban context, thus being able to serve as a low-cost decision support tool for urban stakeholders. considering examples of new york city, boston and chicago, we demonstrate how 311 service requests recorded and categorized by type in each neighborhood can be utilized to generate a meaningful classification of locations across the city, based on distinctive socioeconomic profiles. moreover, the 311-based classification of urban neighborhoods can present sufficient information to model various socioeconomic features. finally, we show that these characteristics are capable of predicting future trends in comparative local real estate prices. we demonstrate 311 service requests data can be used to monitor and predict socioeconomic performance of urban neighborhoods, allowing urban stakeholders to quantify the impacts of their interventions.","['311 service requests', 'urban location', 'structure', 'signature']"
"the remarkable development of deep learning in medicine and healthcare domain presents obvious privacy issues, when deep neural networks are built on users' personal and highly sensitive data, e.g., clinical records, user profiles, biomedical images, etc. however, only a few scientific studies on preserving privacy in deep learning have been conducted. in this paper, we focus on developing a private convolutional deep belief network (pcdbn), which essentially is a convolutional deep belief network (cdbn) under differential privacy. our main idea of enforcing ϵ-differential privacy is to leverage the functional mechanism to perturb the energy-based objective functions of traditional cdbns, rather than their results. one key contribution of this work is that we propose the use of chebyshev expansion to derive the approximate polynomial representation of objective functions. our theoretical analysis shows that we can further derive the sensitivity and error bounds of the approximate polynomial representation. as a result, preserving differential privacy in cdbns is feasible. we applied our model in a health social network, i.e., yesiwell data, and in a handwriting digit dataset, i.e., mnist data, for human behavior prediction, human behavior classification, and handwriting digit recognition tasks. theoretical analysis and rigorous experimental evaluations show that the pcdbn is highly effective. it significantly outperforms existing solutions.","['convolutional deep belief networks', 'preserving differential privacy']"
"teaching renal physiology for undergraduate medical students in an understandable way using methods which improve their deep learning has always been a problem. in this study, early clinical exposure (ece) was used in teaching renal physiology for the second year medical students in shiraz medical school. this article aims to introduce and develop this program and also measure the attitude of medical students toward ece in learning renal physiology.","['early clinical exposure program', 'learning renal physiology']"
"microaneurysms (mas) are known as early signs of diabetic-retinopathy which are called red lesions in color fundus images. detection of mas in fundus images needs highly skilled physicians or eye angiography. eye angiography is an invasive and expensive procedure. therefore, an automatic detection system to identify the mas locations in fundus images is in demand. in this paper, we proposed a system to detect the mas in colored fundus images. the proposed method composed of three stages. in the first stage, a series of pre-processing steps are used to make the input images more convenient for mas detection. to this end, green channel decomposition, gaussian filtering, median filtering, back ground determination, and subtraction operations are applied to input colored fundus images. after pre-processing, a candidate mas extraction procedure is applied to detect potential regions. a five-stepped procedure is adopted to get the potential ma locations. finally, deep convolutional neural network (dcnn) with reinforcement sample learning strategy is used to train the proposed system. the dcnn is trained with color image patches which are collected from ground-truth ma locations and non-ma locations. we conducted extensive experiments on roc dataset to evaluate of our proposal. the results are encouraging.","['novel microaneurysms detection approach based', 'reinforcement sample learning algorithm', 'convolutional neural networks']"
"advances in optical microscopy, biosensors and cell culturing technologies have transformed live cell imaging. thanks to these advances live cell imaging plays an increasingly important role in basic biology research as well as at all stages of drug development. image analysis methods are needed to extract quantitative information from these vast and complex data sets. the aim of this review is to provide an overview of available image analysis methods for live cell imaging, in particular required preprocessing image segmentation, cell tracking and data visualisation methods. the potential opportunities recent advances in machine learning, especially deep learning, and computer vision provide are being discussed. this review includes overview of the different available software packages and toolkits.","['live cell images', 'tools', 'opportunities', 'methods', 'analysis']"
"classification of electroencephalography (eeg)-based application is one of the important process for biomedical engineering. driver fatigue is a major case of traffic accidents worldwide and considered as a significant problem in recent decades. in this paper, a hybrid deep generic model (dgm)-based support vector machine is proposed for accurate detection of driver fatigue. traditionally, a probabilistic dgm with deep architecture is quite good at learning invariant features, but it is not always optimal for classification due to its trainable parameters are in the middle layer. alternatively, support vector machine (svm) itself is unable to learn complicated invariance, but produces good decision surface when applied to well-behaved features. consolidating unsupervised high-level feature extraction techniques, dgm and svm classification makes the integrated framework stronger and enhance mutually in feature extraction and classification. the experimental results showed that the proposed dbn-based driver fatigue monitoring system achieves better testing accuracy of 73.29 % with 91.10 % sensitivity and 55.48 % specificity. in short, the proposed hybrid dgm-based svm is an effective method for the detection of driver fatigue in eeg.","['based driver fatigue detection using hybrid deep generic model', 'eeg']"
"recent works on deep conditional random fields (crfs) have set new records on many vision tasks involving structured predictions. here, we propose a fully connected deep continuous crf model with task-specific losses for both discrete and continuous labeling problems. we exemplify the usefulness of the proposed model on multi-class semantic labeling (discrete) and the robust depth estimation (continuous) problems. in our framework, we model both the unary and the pairwise potential functions as deep convolutional neural networks (cnns), which are jointly learned in an end-to-end fashion. the proposed method possesses the main advantage of continuously valued crfs, which is a closed-form solution for the maximum a posteriori (map) inference. to better take into account the quality of the predicted estimates during the cause of learning, instead of using the commonly employed maximum likelihood crf parameter learning protocol, we propose task-specific loss functions for learning the crf parameters. it enables direct optimization of the quality of the map estimates during the learning process. specifically, we optimize the multi-class classification loss for the semantic labeling task and the tukey's biweight loss for the robust depth estimation problem. experimental results on the semantic labeling and robust depth estimation tasks demonstrate that the proposed method compare favorably against both baseline and state-of-the-art methods. in particular, we show that although the proposed deep crf model is continuously valued, with the equipment of task-specific loss, it achieves impressive results even on discrete labeling tasks.","['deep fully connected continuous crfs', 'specific loss', 'discriminative training', 'task']"
"despite the rising incidence of melanoma, medical students have progressively fewer opportunities to encounter patients with this important condition. curricula tend to attach the greatest value to intellectual forms of learning. however, compared with intellectual learning, experiential learning affords students deep insights about a condition. doctors who experience ill health are more empathic towards patients. however, opportunities to learn about cancer experientially are limited. temporary transfer tattoos can simulate the ill health associated with melanoma. we reasoned that if doctors who have been sick are more empathic temporarily 'having' melanoma might have a similar effect.","['simulated experiences', 'phenomenological analysis', 'medical students', '…', 'melanoma', 'living', 'day']"
"the treatment and management of early stage estrogen receptor positive (er+) breast cancer is hindered by the difficulty in identifying patients who require adjuvant chemotherapy in contrast to those that will respond to hormonal therapy. to distinguish between the more and less aggressive breast tumors, which is a fundamental criterion for the selection of an appropriate treatment plan, oncotype dx (odx) and other gene expression tests are typically employed. while informative, these gene expression tests are expensive, tissue destructive, and require specialized facilities. bloom-richardson (br) grade, the common scheme employed in breast cancer grading, has been shown to be correlated with the oncotype dx risk score. unfortunately, studies have also shown that the br grade determined experiences notable inter-observer variability. one of the constituent categories in br grading is the mitotic index. the goal of this study was to develop a deep learning (dl) classifier to identify mitotic figures from whole slides images of er+ breast cancer, the hypothesis being that the number of mitoses identified by the dl classifier would correlate with the corresponding oncotype dx risk categories. the mitosis detector yielded an average f-score of 0.556 in the amida mitosis dataset using a 6-fold validation setup. for a cohort of 174 whole slide images with early stage er+ breast cancer for which the corresponding oncotype dx score was available, the distributions of the number of mitoses identified by the dl classifier was found to be significantly different between the high vs low oncotype dx risk groups (p\u2009<\u20090.01). comparisons of other risk groups, using both odx score and histological grade, were also found to present significantly different automated mitoses distributions. additionally, a support vector machine classifier trained to separate low/high oncotype dx risk categories using the mitotic count determined by the dl classifier yielded a 83.19% classification accuracy.","['gene expression derived risk categories', 'estrogen receptor positive breast cancers', 'deep learning based strategy', 'associating mitotic activity', 'identifying']"
"the motor symptoms of both parkinson's disease and focal dystonia arise from dysfunction of the basal ganglia, and are improved by pallidotomy or deep brain stimulation of the globus pallidus interna (gpi). however, parkinson's disease is associated with a greater degree of basal ganglia-dependent learning impairment than dystonia. we attempt to understand this observation in terms of a comparison of the electrophysiology of the output of the basal ganglia between the two conditions. we use the natural experiment offered by deep brain stimulation to compare gpi local field potential responses in subjects with parkinson's disease compared to subjects with dystonia performing a forced-choice decision-making task with sensory feedback. in dystonic subjects, we found that auditory feedback was associated with the presence of high gamma oscillations nestled on a negative deflection, morphologically similar to sharp wave ripple complexes described in human rhinal cortex. these were not present in parkinson's disease subjects. the temporal properties of the high gamma burst were modified by incorrect trial performance compared to correct trial performance. both groups exhibited a robust low frequency response to 'incorrect' trial performance in dominant gpi but not non-dominant gpi at theta frequency. our results suggest that cellular processes associated with striatum-dependent memory function may be selectively impaired in parkinson's disease even if dopaminergic drugs are administered, but that error detection mechanisms are preserved.","['globus pallidus interna', 'disease states', 'cognitive role', 'insights']"
"rnas play key roles in cells through the interactions with proteins known as the rna-binding proteins (rbp) and their binding motifs enable crucial understanding of the post-transcriptional regulation of rnas. how the rbps correctly recognize the target rnas and why they bind specific positions is still far from clear. machine learning-based algorithms are widely acknowledged to be capable of speeding up this process. although many automatic tools have been developed to predict the rna-protein binding sites from the rapidly growing multi-resource data, e.g. sequence, structure, their domain specific features and formats have posed significant computational challenges. one of current difficulties is that the cross-source shared common knowledge is at a higher abstraction level beyond the observed data, resulting in a low efficiency of direct integration of observed data across domains. the other difficulty is how to interpret the prediction results. existing approaches tend to terminate after outputting the potential discrete binding sites on the sequences, but how to assemble them into the meaningful binding motifs is a topic worth of further investigation.","['new hybrid deep learning based cross', 'protein binding motifs mining', 'domain knowledge integration approach', 'rna']"
"intelligent fault diagnosis techniques have replaced time-consuming and unreliable human analysis, increasing the efficiency of fault diagnosis. deep learning models can improve the accuracy of intelligent fault diagnosis with the help of their multilayer nonlinear mapping ability. this paper proposes a novel method named deep convolutional neural networks with wide first-layer kernels (wdcnn). the proposed method uses raw vibration signals as input (data augmentation is used to generate more inputs), and uses the wide kernels in the first convolutional layer for extracting features and suppressing high frequency noise. small convolutional kernels in the preceding layers are used for multilayer nonlinear mapping. adabn is implemented to improve the domain adaptation ability of the model. the proposed model addresses the problem that currently, the accuracy of cnn applied to fault diagnosis is not very high. wdcnn can not only achieve 100% classification accuracy on normal signals, but also outperform the state-of-the-art dnn model which is based on frequency features under different working load and noisy environment conditions.","['new deep learning model', 'raw vibration signals', 'domain adaptation ability', 'good anti', 'fault diagnosis', 'noise']"
"identification of human leukocyte antigen (hla)-bound peptides by liquid chromatography-tandem mass spectrometry (lc-ms/ms) is poised to provide a deep understanding of rules underlying antigen presentation. however, a key obstacle is the ambiguity that arises from the co-expression of multiple hla alleles. here, we have implemented a scalable mono-allelic strategy for profiling the hla peptidome. by using cell lines expressing a single hla allele, optimizing immunopurifications, and developing an application-specific spectral search algorithm, we identified thousands of peptides bound to 16 different hla class i alleles. these data enabled the discovery of subdominant binding motifs and an integrative analysis quantifying the contribution of factors critical to epitope presentation, such as protein cleavage and gene expression. we trained neural-network prediction algorithms with our large dataset (>24,000 peptides) and outperformed algorithms trained on datasets of peptides with measured affinities. we thus demonstrate a strategy for systematically learning the rules of endogenous antigen presentation.","['mass spectrometry profiling', 'allelic cells enables', 'accurate epitope prediction', 'associated peptidomes', 'mono', 'hla']"
"interests have been rapidly growing in the field of radiotherapy to replace ct with magnetic resonance imaging (mri), due to superior soft tissue contrast offered by mri and the desire to reduce unnecessary radiation dose. mr-only radiotherapy also simplifies clinical workflow and avoids uncertainties in aligning mr with ct. methods, however, are needed to derive ct-equivalent representations, often known as synthetic ct (sct), from patient mr images for dose calculation and drr-based patient positioning. synthetic ct estimation is also important for pet attenuation correction in hybrid pet-mr systems. we propose in this work a novel deep convolutional neural network (dcnn) method for sct generation and evaluate its performance on a set of brain tumor patient images.","['deep convolutional neural network method', 'based synthetic ct generation using', 'mr']"
"half a century ago, the term ""computer-aided diagnosis"" (cad) was introduced in the scientific literature. pulmonary imaging, with chest radiography and computed tomography, has always been one of the focus areas in this field. in this study, i describe how machine learning became the dominant technology for tackling cad in the lungs, generally producing better results than do classical rule-based approaches, and how the field is now rapidly changing: in the last few years, we have seen how even better results can be obtained with deep learning. the key differences among rule-based processing, machine learning, and deep learning are summarized and illustrated for various applications of cad in the chest.","['machine learning', 'fifty years', 'deep learning', 'computer analysis', 'chest imaging', 'rule', 'based']"
"to identify items for a new instrument that measures emotional behaviour abilities of meaningful learning, according to fink's taxonomy.","['measure emotional behaviour abilities', 'meaningful learning', 'delphi technique', 'instrument', 'developing']"
"brain enlargement has been observed in children with autism spectrum disorder (asd), but the timing of this phenomenon, and the relationship between asd and the appearance of behavioural symptoms, are unknown. retrospective head circumference and longitudinal brain volume studies of two-year olds followed up at four years of age have provided evidence that increased brain volume may emerge early in development. studies of infants at high familial risk of autism can provide insight into the early development of autism and have shown that characteristic social deficits in asd emerge during the latter part of the first and in the second year of life. these observations suggest that prospective brain-imaging studies of infants at high familial risk of asd might identify early postnatal changes in brain volume that occur before an asd diagnosis. in this prospective neuroimaging study of 106 infants at high familial risk of asd and 42 low-risk infants, we show that hyperexpansion of the cortical surface area between 6 and 12 months of age precedes brain volume overgrowth observed between 12 and 24 months in 15 high-risk infants who were diagnosed with autism at 24 months. brain volume overgrowth was linked to the emergence and severity of autistic social deficits. a deep-learning algorithm that primarily uses surface area information from magnetic resonance imaging of the brain of 6-12-month-old individuals predicted the diagnosis of autism in individual high-risk children at 24 months (with a positive predictive value of 81% and a sensitivity of 88%). these findings demonstrate that early brain changes occur during the period in which autistic behaviours are first emerging.","['early brain development', 'autism spectrum disorder', 'high risk', 'infants']"
"computational approaches for predicting protein-ligand interactions can facilitate drug lead discovery and drug target determination. we have previously developed a threading/structural-based approach, findsitecomb, for the virtual ligand screening of proteins that has been extensively experimentally validated. even when low resolution predicted protein structures are employed, findsitecomb has the advantage of being faster and more accurate than traditional high-resolution structure-based docking methods. it also overcomes the limitations of traditional qsar methods that require a known set of seed ligands that bind to the given protein target. here, we further improve findsitecomb by enhancing its template ligand selection from the pdb/drugbank/chembl libraries of known protein-ligand interactions by (1) parsing the template proteins and their corresponding binding ligands in the drugbank and chembl libraries into domains so that the ligands with falsely matched domains to the targets will not be selected as template ligands; (2) applying various thresholds to filter out falsely matched template structures in the structure comparison process and thus their corresponding ligands for template ligand selection. with a sequence identity cutoff of 30% of target to templates and modeled target structures, findsitecomb2.0 is shown to significantly improve upon findsitecomb on the dud-e benchmark set by increasing the 1% enrichment factor from 16.7 to 22.1, with a p-value of 4.3 × 10-3 by the student t-test. with an 80% sequence identity cutoff of target to templates for the dud-e set and modeled target structures, findsitecomb2.0, having a 1% roc enrichment factor of 52.39, also outperforms state-of-the-art methods that employ machine learning such as a deep convolutional neural network, cnn, with an enrichment of 29.65. thus, findsitecomb2.0 represents a significant improvement in the state-of-the-art. the findsitecomb2.0 web service is freely available for academic users at http://pwp.gatech.edu/cssb/findsite-comb-2 .","['virtual target screening', 'virtual ligand screening', 'new approach', 'proteins', 'findsitecomb2', 'biomolecules', '0']"
"zero-shot learning (zsl) aims to classify a test instance from an unseen category based on the training instances from seen categories, in which the gap between seen categories and unseen categories is generally bridged via visual-semantic mapping between the low-level visual feature space and the intermediate semantic space. however, the visual-semantic mapping (i.e., projection) learnt based on seen categories may not generalize well to unseen categories, which is known as the projection domain shift in zsl. to address this projection domain shift issue, we propose a method named adaptive embedding zsl (aezsl) to learn an adaptive visual-semantic mapping for each unseen category, followed by progressive label refinement. moreover, to avoid learning visual-semantic mapping for each unseen category in the large-scale classification task, we additionally propose a deep adaptive embedding model named deep aezsl (daezsl) sharing the similar idea (i.e., visual-semantic mapping should be category-specific and related to the semantic space) with aezsl, which only needs to be trained once, but can be applied to arbitrary number of unseen categories. extensive experiments demonstrate that our proposed methods achieve the state-of-theart results for image classification on three small-scale benchmark datasets and one large-scale benchmark dataset.","['shot learning via category', 'specific visual', 'semantic mapping', 'label refinement', 'zero']"
"the discriminative model learning for image denoising has been recently attracting considerable attentions due to its favorable denoising performance. in this paper, we take one step forward by investigating the construction of feed-forward denoising convolutional neural networks (dncnns) to embrace the progress in very deep architecture, learning algorithm, and regularization method into image denoising. specifically, residual learning and batch normalization are utilized to speed up the training process as well as boost the denoising performance. different from the existing discriminative denoising models which usually train a specific model for additive white gaussian noise at a certain noise level, our dncnn model is able to handle gaussian denoising with unknown noise level (i.e., blind gaussian denoising). with the residual learning strategy, dncnn implicitly removes the latent clean image in the hidden layers. this property motivates us to train a single dncnn model to tackle with several general image denoising tasks, such as gaussian denoising, single image super-resolution, and jpeg image deblocking. our extensive experiments demonstrate that our dncnn model can not only exhibit high effectiveness in several general image denoising tasks, but also be efficiently implemented by benefiting from gpu computing.","['residual learning', 'image denoising', 'gaussian denoiser', 'deep cnn', 'beyond']"
"the purpose of this study was to expedite the contouring process for mri-guided adaptive radiotherapy (mr-igart), a convolutional neural network (cnn) deep-learning (dl) model is proposed to accurately segment the liver, kidneys, stomach, bowel and duodenum in 3d mr images.","['novel mri segmentation method using cnn', 'guided adaptive radiotherapy', 'based correction network', 'mri']"
"machine learning has shown enormous potential for computer-aided drug discovery. here we show how modern convolutional neural networks (cnns) can be applied to structure-based virtual screening. we have coupled our densely connected cnn (densenet) with a transfer learning approach which we use to produce an ensemble of protein family-specific models. we conduct an in-depth empirical study and provide the first guidelines on the minimum requirements for adopting a protein family-specific model. our method also highlights the need for additional data, even in data-rich protein families. our approach outperforms recent benchmarks on the dud-e data set and an independent test set constructed from the chembl database. using a clustered cross-validation on dud-e, we achieve an average auc roc of 0.92 and a 0.5% roc enrichment factor of 79. this represents an improvement in early enrichment of over 75% compared to a recent machine learning benchmark. our results demonstrate that the continued improvements in machine learning architecture for computer vision apply to structure-based virtual screening.","['specific models using deep neural networks', 'transfer learning improve virtual screening', 'protein family', 'need', 'highlight', 'data']"
"anesthesia providers are frequently exposed to radiation during routine patient care in the operating room and remote anesthetizing locations. eighty-two percent of anesthesiology residents (n = 57 responders) at our institution had a ""high"" or ""very high"" concern about the level of ionizing radiation exposure, and 94% indicated interest in educational materials about radiation safety. this article highlights key learning points related to basic physical principles, effects of ionizing radiation, radiation exposure measurement, occupational dose limits, considerations during pregnancy, sources of exposure, factors affecting occupational exposure such as positioning and shielding, and monitoring. the principle source of exposure is through scattered radiation as opposed to direct exposure from the x-ray beam, with the patient serving as the primary source of scatter. as a result, maximizing the distance between the provider and the patient is of great importance to minimize occupational exposure. our dosimeter monitoring project found that anesthesiology residents (n = 41) had low overall mean measured occupational radiation exposure. the highest deep dose equivalent value for a resident was 0.50 msv over a 3-month period, less than 10% of the international commission on radiological protection occupational limit, with the eye dose equivalent being 0.52 msv, approximately 4% of the international commission on radiological protection recommended limit. continued education and awareness of the risks of ionizing radiation and protective strategies will reduce exposure and potential for associated sequelae.","['led radiation safety projects', 'occupational radiation exposure', 'key learning points', 'anesthesia providers', 'summary', 'resident']"
"data science has emerged from the proliferation of digital data, coupled with advances in algorithms, software and hardware (e.g., gpu computing). innovations in structural biology have been driven by similar factors, spurring us to ask: can these two fields impact one another in deep and hitherto unforeseen ways? we posit that the answer is yes. new biological knowledge lies in the relationships between sequence, structure, function and disease, all of which play out on the stage of evolution, and data science enables us to elucidate these relationships at scale. here, we consider the above question from the five key pillars of data science: acquisition, engineering, analytics, visualization and policy, with an emphasis on machine learning as the premier analytics approach.","['structural biology meets data science', 'anything change']"
"we present an integrated methodology for detecting, segmenting and classifying breast masses from mammograms with minimal user intervention. this is a long standing problem due to low signal-to-noise ratio in the visualisation of breast masses, combined with their large variability in terms of shape, size, appearance and location. we break the problem down into three stages: mass detection, mass segmentation, and mass classification. for the detection, we propose a cascade of deep learning methods to select hypotheses that are refined based on bayesian optimisation. for the segmentation, we propose the use of deep structured output learning that is subsequently refined by a level set method. finally, for the classification, we propose the use of a deep learning classifier, which is pre-trained with a regression to hand-crafted feature values and fine-tuned based on the annotations of the breast mass classification dataset. we test our proposed system on the publicly available inbreast dataset and compare the results with the current state-of-the-art methodologies. this evaluation shows that our system detects 90% of masses at 1 false positive per image, has a segmentation accuracy of around 0.85 (dice index) on the correctly detected masses, and overall classifies masses as malignant or benign with sensitivity (se) of 0.98 and specificity (sp) of 0.7.","['minimal user intervention', 'deep learning approach', 'masses', 'mammograms', 'analysis']"
"accurate segmentation of organs-at-risks (oars) is the key step for efficient planning of radiation therapy for head and neck (han) cancer treatment. in the work, we proposed the first deep learning-based algorithm, for segmentation of oars in han ct images, and compared its performance against state-of-the-art automated segmentation algorithms, commercial software, and interobserver variability.","['neck ct images using convolutional neural networks', 'segmentation', 'risks', 'organs', 'head']"
"learning discriminant face representation for pose-invariant face recognition has been identified as a critical issue in visual learning systems. the challenge lies in the drastic changes of facial appearances between the test face and the registered face. to that end, we propose a high-level feature learning framework called ""collaborative random faces (rfs)-guided encoders"" toward this problem. the contributions of this paper are three fold. first, we propose a novel supervised autoencoder that is able to capture the high-level identity feature despite of pose variations. second, we enrich the identity features by replacing the target values of conventional autoencoders with random signals (rfs in this paper), which are unique for each subject under different poses. third, we further improve the performance of the framework by incorporating deep convolutional neural network facial descriptors and linking discriminative identity features from different rfs for the augmented identity features. finally, we conduct face identification experiments on multi-pie database, and face verification experiments on labeled faces in the wild and youtube face databases, where face recognition rate and verification accuracy with receiver operating characteristic curves are rendered. in addition, discussions of model parameters and connections with the existing methods are provided. these experiments demonstrate that our learning system works fairly well on handling pose variations.","['invariant face representation learning', 'collaborative random faces', 'guided encoders', 'pose']"
"we propose a framework for localization and classification of masses in breast ultrasound images. we have experimentally found that training convolutional neural network-based mass detectors with large, weakly annotated datasets presents a non-trivial problem, while overfitting may occur with those trained with small, strongly annotated datasets. to overcome these problems, we use a weakly annotated dataset together with a smaller strongly annotated dataset in a hybrid manner. we propose a systematic weakly and semi-supervised training scenario with appropriate training loss selection. experimental results show that the proposed method can successfully localize and classify masses with less annotation effort. the results trained with only 10 strongly annotated images along with weakly annotated images were comparable to results trained from 800 strongly annotated images, with the 95% confidence interval (ci) of difference -3%-5%, in terms of the correct localization (corloc) measure, which is the ratio of images with intersection over union with ground truth higher than 0.5. with the same number of strongly annotated images, additional weakly annotated images can be incorporated to give a 4.5% point increase in corloc, from 80% to 84.50% (with 95% cis 76%-83.75% and 81%-88%). the effects of different algorithmic details and varied amount of data are presented through ablative analysis.","['supervised deep learning', 'breast ultrasound images', 'joint weakly', 'semi', 'masses', 'localization', 'classification']"
"this paper proposes a fast and reliable method for anomaly detection and localization in video data showing crowded scenes. time-efficient anomaly localization is an ongoing challenge and subject of this paper. we propose a cubicpatch- based method, characterised by a cascade of classifiers, which makes use of an advanced feature-learning approach. our cascade of classifiers has two main stages. first, a light but deep 3d auto-encoder is used for early identification of ""many"" normal cubic patches. this deep network operates on small cubic patches as being the first stage, before carefully resizing remaining candidates of interest, and evaluating those at the second stage using a more complex and deeper 3d convolutional neural network (cnn). we divide the deep autoencoder and the cnn into multiple sub-stages which operate as cascaded classifiers. shallow layers of the cascaded deep networks (designed as gaussian classifiers, acting as weak single-class classifiers) detect ""simple"" normal patches such as background patches, and more complex normal patches are detected at deeper layers. it is shown that the proposed novel technique (a cascade of two cascaded classifiers) performs comparable to current top-performing detection and localization methods on standard benchmarks, but outperforms those in general with respect to required computation time.","['cascading 3d deep neural networks', 'fast anomaly detection', 'crowded scenes', 'deep', 'localization', 'cascade']"
"steady-state visual evoked potentials (ssveps) are neural oscillations from the parietal and occipital regions of the brain that are evoked from flickering visual stimuli. ssveps are robust signals measurable in the electroencephalogram (eeg) and are commonly used in brain-computer interfaces (bcis). however, methods for high-accuracy decoding of ssveps usually require hand-crafted approaches that leverage domain-specific knowledge of the stimulus signals, such as specific temporal frequencies in the visual stimuli and their relative spatial arrangement. when this knowledge is unavailable, such as when ssvep signals are acquired asynchronously, such approaches tend to fail.","['state visual evoked potentials', 'compact convolutional neural networks', 'asynchronous steady', 'classification']"
"high-grade glioma is the most aggressive and severe brain tumor that leads to death of almost 50% patients in 1-2 years. thus, accurate prognosis for glioma patients would provide essential guidelines for their treatment planning. conventional survival prediction generally utilizes clinical information and limited handcrafted features from magnetic resonance images (mri), which is often time consuming, laborious and subjective. in this paper, we propose using deep learning frameworks to automatically extract features from multi-modal preoperative brain images (i.e., t1 mri, fmri and dti) of high-grade glioma patients. specifically, we adopt 3d convolutional neural networks (cnns) and also propose a new network architecture for using multi-channel data and learning supervised features. along with the pivotal clinical features, we finally train a support vector machine to predict if the patient has a long or short overall survival (os) time. experimental results demonstrate that our methods can achieve an accuracy as high as 89.9% we also find that the learned features from fmri and dti play more important roles in accurately predicting the os time, which provides valuable insights into functional neuro-oncological applications.","['guided survival time prediction', 'brain tumor patients', '3d deep learning', 'modal imaging', 'multi']"
"wireless capsule endoscopy (wce) enables physicians to examine the digestive tract without any surgical operations, at the cost of a large volume of images to be analyzed. in the computer-aided diagnosis of wce images, the main challenge arises from the difficulty of robust characterization of images. this study aims to provide discriminative description of wce images and assist physicians to recognize polyp images automatically.","['wireless capsule endoscopy images', 'polyp recognition', 'deep learning']"
"genetic (g) and environmental (e) factors are involved in the etiology and course of the major psychoses (mp), i.e. major depressive disorder (mdd), bipolar disorder (bd), schizoaffective disorder (sza) and schizophrenia (sz). the neurobiological correlates by which these predispositions exert their influence on brain structure, function and course of illness are poorly understood. in the for2107 consortium, animal models and humans are investigated. a human cohort of mp patients, healthy subjects at genetic and/or environmental risk, and control subjects (n\u2009=\u20092500) has been established. participants are followed up after 2\xa0years and twice underwent extensive deep phenotyping (mr imaging, clinical course, neuropsychology, personality, risk/protective factors, biomaterials: blood, stool, urine, hair, saliva). methods for data reduction, quality assurance for longitudinal mri data, and (deep) machine learning techniques are employed. in the parallelised animal cluster, genetic risk was introduced by a rodent model (cacna1c deficiency) and its interactions with environmental risk and protective factors are studied. the animals are deeply phenotyped regarding cognition, emotion, and social function, paralleling the variables assessed in humans. a set of innovative experimental projects connect and integrate data from the human and animal parts, investigating the role of microrna, neuroplasticity, immune signatures, (epi-)genetics and gene expression. biomaterial from humans and animals are analyzed in parallel. the for2107 consortium will delineate pathophysiological entities with common neurobiological underpinnings (""biotypes"") and pave the way for an etiologic understanding of the mp, potentially leading to their prevention, the prediction of individual disease courses, and novel therapies in the future.","['translational perspective', 'major psychoses', 'for2107 consortium', 'brain structure', 'neurobiology', 'function']"
"the goal of this study was to describe the development and validation of an artificial intelligence-based, deep learning algorithm (dla) for the detection of referable diabetic retinopathy (dr).","['threatening referable diabetic retinopathy', 'color fundus photographs', 'automated grading system', 'vision', 'detection', 'basis']"
"the aim of this study was to evaluate the diagnostic accuracy of a multipurpose image analysis software based on deep learning with artificial neural networks for the detection of breast cancer in an independent, dual-center mammography data set.","['multipurpose image analysis software', 'diagnostic accuracy', 'deep learning', 'breast cancer', 'mammography', 'detection']"
"pain is an unpleasant feeling that has been shown to be an important factor for the recovery of patients. since this is costly in human resources and difficult to do objectively, there is the need for automatic systems to measure it. in this paper, contrary to current state-of-the-art techniques in pain assessment, which are based on facial features only, we suggest that the performance can be enhanced by feeding the raw frames to deep learning models, outperforming the latest state-of-the-art results while also directly facing the problem of imbalanced data. as a baseline, our approach first uses convolutional neural networks (cnns) to learn facial features from vgg_faces, which are then linked to a long short-term memory to exploit the temporal relation between video frames. we further compare the performances of using the so popular schema based on the canonically normalized appearance versus taking into account the whole image. as a result, we outperform current state-of-the-art area under the curve performance in the unbc-mcmaster shoulder pain expression archive database. in addition, to evaluate the generalization properties of our proposed methodology on facial motion recognition, we also report competitive results in the cohn kanade+ facial expression database.","['term memory networks', 'facial expression classification', 'exploiting long short', 'deep pain']"
"information visualization has great potential to make sense of the increasing amount of data generated by complex machine-learning algorithms. we design a set of visualizations for a new deep-learning algorithm called facelift (goodcitylife.org/facelift). this algorithm is able to generate a beautified version of a given urban image (such as from google street view), and our visualizations compare pairs of original and beautified images. with those visualizations, we aim at helping practitioners understand what happened during the algorithmic beautification without requiring them to be machine-learning experts. we evaluate the effectiveness of our visualizations to do just that with a survey among practitioners. from the survey results, we derive general design guidelines on how information visualization makes complex machine-learning algorithms more understandable to a general audience.","['learning urban beautification', 'visualizing deep', 'mapping']"
"assessment serves the primary function of determining a student's competence in a subject. several different assessment formats are available for assessing anatomical skills, knowledge and understanding and, as assessment can drive learning, a careful selection of assessments can help to engender the correct deep learning facility required of the safe clinical practitioner. the aim of this review was to survey the published literature to see whether higher education institutions are taking an andragogical approach to assessment. five databases (embase, eric, medline, pubmed, and web of knowledge) were searched using standardized search terms with two limits applied (english language, and 2000 to the present). among the 2,094 papers found, 32 were deemed suitable for this review. current literature on assessment can be categorized into the following themes: assessment driven learning, types of assessments, frequency of assessments, and use of images in assessments. the consensus is to use a variety of methods, written and practical, to assess anatomical knowledge and skill in different domains. institutions aim for different levels of bloom's taxonomy for students at similar stages of their medical degree. formative assessments are used widely, in differing formats, with mostly good effects on the final examination grade. in conclusion, a wide variety of assessments, each aimed at a different level of bloom's taxonomy, are used by different institutions. clin. anat. 30:290-299, 2017.","['higher education institutions', 'approaches taken', 'anatomical knowledge', 'assessment']"
"restricted boltzmann machine (rbm) is the building block of deep belief nets and other deep learning tools. fast learning and prediction are both essential for practical usage of rbm-based machine learning techniques. this paper proposes lean contrastive divergence (lcd), a modified contrastive divergence (cd) algorithm, to accelerate rbm learning and prediction without changing the results. lcd avoids most of the required computations with two optimization techniques. the first is called bounds-based filtering, which, through triangle inequality, replaces expensive calculations of many vector dot products with fast bounds calculations. the second is delta product, which effectively detects and avoids many repeated calculations in the core operation of rbm, gibbs sampling. the optimizations are applicable to both the standard contrastive divergence learning algorithm and its variations. in addition, this paper presents how to implement these optimizations effectively on massively parallel processors. results show that the optimizations can produce several-fold (up to 3x for training and 5.3x for prediction) speedups.","['fast contrastive divergence based algorithm', 'restricted boltzmann machine', 'lcd']"
"various biological factors have been implicated in convulsive seizures, involving side effects of drugs. for the preclinical safety assessment of drug development, it is difficult to predict seizure-inducing side effects. here, we introduced a machine learning-based in\xa0vitro system designed to detect seizure-inducing side effects. we recorded local field potentials from the ca1 alveus in acute mouse neocortico-hippocampal slices, while 14 drugs were bath-perfused at 5 different concentrations each. for each experimental condition, we collected seizure-like neuronal activity and merged their waveforms as one graphic image, which was further converted into a feature vector using caffe, an open framework for deep learning. in the space of the first two principal components, the support vector machine completely separated the vectors (i.e., doses of individual drugs) that induced seizure-like events and identified diphenhydramine, enoxacin, strychnine and theophylline as ""seizure-inducing"" drugs, which indeed were reported to induce seizures in clinical situations. thus, this artificial intelligence-based classification may provide a new platform to detect the seizure-inducing side effects of preclinical drugs.","['adverse drug effects', 'machine learning', 'inducing compounds', 'based prediction', 'seizure', 'example']"
"on behalf of the journal of cell communication and signaling editorial board it is my great pleasure to present through this message of peace and love our warmest wishes of health, happiness and professional success. we sincerely hope that 2017 will be a peaceful year worldwide and that solutions will be brought to resolve the great tensions that crystalized last year into terrible acts of violence which reflected the inability of the political powers to bring satisfactory solutions to human dispair and fear. the year 2017 will be the time for celebration of the 10th jccs anniversary and 9th international workshop on the ccn family of genes. both events should allow us to meet in a productive interactive way. i have had the opportunity to express several times in these columns my deep belief in the power of communication at all levels of human biological and social interactions. indeed, « communication is the key » at large.","['psychological studies sustain', 'print reading', 'cognitive benefits', 'neuroscience']"
"coarctation of aorta (coa) is a critical congenital heart defect (cchd) that requires accurate and immediate diagnosis and treatment. current newborn screening methods to detect coa lack both in sensitivity and specificity, and when suspected in a newborn, it must be confirmed using specialized imaging and expert diagnosis, both of which are usually unavailable at tertiary birthing centers. we explore the feasibility of applying machine learning methods to reliably determine the presence of this difficult-to-diagnose cardiac abnormality from ultrasound image data. we propose a framework that uses deep learning-based machine learning methods for fully automated detection of coa from two-dimensional ultrasound clinical data acquired in the parasternal long axis view, the apical four chamber view, and the suprasternal notch view. on a validation set consisting of 26\xa0coa and 64 normal patients our algorithm achieved a total error rate of 12.9% (11.5% false-negative error and 13.6% false-positive error) when combining decisions of classifiers over three standard echocardiographic view planes. this compares favorably with published results that combine clinical assessments with pulse oximetry to detect coa (71% sensitivity).","['dimensional echocardiograms', 'automated detection', 'two', 'neonates', 'coarctation', 'aorta']"
"machine learning is a technique for recognizing patterns that can be applied to medical images. although it is a powerful tool that can help in rendering medical diagnoses, it can be misapplied. machine learning typically begins with the machine learning algorithm system computing the image features that are believed to be of importance in making the prediction or diagnosis of interest. the machine learning algorithm system then identifies the best combination of these image features for classifying the image or computing some metric for the given image region. there are several methods that can be used, each with different strengths and weaknesses. there are open-source versions of most of these machine learning methods that make them easy to try and apply to images. several metrics for measuring the performance of an algorithm exist; however, one must be aware of the possible associated pitfalls that can result in misleading metrics. more recently, deep learning has started to be used; this method has the benefit that it does not require image feature identification and calculation as a first step; rather, features are identified as part of the learning process. machine learning has been used in medical imaging and will have a greater influence in the future. those working in medical imaging must be aware of how machine learning works. ©rsna, 2017.","['medical imaging', 'machine learning']"
"exposure to low (∼20 cgy) doses of high-energy charged (hze) particles, such as 1 gev/n 56fe, results in impaired hippocampal-dependent learning and memory (e.g., novel object recognition and spatial memory) in rodents. while these findings raise the possibility that astronauts on deep-space missions may develop cognitive deficits, not all rats develop hze-induced cognitive impairments, even after exposure to high (200 cgy) hze doses. the reasons for this differential sensitivity in some animals that develop hze-induced cognitive failure remain speculative. we employed a robust quantitative mass spectrometry-based workflow, which links early-stage discovery to next-stage quantitative verification, to identify differentially active proteins/pathways in rats that developed spatial memory impairment at three months after exposure to 20 cgy of 1 gev/n 56fe (20/impaired), and in those rats that managed to maintain normal cognitive performance (20/functional). quantitative data were obtained on 665-828 hippocampal proteins in the various cohorts of rats studied, of which 580 were expressed in all groups. a total of 107 proteins were upregulated in the irradiated rats irrespective of their spatial memory performance status, which included proteins involved in oxidative damage response, calcium transport and signaling. thirty percent (37/107) of these ""radiation biomarkers"" formed a functional interactome of the proteasome and the cop9 signalosome. these data suggest that there is persistent oxidative stress, ongoing autophagy and altered synaptic plasticity in the irradiated hippocampus, irrespective of the spatial memory performance status, suggesting that the ultimate phenotype may be determined by how well the hippocampal neurons compensate to the ongoing oxidative stress and associated side effects. there were 67 proteins with expression that correlated with impaired spatial memory performance. several of the ""impaired biomarkers"" have been implicated in poor spatial memory performance, neurodegeneration, neuronal loss or neuronal susceptibility to apoptosis, or neuronal synaptic or structural plasticity. therefore, in addition to the baseline oxidative stress and altered adenosine metabolism observed in all irradiated rats, the 20/impaired rats expressed proteins that led to poor spatial memory performance, enhanced neuronal loss and apoptosis, changes in synaptic plasticity and dendritic remodeling. a total of 46 proteins, which were differentially upregulated in the sham-irradiated and 20/functional rat cohorts, can thus be considered as markers of good spatial memory, while another 95 proteins are associated with the maintenance of good spatial memory in the 20/functional rats. the loss or downregulation of these ""good spatial memory"" proteins would most likely exacerbate the situation in the 20/impaired rats, having a major impact on their neurocognitive status, given that many of those proteins play an important role in neuronal homeostasis and function. our large-scale comprehensive proteomic analysis has provided some insight into the processes that are altered after exposure, and the collective data suggests that there are multiple problems with the functionality of the neurons and astrocytes in the irradiated hippocampi, which appear to be further exacerbated in the rats that have impaired spatial memory performance or partially compensated for in the rats with good spatial memory.","['spatial memory impairment', 'hippocampal proteome associated', '20 cg', 'low', 'exposure', 'changes']"
"this review examines the relevance of parameter identifiability for statistical models used in machine learning. in addition to defining main concepts, we address several issues of identifiability closely related to machine learning, showing the advantages and disadvantages of state-of-the-art research and demonstrating recent progress. first, we review criteria for determining the parameter structure of models from the literature. this has three related issues: parameter identifiability, parameter redundancy, and reparameterization. second, we review the deep influence of identifiability on various aspects of machine learning from theoretical and application viewpoints. in addition to illustrating the utility and influence of identifiability, we emphasize the interplay among identifiability theory, machine learning, mathematical statistics, information theory, optimization theory, information geometry, riemann geometry, symbolic computation, bayesian inference, algebraic geometry, and others. finally, we present a new perspective together with the associated challenges.","['statistical machine learning', 'parameter identifiability', 'review']"
"our primary objectives were to create a reliable, noninvasive method for three-dimensional morphometry of deep bony parameters within the sigmoid notch of the distal radius, to identify its morphological patterns, and to identify any significant variation between the left and the right wrists. our secondary objectives were to obtain morphometric values that could represent our population and to identify any possible ethnic variations.","['dimensional virtual morphometry study', 'sigmoid notch', 'distal radius', 'three']"
"artificial intelligence (ai) is a branch of computer science that deals with the development of algorithms that seek to simulate human intelligence. we provide an overview of the basic principles in ai that are essential to the understanding of ai and its application in health care. we also present a descriptive analysis of the current state of ai in various fields of medicine, especially ophthalmology. finally, we review the potential limitations and challenges that come along with the development and implementation of this new technology that will likely play a major role in clinical medicine in the near future.","['current state', 'artificial intelligence', 'ophthalmology']"
"residents have a limited time to be trained. although having a highly variable caseload should be beneficial for resident training, residents do not necessarily get a uniform distribution of cases. by developing a dashboard where residents and their attendings can track the procedures they have done and cases that they have seen, we hope to give residents a greater insight into their training and into where gaps in their training may be occurring. by taking advantage of modern advances in nlp techniques, we process medical records and generate statistics describing each resident's progress so far. we have built the system described and its life within the nyp ecosystem. by creating better tracking, we hope that caseloads can be shifted to better close any individual gaps in training. one of the educational pain points for radiology residency is the assignment of cases to match a well-balanced curriculum. by illuminating the historical cases of a resident, we can better assign future cases for a better educational experience.","['responsive radiology resident dashboard', 'developing']"
"the rodent parafascicular nucleus (pfn) or the centromedian-parafascicular complex of primates is a posterior intralaminar nucleus of the thalamus related to cortical activation and maintenance of states of consciousness underlying attention, learning and memory. deep brain stimulation (dbs) of the pfn has been proved to restore arousal and consciousness in humans and to enhance performance in learning and memory tasks in rats. the primary expected effect of pfn dbs is to induce plastic changes in target neurons of brain areas associated with cognitive function. in this study, wistar rats were stimulated for 20mins in the pfn following a dbs protocol that had previously facilitated memory in rats. nmda and gabab receptor binding, and gene expression of the glun1subunit of the nmda receptor (nmdar) were assessed in regions related to cognitive functions, such as the prefrontal cortex and hippocampus. the results showed that pfn dbs induced a decrease in nmdar glun1 subunit gene expression in the cingulate and prelimbic cortices, but no significant statistical differences were found in the density of nmda or gabab receptors in any of the analyzed regions. taken together, our findings suggest a possible role for the nmdar glun1 subunit in the prefrontal cortex in the procognitive actions of the pfn dbs.","['parafascicular thalamic nucleus deep brain stimulation decreases nmda receptor glun1 subunit gene expression', 'prefrontal cortex']"
"omics, such as genomics, transcriptome and proteomics, has been affected by the era of big data. a huge amount of high dimensional and complex structured data has made it no longer applicable for conventional machine learning algorithms. fortunately, deep learning technology can contribute toward resolving these challenges. there is evidence that deep learning can handle omics data well and resolve omics problems. this survey aims to provide an entry-level guideline for researchers, to understand and use deep learning in order to solve omics problems. we first introduce several deep learning models and then discuss several research areas which have combined omics and deep learning in recent years. in addition, we summarize the general steps involved in using deep learning which have not yet been systematically discussed in the existent literature on this topic. finally, we compare the features and performance of current mainstream open source deep learning frameworks and present the opportunities and challenges involved in deep learning. this survey will be a good starting point and guideline for omics researchers to understand deep learning.","['deep learning', 'survey', 'omics', 'guideline']"
"entropy images, representing the complexity of original fundus photographs, may strengthen the contrast between diabetic retinopathy (dr) lesions and unaffected areas. the aim of this study is to compare the detection performance for severe dr between original fundus photographs and entropy images by deep learning. a sample of 21,123 interpretable fundus photographs obtained from a publicly available data set was expanded to 33,000 images by rotating and flipping. all photographs were transformed into entropy images using block size 9 and downsized to a standard resolution of 100\u2009×\u2009100 pixels. the stages of dr are classified into 5 grades based on the international clinical diabetic retinopathy disease severity scale: grade 0 (no dr), grade 1 (mild nonproliferative dr), grade 2 (moderate nonproliferative dr), grade 3 (severe nonproliferative dr), and grade 4 (proliferative dr). of these 33,000 photographs, 30,000 images were randomly selected as the training set, and the remaining 3,000 images were used as the testing set. both the original fundus photographs and the entropy images were used as the inputs of convolutional neural network (cnn), and the results of detecting referable dr (grades 2-4) as the outputs from the two data sets were compared. the detection accuracy, sensitivity, and specificity of using the original fundus photographs data set were 81.80%, 68.36%, 89.87%, respectively, for the entropy images data set, and the figures significantly increased to 86.10%, 73.24%, and 93.81%, respectively (all p values <0.001). the entropy image quantifies the amount of information in the fundus photograph and efficiently accelerates the generating of feature maps in the cnn. the research results draw the conclusion that transformed entropy imaging of fundus photographs can increase the machinery detection accuracy, sensitivity, and specificity of referable dr for the deep learning-based system.","['transforming retinal photographs', 'improve automated detection', 'entropy images', 'diabetic retinopathy', 'deep learning']"
"with the advent of robot-assisted surgery, the role of data-driven approaches to integrate statistics and machine learning is growing rapidly with prominent interests in objective surgical skill assessment. however, most existing work requires translating robot motion kinematics into intermediate features or gesture segments that are expensive to extract, lack efficiency, and require significant domain-specific knowledge.","['objective skill evaluation', 'convolutional neural network', 'deep learning', 'assisted surgery', 'robot']"
"we recently showed that deep brain stimulation (dbs) in the bed nucleus of the stria terminalis (bst) reduces obsessions, compulsions and associated anxiety in patients suffering from severe, treatment-refractory obsessive-compulsive disorder. here, we investigated the anxiolytic effects of electrical bst stimulation in a rat model of conditioned anxiety, unrelated to obsessions or compulsions. two sets of stimulation parameters were evaluated. using fixed settings at 100\u2009hz, 40\u2009μs and 300\u2009μa (set a), we observed elevated freezing and startle levels, whereas stimulation at 130\u2009hz, 220\u2009μs and individually tailored amplitudes (set b) appeared to reduce freezing. in a follow-up experiment, we evaluated the anxiolytic potential of set b more extensively, by adding a lesion group and an additional day of stimulation. we found that electrical stimulation significantly reduced freezing, but not to the same extent as lesions. neither lesions nor stimulation of the bst affected motor behavior or unconditioned anxiety in an open-field test. in summary, electrical stimulation of the bst was successful in reducing contextual anxiety in a rat model, without eliciting unwanted motor effects. our findings underline the therapeutic potential of dbs in the bst for disorders that are hallmarked by pathological anxiety. further research will be necessary to assess the translatability of these findings to the clinic.","['stria terminalis reduces anxiety', 'rat model', 'electrical stimulation', 'bed nucleus']"
this study aims to accurately segment the right ventricle (rv) from cardiac mri using a fully automatic learning-based method.,"['cardiac mri using', 'right ventricle', 'based approach', 'automatic segmentation', 'learning']"
"combined analysis of spect myocardial perfusion imaging (mpi) performed with a solid-state camera on patients in 2 positions (semiupright, supine) is routinely used to mitigate attenuation artifacts. we evaluated the prediction of obstructive disease from combined analysis of semiupright and supine stress mpi by deep learning (dl) as compared with standard combined total perfusion deficit (tpd). methods: 1,160 patients without known coronary artery disease (64% male) were studied. patients underwent stress 99mtc-sestamibi mpi with new-generation solid-state spect scanners in 4 different centers. all patients had on-site clinical reads and invasive coronary angiography correlations within 6 mo of mpi. obstructive disease was defined as at least 70% narrowing of the 3 major coronary arteries and at least 50% for the left main coronary artery. images were quantified at cedars-sinai. the left ventricular myocardium was segmented using standard clinical nuclear cardiology software. the contour placement was verified by an experienced technologist. combined stress tpd was computed using sex- and camera-specific normal limits. dl was trained using polar distributions of normalized radiotracer counts, hypoperfusion defects, and hypoperfusion severities and was evaluated for prediction of obstructive disease in a novel leave-one-center-out cross-validation procedure equivalent to external validation. during the validation procedure, 4 dl models were trained using data from 3 centers and then evaluated on the 1 center left aside. predictions for each center were merged to have an overall estimation of the multicenter performance. results: 718 (62%) patients and 1,272 of 3,480 (37%) arteries had obstructive disease. the area under the receiver operating characteristics curve for prediction of disease on a per-patient and per-vessel basis by dl was higher than for combined tpd (per-patient, 0.81 vs. 0.78; per-vessel, 0.77 vs. 0.73; p < 0.001). with the dl cutoff set to exhibit the same specificity as the standard cutoff for combined tpd, per-patient sensitivity improved from 61.8% (tpd) to 65.6% (dl) (p < 0.05), and per-vessel sensitivity improved from 54.6% (tpd) to 59.1% (dl) (p < 0.01). with the threshold matched to the specificity of a normal clinical read (56.3%), dl had a sensitivity of 84.8%, versus 82.6% for an on-site clinical read (p = 0.3). conclusion: dl improves automatic interpretation of mpi as compared with current quantitative methods.","['efficiency spect myocardial perfusion imaging', 'obstructive coronary artery disease', 'deep learning analysis', 'supine high', 'multicenter study', 'upright', 'prediction']"
"epithelial (ep) and stromal (st) are two types of tissues in histological images. automated segmentation or classification of ep and st tissues is important when developing computerized system for analyzing the tumor microenvironment. in this paper, a deep convolutional neural networks (dcnn) based feature learning is presented to automatically segment or classify ep and st regions from digitized tumor tissue microarrays (tmas). current approaches are based on handcraft feature representation, such as color, texture, and local binary patterns (lbp) in classifying two regions. compared to handcrafted feature based approaches, which involve task dependent representation, dcnn is an end-to-end feature extractor that may be directly learned from the raw pixel intensity value of ep and st tissues in a data driven fashion. these high-level features contribute to the construction of a supervised classifier for discriminating the two types of tissues. in this work we compare dcnn based models with three handcraft feature extraction based approaches on two different datasets which consist of 157 hematoxylin and eosin (h&e) stained images of breast cancer and 1376 immunohistological (ihc) stained images of colorectal cancer, respectively. the dcnn based feature learning approach was shown to have a f1 classification score of 85%, 89%, and 100%, accuracy (acc) of 84%, 88%, and 100%, and matthews correlation coefficient (mcc) of 86%, 77%, and 100% on two h&e stained (nki and vgh) and ihc stained data, respectively. our dnn based approach was shown to outperform three handcraft feature extraction based approaches in terms of the classification of ep and st regions.","['deep convolutional neural network', 'stromal regions', 'histopathological images', 'classifying epithelial', 'segmenting']"
"one of the factors that significantly affects bistatic scattering from seabed targets is bottom type. this factor has the potential to impact classification, as models that do not take bottom composition into account could improperly characterize target type, geometry, or material. this paper looks at the impact of bottom composition and self-burial on scattering from spherical and cylindrical targets in a 6.5\u2009m deep environment with a mud and sand bottom. sphere and cylinder scattering data from an autonomous underwater vehicle-based bistatic scattering experiment are compared to scattering simulation models with a range of bottom compositions and target burial increments. three different sets of sediment parameters were tested. correlation between the real and simulated data are then used to assess the similarity of each simulated scattering data set to the experiment data. robustness to bottom composition in classification was then tested by training a model using simulated data and classifying experiment target data using a machine learning method for each environment type. combined-environment classification models, composed of different ranges of mud depths and target burial increments, were shown to be effective at classifying the experiment data.","['seabed object bistatic scattering classification', 'environmental effects']"
"left ventricular noncompaction (lvnc) is a distinct cardiomyopathy that is morphologically characterized by a two-layered myocardium, numerous prominent trabeculations, and deep intertrabecular recesses communicating with the left ventricular cavity. we present a case report regarding the identification of a new mutation in tnni3 in a patient with lvnc using next-generation sequencing. a 13-year-old girl who had no family history of cardiac disease was hospitalized with dyspnea after exercise and electrocardiographic abnormalities during a school screening. based on her clinical features, she was diagnosed with lvnc. via genetic analysis, a tnni3 heterozygous missense variant was identified in the proband. although mutations in tnni3 have been reported in patients with hypertrophic cardiomyopathy and restrictive cardiomyopathy, this is the first report of a mutation in this gene in a patient with lvnc. <learning objective: we identified a variant in tnni3 in a patient with isolated left ventricular noncompaction using next-generation sequencing (ngs). mutations in tnni3 have been reported in patients with hypertrophic cardiomyopathy and restrictive cardiomyopathy. the use of ngs also results in the identification of multiple genetic variants of unknown significance to the investigated disease.>.","['tnni3 arg192his mutation', 'left ventricular noncompaction', 'old girl', 'year', '13']"
": identification of early-stage pulmonary adenocarcinomas before surgery, especially in cases of subcentimeter cancers, would be clinically important and could provide guidance to clinical decision making. in this study, we developed a deep learning system based on 3d convolutional neural networks and multitask learning, which automatically predicts tumor invasiveness, together with 3d nodule segmentation masks. the system processes a 3d nodule-centered patch of preprocessed ct and learns a deep representation of a given nodule without the need for any additional information. a dataset of 651 nodules with manually segmented voxel-wise masks and pathological labels of atypical adenomatous hyperplasia (aah), adenocarcinomas in situ (ais), minimally invasive adenocarcinoma (mia), and invasive pulmonary adenocarcinoma (ia) was used in this study. we trained and validated our deep learning system on 523 nodules and tested its performance on 128 nodules. an observer study with 2 groups of radiologists, 2 senior and 2 junior, was also investigated. we merged aah and ais into one single category aah-ais, comprising a 3-category classification in our study. the proposed deep learning system achieved better classification performance than the radiologists; in terms of 3-class weighted average f1 score, the model achieved 63.3% while the radiologists achieved 55.6%, 56.6%, 54.3%, and 51.0%, respectively. these results suggest that deep learning methods improve the yield of discriminative results and hold promise in the cadx application domain, which could help doctors work efficiently and facilitate the application of precision medicine. significance: machine learning tools are beginning to be implemented for clinical applications. this study represents an important milestone for this emerging technology, which could improve therapy selection for patients with lung cancer.","['ct scans predicts tumor invasiveness', 'subcentimeter pulmonary adenocarcinomas', '3d deep learning']"
"one of the major challenges currently facing researchers in applying deep learning (dl) models to medical image analysis is the limited amount of annotated data. collecting such ground-truth annotations requires domain knowledge, cost, and time, making it infeasible for large-scale databases. albarqouni et al. [s","['g ., amazon mechanical turk', 'noisy annotations collected', 'learning dl models', 'novel concept', 'crowdsourcing platforms', 'esented', 'e', 'crowdflowe']"
"body-worn sensors in general and accelerometers in particular have been widely used in order to detect human movements and activities. the execution of each type of movement by each particular individual generates sequences of time series of sensed data from which specific movement related patterns can be assessed. several machine learning algorithms have been used over windowed segments of sensed data in order to detect such patterns in activity recognition based on intermediate features (either hand-crafted or automatically learned from data). the underlying assumption is that the computed features will capture statistical differences that can properly classify different movements and activities after a training phase based on sensed data. in order to achieve high accuracy and recall rates (and guarantee the generalization of the system to new users), the training data have to contain enough information to characterize all possible ways of executing the activity or movement to be detected. this could imply large amounts of data and a complex and time-consuming training phase, which has been shown to be even more relevant when automatically learning the optimal features to be used. in this paper, we present a novel generative model that is able to generate sequences of time series for characterizing a particular movement based on the time elasticity properties of the sensed data. the model is used to train a stack of auto-encoders in order to learn the particular features able to detect human movements. the results of movement detection using a newly generated database with information on five users performing six different movements are presented. the generalization of results using an existing database is also presented in the paper. the results show that the proposed mechanism is able to obtain acceptable recognition rates (f = 0.77) even in the case of using different people executing a different sequence of movements and using different hardware.","['human activity recognition', 'elastic generative model', 'acceleration time series', 'time']"
"it is largely unknown whether there is functional role difference between cortical gyral and sulcal regions. recent advancements in neuroimaging studies demonstrate clear difference of structural connection profiles in gyral and sulcal areas, suggesting possible functional role difference in these convex and concave cortical regions. to explore and confirm such possible functional difference, we design and apply a powerful deep learning model of convolutional neural networks (cnn) that has been proven to be superior in learning discriminative and meaningful patterns on fmri. by using the cnn model, gyral and sulcal fmri signals are learned and predicted, and the prediction performance is adopted to demonstrate the functional difference between gyri and sulci. by using the human connectome project (hcp) fmri data and macaque brain fmri data, an average of 83% and 90% classification accuracy has been achieved to separate gyral/sulcal hcp task fmri signals at the population and individual subject level, respectively; 81% and 86% classification accuracy for resting state fmri signals at the group and individual subject level, respectively. in addition, 78% classification accuracy has been achieved to separate gyral/sulcal resting state fmri signals in macaque brains. importantly, further analysis reveals that the discriminative features that are learned by cnns to differentiate gyral/sulcal fmri signals can be meaningfully interpreted, thus unveiling the fundamental functional difference between cortical gyri and sulci. that is, gyri are more global functional integration centers with simpler lower frequency signal components, while sulci are more local processing units with more complex higher frequency signal components.","['deep learning models unveiled functional difference', 'cortical gyri', 'sulci']"
"in this paper, a novel classification technique for large data set of mammograms using a deep learning method is proposed. the proposed model targets a three-class classification study (normal, malignant, and benign cases). in our model we have presented two methods, namely, convolutional neural network-discrete wavelet (cnn-dw) and convolutional neural network-curvelet transform (cnn-ct). an augmented data set is generated by using mammogram patches. to enhance the contrast of mammogram images, the data set is filtered by contrast limited adaptive histogram equalization (clahe). in the cnn-dw method, enhanced mammogram images are decomposed as its four subbands by means of two-dimensional discrete wavelet transform (2d-dwt), while in the second method discrete curvelet transform (dct) is used. in both methods, dense scale invariant feature (dsift) for all subbands is extracted. input data matrix containing these subband features of all the mammogram patches is created that is processed as input to convolutional neural network (cnn). softmax layer and support vector machine (svm) layer are used to train cnn for classification. proposed methods have been compared with existing methods in terms of accuracy rate, error rate, and various validation assessment measures. cnn-dw and cnn-ct have achieved accuracy rate of 81.83% and 83.74%, respectively. simulation results clearly validate the significance and impact of our proposed model as compared to other well-known existing techniques.","['class mammogram classification based', 'descriptive cnn features', 'three']"
"in this paper, we study the challenging problem of categorizing videos according to high-level semantics such as the existence of a particular human action or a complex event. although extensive efforts have been devoted in recent years, most existing works combined multiple video features using simple fusion strategies and neglected the utilization of inter-class semantic relationships. this paper proposes a novel unified framework that jointly exploits the feature relationships and the class relationships for improved categorization performance. specifically, these two types of relationships are estimated and utilized by imposing regularizations in the learning process of a deep neural network (dnn). through arming the dnn with better capability of harnessing both the feature and the class relationships, the proposed regularized dnn (rdnn) is more suitable for modeling video semantics. we show that rdnn produces better performance over several state-of-the-art approaches. competitive results are reported on the well-known hollywood2 and columbia consumer video benchmarks. in addition, to stimulate future research on large scale video categorization, we collect and release a new benchmark dataset, called fcvid, which contains 91,223 internet videos and 239 manually annotated categories.","['regularized deep neural networks', 'video categorization', 'exploiting feature', 'class relationships']"
"while there have been concerted efforts to reform undergraduate biology toward teaching students to organize their conceptual knowledge like experts, there are few tools that attempt to measure this. we previously developed the biology card sorting task (bcst), designed to probe how individuals organize their conceptual biological knowledge. previous results showed the bcst could differentiate between different populations, namely non-biology majors (nbm) and biology faculty (bf). in this study, we administered the bcst to three additional populations, using a cross-sectional design: entering biology majors (ebm), advanced biology majors (abm), and biology graduate students (bgs). intriguingly, abm did not initially sort like experts any more frequently than ebm. however, once the deep-feature framework was revealed, abm were able to sort like experts more readily than did ebm. these results are consistent with the conclusion that biology education enables advanced biology students to use an expert-like conceptual framework. however, these results are also consistent with a process of ""selection,"" wherein students who persist in the major may have already had an expert-like conceptual framework to begin with. these results demonstrate the utility of the bcst in measuring differences between groups of students over the course of their undergraduate education.","['biology card sorting task', 'postsecondary biology education', 'measure changes', 'conceptual expertise', 'using']"
"this paper presents a simple yet effective supervised deep hash approach that constructs binary hash codes from labeled data for large-scale image search. we assume that the semantic labels are governed by several latent attributes with each attribute on or off, and classification relies on these attributes. based on this assumption, our approach, dubbed supervised semantics-preserving deep hashing (ssdh), constructs hash functions as a latent layer in a deep network and the binary codes are learned by minimizing an objective function defined over classification error and other desirable hash codes properties. with this design, ssdh has a nice characteristic that classification and retrieval are unified in a single learning model. moreover, ssdh performs joint learning of image representations, hash codes, and classification in a point-wised manner, and thus is scalable to large-scale datasets. ssdh is simple and can be realized by a slight enhancement of an existing deep architecture for classification; yet it is effective and outperforms other hashing approaches on several benchmarks and large datasets. compared with state-of-the-art approaches, ssdh achieves higher retrieval accuracy, while the classification performance is not sacrificed.","['preserving hash via deep convolutional neural networks', 'supervised learning', 'semantics']"
"short text clustering is a challenging problem due to its sparseness of text representation. here we propose a flexible self-taught convolutional neural network framework for short text clustering (dubbed stc2), which can flexibly and successfully incorporate more useful semantic features and learn non-biased deep text representation in an unsupervised manner. in our framework, the original raw text features are firstly embedded into compact binary codes by using one existing unsupervised dimensionality reduction method. then, word embeddings are explored and fed into convolutional neural networks to learn deep feature representations, meanwhile the output units are used to fit the pre-trained binary codes in the training process. finally, we get the optimal clusters by employing k-means to cluster the learned representations. extensive experimental results demonstrate that the proposed framework is effective, flexible and outperform several popular clustering methods when tested on three public short text datasets.","['taught convolutional neural networks', 'short text clustering', 'self']"
"this work presents a proof-of-concept study in artificial-intelligence-assisted (ai-assisted) chemistry where a machine-learning-based molecule generator is coupled with density functional theory (dft) calculations, synthesis, and measurement. although deep-learning-based molecule generators have shown promise, it is unclear to what extent they can be useful in real-world materials development. to assess the reliability of ai-assisted chemistry, we prepared a platform using a molecule generator and a dft simulator, and attempted to generate novel photofunctional molecules whose lowest excited states lie at desired energetic levels. a 10 day run on the 12-core server discovered 86 potential photofunctional molecules around target lowest excitation levels, designated as 200, 300, 400, 500, and 600 nm. among the molecules discovered, six were synthesized, and five were confirmed to reproduce dft predictions in ultraviolet visible absorption measurements. this result shows the potential of ai-assisted chemistry to discover ready-to-synthesize novel molecules with modest computational resources.","['desired excitation energies', 'organic molecules', 'molecules optimized', 'artificial intelligence', 'hunting']"
"accurate computational identification of promoters remains a challenge as these key dna regulatory regions have variable structures composed of functional motifs that provide gene-specific initiation of transcription. in this paper we utilize convolutional neural networks (cnn) to analyze sequence characteristics of prokaryotic and eukaryotic promoters and build their predictive models. we trained a similar cnn architecture on promoters of five distant organisms: human, mouse, plant (arabidopsis), and two bacteria (escherichia coli and bacillus subtilis). we found that cnn trained on sigma70 subclass of escherichia coli promoter gives an excellent classification of promoters and non-promoter sequences (sn = 0.90, sp = 0.96, cc = 0.84). the bacillus subtilis promoters identification cnn model achieves sn = 0.91, sp = 0.95, and cc = 0.86. for human, mouse and arabidopsis promoters we employed cnns for identification of two well-known promoter classes (tata and non-tata promoters). cnn models nicely recognize these complex functional regions. for human promoters sn/sp/cc accuracy of prediction reached 0.95/0.98/0,90 on tata and 0.90/0.98/0.89 for non-tata promoter sequences, respectively. for arabidopsis we observed sn/sp/cc 0.95/0.97/0.91 (tata) and 0.94/0.94/0.86 (non-tata) promoters. thus, the developed cnn models, implemented in cnnprom program, demonstrated the ability of deep learning approach to grasp complex promoter sequence characteristics and achieve significantly higher accuracy compared to the previously developed promoter prediction programs. we also propose random substitution procedure to discover positionally conserved promoter functional elements. as the suggested approach does not require knowledge of any specific promoter features, it can be easily extended to identify promoters and other complex functional regions in sequences of many other and especially newly sequenced genomes. the cnnprom program is available to run at web server http://www.softberry.com.","['eukaryotic promoters using convolutional deep learning neural networks', 'recognition', 'prokaryotic']"
"we present deepisp, a full end-to-end deep neural model of the camera image signal processing (isp) pipeline. our model learns a mapping from the raw low-light mosaiced image to the final visually compelling image and encompasses low-level tasks such as demosaicing and denoising as well as higher-level tasks such as color correction and image adjustment. the training and evaluation of the pipeline were performed on a dedicated dataset containing pairs of low-light and well-lit images captured by a samsung s7 smartphone camera in both raw and processed jpeg formats. the proposed solution achieves state-of-the-art performance in objective evaluation of psnr on the subtask of joint denoising and demosaicing. for the full end-to-end pipeline, it achieves better visual quality compared to the manufacturer isp, in both a subjective human assessment and when rated by a deep model trained for assessing image quality.","['end image processing pipeline', 'towards learning', 'end', 'deepisp']"
"purpose to develop and validate a deep learning-based automatic detection algorithm (dlad) for malignant pulmonary nodules on chest radiographs and to compare its performance with physicians including thoracic radiologists. materials and methods for this retrospective study, dlad was developed by using 43 292 chest radiographs (normal radiograph-to-nodule radiograph ratio, 34 067:9225) in 34 676 patients (healthy-to-nodule ratio, 30 784:3892; 19 230 men [mean age, 52.8 years; age range, 18-99 year","['5 446 women', 'mean age', 'age range', '98 years', '3 years', '52', '18']"
"the large amount of clinical signals in intensive care units can easily overwhelm health-care personnel and can lead to treatment delays, suboptimal care, or clinical errors. the aim of this study was to apply deep machine learning methods to predict severe complications during critical care in real time after cardiothoracic surgery.","['time prediction', 'retrospective study', 'machine learning', 'critical care', 'real', 'complications']"
"minimally invasive endoscopic hematoma evacuation is a promising treatment option for intracerebral hemorrhage. however, the technique still needs improvement. we report our clinical experience of using this technique to evacuate deep-seated basal ganglia hematomas.","['basal ganglia hematoma', 'surgical technique', 'learning curve', 'endoscopic evacuation', 'outcome']"
"differentiation alters molecular properties of stem and progenitor cells, leading to changes in their shape and movement characteristics. we present a deep neural network that prospectively predicts lineage choice in differentiating primary hematopoietic progenitors using image patches from brightfield microscopy and cellular movement. surprisingly, lineage choice can be detected up to three generations before conventional molecular markers are observable. our approach allows identification of cells with differentially expressed lineage-specifying genes without molecular labeling.","['hematopoietic lineage choice', 'prospective identification', 'deep learning']"
"comparison and reminding have both been shown to support learning and transfer. comparison is thought to support transfer because it allows learners to disregard non-matching features of superficially different episodes in order to abstract the essential structure of concepts. remindings promote memory for the individual episodes and generalization because they prompt learners to retrieve earlier episodes during the encoding of later related episodes and to compare across episodes. across three experiments, we compared the consequences of comparison and reminding on memory and transfer. participants studied a sequence of related, but superficially different, proverb pairs. in the comparison condition, participants saw proverb pairs presented together and compared their meaning. in the reminding condition, participants viewed proverbs one at a time and retrieved any prior studied proverb that shared the same deep meaning as the current proverb. experiment 1 revealed that participants in the reminding condition recalled more proverbs than those in the comparison condition. experiment 2 showed that the mnemonic benefits of reminding persisted over a one-week retention interval. finally, in experiment 3, we examined the ability of participants to generalize their remembered information to new items in a task that required participants to identify unstudied proverbs that shared the same meaning as studied proverbs. comparison led to worse discrimination between proverbs related to studied proverbs and proverbs unrelated to studied proverbs than reminding. reminding supported better memory for individual instances and transfer to new situations than comparison.",['comparison versus reminding']
"non-intrusive inspection systems based on x-ray radiography techniques are routinely used at transport hubs to ensure the conformity of cargo content with the supplied shipping manifest. as trade volumes increase and regulations become more stringent, manual inspection by trained operators is less and less viable due to low throughput. machine vision techniques can assist operators in their task by automating parts of the inspection workflow. since cars are routinely involved in trafficking, export fraud, and tax evasion schemes, they represent an attractive target for automated detection and flagging for subsequent inspection by operators.","['ray imagery using deep learning', 'complex cargo x', 'concealed cars', 'detection']"
investigation of the automation of radiological features from magnetic resonance images (mris) of the lumbar spine.,"['magnetic resonance images', 'bioengineering science 2017', 'radiological features', 'issls prize', 'reading', 'mri', 'automation']"
"radiation exposure and the associated risk of cancer for patients in computed tomography (ct) scans have been major clinical concerns. the radiation exposure can be reduced effectively via lowering the x-ray tube current (ma). however, this strategy may lead to excessive noise and streak artifacts in the conventional filtered back-projection reconstructed images. to address this issue, some deep convolutional neural network (convnet) based approaches have been developed for low-dose ct imaging inspired by the recent development of machine learning. nevertheless, some of the image textures reconstructed by the convnet could be corrupted by the severe streaks, especially in ultra-low-dose cases, which could be close to prostheses and hamper diagnosis. therefore, in this work, we propose an iterative residual-artifact learning convnet (irlnet) approach to improve the reconstruction performance over the convnet based approaches. specifically, the proposed irlnet estimates the high-frequency details within the noise and then removes them iteratively; after eliminating severe streaks in the low-dose ct images, the residual low-frequency details can be processed through the conventional network. moreover, the proposed irlnet scheme can be extended for robust handling of quantitative dual energy ct/cerebral perfusion ct imaging, and statistical iterative reconstruction. real patient data are used to evaluate the proposed irlnet, and the experimental results demonstrate that the proposed irlnet approach outperforms the previous convnet based approaches in reducing the image noise and streak artifacts efficiently at the same time as preserving edge details well, suggesting that the proposed irlnet approach can be used to improve the ct image quality, especially in ultra-low-dose cases.","['iterative quality enhancement via residual', 'artifact learning networks', 'dose ct', 'low']"
"in this paper, a hierarchical deep multi-task learning (hd-mtl) algorithm is developed to support large-scale visual recognition (e.g., recognizing thousands or even tens of thousands of atomic object classes automatically). first, multiple sets of multi-level deep features are extracted from different layers of deep convolutional neural networks (deep cnns), and they are used to achieve more effective accomplishment of the coarseto- fine tasks for hierarchical visual recognition. a visual tree is then learned by assigning the visually-similar atomic object classes with similar learning complexities into the same group, which can provide a good environment for determining the interrelated learning tasks automatically. by leveraging the inter-task relatedness (inter-class similarities) to learn more discriminative group-specific deep representations, our deep multi-task learning algorithm can train more discriminative node classifiers for distinguishing the visually-similar atomic object classes effectively. our hierarchical deep multi-task learning (hd-mtl) algorithm can integrate two discriminative regularization terms to control the inter-level error propagation effectively, and it can provide an end-to-end approach for jointly learning more representative deep cnns (for image representation) and more discriminative tree classifier (for large-scale visual recognition) and updating them simultaneously. our incremental deep learning algorithms can effectively adapt both the deep cnns and the tree classifier to the new training images and the new object classes. our experimental results have demonstrated that our hd-mtl algorithm can achieve very competitive results on improving the accuracy rates for large-scale visual recognition.","['scale visual recognition', 'hierarchical deep multi', 'task learning', 'mtl', 'large', 'hd']"
"delusions, the fixed false beliefs characteristic of psychotic illness, have long defied understanding despite their response to pharmacological treatments (e.g., d2 receptor antagonists). however, it can be challenging to discern what makes beliefs delusional compared with other unusual or erroneous beliefs. we suggest mapping the putative biology to clinical phenomenology with a cognitive psychology of belief, culminating in a teleological approach to beliefs and brain function supported by animal and computational models. we argue that organisms strive to minimize uncertainty about their future states by forming and maintaining a set of beliefs (about the organism and the world) that are robust, but flexible. if uncertainty is generated endogenously, beliefs begin to depart from consensual reality and can manifest into delusions. central to this scheme is the notion that formal associative learning theory can provide an explanation for the development and persistence of delusions. beliefs, in animals and humans, may be associations between representations (e.g., of cause and effect) that are formed by minimizing uncertainty via new learning and attentional allocation. animal research has equipped us with a deep mechanistic basis of these processes, which is now being applied to delusions. this work offers the exciting possibility of completing revolutions of translation, from the bedside to the bench and back again. the more we learn about animal beliefs, the more we may be able to apply to human beliefs and their aberrations, enabling a deeper mechanistic understanding.","['reducing uncertainty', 'explaining delusions', 'computational neuroscience', 'basic']"
"the challenge of person re-identification (re-id) is to match individual images of the same person captured by different non-overlapping camera views against significant and unknown cross-view feature distortion. while a large number of distance metric/subspace learning models have been developed for re-id, the cross-view transformations they learned are view-generic and thus potentially less effective in quantifying the feature distortion inherent to each camera view. learning view-specific feature transformations for re-id (i.e., view-specific re-id), an under-studied approach, becomes an alternative resort for this problem. in this work, we formulate a novel view-specific person re-identification framework from the feature augmentation point of view, called camera cor relation aware feature augmentation (craft). specifically, craft performs cross-view adaptation by automatically measuring camera correlation from cross-view visual data distribution and adaptively conducting feature augmentation to transform the original features into a new adaptive space. through our augmentation framework, view-generic learning algorithms can be readily generalized to learn and optimize view-specific sub-models whilst simultaneously modelling view-generic discrimination information. therefore, our framework not only inherits the strength of view-generic model learning but also provides an effective way to take into account view specific characteristics. our craft framework can be extended to jointly learn view-specific feature transformations for person re-id across a large network with more than two cameras, a largely under-investigated but realistic re-id setting. additionally, we present a domain-generic deep person appearance representation which is designed particularly to be towards view invariant for facilitating cross-view adaptation by craft. we conducted extensively comparative experiments to validate the superiority and advantages of our proposed framework over state-of-the-art competitors on contemporary challenging person re-id datasets.","['camera correlation aware feature augmentation', 'person', 'identification']"
"vascular cognitive disorders are heterogeneous and increasingly recognized entities with intricate correlation to neurodegenerative conditions. retinal vascular analysis is a noninvasive approach to study cerebrovascular pathology, with promise to assist particularly during early disease phases. in this article, we have systematically summarized the current understanding, potential applications, and inevitable limitations of retinal vascular imaging in patients with vascular cognitive impairment. in addition, future directions in the field with support from automated technology using deep learning methods and their existing challenges are emphasized.","['vascular cognitive impairment', 'retinal vascular imaging', 'future perspectives', 'current']"
"this paper reports on a unique practice based learning model to prepare undergraduate nursing students for clinical placement. the learning and teaching model described in this paper outlines the establishment of an entire on-campus simulated hospital and health service (shhs) at the university of south australia, school of nursing and midwifery. the model is pedagogically structured to immerse students in an authentic clinical environment to achieve deep learning in preparation for safe practice. a quality improvement cycle was used to evaluate the outcomes of the model in two phases: phase 1: purposive sampling of first and second year bachelor of nursing students from 2012 to 2015 who were surveyed about their satisfaction with the model of learning. bachelor of nursing students were invited to complete a survey about their experience with the teaching and learning model employed in the shhs in response to the question, 'what aspects of the shhs are the most important to your success?' phase 2: external clinical stakeholders working with nursing students in clinical placements were asked to respond to questions about the preparedness of students educated in this model to transition to employment. the evaluation showed that the shhs model positively influenced students' satisfaction and confidence and increased the perception of clinicians of the work readiness of students.","['support undergraduate nursing students', 'campus simulated hospital', 'authentic practice environments', 'hospital placements', 'new model', 'health service', 'practice', 'readiness']"
"video understanding of robot-assisted surgery (ras) videos is an active research area. modeling the gestures and skill level of surgeons presents an interesting problem. the insights drawn may be applied in effective skill acquisition, objective skill assessment, real-time feedback, and human-robot collaborative surgeries. we propose a solution to the tool detection and localization open problem in ras video understanding, using a strictly computer vision approach and the recent advances of deep learning. we propose an architecture using multimodal convolutional neural networks for fast detection and localization of tools in ras videos. to the best of our knowledge, this approach will be the first to incorporate deep neural networks for tool detection and localization in ras videos. our architecture applies a region proposal network (rpn) and a multimodal two stream convolutional network for object detection to jointly predict objectness and localization on a fusion of image and temporal motion cues. our results with an average precision of 91% and a mean computation time of 0.1 s per test frame detection indicate that our study is superior to conventionally used methods for medical imaging while also emphasizing the benefits of using rpn for precision and efficiency. we also introduce a new data set, atlas dione, for ras video understanding. our data set provides video data of ten surgeons from roswell park cancer institute, buffalo, ny, usa, performing six different surgical tasks on the davinci surgical system (dvss) with annotations of robotic tools per frame.","['assisted surgery videos using deep neural networks', 'robotic tools', 'region proposal', 'robot', 'localization', 'detection']"
"when left untreated, age-related macular degeneration (amd) is the leading cause of vision loss in people over fifty in the us. currently it is estimated that about eight million us individuals have the intermediate stage of amd that is often asymptomatic with regard to visual deficit. these individuals are at high risk for progressing to the advanced stage where the often treatable choroidal neovascular form of amd can occur. careful monitoring to detect the onset and prompt treatment of the neovascular form as well as dietary supplementation can reduce the risk of vision loss from amd, therefore, preferred practice patterns recommend identifying individuals with the intermediate stage in a timely manner.","['using universal deep features', 'deep learning performance', 'automated amd analysis', 'transfer learning', 'grading amd', 'comparing humans', 'study']"
"object detection and classification have countless applications in human-robot interacting systems. it is a necessary skill for autonomous robots that perform tasks in household scenarios. despite the great advances in deep learning and computer vision, social robots performing non-trivial tasks usually spend most of their time finding and modeling objects. working in real scenarios means dealing with constant environment changes and relatively low-quality sensor data due to the distance at which objects are often found. ambient intelligence systems equipped with different sensors can also benefit from the ability to find objects, enabling them to inform humans about their location. for these applications to succeed, systems need to detect the objects that may potentially contain other objects, working with relatively low-resolution sensor data. a passive learning architecture for sensors has been designed in order to take advantage of multimodal information, obtained using an rgb-d camera and trained semantic language models. the main contribution of the architecture lies in the improvement of the performance of the sensor under conditions of low resolution and high light variations using a combination of image labeling and word semantics. the tests performed on each of the stages of the architecture compare this solution with current research labeling techniques for the application of an autonomous social robot working in an apartment. the results obtained demonstrate that the proposed sensor architecture outperforms state-of-the-art approaches.","['passive learning sensor architecture', 'multimodal image labeling', 'social robots', 'application']"
"pregnancy is well-known risk factor for deep vein thrombosis (dvt), which usually occurs during the third trimester and in the left-sided lower extremity. we present a case of left subclavian and right femoral vein thrombosis in a pregnant woman with a gestational age of 10 weeks. a 39-year-old woman visited the emergency department complaining of acute pain and swelling of the left upper arm and right lower extremity. she showed swelling of the left upper arm and right lower extremity and a low antithrombin level of 40%. ultrasound examination showed right femoral and left subclavian vein thrombosis. her dvts were treated with unfractionated heparin. five months later, she received a cesarean delivery with intravenous unfractionated heparin and antithrombin replacement to prevent dvt, and she successfully gave birth. a genetic test for antithrombin deficiency confirmed hereditary antithrombin deficiency. dvt during pregnancy can occur in an upper extremity and at multiple sites. an undiagnosed coagulation disorder magnifies the risk of dvt in pregnant patients. we should examine all extremities for which there are complaints of pain and swelling with suspicion of dvt and consecutively search for an underlying coagulation disorder in pregnant patients with unusual clinical features of dvt. <learning objective: deep venous thrombosis (dvt) during pregnancy can occur in an upper extremity and at multiple sites. an undiagnosed coagulation disorder magnifies the risk of dvt in pregnant patients. we should examine all extremities for which there are complaints of pain and swelling with suspicion of dvt and consecutively search for an underlying coagulation disorder in pregnant patients with unusual clinical features of dvt.>.","['right femoral vein thrombosis', 'pregnant patient', 'left subclavian', 'antithrombin deficiency']"
"the correct protein coding region identification is an important and latent problem in the molecular biology field. this problem becomes a challenge due to the lack of deep knowledge about the biological systems and unfamiliarity of conservative characteristics in the messenger rna (mrna). therefore, it is fundamental to research for computational methods aiming to help the patterns discovery for identification of the translation initiation sites (tis). in the field of bioinformatics, machine learning methods have been widely applied based on the inductive inference, as inductive support vector machine (isvm). on the other hand, not so much attention has been given to transductive inference-based machine learning methods such as transductive support vector machine (tsvm). the transductive inference performs well for problems in which the amount of unlabeled sequences is considerably greater than the labeled ones. similarly, the problem of predicting the tis may take advantage of transductive methods due to the fact that the amount of new sequences grows rapidly with the progress of genome project that allows the study of new organisms. consequently, this work aims to investigate the transductive learning towards tis identification and compare the results with those obtained in inductive method.","['translation initiation site identification', 'transductive learning', 'alternative']"
"recent breakthroughs in deep learning using automated measurement of face and head motion have made possible the first objective measurement of depression severity. while powerful, deep learning approaches lack interpretability. we developed an interpretable method of automatically measuring depression severity that uses barycentric coordinates of facial landmarks and a lie-algebra based rotation matrix of 3d head motion. using these representations, kinematic features are extracted, preprocessed, and encoded using gaussian mixture models (gmm) and fisher vector encoding. a multi-class svm is used to classify the encoded facial and head movement dynamics into three levels of depression severity. the proposed approach was evaluated in adults with history of chronic depression. the method approached the classification accuracy of state-of-the-art deep learning while enabling clinically and theoretically relevant findings. the velocity and acceleration of facial movement strongly mapped onto depression severity symptoms consistent with clinical data and theory.","['detecting depression severity', 'motion dynamics', 'interpretable representations']"
"deep convolutional networks (cnn) can achieve impressive results on rgb scene recognition thanks to large datasets such as places. in contrast, rgb-d scene recognition is still underdeveloped in comparison, due to two limitations of rgb-d data we address in this paper. the first limitation is the lack of depth data for training deep learning models. rather than fine tuning or transferring rgb-specific features, we address this limitation by proposing an architecture and a twostep training approach that directly learns effective depth-specific features using weak supervision via patches. the resulting rgbd model also benefits from more complementary multimodal features. another limitation is the short range of depth sensors (typically 0.5m to 5.5m), resulting in depth images not capturing distant objects in the scenes that rgb images can. we show that this limitation can be addressed by using rgb-d videos, where more comprehensive depth information is accumulated as the camera travels across the scenes. focusing on this scenario, we introduce the isia rgb-d video dataset to evaluate rgb-d scene recognition with videos. our video recognition architecture combines convolutional and recurrent neural networks (rnns) that are trained in three steps with increasingly complex data to learn effective features (i.e. patches, frames and sequences). our approach obtains state-of-the-art performances on rgb-d image (nyud2 and sun rgb-d) and video (isia rgb-d) scene recognition.","['learning effective rgb', 'scene recognition', 'representations']"
"照片识别是评估种群丰度和监测种群动态的重要工具。然而, 人工地将照片与已知个体进行比对需耗费大量时间。受到最近图像识别领域发展的启发, 我们在众包平台\xa0kaggle\xa0网站举办了一项数据科学挑战, 来自动识别濒危的北太平洋露脊鲸 (eubalaena glacialis) 。获胜的方案能以87%的准确率自动识别鲸鱼个体, 它利用一系列卷积神经网络来找到图像上关注的区域, 加以旋转、裁剪, 并创建统一尺寸和方向的标准化照片, 然后从这些类似护照的照片中正确识别出鲸鱼个体。目前深度学习领域的进展加上这种完全自动化的工作流程, 已取得了显著成果, 并有可能给野生动物种群丰度和分布的传统数据收集方法带来变革。我们将这些结果呈现给广大受众, 以期进一步缩小数据科学和保护科学群体之间的距离。【翻译: 胡怡思; 审校: 聂永刚】.","['right whale photo identification', 'applying deep learning']"
"segmentation and quantification of microvasculature structures are the main steps toward studying microvasculature remodeling. the proposed patch based semantic architecture enables accurate segmentation for the challenging epifluorescence microscopy images. our pixel-based fast semantic network trained on random patches from different epifluorescence images to learn how to discriminate between vessels versus nonvessels pixels. the proposed semantic vessel network (svnet) relies on understanding the morphological structure of the thin vessels in the patches rather than considering the whole image as input to speed up the training process and to maintain the clarity of thin structures. experimental results on our ovariectomized - ovary removed (ovx) - mice dura mater epifluorescence microscopy images shows promising results in both arteriole and venule part. we compared our results with different segmentation methods such as local, global thresholding, matched based filter approaches and related state of the art deep learning networks. our overall accuracy (> 98%) outperforms all the methods including our previous work (vnet). [","['based semantic segmentation', 'epifluorescence imagery', 'detecting arterioles', 'venules', 'patch']"
"a simple ""stop think"" approach was developed to encourage the self-assessment of learning. a key element was the requirement for students to rate their feeling of difficulty before [fod(pre","['pos', 'fod']"
"synovial sarcoma is a rare disease with diverse progression characteristics. we developed a novel deep-learning-based prediction algorithm for survival rates of synovial sarcoma patients. the purpose of this study is to evaluate the performance of the proposed prediction model and demonstrate its clinical usage. the study involved 242 patients who were diagnosed with synovial sarcoma in three institutions between march 2001 and february 2013. the patients were randomly divided into a training set (80%) and a testing set (20%). fivefold cross validation was performed utilizing the training set. the test set was retained for the final testing. a cox proportional hazard model, simple neural network, and the proposed survival neural network were all trained utilizing the same training set, and fivefold cross validation was performed. the final testing was performed utilizing the isolated test data to determine the best prediction model. the multivariate cox proportional hazard regression analysis revealed that size, initial metastasis, and margin were independent prognostic factors. in fivefold cross validation, the median value of the receiver-operating characteristic curve (area under the curve) was 0.87 in the survival neural network, which is significantly higher compared to the area under the curve of 0.792 for the simple neural network (p\u2009=\u20090.043). in the final test, survival neural network model showed the better performance (area under the curve: 0.814) compared to the cox proportional hazard model (area under the curve: 0.629; p\u2009=\u20090.0001). the survival neural network model predicted survival of synovial sarcoma patients more accurately compared to cox proportional hazard model.","['deep learning approach', 'synovial sarcoma', 'survival prediction', 'patients']"
"breast cancer is one of the leading cancer type among women in worldwide. many breast cancer patients die every year due to the late diagnosis and treatment. thus, in recent years, early breast cancer detection systems based on patient's imagery are in demand. deep learning attracts many researchers recently and many computer vision applications have come out in various environments. convolutional neural network (cnn) which is known as deep learning architecture, has achieved impressive results in many applications. cnns generally suffer from tuning a huge number of parameters which bring a great amount of complexity to the system. in addition, the initialization of the weights of the cnn is another handicap that needs to be handle carefully. in this paper, transfer learning and deep feature extraction methods are used which adapt a pre-trained cnn model to the problem at hand. alexnet and vgg16 models are considered in the presented work for feature extraction and alexnet is used for further fine-tuning. the obtained features are then classified by support vector machines (svm). extensive experiments on a publicly available histopathologic breast cancer dataset are carried out and the accuracy scores are calculated for performance evaluation. the evaluation results show that the transfer learning produced better result than deep feature extraction and svm classification.","['transfer learning based histopathologic image classification', 'breast cancer detection']"
"multiple kernel learning (mkl) is a widely used technique for kernel design. its principle consists in learning, for a given support vector classifier, the most suitable convex (or sparse) linear combination of standard elementary kernels. however, these combinations are shallow and often powerless to capture the actual similarity between highly semantic data, especially for challenging classification tasks such as image annotation. in this paper, we redefine multiple kernels using deep multi-layer networks. in this new contribution, a deep multiple kernel is recursively defined as a multi-layered combination of nonlinear activation functions, each one involves a combination of several elementary or intermediate kernels, and results into a positive semi-definite deep kernel. we propose four different frameworks in order to learn the weights of these networks: supervised, unsupervised, kernel-based semisupervised and laplacian-based semi-supervised. when plugged into support vector machines (svms), the resulting deep kernel networks show clear gain, compared to several shallow kernels for the task of image annotation. extensive experiments and analysis on the challenging imageclef photo annotation benchmark, the corel5k database and the banana dataset validate the effectiveness of the proposed method.","['nonlinear deep kernel learning', 'image annotation']"
"prenatal alcohol exposure has been linked to a broad range of developmental deficits, with eyeblink classical conditioning (ebc) among the most sensitive endpoints. this fmri study compared ebc-related brain activity in 47 children with fetal alcohol syndrome (fas), partial fas (pfas), heavily exposed (he) non-syndromal children, and healthy controls. all of the children had previously participated in two ebc studies conducted as part of our longitudinal study of fetal alcohol spectrum disorders. although learning-related behavioral differences were seen in all groups during the scans, controls showed more conditioned responses (cr) than the alcohol-exposed groups. despite lower conditioning levels relative to controls, the exposed groups exhibited extensive cerebellar activations. specifically, children with fas/pfas showed increased activation of cerebellar lobule vi in session 2, while he children showed increased activation in session 1. continuous measures of prenatal alcohol use correlated with learning-related activations in cerebellum and frontal cortices. only controls showed significant cerebellar activation-cr correlations in the deep nuclei and lateral lobule vi, suggesting that these key regions supporting ebc may be functionally disorganized in alcohol-exposed children. these findings are the first to characterize abnormalities in brain function associated with the behavioral conditioning deficits seen in children with prenatal alcohol exposure.","['human eyeblink classical conditioning', 'fetal alcohol spectrum disorders', 'functional mri', 'children']"
"with the developments of dna sequencing technology, large amounts of sequencing data have become available in recent years and provide unprecedented opportunities for advanced association studies between somatic point mutations and cancer types/subtypes, which may contribute to more accurate somatic point mutation based cancer classification (smcc). however in existing smcc methods, issues like high data sparsity, small volume of sample size, and the application of simple linear classifiers, are major obstacles in improving the classification performance.","['advanced cancer type classifier based', 'somatic point mutations', 'deep learning', 'deepgene']"
"the segmentation of organs at risk is a crucial and time-consuming step in radiotherapy planning. good automatic methods can significantly reduce the time clinicians have to spend on this task. due to its variability in shape and low contrast to surrounding structures, segmenting the parotid gland is challenging. motivated by the recent success of deep learning, we study the use of two-dimensional (2-d), 2-d ensemble, and three-dimensional (3-d) u-nets for segmentation. the mean dice similarity to ground truth is ∼ 0.83 for all three models. a patch-based approach for class balancing seems promising for false-positive reduction. the 2-d ensemble and 3-d u-net are applied to the test data of the 2015 miccai challenge on head and neck autosegmentation. both deep learning methods generalize well onto independent data (dice 0.865 and 0.88) and are superior to a selection of model- and atlas-based methods with respect to the dice coefficient. since appropriate reference annotations are essential for training but often difficult and expensive to obtain, it is important to know how many samples are needed for training. we evaluate the performance after training with different-sized training sets and observe no significant increase in the dice coefficient for more than 250 training cases.","['parotid gland segmentation', 'deep learning methods', 'ct images', 'evaluation']"
to develop an improved k-space reconstruction method using scan-specific deep learning that is trained on autocalibration signal (acs) data.,"['specific robust artificial', 'space interpolation', 'scan', 'rak', 'neural', 'networks', 'k']"
"this article presents a new deep learning approach for cardiac arrhythmia (17 classes) detection based on long-duration electrocardiography (ecg) signal analysis. cardiovascular disease prevention is one of the most important tasks of any health care system as about 50 million people are at risk of heart disease in the world. although automatic analysis of ecg signal is very popular, current methods are not satisfactory. the goal of our research was to design a new method based on deep learning to efficiently and quickly classify cardiac arrhythmias. described research are based on 1000 ecg signal fragments from the mit - bih arrhythmia database for one lead (mlii) from 45 persons. approach based on the analysis of 10-s ecg signal fragments (not a single qrs complex) is applied (on average, 13 times less classifications/analysis). a complete end-to-end structure was designed instead of the hand-crafted feature extraction and selection used in traditional methods. our main contribution is to design a new 1d-convolutional neural network model (1d-cnn). the proposed method is 1) efficient, 2) fast (real-time classification) 3) non-complex and 4) simple to use (combined feature extraction and selection, and classification in one stage). deep 1d-cnn achieved a recognition overall accuracy of 17 cardiac arrhythmia disorders (classes) at a level of 91.33% and classification time per single sample of 0.015\u202fs. compared to the current research, our results are one of the best results to date, and our solution can be implemented in mobile devices and cloud computing.","['arrhythmia detection using deep convolutional neural network', 'long duration ecg signals']"
"temporal lobe epilepsy often leads to hippocampal sclerosis and persistent cognitive deficits, including difficulty with learning and memory. hippocampal theta oscillations are critical in optimizing hippocampal function and facilitating plasticity. we hypothesized that pilocarpine-induced status epilepticus would disrupt oscillations and behavioral performance and that electrical neuromodulation to entrain theta would improve cognition specifically in injured rats. rats received a pilocarpine (n=30) or saline injection (n=27) and unilateral bi-polar electrodes were implanted into the medial septum and hippocampus the following day. hippocampal and septal theta were recorded in a plexiglas box over the first week following implantation. control and pilocarpine-treated rats were split into stimulation (continuous 7.7hz, 80μa, 1ms pulse width) and non-stimulation groups for behavioral analysis. continuous stimulation was initiated one-minute prior to and throughout an object exploration task (post-injury day seven) and again for each of six trials on the barnes maze (post-injury days 12-14). there was a significant reduction in hippocampal theta power (p<0.05) and percentage of time oscillating in theta (p<0.05). in addition there was a significant decrease in object exploration in rats post-pilocarpine (p<0.05) and an impairment in spatial learning. specifically, pilocarpine-treated rats were more likely to use random search strategies (p<0.001) and had an increase in latency to find the hidden platform (p<0.05) on the barnes maze. stimulation of the medial septum at 7.7hz in pilocarpine-treated rats resulted in performance similar to shams in both the object recognition and barnes maze tasks. stimulation of sham rats resulted in impaired object exploration (p<0.05) with no difference in barnes maze latency or strategy. in conclusion, pilocarpine-induced seizures diminished hippocampal oscillations and impaired performance in both an object exploration and a spatial memory task in pilocarpine-treated rats. theta stimulation at 7.7hz improved behavioral outcome on the barnes maze task; this improvement in function was not related to a general cognitive enhancement, as shams did not benefit from stimulation. therefore, stimulation of the medial septum represents an exciting target to improve behavioral outcome in patients with epilepsy.","['spatial learning following pilocarpine', 'medial septum improves performance', 'induced status epilepticus', 'stimulation']"
"manual ultrasound (us)-based methods are adapted for lumen diameter (ld) measurement to estimate the risk of stroke but they are tedious, error prone, and subjective causing variability. we propose an automated deep learning (dl)-based system for lumen detection. the system consists of a combination of two dl systems: encoder and decoder for lumen segmentation. the encoder employs a 13-layer convolution neural network model (cnn) for rich feature extraction. the decoder employs three up-sample layers of fully convolution network (fcn) for lumen segmentation. three sets of manual tracings were used during the training paradigm leading to the design of three dl systems. cross-validation protocol was implemented for all three dl systems. using the polyline distance metric, the precision of merit for three dl systems over 407 us scans was 99.61%, 97.75%, and 99.89%, respectively. the jaccard index and dice similarity of dl lumen segmented region against three ground truth (gt) regions were 0.94, 0.94, and 0.93 and 0.97, 0.97, and 0.97, respectively. the corresponding auc for three dl systems was 0.95, 0.91, and 0.93. the experimental results demonstrated superior performance of proposed deep learning system over conventional methods in literature. graphical abstract ᅟ.","['diabetic patients using carotid ultrasound', 'deep learning fully convolution network', 'stroke risk', 'lumen characterization', 'tool']"
"segmentation of the left ventricle (lv) from three-dimensional echocardiography (3de) plays a key role in the clinical diagnosis of the lv function. in this work, we proposed a new automatic method for the segmentation of lv, based on the fully convolutional networks (fcn) and deformable model. this method implemented a coarse-to-fine framework. firstly, a new deep fusion network based on feature fusion and transfer learning, combining the residual modules, was proposed to achieve coarse segmentation of lv on 3de. secondly, we proposed a method of geometrical model initialization for a deformable model based on the results of coarse segmentation. thirdly, the deformable model was implemented to further optimize the segmentation results with a regularization item to avoid the leakage between left atria and left ventricle to achieve the goal of fine segmentation of lv. numerical experiments have demonstrated that the proposed method outperforms the state-of-the-art methods on the challenging cetus benchmark in the segmentation accuracy and has a potential for practical applications.","['automatic left ventricle segmentation based', 'combined fully convolutional networks', 'deformable model', '3d echocardiography']"
"niemann-pick disease type c (npc) is a rare neurovisceral disease caused mainly by mutations in the npc1 gene. this autosomal recessive lysosomal disorder is characterised by the defective lysosomal secretion of cholesterol and sphingolipids. no effective therapy exists for the disease. we previously described a deep intronic point mutation (c.1554-1009\u2009g\u2009>\u2009a) in npc1 that generated a pseudoexon, which could be corrected at the cellular level using antisense oligonucleotides. here, we describe the generation of two mouse models bearing this mutation, one in homozygosity and the other in compound heterozygosity with the c.1920delg mutation. both the homozygotes for the c.1554-1009\u2009g\u2009>\u2009a mutation and the compound heterozygotes recapitulated the hallmarks of npc. lipid analysis revealed accumulation of cholesterol in the liver and sphingolipids in the brain, with both types of transgenic mice displaying tremor and ataxia at 7-8 weeks of age. behavioural tests showed motor impairment, hyperactivity, reduced anxiety-like behaviour and impaired learning and memory performances, features consistent with those reported previously in npc animal models and human patients. these mutant mice, the first npc models bearing a pseudoexon-generating mutation, could be suitable for assessing the efficacy of specific splicing-targeted therapeutic strategies against npc.","['pick type c models bearing', 'new murine niemann', 'generating mutation recapitulate', 'molecular features', 'main neurobehavioural', 'pseudoexon', 'disease']"
"in an effort to develop quantitative biomarkers for degenerative joint disease and fill the void that exists for diagnosing, monitoring, and assessing the extent of whole joint degeneration, the past decade has been marked by a greatly increased role of noninvasive imaging. this coupled with recent advances in image processing and deep learning opens new possibilities for promising quantitative techniques. the clinical translation of quantitative imaging was previously hampered by tedious non-scalable and subjective image analysis. osteoarthritis (oa) diagnosis using x-rays can be automated by the use of deep learning models and pilot studies showed feasibility of using similar techniques to reliably segment multiple musculoskeletal tissues and detect and stage the severity of morphological abnormalities in magnetic resonance imaging (mri). automation and more advanced feature extraction techniques have applications on larger more heterogeneous samples. analyses based on voxel based relaxometry have shown local patterns in relaxation time elevations and local correlations with outcome variables. bone cartilage interactions are also enhanced by the analysis of three-dimensional bone morphology and the potential for the assessment of metabolic activity with simultaneous positron emission tomography (pet)/mr systems. novel techniques in image processing and deep learning are augmenting imaging to be a source of quantitative and reliable data and new multidimensional analytics allow us to exploit the interactions of data from various sources. in this review, we aim to summarize recent advances in quantitative imaging, the application of image processing and deep learning techniques to study knee and hip oa. ©2018 orthopaedic research society. published by wiley periodicals, inc. j orthop res xx:xx-xx, 2018.","['functional musculoskeletal imaging', 'translation', 'morphological']"
"a right-sided aortic arch is normally asymptomatic. we report the case of an 84-year-old man with right internal jugular vein thrombosis caused by an aneurysm in a right-sided aortic arch. the patient had undergone open repair of an abdominal aortic aneurysm and had an uneventful postoperative course. however, a routine postoperative contrast-enhanced thoracic and abdominal computed tomography scan showed right internal jugular vein thrombosis. the patient had no history of catheter insertion in the right jugular veins and had no hereditary coagulopathy. it was presumed that the cause of this thrombosis was compression of the right brachiocephalic vein by an aneurysm of the right-sided ascending aorta that was considered too small to require surgical repair. the right internal jugular vein thrombosis was successfully treated with edoxaban. <learning objective: this case report alerts us to consider that a right-sided aortic arch aneurysm considered too small for surgery can later cause upper-extremity deep vein thrombosis.>.","['right internal jugular vein thrombosis caused', 'sided aortic arch', 'right', 'aneurysm']"
"high throughput mrna expression profiling can be used to characterize the response of cell culture models to perturbations such as pharmacologic modulators and genetic perturbations. as profiling campaigns expand in scope, it is important to homogenize, summarize, and analyze the resulting data in a manner that captures significant biological signals in spite of various noise sources such as batch effects and stochastic variation. we used the l1000 platform for large-scale profiling of 978 representative genes across thousands of compound treatments. here, a method is described that uses deep learning techniques to convert the expression changes of the landmark genes into a perturbation barcode that reveals important features of the underlying data, performing better than the raw data in revealing important biological insights. the barcode captures compound structure and target information, and predicts a compound's high throughput screening promiscuity, to a higher degree than the original data measurements, indicating that the approach uncovers underlying factors of the expression data that are otherwise entangled or masked by noise. furthermore, we demonstrate that visualizations derived from the perturbation barcode can be used to more sensitively assign functions to unknown compounds through a guilt-by-association approach, which we use to predict and experimentally validate the activity of compounds on the mapk pathway. the demonstrated application of deep metric learning to large-scale chemical genetics projects highlights the utility of this and related approaches to the extraction of insights and testable hypotheses from big, sometimes noisy data.",['representing high throughput expression profiles via perturbation barcodes reveals compound targets']
"the recent success of deep learning techniques in machine learning and artificial intelligence has stimulated a great deal of interest among bioinformaticians, who now wish to bring the power of deep learning to bare on a host of bioinformatical problems. deep learning is ideally suited for biological problems that require automatic or hierarchical feature representation for biological data when prior knowledge is limited. in this work, we address the sequence-specific bias correction problem for rna-seq data redusing recurrent neural networks (rnns) to model nucleotide sequences without pre-determining sequence structures. the sequence-specific bias of a read is then calculated based on the sequence probabilities estimated by rnns, and used in the estimation of gene abundance.","['seq data using recurrent neural networks', 'specific bias correction', 'sequence', 'rna']"
"abundant accumulation of digital histopathological images has led to the increased demand for their analysis, such as computer-aided diagnosis using machine learning techniques. however, digital pathological images and related tasks have some issues to be considered. in this mini-review, we introduce the application of digital pathological image analysis using machine learning algorithms, address some problems specific to such analysis, and propose possible solutions.","['machine learning methods', 'histopathological image analysis']"
"performance of models highly depend not only on the used algorithm but also the data set it was applied to. this makes the comparison of newly developed tools to previously published approaches difficult. either researchers need to implement others' algorithms first, to establish an adequate benchmark on their data, or a direct comparison of new and old techniques is infeasible. the ischemic stroke lesion segmentation (isles) challenge, which has ran now consecutively for 3 years, aims to address this problem of comparability. isles 2016 and 2017 focused on lesion outcome prediction after ischemic stroke: by providing a uniformly pre-processed data set, researchers from all over the world could apply their algorithm directly. a total of nine teams participated in isles 2015, and 15 teams participated in isles 2016. their performance was evaluated in a fair and transparent way to identify the state-of-the-art among all submissions. top ranked teams almost always employed deep learning tools, which were predominately convolutional neural networks (cnns). despite the great efforts, lesion outcome prediction persists challenging. the annotated data set remains publicly available and new approaches can be compared directly via the online evaluation system, serving as a continuing benchmark (www.isles-challenge.org).","['benchmarking ischemic stroke lesion outcome prediction based', 'multispectral mri', 'isles 2016', '2017']"
"traditional laboratory experiments, rehabilitation clinics, and wearable sensors offer biomechanists a wealth of data on healthy and pathological movement. to harness the power of these data and make research more efficient, modern machine learning techniques are starting to complement traditional statistical tools. this survey summarizes the current usage of machine learning methods in human movement biomechanics and highlights best practices that will enable critical evaluation of the literature. we carried out a pubmed/medline database search for original research articles that used machine learning to study movement biomechanics in patients with musculoskeletal and neuromuscular diseases. most studies that met our inclusion criteria focused on classifying pathological movement, predicting risk of developing a disease, estimating the effect of an intervention, or automatically recognizing activities to facilitate out-of-clinic patient monitoring. we found that research studies build and evaluate models inconsistently, which motivated our discussion of best practices. we provide recommendations for training and evaluating machine learning models and discuss the potential of several underutilized approaches, such as deep learning, to generate new knowledge about human movement. we believe that cross-training biomechanists in data science and a cultural shift toward sharing of data and tools are essential to maximize the impact of biomechanics research.","['human movement biomechanics', 'new opportunities', 'machine learning', 'common pitfalls', 'best practices']"
"recent studies on brain imaging analysis witnessed the core roles of machine learning techniques in computer-assisted intervention for brain disease diagnosis. of various machine-learning techniques, sparse regression models have proved their effectiveness in handling high-dimensional data but with a small number of training samples, especially in medical problems. in the meantime, deep learning methods have been making great successes by outperforming the state-of-the-art performances in various applications. in this paper, we propose a novel framework that combines the two conceptually different methods of sparse regression and deep learning for alzheimer's disease/mild cognitive impairment diagnosis and prognosis. specifically, we first train multiple sparse regression models, each of which is trained with different values of a regularization control parameter. thus, our multiple sparse regression models potentially select different feature subsets from the original feature set; thereby they have different powers to predict the response values, i.e., clinical label and clinical scores in our work. by regarding the response values from our sparse regression models as target-level representations, we then build a deep convolutional neural network for clinical decision making, which thus we call 'deep ensemble sparse regression network.' to our best knowledge, this is the first work that combines sparse regression models with deep neural network. in our experiments with the adni cohort, we validated the effectiveness of the proposed method by achieving the highest diagnostic accuracies in three classification tasks. we also rigorously analyzed our results and compared with the previous studies on the adni cohort in the literature.","['sparse regression models', 'deep ensemble learning', 'brain disease diagnosis']"
"accurate identification of prognostic biomarkers is an important yet challenging goal in bioinformatics. many bioinformatics approaches have been proposed for this purpose, but there is still room for improvement. in this paper, we propose a novel machine learning-based method for more accurate identification of prognostic biomarker genes and use them for prediction of cancer prognosis. the proposed method specifies the candidate prognostic gene module by graph learning using the generative adversarial networks (gans) model, and scores genes using a pagerank algorithm. we applied the proposed method to multiple-omics data that included copy number, gene expression, dna methylation, and somatic mutation data for five cancer types. the proposed method showed better prediction accuracy than did existing methods. we identified many prognostic genes and their roles in their biological pathways. we also showed that the genes identified from different omics data were complementary, which led to improved accuracy in prediction using multi-omics data.","['network learning', 'improved method', 'cancer prognosis', 'prediction']"
"for using counts of circulating tumor cells (ctcs) in the clinic to aid a physician's decision, its reported values will need to be accurate and comparable between institutions. many technologies have become available to enumerate and characterize ctcs, thereby showing a large range of reported values. here we introduce an open source ctc scoring tool to enable comparison of different reviewers and facilitate the reach of a consensus on assigning objects as ctcs. one hundred images generated from two different platforms were used to assess concordance between 15 reviewers and an expert panel. large differences were observed between reviewers in assigning objects as ctcs urging the need for computer recognition of ctcs. a demonstration of a deep learning approach on the 100 images showed the promise of this technique for future ctc enumeration. © 2018 the authors. cytometry part a published by wiley periodicals, inc. on behalf of international society for advancement of cytometry.","['circulating tumor cell scoring', 'evaluating', 'ctc', 'consensus', 'agree']"
"the purpose of the study was to develop a deep residual learning algorithm to screen for glaucoma from fundus photography and measure its diagnostic performance compared to residents in ophthalmology. a training dataset consisted of 1,364 color fundus photographs with glaucomatous indications and 1,768 color fundus photographs without glaucomatous features. a testing dataset consisted of 60 eyes of 60 glaucoma patients and 50 eyes of 50 normal subjects. using the training dataset, a deep learning algorithm known as deep residual learning for image recognition (resnet) was developed to discriminate glaucoma, and its diagnostic accuracy was validated in the testing dataset, using the area under the receiver operating characteristic curve (aroc). the deep residual learning for image recognition was constructed using the training dataset and validated using the testing dataset. the presence of glaucoma in the testing dataset was also confirmed by three residents in ophthalmology. the deep learning algorithm achieved significantly higher diagnostic performance compared to residents in ophthalmology; with resnet, the aroc from all testing data was 96.5 (95% confidence interval [c","['99', '5', '3']"
"parkinson's disease (pd) is a neurodegenerative disease of the central nervous system caused due to the loss of dopaminergic neurons. it is classified under movement disorder as patients with pd present with tremor, rigidity, postural changes, and a decrease in spontaneous movements. comorbidities including anxiety, depression, fatigue, and sleep disorders are observed prior to the diagnosis of pd. gene mutations, exposure to toxic substances, and aging are considered as the causative factors of pd even though its genesis is unknown. this paper reviews pd etiologies, progression, and in particular measurable indicators of pd such as neuroimaging and electrophysiology modalities. in addition to gene therapy, neuroprotective, pharmacological, and neural transplantation treatments, researchers are actively aiming at identifying biological markers of pd with the goal of early diagnosis. neuroimaging modalities used together with advanced machine learning techniques offer a promising path for the early detection and intervention in pd patients.","['measurable indicators', 'early diagnosis', 'cause factors', 'parkinson', 'disease']"
"because the prognosis of pulmonary thromboembolism (pte) will be often poor, early diagnosis and assessing severity at the first visit is important. a 76-year-old man with suspected venous thromboembolism and a contrast deficit in the pulmonary artery (pa) was revealed by contrast-enhanced computed tomography (ct) imaging by dual-layer spectral-detector ct (iqon spectral ct®, philips healthcare, best, the netherlands). the lung perfusion image showed decreased perfusion in the culprit lesion. the dual-energy analysis of the virtual monoenergetic imaging showed clear visualization of deep vein thrombosis (dvt). in a 64-year-old man, an iqon spectral ct® revealed a small contrast deficit in the pa. however, no perfusion abnormality was detected in the lung perfusion analysis. the iqon spectral ct® enables the detection of lung perfusion abnormalities in addition to pte. the iqon spectral ct® imaging may be useful for the ""one-stop shop"" evaluation of pte and dvt. <learning objective: the prognosis of pulmonary thromboembolism (pte) will be often poor, so early diagnosis and assessing severity at the first visit is important. the dual-layer spectral-detector computed tomography imaging for pte, whereby the iodine map provided information regarding lung perfusion, whereas virtual monoenergetic images enabled clear visualization of deep vein thrombosis.>.","['venous thromboembolism', 'novel assessment', 'layer spectral', 'detector ct', 'demand analysis', 'retrospective', 'dual']"
"photoreceptor ellipsoid zone (ez) defects visible on optical coherence tomography (oct) are important imaging biomarkers for the onset and progression of macular diseases. as such, accurate quantification of ez defects is paramount to monitor disease progression and treatment efficacy over time. we developed and trained a novel deep learning-based method called deep oct atrophy detection (doctad) to automatically segment ez defect areas by classifying 3-dimensional a-scan clusters as normal or defective. furthermore, we introduce a longitudinal transfer learning paradigm in which the algorithm learns from segmentation errors on images obtained at one time point to segment subsequent images with higher accuracy. we evaluated the performance of this method on 134 eyes of 67 subjects enrolled in a clinical trial of a novel macular telangiectasia type 2 (mactel2) therapeutic agent. our method compared favorably to other deep learning-based and non-deep learning-based methods in matching expert manual segmentations. to the best of our knowledge, this is the first automatic segmentation method developed for ez defects on oct images of mactel2.","['photoreceptor ellipsoid zone defects', 'optical coherence tomography images', 'macular telangiectasia type 2', 'deep longitudinal transfer learning', 'based automatic segmentation']"
to evaluate the accuracy of a deep learning software (dls) in the discrimination between phyllodes tumors (pt) and fibroadenomas (fa).,"['breast ultrasound using deep learning image analysis', 'phyllodes tumor', 'fibroadenoma', 'distinction']"
"the orchestration of orienting behaviors requires the interaction of many cortical and subcortical areas, for example the superior colliculus (sc), as well as prefrontal areas responsible for top-down control. orienting involves different behaviors, such as approach and avoidance. in the rat, these behaviors are at least partially mapped onto different sc subdomains, the lateral (scl) and medial (scm), respectively. to delineate the circuitry involved in the two types of orienting behavior in mice, we injected retrograde tracer into the intermediate and deep layers of the scm and scl, and thereby determined the main input structures to these subdomains. overall the scm receives larger numbers of afferents compared to the scl. the prefrontal cingulate area (cg), visual, oculomotor, and auditory areas provide strong input to the scm, while prefrontal motor area 2 (m2), and somatosensory areas provide strong input to the scl. the prefrontal areas cg and m2 in turn connect to different cortical and subcortical areas, as determined by anterograde tract tracing. even though connectivity pattern often overlap, our labeling approaches identified segregated neural circuits involving scm, cg, secondary visual cortices, auditory areas, and the dysgranular retrospenial cortex likely to be involved in avoidance behaviors. conversely, scl, m2, somatosensory cortex, and the granular retrospenial cortex comprise a network likely involved in approach/appetitive behaviors.","['avoidance orienting behaviors', 'segregated fronto', 'midbrain connections', 'relation', 'mouse', 'cortical', 'approach']"
"due to the occult anatomic location of the nasopharynx and frequent presence of adenoid hyperplasia, the positive rate for malignancy identification during biopsy is low, thus leading to delayed or missed diagnosis for nasopharyngeal malignancies upon initial attempt. here, we aimed to develop an artificial intelligence tool to detect nasopharyngeal malignancies under endoscopic examination based on deep learning.","['based deep learning model', 'nasopharyngeal malignancies', 'endoscopic images', 'validation', 'development', 'detection']"
"familial hypercholesterolemia (fh) is one of the most frequent diseases with monogenic inheritance. previous data indicated that the heterozygous form occurred in 1:250 people. based on these reports, around 36,000-40,000 people are estimated to have fh in hungary, however, there are no exact data about the frequency of the disease in our country. therefore, we initiated a cooperation with a clinical site partner company that provides modern data mining methods, on the basis of medical and statistical records, and we applied them to two major hospitals in the northern great plain region of hungary to find patients with a possible diagnosis of fh.","['familial hypercholesterolemia using data mining methods', 'northern great plain region', 'identifying patients', 'hungary']"
"cardiac and pericardial involvement by malignant lymphoma is a rare condition. the present case report describes a case of primary cardiac myc/bcl6 double hit non-hodgkin lymphoma in the pericardium, and highlights the importance of a prompt diagnosis and aggressive pharmacologic treatment of this disease. in a symptomatic patient, a minimally invasive 3\xa0cm sub-xiphoidal incision was performed under deep sedation with spontaneous ventilation to perform a pericardial biopsy. a 5\xa0cm\xa0×\xa03\xa0cm portion of pericardium was removed from above the right ventricle, thus ameliorating the extrinsic compression on the right chambers. the patient received 6 cycles of immuno-chemotherapy (rituximab plus cyclophosphamide, vincristine, and methylprednisolone), with no complications, achieving complete remission with no symptoms. malignancies must be excluded in every case of acute pericardial disease with imaging techniques, and lymphomas should be always considered in the differential diagnosis of cardiac tumors. complete surgical removal of the tumor is not necessary to achieve complete remission, and minimally invasive surgical approaches are an effective tool to confirm diagnosis and allow a precise histologic characterization. <learning objective: primary myc/bcl6 double hit non-hodgkin lymphoma is a rare tumor of the pericardium, which requires prompt diagnosis and treatment. minimally invasive surgical approaches are an effective tool to confirm diagnosis and allow a precise histologic characterization. pericardial tumors should always be considered in the differential diagnosis of acute pericardial disease presenting with pericardial effusion. double hit diffuse large b cell-lymphoma has a poor prognosis with standard chemotherapy and the treatment should be tailored according to the patient's comorbidities and performance status.>.","['bcl6 double hit non', 'primary cardiac myc', 'hodgkin lymphoma']"
artificial intelligence (ai) plays a pivotal role in drug discovery. in particular artificial neural networks such as deep neural networks or recurrent networks drive this area. numerous applications in property or activity predictions like physicochemical and admet properties have recently appeared and underpin the strength of this technology in quantitative structure-property relationships (qspr) or quantitative structure-activity relationships (qsar). artificial intelligence in de novo design drives the generation of meaningful new biologically active molecules towards desired properties. several examples establish the strength of artificial intelligence in this field. combination with synthesis planning and ease of synthesis is feasible and more and more automated drug discovery by computers is expected in the near future.,"['drug design', 'artificial intelligence']"
"in domain adaptation, the automatic discovery of multiple latent source domains has succeeded by capturing the intrinsic structure underlying the source data. different from previous works that mainly rely on shallow models for domain discovery, we propose a novel unified framework based on deep neural networks to jointly address latent domain prediction from source data and deep representation learning from both source and target data. within this framework, an iterative algorithm is proposed to alternate between 1) utilizing a new probabilistic hierarchical clustering method to separate the source domain into latent clusters and 2) training deep neural networks by using the domain membership as the supervision to learn deep representations. the key idea behind this joint learning framework is that good representations can help to improve the prediction accuracy of latent domains and, in turn, domain prediction results can provide useful supervisory information for feature learning. during the training of the deep model, a domain prediction loss, a domain confusion loss, and a task-specific classification loss are effectively integrated to enable the learned feature to distinguish between different latent source domains, transfer between source and target domains, and become semantically meaningful among different classes. trained in an end-to-end fashion, our framework outperforms the state-of-the-art methods for latent domain discovery, as validated by extensive experiments on both object classification and human action-recognition tasks.","['multiple latent domains', 'joint learning', 'domain adaptation', 'deep representations']"
"cells in culture display diverse motility behaviors that may reflect differences in cell state and function, providing motivation to discriminate between different motility behaviors. current methods to do so rely upon manual feature engineering. however, the types of features necessary to distinguish between motility behaviors can vary greatly depending on the biological context, and it is not always clear which features may be most predictive in each setting for distinguishing particular cell types or disease states. convolutional neural networks (cnns) are machine learning models ideally suited to the analysis of spatial data, allowing for relevant spatial features to be learned as parameters of a model. given that motility data is inherently spatial, we apply cnns to classify different motility behaviors using two novel approaches. the first approach represents motility explicitly as a 3d space with markers denoting a cell's location at each time point, and the second utilizes recurrent long-term short-term memory (lstm) units to represent the temporal dimension implicitly. both 3d cnns and convolutionalrecurrent neural networks (rnns) provide accurate classification of simulated motility behaviors, the experimentally measured motility behaviors of multiple cell types, and characteristic motility behaviors of muscle stem cell differentiation states.","['recurrent neural networks', 'cell motility discrimination', 'deep convolutional', 'prediction']"
"although deep learning (dl) can identify the intermediate or advanced stages of age-related macular degeneration (amd) as a binary yes or no, stratified gradings using the more granular age-related eye disease study (areds) 9-step detailed severity scale for amd provide more precise estimation of 5-year progression to advanced stages. the areds 9-step detailed scale's complexity and implementation solely with highly trained fundus photograph graders potentially hampered its clinical use, warranting development and use of an alternate areds simple scale, which although valuable, has less predictive ability.","['year risk among patients', 'related macular degeneration', 'detailed severity characterization', 'deep learning', 'use', 'estimation', 'age', '5']"
"brain-computer interface (bci) neurotechnology has the potential to reduce disability associated with paralysis by translating neural activity into control of assistive devices1-9. surveys of potential end-users have identified key bci system features10-14, including high accuracy, minimal daily setup, rapid response times, and multifunctionality. these performance characteristics are primarily influenced by the bci's neural decoding algorithm1,15, which is trained to associate neural activation patterns with intended user actions. here, we introduce a new deep neural network16 decoding framework for bci systems enabling discrete movements that addresses these four key performance characteristics. using intracortical data from a participant with tetraplegia, we provide offline results demonstrating that our decoder is highly accurate, sustains this performance beyond a year without explicit daily retraining by combining it with an unsupervised updating procedure3,17-20, responds faster than competing methods8, and can increase functionality with minimal retraining by using a technique known as transfer learning21. we then show that our participant can use the decoder in real-time to reanimate his paralyzed forearm with functional electrical stimulation (fes), enabling accurate manipulation of three objects from the grasp and release test (grt)22. these results demonstrate that deep neural network decoders can advance the clinical translation of bci technology.","['computer interface user performance expectations using', 'deep neural network decoding framework', 'meeting brain']"
"in 3d optical metrology, single-shot structured light profilometry techniques have inherent advantages over their multi-shot counterparts in terms of measurement speed, optical setup simplicity, and robustness to motion artifacts. in this paper, we present a new approach to extract height information from single deformed fringe patterns, based entirely on deep learning. by training a fully convolutional neural network on a large set of simulated height maps with corresponding deformed fringe patterns, we demonstrate the ability of the network to obtain full-field height information from previously unseen fringe patterns with high accuracy. as an added benefit, intermediate data processing steps such as background masking, noise reduction and phase unwrapping that are otherwise required in classic demodulation strategies, can be learned directly by the network as part of its mapping function.","['single shot structured light profilometry', 'deep neural networks']"
"systemic lupus erythematosus (sle) is a rare, autoimmune disorder known to affect most organ sites. complicating clinical management is a poorly differentiated, heterogenous sle disease state. while some small molecule drugs and biologics are available for treatment, additional therapeutic options are needed. parsing complex biological signatures using powerful, yet human interpretable approaches is critical to advancing our understanding of sle etiology and identifying therapeutic repositioning opportunities. to approach this goal, we developed a semi-supervised deep neural network pipeline for gene expression profiling of sle patients and subsequent characterization of individual gene features. our pipeline performed exemplar multinomial classification of sle patients in independent balanced validation (f1=0.956) and unbalanced, under-powered testing (f1=0.944) cohorts. a stacked autoencoder disambiguated individual feature representativeness by regenerating an input-like(a ') feature matrix. a to a' comparisons suggest the top associated features to be key features in gene expression profiling using neural nets.","['approaching neural net feature interpretation using stacked autoencoders', 'systemic lupus erythematosus patients', 'gene expression profiling']"
"in recent years, the amount of video content created and uploaded to the internet has grown exponentially. video content has unique accessibility challenges: indexing, transcribing, and searching video has always been very labor intensive, and there were no automated ways of searching videos for specific content. new software tools that use deep learning methods are automating some of these processes, making video content more discoverable and useful. there are also many new tools for processing and manipulating video in interesting ways. this column will briefly discuss the idea of deep learning and how deep learning tools can be used to transcribe, translate, search, and even manipulate videos. it will suggest ways that librarians can use these tools to help their institutions better manage video content. it also includes a list of video-related software tools.","['online video', 'deep learning', 'automated indexing', 'transcription', 'manipulation', 'advances']"
"due to the massive data sets available for drug candidates, modern drug discovery has advanced to the big data era. central to this shift is the development of artificial intelligence approaches to implementing innovative modeling based on the dynamic, heterogeneous, and large nature of drug data sets. as a result, recently developed artificial intelligence approaches such as deep learning and relevant modeling studies provide new solutions to efficacy and safety evaluations of drug candidates based on big data modeling and analysis. the resulting models provided deep insights into the continuum from chemical structure to in vitro, in vivo, and clinical outcomes. the relevant novel data mining, curation, and management techniques provided critical support to recent modeling studies. in summary, the new advancement of artificial intelligence in the big data era has paved the road to future rational drug development and optimization, which will have a significant impact on drug discovery procedures and, eventually, public health.","['artificial intelligence modeling', 'drug discovery', 'big data']"
"network embedding is the process of learning low-dimensional representations for nodes in a network while preserving node features. existing studies only leverage network structure information and emphasize the preservation of structural features. however, nodes in real-world networks often have a rich set of attributes providing extra semantic information. it has been demonstrated that both structural and attribute features are important for network analysis tasks. to preserve both features, we investigate the problem of integrating structure and attribute information to perform network embedding and propose a multimodal deep network embedding (mdne) method. mdne captures the non-linear network structures and the complex interactions among structures and attributes using a deep model consisting of multiple layers of non-linear functions. since structures and attributes are two different types of information, a multimodal learning method is adopted to pre-process them and help the model to better capture the correlations between node structure and attribute information. we define the loss function employing structural and attribute proximities to preserve the respective features, and the representations are obtained by minimizing the loss function. results of extensive experiments on four real-world data sets show that the proposed method performs significantly better than baselines on a variety of tasks, which demonstrates the effectiveness and generality of our method.","['multimodal deep network embedding', 'integrated structure', 'attribute information']"
"faster region-based convolutional network (faster r-cnn) is a state-of-the-art object detection method. however, the object detection effect of faster r-cnn is not good based on the region proposal network (rpn). inspired by rpn of faster r-cnn, we propose a novel proposal generation method called enhanced region proposal network (erpn). four improvements are presented in erpn. firstly, our proposed deconvolutional feature pyramid network (dfpn) is introduced to improve the quality of region proposals. secondly, novel anchor boxes are designed with interspersed scales and adaptive aspect ratios. thereafter, the capability of object localization is increased. thirdly, a particle swarm optimization (pso) based support vector machine (svm), termed pso-svm, is developed to distinguish the positive and negative anchor boxes. fourthly, the classification part of multi-task loss function in rpn is improved. consequently, the effect of classification loss is strengthened. in this study, our proposed erpn is compared with five object detection methods on both pascal voc and coco data sets. for the vgg-16 model, our erpn obtains 78.6% map on voc 2007 data set, 74.4% map on voc 2012 data set and 31.7% on coco data set. the performance of erpn is the best among the comparison object detection methods. furthermore, the detection speed of erpn is 5.8 fps. additionally, erpn obtains good effect on small object detection.","['object detection using deep learning method', 'enhanced region proposal network']"
"while the use of deep learning in drug discovery is gaining increasing attention, the lack of methods to compute reliable errors in prediction for neural networks prevents their application to guide decision making in domains where identifying unreliable predictions is essential, e.g., precision medicine. here, we present a framework to compute reliable errors in prediction for neural networks using test-time dropout and conformal prediction. specifically, the algorithm consists of training a single neural network using dropout, and then applying it n times to both the validation and test sets, also employing dropout in this step. therefore, for each instance in the validation and test sets an ensemble of predictions are generated. the residuals and absolute errors in prediction for the validation set are then used to compute prediction errors for the test set instances using conformal prediction. we show using 24 bioactivity data sets from chembl 23 that dropout conformal predictors are valid (i.e., the fraction of instances whose true value lies within the predicted interval strongly correlates with the confidence level) and efficient, as the predicted confidence intervals span a narrower set of values than those computed with conformal predictors generated using random forest (rf) models. lastly, we show in retrospective virtual screening experiments that dropout and rf-based conformal predictors lead to comparable retrieval rates of active compounds. overall, we propose a computationally efficient framework (as only n extra forward passes are required in addition to training a single network) to harness test-time dropout and the conformal prediction framework, which is generally applicable to generate reliable prediction errors for deep neural networks in drug discovery and beyond.","['deep neural networks using test', 'reliable prediction errors', 'time dropout']"
the large-scale kinome-wide virtual profiling for small molecules is a daunting task by experimental and traditional in silico drug design approaches. recent advances in deep learning algorithms have brought about new opportunities in promoting this process.,"['wide polypharmacology effect', 'web application', 'small molecules', 'predicting kinome', 'kinomex']"
"atmospheric transmission distortion is one of the main challenges hampering the practical application of a vortex beam (vb) which carries orbital angular momentum (oam). in this work, we propose and investigate a deep learning based atmospheric turbulence compensation method for correcting the distorted vb and improving the performance of oam multiplexing communication. a deep convolutional neural network (cnn) model, which can automatically learn the mapping relationship of the intensity distributions of input and the turbulent phase, is well designed. after trained with loads of studying samples, the cnn model possesses a good generalization ability in quickly and accurately predicting equivalent turbulent phase screen, including the untrained turbulent phase screens. the results show that through correction, the mode purity of the distorted vb improves from 39.52% to 98.34% under the turbulence intensity of cn2 = 1 × 10-13. constructing an oam multiplexing communication link, the bit-error-rate (ber) of the transmitted signals in each oam channel is reduced by almost two orders of magnitude under moderate-strong turbulence, and the demodulated constellation diagram also converges well after compensated by the cnn model.","['deep learning based atmospheric turbulence compensation', 'orbital angular momentum beam distortion', 'communication']"
"pegasus outperformed 5 of the 6 ophthalmologists in terms of diagnostic performance, and there was no statistically significant difference between the deep learning system and the ""best case"" consensus between the ophthalmologists. the agreement between pegasus and gold standard was 0.715, whereas the highest ophthalmologist agreement with the gold standard was 0.613. furthermore, the high sensitivity of pegasus makes it a valuable tool for screening patients with glaucomatous optic neuropathy.","['identifying glaucomatous optic neuropathy based', 'deep learning system', 'color fundus photographs', 'evaluation']"
"the availability of large-scale annotated image datasets and recent advances in supervised deep learning methods enable the end-to-end derivation of representative image features that can impact a variety of image analysis problems. such supervised approaches, however, are difficult to implement in the medical domain where large volumes of labelled data are difficult to obtain due to the complexity of manual annotation and inter- and intra-observer variability in label assignment. we propose a new convolutional sparse kernel network (cskn), which is a hierarchical unsupervised feature learning framework that addresses the challenge of learning representative visual features in medical image analysis domains where there is a lack of annotated training data. our framework has three contributions: (i) we extend kernel learning to identify and represent invariant features across image sub-patches in an unsupervised manner. (ii) we initialise our kernel learning with a layer-wise pre-training scheme that leverages the sparsity inherent in medical images to extract initial discriminative features. (iii) we adapt a multi-scale spatial pyramid pooling (spp) framework to capture subtle geometric differences between learned visual features. we evaluated our framework in medical image retrieval and classification on three public datasets. our results show that our cskn had better accuracy when compared to other conventional unsupervised methods and comparable accuracy to methods that used state-of-the-art supervised convolutional neural networks (cnns). our findings indicate that our unsupervised cskn provides an opportunity to leverage unannotated big data in medical imaging repositories.","['unsupervised medical image analysis', 'convolutional sparse kernel network']"
"the multivariate nature of a fluidized bed system creates process complexity that increases the risk of production upset. this research explores the use of passive acoustic emissions monitoring paired with an artificial neural network to detect fluidized bed distributor plate blockage. in many cases, early process failure detection can allow for immediate intervention, thus lowering operation costs. blockages were simulated by actively covering portions of a top-spray fluidized bed distributor plate. piezoelectric microphones were placed within the fluidized bed exhaust and attached externally to the vessel wall. several time and frequency domain feature vectors were extracted from the monitoring data using the open source pyaudioanalysis library in python. through deep learning, the artificial neural network used these feature vectors to train against each distributor plate blockage condition. the deep learning model was then evaluated using k-fold cross validation. the findings were very positive and successfully demonstrated an application of deep learning to detect process upset.","['pharmaceutical manufacturing using passive acoustic emissions', 'detect process upset', 'deep learning', 'application']"
the detection of intestinal/rectal gas is very important during image-guided radiation therapy (igrt) of prostate cancer patients because intestinal/rectal gas increases the inter- and intra-fractional prostate motion. we propose a deep convolutional neural network (dcnn) to detect intestinal/rectal gas in the pelvic region.,"['guided radiation therapy using', 'deep convolutional neural network', 'prostate cancer patients', 'automatic gas detection', 'image']"
"artificial intelligence methods for the classification of melanoma have been studied extensively. however, few studies compare these methods under the same standards.","['artificial intelligence methods', 'retrospective review', 'melanoma', 'effectiveness', 'assessing']"
"this paper presents a method for automatic breast pectoral muscle segmentation in mediolateral oblique mammograms using a convolutional neural network (cnn) inspired by the holistically-nested edge detection (hed) network. most of the existing methods in the literature are based on hand-crafted models such as straight-line, curve-based techniques or a combination of both. unfortunately, such models are insufficient when dealing with complex shape variations of the pectoral muscle boundary and when the boundary is unclear due to overlapping breast tissue. to compensate for these issues, we propose a neural network framework that incorporates multi-scale and multi-level learning, capable of learning complex hierarchical features to resolve spatial ambiguity in estimating the pectoral muscle boundary. for this purpose, we modified the hed network architecture to specifically find 'contour-like' objects in mammograms. the proposed framework produced a probability map that can be used to estimate the initial pectoral muscle boundary. subsequently, we process these maps by extracting morphological properties to find the actual pectoral muscle boundary. finally, we developed two different post-processing steps to find the actual pectoral muscle boundary. quantitative evaluation results show that the proposed method is comparable with alternative state-of-the-art methods producing on average values of 94.8\u202f±\u202f8.5% and 97.5\u202f±\u202f6.3% for the jaccard and dice similarity metrics, respectively, across four different databases.","['nested edge detection network', 'breast pectoral muscle segmentation', 'modified holistically', 'mammograms using']"
"electrocardiography is the most common tool to diagnose cardiovascular diseases. annotation, segmentation and rhythm classification of ecgs are challenging tasks, especially in the presence of atrial fibrillation and other arrhythmias. our aim is to increase the accuracy of heart rhythm estimation by the use of extreme gradient boosting trees and the development of a deep convolutional neural network for ecg segmentation.","['convolutional neural network', 'ecg annotation', 'cardiac rhythms', 'classification', 'basis']"
"in a crowded harbor water area, it is a major concern to control ship traffic for assuring safety and maximizing the efficiency of port operations. vessel traffic service (vts) operators pay much attention to caution areas like ship route intersections or traffic congestion area in which there are some risks of ship collision. they want to control the traffic of the caution area at a proper level to lessen risk. inertial ship movement makes swift changes in direction and speed difficult. it is hence important to predict future traffic of the caution area earlier on so as to get enough time for control actions on ship movements. in the harbor area, vts stations collect a large volume of automatic identification service (ais) sensor data, which contain information about ship movement and ship attributes. this paper proposes a new deep neural network model called ship traffic extraction network (stenet) to predict the medium-term traffic and long-term traffic of the caution area. the stenet model is trained with ais sensor data. the stenet model is organized into a hierarchical architecture in which the outputs of the movement and contextual feature extraction modules are concatenated and fed into a prediction module. the movement module extracts the features of overall ship movements with a convolutional neural network. the contextual modules consist of five separated fully-connected neural networks, each of which receives an associated attribute. the separation of feature extraction modules at the front phase helps extract the effective features by preventing unrelated attributes from crosstalking. to evaluate the performance of the proposed model, the developed model is applied to a real ais sensor dataset, which has been collected over two years at a korean port called yeosu. in the experiments, four methods have been compared including two new methods: stenet and vggnet-based models. for the real ais sensor dataset, the proposed model has shown 50.65% relative performance improvement on average for the medium-term predictions and 57.65% improvement on average for the long-term predictions over the benchmark method, i.e., the svr-based method.","['based caution area traffic prediction', 'automatic identification system sensor data', 'deep learning']"
"recently there have been significant advances in the field of machine learning and artificial intelligence (ai) centered around imaging-based applications such as computer vision. in particular, the tremendous power of deep learning algorithms, primarily based on convolutional neural network strategies, is becoming increasingly apparent and has already had direct impact on the fields of radiology and nuclear medicine. while most early applications of computer vision to radiological imaging have focused on classification of images into disease categories, it is also possible to use these methods to improve image quality. hybrid imaging approaches, such as pet/mri and pet/ct, are ideal for applying these methods.","['ct imaging using deep learning', 'next generation research applications', 'hybrid pet', 'pet', 'mr']"
"chest digital tomosynthesis (cdt) provides more limited image information required for diagnosis when compared to computed tomography. moreover, the radiation dose received by patients is higher in cdt than in chest radiography. thus, cdt has not been actively used in clinical practice. to increase the usefulness of cdt, the radiation dose should reduce to the level used in chest radiography. given the trade-off between image quality and radiation dose in medical imaging, a strategy to generating high-quality images from limited data is need. we investigated a novel approach for acquiring low-dose cdt images based on learning-based algorithms, such as deep convolutional neural networks. we used both simulation and experimental imaging data and focused on restoring reconstructed images from sparse to full sampling data. we developed a deep learning model based on end-to-end image translation using u-net. we used 11 and 81 cdt reconstructed input and output images, respectively, to develop the model. to measure the radiation dose of the proposed method, we investigated effective doses using monte carlo simulations. the proposed deep learning model effectively restored images with degraded quality due to lack of sampling data. quantitative evaluation using structure similarity index measure (ssim) confirmed that ssim was increased by approximately 20% when using the proposed method. the effective dose required when using sparse sampling data was approximately 0.11\xa0msv, similar to that used in chest radiography (0.1\xa0msv) based on a report by the radiation society of north america. we investigated a new approach for reconstructing tomosynthesis images using sparse projection data. the model-based iterative reconstruction method has previously been used for conventional sparse sampling reconstruction. however, model-based computing requires high computational power, which limits fast three-dimensional image reconstruction and thus clinical applicability. we expect that the proposed learning-based reconstruction strategy will generate images with excellent quality quickly and thus have the potential for clinical use.","['dose chest digital tomosynthesis using deep convolutional neural networks', 'sparse data', 'full data', 'restoration', 'low']"
"atrophy of the deep gray matter (dgm) has been associated with a risk of conversion from mild cognitive impairment (mci) to alzheimer's disease (ad) and the degree of cognitive impairment. however, specific knowledge of the associations between degenerative dgm changes and neurocognitive functions remains limited.","['deep gray matter changes', 'based morphometric mri study', 'mild cognitive impairment', 'neurocognitive function', 'tensor', 'disease', 'association', 'alzheimer']"
"mental health issues are widely accepted as one of the most prominent health challenges in the world, with over 300 million people currently suffering from depression alone. with massive volumes of user-generated data on social networking platforms, researchers are increasingly using machine learning to determine whether this content can be used to detect mental health problems in users. this study aims to develop a deep learning model to classify users with depression via multiple instance learning, which can learn from user-level labels to identify post-level labels. by combining every possibility of posts label category, it can generate temporal posting profiles which can then be used to classify users with depression. this paper shows that there are clear differences in posting patterns between users with depression and non-depression, which is represented through the combined likelihood of posts label category.","['social network data', 'multiple instance learning', 'modeling depression symptoms']"
an amendment to this paper has been published and can be accessed via a link at the top of the paper.,"['dose chest computed tomography', 'end lung cancer screening', 'dimensional deep learning', 'author correction', 'end', 'three', 'low']"
"although deep-learning algorithms have been used to compute fractional flow reserve (ffr) from coronary computed tomography angiography (ccta), no study has achieved 'fully automated' (i.e. free from human input) ffr calculation using deep-learning algorithms. the purpose of the study was to evaluate the accuracy of a fully automated 3d deep-learning model for estimating minimum ffr from ccta data, with invasive ffr as the reference standard.","['level minimum fractional flow reserve', 'coronary computed tomography angiography', 'based fully automated estimation', 'diagnostic accuracy', '3d deep', 'patient', 'learning']"
"because of the limited reflected energy and incoming illumination in an individual band, the reflected energy captured by a hyperspectral sensor might be low and there is inevitable noise that significantly decreases the performance of the subsequent analysis. denoising is therefore of first importance in hyperspectral image (hsi) analysis and interpretation. however, most hsi denoising methods remove noise with the important spectral information being severely distorted. this paper presents an hsi denoising method using trainable spectral difference learning with spatial initialization (called hdntsdl) aimed at preserving the spectral information. in the proposed hdntsdl model, a key band is automatically selected and denoised. the denoised key band acts as a starting point to reconstruct the rest of the non-key bands. meanwhile, a deep convolutional neural network (cnn) with trainable non-linearity functions is proposed to learn the spectral difference mapping. then, the rest of the non-key bands are denoised under the guidance of the learned spectral difference with the key band as a starting point. experiments have been conducted on five databases with both indoor and outdoor scenes. comparative analyses validate that the proposed method: (i) presents superior performance in spatial recovery and spectral preservation, and (ii) requires less computational time than state-of-the-art methods.","['trainable spectral difference learning', 'hyperspectral image denoising', 'spatial starting']"
通过经阴道超声检查探测输尿管盆腔部位的学习曲线:可行性研究 目标: 调查需要经过多少次检查才能通过经阴道超声检查(tvs)识别出输尿管盆腔部位。 方法: 本研究是一项前瞻性调查，涉及在三级转诊背景下有女性患者连续不断就诊的一家妇科门诊。在本研究开始之前，以妇科手术和tvs为重点(但并无识别输尿管经验)的三名实习生，各自观摩了一位专家进行10次常规tvs检查，其中包括对双侧输尿管的识别。所有检查均为标准妇科tvs检查，包含双侧输尿管盆腔部位可视化。女性患者连续不断地接受检查，首先由专家检查，实习生在旁观摩，然后在专家面前，由三名实习生中的一名实施检查。为确保在三级转诊背景下将识别输尿管盆腔部位可行地纳入常规妇科tvs检查中，我们把150秒设定为成功识别每侧输尿管的时限。我们将一次成功的检查定义为在时限内识别出双侧输尿管。每名实习生检查女性患者的人数是根据实习生快速精通操作的程度来决定的，这个程度则是采用学习曲线累积合计(lc-cusum)评分进行评估的。 结果: 在2017年1月至6月之间，总共为该研究征募到140名女性，有135名患者被包含到最终分析中去。三名实习生能够在最多48次(范围为34-48次)tvs检查中识别出右侧输尿管，并在最多47次(范围为27-47次)tvs检查中识别出左侧输尿管。 结论: 熟悉妇科tvs的超声波检查医师和/或妇科医生应当能够在40-50次tvs检查后熟练识别双侧输尿管。探测输尿管是患者在前往三级转诊中心门诊接受tvs病情检查时切实可行的一部分。© 2019 作者。威利父子公司(john wiley & sons ltd)代表国际妇产科超声学会(isuog)出版《国际妇产超声杂志》(ultrasound in obstetrics & gynecology)。.,"['transvaginal sonography', 'pelvic parts', 'learning curve', 'feasibility study', 'ureters', 'detection']"
"protein nitration and nitrosylation are essential post-translational modifications (ptms) involved in many fundamental cellular processes. recent studies have revealed that excessive levels of nitration and nitrosylation in some critical proteins are linked to numerous chronic diseases. therefore, the identification of substrates that undergo such modifications in a site-specific manner is an important research topic in the community and will provide candidates for targeted therapy. in this study, we aimed to develop a computational tool for predicting nitration and nitrosylation sites in proteins. we first constructed four types of encoding features, including positional amino acid distributions, sequence contextual dependencies, physicochemical properties, and position-specific scoring features, to represent the modified residues. based on these encoding features, we established a predictor called deepnitro using deep learning methods for predicting protein nitration and nitrosylation. using n-fold cross-validation, our evaluation shows great auc values for deepnitro, 0.65 for tyrosine nitration, 0.80 for tryptophan nitration, and 0.70 for cysteine nitrosylation, respectively, demonstrating the robustness and reliability of our tool. also, when tested in the independent dataset, deepnitro is substantially superior to other similar tools with a 7%-42% improvement in the prediction performance. taken together, the application of deep learning method and novel encoding schemes, especially the position-specific scoring feature, greatly improves the accuracy of nitration and nitrosylation site prediction and may facilitate the prediction of other ptm sites. deepnitro is implemented in java and php and is freely available for academic research at http://deepnitro.renlab.org.","['protein nitration', 'nitrosylation sites', 'deep learning', 'prediction', 'deepnitro']"
"deep learning has recently gained more and more popularity, because of its high accuracy and wide range of coverage. in particular, deep learning is widely used in the medical field. because in the field of image classification and biological applications, the accuracy of deep learning is very high. unfortunately, even under the collaborative deep learning, there is still serious risk of information leakage. moreover, the risk of information leakage in the medical field is greater and the harm is even greater. for example, medical treatment data may be leaked to third-party organizations. when these important medical data is illegally used by for-profit organizations or obtained by criminals, it will not only lead to the disclosure of personal privacy information, but also cause serious economic losses to the victims. however, the victim cannot delete the leaked information by itself or limit the scope and use of the information that has been leaked. therefore, the adverse effects are unimaginable. this paper mainly studies the information protection methods under gan model attack, in order to find a better way to prevent attacks and effectively protect information.","['gan model attack', 'collaborative deep learning', 'information protection', 'method']"
"biomedical text mining is becoming increasingly important as the number of biomedical documents grow rapidly. deep learning has boosted the development of biomedical text mining models. however, as deep learning models require a large amount of training data, a hierarchical attention based transfer learning model is proposed in this paper for the question answering task in biomedical field which lacks of sufficient training data. we adopt bert (bidirectional encoder representation transformers), which has the ability to learn from large-scale unsupervised data, to enrich the semantic representation in our model. especially, the scaled dot-product attention mechanism captures the question interaction clues for passage encoding. the domain adaptation technique of fine-tuning is used to reinforce the performance, which penalizes the deviations from the source model's parameters and remembers the knowledge of source domain. we evaluate the system performance on the open data set of bioasq-task b. the results show that our system achieves the state-of-the-art performance without any handcrafted features and outperforms the best solution for factoid questions in 2016 and 2017 bioasq-task b.","['product attention based domain adaptation model', 'deep scaled dot', 'biomedical question answering']"
"there is currently significant interest in 3d fabrication in middle school classrooms. at its best 3d printing can be utilized in authentic design projects that integrate math, science, and technology, which facilitate deep learning by students. in essence, students are able to tinker in a virtual world using 3d design software and then tinker in the real world using printed parts. we describe a professional development activity we designed to enable middle school teachers who had taken part in a three-year math science partnership program to authentically integrate 3d printing into design-based lessons. we include some examples of successful design-based lesson plans.","['taking professional development', 'aligned lesson plans', 'based learning', 'authentic standards', '3d fabrication', '2d modeling', '3d', '2d', 'design']"
to explore a segmentation algorithm based on deep learning to achieve accurate diagnosis and treatment of patients with retinal fluid.,"['dimensional fully convolutional neural networks', 'optical coherence tomography images', 'retinal fluid based', 'deep learning', 'three', 'segmentation', 'application']"
"the objective of this study is to devise a modelling strategy for attaining in-silico models replicating human physiology and, in particular, the activity of the autonomic nervous system.","['silico models replicating human physiology', 'coupling discrete multiphysics', 'deep multiphysics', 'attain self', 'machine learning', 'learning']"
"face sketch synthesis is a crucial issue in digital entertainment and law enforcement. it can bridge the considerable texture discrepancy between face photos and sketches. most of the current face sketch synthesis approaches directly to learn the relationship between the photos and sketches, and it is very difficult for them to generate the individual specific features, which we call rare characteristics. in this paper, we propose a novel face sketch synthesis approach through residual learning. in contrast to traditional approaches, which aim to reconstruct a sketch image directly (i.e., learn the mapping relationship between the photo and sketch), we aim to predict the residual image by learning the mapping relationship between the photo and residual, i.e., the difference between the photo and sketch, given an observed photo. this technique will render optimizing the residual mapping easier than optimizing the original mapping and deriving rare characteristic information. we also introduce a joint dictionary learning algorithm by preserving the local geometry structure of a data space. through the learned joint dictionary, we transform the face sketch synthesis from an image space to a new and compact space; the new and compact space is spanned by learned dictionary atoms, where the manifold assumption can be further guaranteed. results show that the proposed method demonstrates an impressive performance in the face sketch synthesis task on three public face sketch datasets and various real-world photos. these results are derived by comparing the proposed method with several state-of-the-art techniques, including certain recently proposed deep learning-based approaches.","['face sketch synthesis', 'constrained joint dictionary', 'residual learning', 'regularized locality', 'graph']"
to test the diagnostic performance of a deep learning-based system for the detection of clinically significant pulmonary nodules/masses on chest radiographs.,"['chest radiography using deep learning', 'improve clinical practice', 'identifying pulmonary nodules', 'external validation', 'strategies', 'masses']"
"portable box volume measurement has always been a popular issue in the intelligent logistic industry. this work presents a portable system for box volume measurement that is based on line-structured light vision and deep learning. this system consists of a novel 2 × 2 laser line grid projector, a sensor, and software modules, with which only two laser-modulated images of boxes are required for volume measurement. for laser-modulated images, a novel end-to-end deep learning model is proposed by using an improved holistically nested edge detection network to extract edges. furthermore, an automatic one-step calibration method for the line-structured light projector is designed for fast calibration. the experimental results show that the measuring range of our proposed system is 100-1800 mm, with errors less than ±5.0 mm. theoretical analysis indicates that within the measuring range of the system, the measurement uncertainty of the measuring device is ±0.52 mm to ±4.0 mm, which is consistent with the experimental results. the device size is 140 mm × 35 mm × 35 mm and the weight is 110 g, thus the system is suitable for portable automatic box volume measurement.","['box volume measurement based', 'structured light vision', 'portable system', 'deep learning', 'line']"
"many neuroscience faculty assign readings from the textbook or primary literature to their students. what can we learn from research about how many of the students actually ""do"" the reading and, of those who do it, comprehend what they read? this article presents findings from studies on college student compliance with and comprehension of assigned readings and offers research-based strategies for motivating students to complete the readings in ways that promote deep learning. faculty are encouraged not only to ask about the role that reading plays in undergraduate learning, but also the role that they themselves play in developing college student reading proficiencies.","['neuroscience instructors', 'reading compliance', 'reading', 'know', 'comprehension', 'college']"
"we consider learning from comparison labels generated as follows: given two samples in a dataset, a labeler produces a label indicating their relative order. such comparison labels scale quadratically with the dataset size; most importantly, in practice, they often exhibit lower variance compared to class labels. we propose a new neural network architecture based on siamese networks to incorporate both class and comparison labels in the same training pipeline, using bradley-terry and thurstone loss functions. our architecture leads to a significant improvement in predicting both class and comparison labels, increasing classification auc by as much as 35% and comparison auc by as much as 6% on several real-life datasets. we further show that, by incorporating comparisons, training from few samples becomes possible: a deep neural network of 5.9 million parameters trained on 80 images attains a 0.92 auc when incorporating comparisons.","['comparison via neural networks', 'classification']"
"the electrocardiogram is the most widely used diagnostic tool that records the electrical activity of the heart and, therefore, its use for identifying markers for early diagnosis and detection is of paramount importance. in the last years, the huge increase of electronic health records containing a systematised collection of different type of digitalised medical data, together with new tools to analyse this large amount of data in an efficient way have re-emerged the field of machine learning in healthcare innovation. this review describes the most recent machine learning-based systems applied to the electrocardiogram as well as pros and cons in the use of these techniques. machine learning, including deep learning, have shown to be powerful tools for aiding clinicians in patient screening and risk stratification tasks. however, they do not provide the physiological basis of classification outcomes. computational modelling and simulation can help in the interpretation and understanding of key physiologically meaningful ecg biomarkers extracted from machine learning techniques.","['machine learning', 'electrocardiogram']"
"survival analyses of populations and the establishment of prognoses for individual patients are important activities in the practice of medicine. standard survival models, such as the cox proportional hazards model, require extensive feature engineering or prior knowledge to model at an individual level. some survival analysis models can avoid these problems by using machine learning extended the cph model, and higher performance has been reported. in this paper, we propose an innovative loss function that is defined as the sum of an extended mean squared error loss and a pairwise ranking loss based on ranking information on survival data. we apply this loss function to optimize a deep feed-forward neural network (rankdeepsurv), which can be used to model survival data. we demonstrate that the performance of our model, rankdeepsurv, is superior to that of other state-of-the-art survival models based on an analysis of 4 public medical clinical datasets. when modelling the prognosis of nasopharyngeal carcinoma (npc), rankdeepsurv achieved better prognostic accuracy than the cph established by clinical experts. the difference between high and low risk groups in the rankdeepsurv model is greater than the difference in the cph. the results show that our method has considerable potential to model survival data in medical settings.","['deep survival analysis method based', 'ranking']"
现有的心律失常分类方法通常采用人为选取心电图（ecg）信号特征的方式，其特征选取具有主观性，且特征提取复杂，导致分类准确性容易受到影响等。基于以上问题，本文提出了一种基于判别式深度置信网络（ddbns）的心律失常自动分类新方法。该方法所构建的生成受限玻尔兹曼机（grbm）自动提取心拍信号形态特征，然后引入具有特征学习和分类能力的判别式受限玻尔兹曼机（drbm），依据提取的形态特征和 rr 间期特征进行心律失常分类。为了进一步提高 ddbns 的分类性能，本文将 ddbns 转换为使用柔性最大值（softmax）回归层进行监督分类的深度神经网络（dnn），通过反向传播对网络进行微调。最后，采用麻省理工学院与贝斯以色列医院心律失常数据库（mit-bih ar）进行实验验证，对于数据来源一致的训练集和测试集，该方法整体分类精度可达 99.84% ± 0.04%；对于数据来源非一致的训练集和测试集，通过主动学习（al）方法扩充少量训练集，该方法整体分类精度可达 99.31% ± 0.23%。实验结果表明了该方法在心律失常自动特征提取和分类上的有效性，为深度学习自动提取 ecg 信号特征及分类提供了一种新的解决方法。.,"['discriminative deep belief networks ].', 'automatic classification method', 'arrhythmia based']"
"manual annotation is considered to be the ""gold standard"" in medical imaging analysis. however, medical imaging datasets that include expert manual segmentation are scarce as this step is time-consuming, and therefore expensive. moreover, single-rater manual annotation is most often used in data-driven approaches making the network biased to only that single expert. in this work, we propose a cnn for brain extraction in magnetic resonance (mr) imaging, that is fully trained with what we refer to as ""silver standard"" masks. therefore, eliminating the cost associated with manual annotation. silver standard masks are generated by forming the consensus from a set of eight, public, non-deep-learning-based brain extraction methods using the simultaneous truth and performance level estimation (staple) algorithm. our method consists of (1) developing a dataset with ""silver standard"" masks as input, and implementing (2) a tri-planar method using parallel 2d u-net-based convolutional neural networks (cnns) (referred to as consnet). this term refers to our integrated approach, i.e., training with silver standard masks and using a 2d u-net-based architecture. we conducted our analysis using three public datasets: the calgary-campinas-359 (cc-359), the loni probabilistic brain atlas (lpba40), and the open access series of imaging studies (oasis). five performance metrics were used in our experiments: dice coefficient, sensitivity, specificity, hausdorff distance, and symmetric surface-to-surface mean distance. our results showed that we outperformed (i.e., larger dice coefficients) the current state-of-the-art skull-stripping methods without using gold standard annotation for the cnns training stage. consnet is the first deep learning approach that is fully trained using silver standard data and is, thus, more generalizable. using these masks, we eliminate the cost of manual annotation, decreased inter-/intra-rater variability, and avoided cnn segmentation overfitting towards one specific manual annotation guideline that can occur when gold standard masks are used. moreover, once trained, our method takes few seconds to process a typical brain image volume using modern a high-end gpu. in contrast, many of the other competitive methods have processing times in the order of minutes.","['brain mr imaging using silver standard masks', 'convolutional neural networks', 'stripping', 'skull']"
multiple layers of genetic and epigenetic variability are being simultaneously explored in an increasing number of health studies. we summarize here different approaches applied in the data mining and machine learning group at the gaw20 to integrate genome-wide genotype and methylation array data.,"['machine learning approaches', 'wide association', 'methylation data', 'main conclusions', 'data mining', 'methodology', 'integration', 'genome', 'gaw20']"
"determining how ant colonies optimize foraging while mitigating pathogen and predator risks provides insight into how the ants have achieved ecological success. ants must respond to changing resource conditions, but exploration comes at a cost of higher potential exposure to threats. fungal infected cadavers surround the main foraging trails of the carpenter ant camponotus rufipes, offering a system to study how foragers behave given the persistent occurrence of disease threats. studies on social insect foraging behavior typically require many hours of human labor due to the high density of individuals. to overcome this, we developed deep learning based computer vision algorithms to track foraging ants, frame-by-frame, from video footage shot under the natural conditions of a tropical forest floor at night. we found that most foragers walk in straight lines overlapping the same areas as other ants, but there is a subset of foragers with greater exploration. consistency in walking behavior may protect most ants from infection, while foragers that explore unique portions of the trail may be more likely to encounter fungal spores implying a trade-off between resource discovery and risk avoidance.","['ant trajectories shows variation', 'forager exploration', 'automated tracking', 'analysis']"
"domain adaptation aims to leverage knowledge from a well-labeled source domain to a poorly labeled target domain. a majority of existing works transfer the knowledge at either feature level or sample level. recent studies reveal that both of the paradigms are essentially important, and optimizing one of them can reinforce the other. inspired by this, we propose a novel approach to jointly exploit feature adaptation with distribution matching and sample adaptation with landmark selection. during the knowledge transfer, we also take the local consistency between the samples into consideration so that the manifold structures of samples can be preserved. at last, we deploy label propagation to predict the categories of new instances. notably, our approach is suitable for both homogeneous- and heterogeneous-domain adaptations by learning domain-specific projections. extensive experiments on five open benchmarks, which consist of both standard and large-scale datasets, verify that our approach can significantly outperform not only conventional approaches but also end-to-end deep models. the experiments also demonstrate that we can leverage handcrafted features to promote the accuracy on deep features by heterogeneous adaptation.","['locality preserving joint transfer', 'domain adaptation']"
"several recent studies showed that the application of deep neural networks advanced the state-of-the-art in named entity recognition (ner), including biomedical ner. however, the impact on performance and the robustness of improvements crucially depends on the availability of sufficiently large training corpora, which is a problem in the biomedical domain with its often rather small gold standard corpora.","['improving biomedical ner', 'pretraining', 'huner']"
"in multi-label text classification, each textual document is assigned 1 or more labels. as an important task that has broad applications in biomedicine, a number of different computational methods have been proposed. many of these methods, however, have only modest accuracy or efficiency and limited success in practical use. we propose ml-net, a novel end-to-end deep learning framework, for multi-label classification of biomedical texts.","['deep neural networks', 'label classification', 'biomedical texts', 'net', 'multi', 'ml']"
"most deep learning (dl) studies have focused on neoplastic pathology, with the realm of inflammatory pathology remaining largely untouched.","['deep learning convolutional neural network', 'recognize common patterns', 'gastric pathology', 'injury']"
"in this paper, we propose a learning-based depth estimation framework suitable for both densely and sparsely sampled light fields. the proposed framework consists of three processing steps: initial depth estimation, fusion with occlusion handling, and refinement. the estimation can be performed from a flexible subset of input views. the fusion of initial disparity estimates, relying on two warping error measures, allows us to have an accurate estimation in occluded regions and along the contours. in contrast with methods relying on the computation of cost volumes, the proposed approach does not need any prior information on the disparity range. experimental results show that the proposed method outperforms state-of-the-art light fields depth estimation methods, including prior methods based on deep neural architectures.","['sparse light field views', 'learning depth', 'flexible subset', 'framework', 'dense']"
"atmospheric chemical transport models (ctms) have been widely used to simulate spatiotemporally resolved pm2.5 concentrations. however, ctm results are usually prone to bias and errors. in this study, we improved the accuracy of pm2.5 predictions by developing an ensemble deep learning framework to fuse model simulations with ground-level observations. the framework encompasses four machine-learning models, i.e., general linear model, fully connected neural network, random forest, and gradient boosting machine, and combines them by stacking approach. this framework is applied to pm2.5 concentrations simulated by the community multiscale air quality (cmaq) model for china from 2014 to 2017, which has complete spatial coverage over the entirety of china at a 12-km resolution, with no sampling biases. the fused pm2.5 concentration fields were evaluated by comparing with an independent network of observations. the r2 values increased from 0.39 to 0.64, and the rmse values decreased from 33.7 μg/m3 to 24.8 μg/m3. according to the fused data, the percentage of chinese population residing under the level ii national ambient air quality standards of 35 μg/m3 for pm2.5 has increased from 46.5% in 2014 to 61.7% in 2017. the method is readily adapted to utilize near-real-time observations for operational analyses and forecasting of pollutant concentrations and can be extended to provide source apportionment forecasts as well.","['chemical transport model predictions using', 'fusion method combining ground', 'ensemble deep learning framework', '5 exposure fields', 'resolved pm2', 'level observations', 'estimate spatiotemporally', 'china', 'application', '2017', '2014']"
"we believe junior doctors are in a unique position in relation to reporting of incidents and safety culture. they are still in training and are also 'fresh eyes' on the system providing valuable insights into what they perceive as safe and unsafe behaviour. the aim of this study was to co-design and implement an embedded learning intervention - a serious board game - to educate junior doctors about patient safety and the importance of reporting safety concerns, while at the same time shaping a culture of responsiveness from senior medical staff.","['serious board game', 'educate junior doctors', 'reporting safety concerns', 'playdecide patient safety', 'patient safety', 'importance', 'implementation', 'evaluation', 'design', 'co']"
"this paper proposes a sinogram-consistency learning method to deal with beam hardening-related artifacts in polychromatic computerized tomography (ct). the presence of highly attenuating materials in the scan field causes an inconsistent sinogram that does not match the range space of the radon transform. when the mismatched data are entered into the range space during ct reconstruction, streaking and shading artifacts are generated owing to the inherent nature of the inverse radon transform methods: the proposed learning method aims to repair inconsistent sinogram by removing the primary metal-induced beam hardening factors along the metal trace in the sinogram. taking account of the fundamental difficulty in obtaining sufficient training data in a medical environment, the learning method is designed to use simulated training data and a patient's implant type-specific learning model is used to simplify the learning process.","['induced beam hardening correction', 'ct sinogram', 'consistency learning', 'metal']"
"to compare results for radiological prediction of pathological invasiveness in lung adenocarcinoma between radiologists and a deep learning (dl) system.ninety patients (50 men, 40 women; mean age, 66 years; range, 40-88 years) who underwent pre-operative chest computed tomography (ct) with 0.625-mm slice thickness were included in this retrospective study. twenty-four cases of adenocarcinoma in situ (ais), 20 cases of minimally invasive adenocarcinoma (mia), and 46 cases of invasive adenocarcinoma (iva) were pathologically diagnosed. three radiologists of different levels of experience diagnosed each nodule by using previously documented ct findings to predict pathological invasiveness. dl was structured using a 3-dimensional (3d) convolutional neural network (3d-cnn) constructed with 2 successive pairs of convolution and max-pooling layers, and 2 fully connected layers. the output layer comprises 3 nodes to recognize the 3 conditions of adenocarcinoma (ais, mia, and iva) or 2 nodes for 2 conditions (ais and mia/iva). results from dl and the 3 radiologists were statistically compared.no significant differences in pathological diagnostic accuracy rates were seen between dl and the 3 radiologists (p\u200a>.11). receiver operating characteristic analysis demonstrated that area under the curve for dl (0.712) was almost the same as that for the radiologist with extensive experience (0.714; p\u200a=\u200a.98). compared with the consensus results from radiologists, dl offered significantly inferior sensitivity (p\u200a=\u200a.0005), but significantly superior specificity (p\u200a=\u200a.02).despite the small training data set, diagnostic performance of dl was almost the same as the radiologist with extensive experience. in particular, dl provided higher specificity than radiologists.","['dimensional convolutional neural networ', 'deep learning', 'application', '3']"
"age-related macular degeneration (amd) is a leading cause of blindness. although the age-related eye disease study group previously developed a 9-step amd severity scale for manual classification of amd severity from color fundus images, manual grading of images is time-consuming and expensive. built on our previous work deepseenet, we developed a novel deep learning model for automated classification of images into the 9-step scale. instead of predicting the 9-step score directly, our approach simulates the reading center grading process. it first detects four amd characteristics (drusen area, geographic atrophy, increased pigment, and depigmentation), then combines these to derive the overall 9-step score. importantly, we applied multi-task learning techniques, which allowed us to train classification of the four characteristics in parallel, share representation, and prevent overfitting. evaluation on two image datasets showed that the accuracy of the model exceeded the current state-of-the-art model by > 10%. availability: https://github.com/ncbi-nlp/deepseenet.","['task deep learning model', 'related macular degeneration', 'multi', 'classification', 'age']"
"artificial intelligence (ai) in medicine is a fast-growing field. the rise of deep learning algorithms, such as convolutional neural networks (cnns), offers fascinating perspectives for the automation of medical image analysis. in this systematic review article, we screened the current literature and investigated the following question: ""can deep learning algorithms for image recognition improve visual diagnosis in medicine?""","['medical image analysis', 'third eye', 'deep learning', 'doctors']"
"identification of nodal metastasis and tumor extranodal extension (ene) is crucial for head and neck cancer management, but currently only can be diagnosed via postoperative pathology. pretreatment, radiographic identification of ene, in particular, has proven extremely difficult for clinicians, but would be greatly influential in guiding patient management. here, we show that a deep learning convolutional neural network can be trained to identify nodal metastasis and ene with excellent performance that surpasses what human clinicians have historically achieved. we trained a 3-dimensional convolutional neural network using a dataset of 2,875 ct-segmented lymph node samples with correlating pathology labels, cross-validated and fine-tuned on 124 samples, and conducted testing on a blinded test set of 131 samples. on the blinded test set, the model predicted ene and nodal metastasis each with area under the receiver operating characteristic curve (auc) of 0.91 (95%ci: 0.85-0.97). the model has the potential for use as a clinical decision-making tool to help guide head and neck cancer patient management.","['extranodal extension using deep learning neural networks', 'neck cancer nodal metastasis', 'pretreatment identification', 'head']"
"the bidirectional encoder representations from transformers (bert) model has achieved great success in many natural language processing (nlp) tasks, such as named entity recognition and question answering. however, little prior work has explored this model to be used for an important task in the biomedical and clinical domains, namely entity normalization.","['tuning bidirectional encoder representations', 'transformers', 'fine', 'ber']"
"we report a deep learning-enabled field-portable and cost-effective imaging flow cytometer that automatically captures phase-contrast color images of the contents of a continuously flowing water sample at a throughput of 100\u2009ml/h. the device is based on partially coherent lens-free holographic microscopy and acquires the diffraction patterns of flowing micro-objects inside a microfluidic channel. these holographic diffraction patterns are reconstructed in real time using a deep learning-based phase-recovery and image-reconstruction method to produce a color image of each micro-object without the use of external labeling. motion blur is eliminated by simultaneously illuminating the sample with red, green, and blue light-emitting diodes that are pulsed. operated by a laptop computer, this portable device measures 15.5\u2009cm\u2009×\u200915\u2009cm\u2009×\u200912.5\u2009cm, weighs 1\u2009kg, and compared to standard imaging flow cytometers, it provides extreme reductions of cost, size and weight while also providing a high volumetric throughput over a large object size range. we demonstrated the capabilities of this device by measuring ocean samples at the los angeles coastline and obtaining images of its micro- and nanoplankton composition. furthermore, we measured the concentration of a potentially toxic alga (pseudo-nitzschia) in six public beaches in los angeles and achieved good agreement with measurements conducted by the california department of public health. the cost-effectiveness, compactness, and simplicity of this computational platform might lead to the creation of a network of imaging flow cytometers for large-scale and continuous monitoring of the ocean microbiome, including its plankton composition.","['enabled portable imaging flow cytometer', 'natural water samples', 'free analysis', 'deep learning', 'throughput', 'label', 'high', 'effective', 'cost']"
"with the development of theories and technologies in medical imaging, most of the tumors can be detected in the early stage. however, the nature of ovarian cysts lacks accurate judgement, leading to that many patients with benign nodules still need fine needle aspiration (fna) biopsies or surgeries, increasing the physical pain and mental pressure of patients as well as unnecessary medical health care costs. therefore, we present an image diagnosis system for classifying the ovarian cysts in color ultrasound images, which novelly applies the image features fused by both high-level features from deep learning network and low-level features from texture descriptor. firstly, the ultrasound images are enhanced to improve the quality of training data set and the rotation invariant uniform local binary pattern (ulbp) features are extracted from each of the images as the low-level texture features. then the high-level deep features extracted by the fine-tuned googlenet neural network and the low-level ulbp features are normalized and cascaded as one fusion feature that can represent both the semantic context and the texture patterns distributed in the image. finally, the fusion features are input to the cost-sensitive random forest classifier to classify the images into ""malignant"" and ""benign"". the high-level features extracted by the deep neural network from the medical ultrasound image can reflect the visual features of the lesion region, while the low-level texture features can describe the edges, direction and distribution of intensities. experimental results indicate that the combination of the two types of features can describe the differences between the lesion regions and other regions, and the differences between lesions regions of malignant and benign ovarian cysts.","['improved deep learning network based', 'color ultrasound detecting system', 'sensitive learning', 'ovarian cancer', 'early detection', 'cost', 'combination']"
"in research on co-creation in nursing, a caring manner can be used to create opportunities for the patient to reach vital goals and thereby increase the patient's quality of life in palliative home care. this can be described as an ethical cornerstone and the goal of palliative care. nurses must be extra sensitive to patients' and their relatives' needs with regard to ethical and existential issues and situations in home care encounters, especially at the end of life.","['existential issues', 'life', 'ethical', 'end', 'dealing', 'creation', 'co']"
"the present study used a deep learning model (recurrent neural network) for testing: (i) whether social determinants are major determinants of the association among cerebrovascular disease, hearing loss and cognitive impairment in a middle-aged or older population (hypothesis\u20091); and (ii) whether the association among the three diseases is very strong in the middle-aged or older population (hypothesis\u20092).","['recurrent neural network analysis', 'association among cerebrovascular disease', 'korean longitudinal study', 'social determinants', 'older population', 'hearing loss', 'cognitive impairment', 'middle', 'aging', 'aged', '2014', '201']"
"a great diversity of factors contribute to the pathogenesis of autism and autism spectrum disorder (asd). early detection is known to correlate with improved long term outcomes. there is therefore intense scientific interest in the pathogenesis of and early prediction of autism. recent reports suggest that epigenetic alterations may play a vital role in disease pathophysiology. we conducted an epigenome-wide analysis of newborn leucocyte (blood spot) dna in autism as defined at the time of sample collection. our goal was to investigate the epigenetic basis of autism and identification of early biomarkers for disease prediction. infinium humanmethylation450 beadchip assay was performed to measure dna methylation level in 14 autism cases and 10 controls. the accuracy of cytosine methylation for autism detection using six different machine learning/artificial intelligence (ai) approaches including deep-learning (dl) was determined. ingenuity pathway analysis (ipa) was further used to interrogate autism pathogenesis by identifying over-represented biological pathways. we found highly significant dysregulation of cpg methylation in 230 loci (249 genes). dl yielded an auc (95% ci)\u202f=\u202f1.00 (0.80-1.00) with 97.5% sensitivity and 100.0% specificity for autism detection. epigenetic dysregulation was identified in several important candidate genes including some previously linked to autism development e.g.: eif4e, fyn, shank1, vim, lmx1b, gabrb1, sdhap3 and pacs2. we observed significant enrichment of molecular pathways involved in neuroinflammation signaling, synaptic long term potentiation, serotonin degradation, mtor signaling and signaling by rho-family gtpases. our findings suggest significant epigenetic role in autism development and epigenetic markers appeared highly accurate for newborn prediction.","['newborn leucocyte epigenomic markers', 'artificial intelligence analysis', 'prediction', 'autism']"
"accurate diagnosis of thyroid nodules using ultrasonography is a valuable but tough task even for experienced radiologists, considering both benign and malignant nodules have heterogeneous appearances. computer-aided diagnosis (cad) methods could potentially provide objective suggestions to assist radiologists. however, the performance of existing learning-based approaches is still limited, for direct application of general learning models often ignores critical domain knowledge related to the specific nodule diagnosis. in this study, we propose a novel deep-learning-based cad system, guided by task-specific prior knowledge, for automated nodule detection and classification in ultrasound images. our proposed cad system consists of two stages. first, a multi-scale region-based detection network is designed to learn pyramidal features for detecting nodules at different feature scales. the region proposals are constrained by the prior knowledge about size and shape distributions of real nodules. then, a multi-branch classification network is proposed to integrate multi-view diagnosis-oriented features, in which each network branch captures and enhances one specific group of characteristics that were generally used by radiologists. we evaluated and compared our method with the state-of-the-art cad methods and experienced radiologists on two datasets, i.e. dataset i and dataset ii. the detection and diagnostic accuracy on dataset i were 97.5% and 97.1%, respectively. besides, our cad system also achieved better performance than experienced radiologists on dataset ii, with improvements of accuracy for 8%. the experimental results demonstrate that our proposed method is effective in the discrimination of thyroid nodules.","['ultrasound images using clinical', 'guided convolutional neural networks', 'thyroid nodules', 'automated detection', 'knowledge', 'classification']"
dual-energy computed tomography (dect) has been widely used due to improved substances identification from additional spectral information. the quality of material-specific image produced by dect attaches great importance to the elaborated design of the basis material decomposition method.,"['energy computed tomography via fully convolutional network', 'image decomposition algorithm', 'dual']"
"predicting where people look in static scenes, a.k.a visual saliency, has received significant research interests recently. however, relatively less effort has been spent in understanding visual attention over dynamic scenes. this work makes three contributions to video saliency research. first, we introduce a new benchmark, called dhf1k, for predicting fixations during dynamic scene free-viewing, which is a long-time need in this field. dhf1k consists of 1k high-quality, elaborately selected videos annotated by 17 observers using an eye tracker. the videos span a wide range of scenes, motions, object types and backgrounds. second, we propose a novel video saliency model, called aclnet, that augments the cnn-lstm network with a supervised attention mechanism to enable fast end-to-end learning. the attention mechanism explicitly encodes static saliency information, thus allowing lstm to focus on learning a more flexible temporal saliency representation. such a design leverages existing large-scale static fixation datasets, avoids overfitting, and significantly improves training efficiency and testing performance. third, we perform an extensive evaluation of state-of-the-art saliency models on three current datasets (i.e., dhf1k, hollywood2, ucf sports). experimental results over more than 1.2k testing videos containing 400k frames demonstrate that aclnet outperforms other contenders and has a fast processing speed (40fps).","['revisiting video saliency prediction', 'deep learning era']"
"in precision medicine, deep phenotyping is defined as the precise and comprehensive analysis of phenotypic abnormalities, aiming to acquire a better understanding of the natural history of a disease and its genotype-phenotype associations. detecting phenotypic relevance is an important task when translating precision medicine into clinical practice, especially for patient stratification tasks based on deep phenotyping. in our previous work, we developed node embeddings for the human phenotype ontology (hpo) to assist in phenotypic relevance measurement incorporating distributed semantic representations. however, the derived hpo embeddings hold only distributed representations for is-a relationships among nodes, hampering the ability to fully explore the graph.","['hpo2vec +: leveraging heterogeneous knowledge resources', 'human phenotype ontology', 'enrich node embeddings']"
"in recent studies, convolutional neural networks (cnns) outperformed dermatologists in distinguishing dermoscopic images of melanoma and nevi. in these studies, dermatologists and artificial intelligence were considered as opponents. however, the combination of classifiers frequently yields superior results, both in machine learning and among humans. in this study, we investigated the potential benefit of combining human and artificial intelligence for skin cancer classification.","['superior skin cancer classification', 'artificial intelligence', 'human', 'combination']"
"the biocreative vi track iv (mining protein interactions and mutations for precision medicine) challenge was organized in 2017 with the goal of applying biomedical text mining methods to support advancements in precision medicine approaches. as part of the challenge, a new dataset was introduced for the purpose of building a supervised relation extraction model capable of taking a test article and returning a list of interacting protein pairs identified by their entrez gene ids. specifically, such pairs represent proteins participating in a binary protein-protein interaction relation where the interaction is additionally affected by a genetic mutation-referred to as a ppim relation. in this study, we explore an end-to-end approach for ppim relation extraction by deploying a three-component pipeline involving deep learning-based named-entity recognition and relation classification models along with a knowledge-based approach for gene normalization. we propose several recall-focused improvements to our original challenge entry that placed second when matching on entrez gene id (exact matching) and on homologene id. on exact matching, the improved system achieved new competitive test results of 37.78% micro-f1 with a precision of 38.22% and recall of 37.34% that corresponds to an improvement from the prior best system by approximately three micro-f1 points. when matching on homologene ids, we report similarly competitive test results at 46.17% micro-f1 with a precision and recall of 46.67 and 45.59%, respectively, corresponding to an improvement of more than eight micro-f1 points over the prior best result. the code for our deep learning system is made publicly available at https://github.com/bionlproc/biocppi_extraction.","['end deep learning architecture', 'protein interactions affected', 'extracting protein', 'genetic mutations', 'end']"
"there is a clinical need to assess the resection margins of tongue cancer specimens, intraoperatively. in the current ex vivo study, we evaluated the feasibility of hyperspectral diffuse reflectance imaging (hsi) for distinguishing tumor from the healthy tongue tissue.","['resection margins using hyperspectral diffuse reflection imaging', 'toward assessment', 'u2009n', '700', '400', '1']"
"cellular processes are governed by macromolecular complexes inside the cell. study of the native structures of macromolecular complexes has been extremely difficult due to lack of data. with recent breakthroughs in cellular electron cryo-tomography (cect) 3d imaging technology, it is now possible for researchers to gain accesses to fully study and understand the macro-molecular structures single cells. however, systematic recovery of macromolecular structures from cect is very difficult due to high degree of structural complexity and practical imaging limitations. specifically, we proposed a deep learning-based image classification approach for large-scale systematic macromolecular structure separation from cect data. however, our previous work was only a very initial step toward exploration of the full potential of deep learning-based macromolecule separation. in this paper, we focus on improving classification performance by proposing three newly designed individual cnn models: an extended version of (deep small receptive field) dsrf3d, donated as dsrf3d-v2, a 3d residual block-based neural network, named as rb3d, and a convolutional 3d (c3d)-based model, cb3d. we compare them with our previously developed model (dsrf3d) on 12 datasets with different snrs and tilt angle ranges. the experiments show that our new models achieved significantly higher classification accuracies. the accuracies are not only higher than 0.9 on normal datasets, but also demonstrate potentials to operate on datasets with high levels of noises and missing wedge effects presented.","['based macromolecules structure classification', 'improved deep learning', 'electron cryo', 'tomograms']"
"one of the largest factors affecting disease recurrence after surgical cancer resection is negative surgical margins. hyperspectral imaging (hsi) is an optical imaging technique with potential to serve as a computer aided diagnostic tool for identifying cancer in gross ex-vivo specimens. we developed a tissue classifier using three distinct convolutional neural network (cnn) architectures on hsi data to investigate the ability to classify the cancer margins from ex-vivo human surgical specimens, collected from 20 patients undergoing surgical cancer resection as a preliminary validation group. a new approach for generating the hsi ground truth using a registered histological cancer margin is applied in order to create a validation dataset. the cnn-based method classifies the tumor-normal margin of squamous cell carcinoma (scca) versus normal oral tissue with an area under the curve (auc) of 0.86 for inter-patient validation, performing with 81% accuracy, 84% sensitivity, and 77% specificity. thyroid carcinoma cancer-normal margins are classified with an auc of 0.94 for inter-patient validation, performing with 90% accuracy, 91% sensitivity, and 88% specificity. our preliminary results on a limited patient dataset demonstrate the predictive ability of hsi-based cancer margin detection, which warrants further investigation with more patient data and additional processing techniques to optimize the proposed deep learning method.","['neck cancer using hyperspectral imaging', 'tumor margin classification', 'convolutional neural networks', 'head']"
"in online health expert question-answering (hqa) services, it is significant to automatically determine the quality of the answers. there are two prominent challenges in this task. first, the answers are usually written in short text, which makes it difficult to absorb the text semantic information. second, it usually lacks sufficient labeled data but contains a huge amount of unlabeled data. to tackle these challenges, we propose a novel deep co-training framework based on factorization machines (fm) and deep textual views to intelligently and automatically identify the quality of hqa systems. more specifically, we exploit additional domain-specific semantic information from domain-specific word embeddings to expand the semantic space of short text and apply fm to excavate the non-independent interaction relationships among diverse features within individual views for improving the performance of the base classifier via co-training. our learned deep textual views, the convolutional neural networks (cnn) view which focuses on extracting local features using convolution filters to locally model short text and the dependency-sensitive convolutional neural networks (dscnn) view which focuses on capturing long-distance dependency information within the text to globally model short text, can then overcome the challenge of feature sparseness in the short text answers from the doctors. the developed co-training framework can effectively mine the highly non-linear semantic information embedded in the unlabeled data and expose the highly non-linear relationships between different views, which minimizes the labeling effort. finally, we conduct extensive empirical evaluations and demonstrate that our proposed method can significantly improve the predictive performance of the answer quality in the context of hqa services.","['online health expert question', 'improving answer quality prediction', 'factorization machines', 'deep views', 'based co', 'answering services', 'training']"
"magnetic resonance (mr) images with both high resolutions and high signal-to-noise ratios (snrs) are desired in many clinical and research applications. however, acquiring such images takes a long time, which is both costly and susceptible to motion artifacts. acquiring mr images with good in-plane resolution and poor through-plane resolution is a common strategy that saves imaging time, preserves snr, and provides one viewpoint with good resolution in two directions. unfortunately, this strategy also creates orthogonal viewpoints that have poor resolution in one direction and, for 2d mr acquisition protocols, also creates aliasing artifacts. a deep learning approach called smore that carries out both anti-aliasing and super-resolution on these types of acquisitions using no external atlas or exemplars has been previously reported but not extensively validated. this paper reviews the smore algorithm and then demonstrates its performance in four applications with the goal to demonstrate its potential for use in both research and clinical scenarios. it is first shown to improve the visualization of brain white matter lesions in flair images acquired from multiple sclerosis patients. then it is shown to improve the visualization of scarring in cardiac left ventricular remodeling after myocardial infarction. third, its performance on multi-view images of the tongue is demonstrated and finally it is shown to improve performance in parcellation of the brain ventricular system. both visual and selected quantitative metrics of resolution enhancement are demonstrated.","['deep learning method', 'super', 'resolution', 'mri', 'applications', 'anti', 'aliasing']"
"audio tagging aims to infer descriptive labels from audio clips and it is challenging due to the limited size of data and noisy labels. the solution to the tagging task is described in this paper. the main contributions include the following: an ensemble learning framework is applied to ensemble statistical features and the outputs from the deep classifiers, with the goal to utilize complementary information. moreover, a sample re-weight strategy is employed to address the noisy label problem within the framework. the approach achieves a mean average precision of 0.958, outperforming the baseline system with a large margin.","['ensembling convolutional neural networks', 'general audio tagging', 'statistical features']"
"this paper proposes deep learning methods with signal alignment that facilitate the end-to-end classification of raw electrocardiogram (ecg) signals into heartbeat types, i.e., normal beat or different types of arrhythmias. time-domain sample points are extracted from raw ecg signals, and consecutive vectors are extracted from a sliding time-window covering these sample points. each of these vectors comprises the consecutive sample points of a complete heartbeat cycle, which includes not only the qrs complex but also the p and t waves. unlike existing heartbeat classification methods in which medical doctors extract handcrafted features from raw ecg signals, the proposed end-to-end method leverages a deep neural network for both feature extraction and classification based on aligned heartbeats. this strategy not only obviates the need to handcraft the features but also produces optimized ecg representation for heartbeat classification. evaluations on the mit-bih arrhythmia database show that at the same specificity, the proposed patient-independent classifier can detect supraventricular- and ventricular-ectopic beats at a sensitivity that is at least 10% higher than current state-of-the-art methods. more importantly, there is a wide range of operating points in which both the sensitivity and specificity of the proposed classifier are higher than those achieved by state-of-the-art classifiers. the proposed classifier can also perform comparable to patient-specific classifiers, but at the same time enjoys the advantage of patient independence.","['raw signal extraction', 'deep neural networks', 'end ecg classification', 'towards end']"
"radiology reports contain descriptions of radiological observations followed by diagnosis and follow up recommendations, transcribed by radiologists while reading medical images. one of the most challenging tasks in a radiology workflow is to extract, characterize and structure such content to be able to pair each observation with an appropriate action. this requires classification of the findings based on the provided characterization. in most clinical setups, this is done manually, which is tedious, time-consuming and prone to human error yet of great importance as various types of findings in the reports require different follow-up decision supports and draw different levels of attention. in this work, we present a framework for detection and classification of change characteristics of pulmonary nodular findings in radiology reports. we combine a pre-trained word embedding model with a deep learning based sentence encoder. to overcome the challenge of access to limited labeled data for training, we apply siamese network with pairwise inputs, which enforces the similarities between findings under the same category. the proposed multitask neural network classifier was evaluated and compared against state-of-the-art approaches and demonstrated promising performance.","['pulmonary nodular findings based', 'change using radiology reports', 'classification', 'characterization']"
"automated gleason grading is an important preliminary step for quantitative histopathological feature extraction. different from the traditional task of classifying small pre-selected homogeneous regions, semantic segmentation provides pixel-wise gleason predictions across an entire slide. deep learning-based segmentation models can automatically learn visual semantics from data, which alleviates the need for feature engineering. however, performance of deep learning models is limited by the scarcity of large-scale fully annotated datasets, which can be both expensive and time-consuming to create. one way to address this problem is to leverage external weakly labeled datasets to augment models trained on the limited data. in this paper, we developed an expectation maximization-based approach constrained by an approximated prior distribution in order to extract useful representations from a large number of weakly labeled images generated from low-magnification annotations. this method was utilized to improve the performance of a model trained on a limited fully annotated dataset. our semi-supervised approach trained with 135 fully annotated and 1800 weakly annotated tiles achieved a mean jaccard index of 49.5% on an independent test set, which was 14% higher than the initial model trained only on the fully annotated dataset.","['supervised deep learning approach', 'semantic segmentation', 'radical prostatectomies', 'histopathological images', 'based semi', 'em']"
"deep brain stimulation (dbs) of nucleus basalis of meynert (nbm) is currently being evaluated as a potential therapy to improve memory and overall cognitive function in dementia. although, the animal literature has demonstrated robust improvement in cognitive functions, phase 1 trial results in humans have not been as clear-cut. we hypothesize that this may reflect differences in electrode location within the nbm, type and timing of stimulation, and the lack of a biomarker for determining the stimulation's effectiveness in real time. in this article, we propose a methodology to address these issues in an effort to effectively interface with this powerful cognitive nucleus for the treatment of dementia. specifically, we propose the use of diffusion tensor imaging to identify the nucleus and its tracts, quantitative electroencephalography (qeeg) to identify the physiologic response to stimulation during programming, and investigation of stimulation parameters that incorporate the phase locking and cross frequency coupling of gamma and slower oscillations characteristic of the nbm's innate physiology. we propose that modulating the baseline gamma burst stimulation frequency, specifically with a slower rhythm such as theta or delta will pose more effective coupling between nbm and different cortical regions involved in many learning processes.","['technical considerations', 'nucleus basalis', 'meynert stimulation', 'theoretical', 'dementia']"
"training deep neural networks with the error backpropagation algorithm is considered implausible from a biological perspective. numerous recent publications suggest elaborate models for biologically plausible variants of deep learning, typically defining success as reaching around 98% test accuracy on the mnist data set. here, we investigate how far we can go on digit (mnist) and object (cifar10) classification with biologically plausible, local learning rules in a network with one hidden layer and a single readout layer. the hidden layer weights are either fixed (random or random gabor filters) or trained with unsupervised methods (principal/independent component analysis or sparse coding) that can be implemented by local learning rules. the readout layer is trained with a supervised, local learning rule. we first implement these models with rate neurons. this comparison reveals, first, that unsupervised learning does not lead to better performance than fixed random projections or gabor filters for large hidden layers. second, networks with localized receptive fields perform significantly better than networks with all-to-all connectivity and can reach backpropagation performance on mnist. we then implement two of the networks - fixed, localized, random & random gabor filters in the hidden layer - with spiking leaky integrate-and-fire neurons and spike timing dependent plasticity to train the readout layer. these spiking models achieve >98.2% test accuracy on mnist, which is close to the performance of rate networks with one hidden layer trained with backpropagation. the performance of our shallow network models is comparable to most current biologically plausible models of deep learning. furthermore, our results with a shallow spiking network provide an important reference and suggest the use of data sets other than mnist for testing the performance of future models of biologically plausible deep learning.","['biologically plausible deep learning', 'shallow networks', 'go', 'far']"
"small interfering rna (sirna) can be used to post-transcriptional gene regulation by knocking down targeted genes. in functional genomics, biomedical research and cancer therapeutics, sirna design is a critical research topic. various computational algorithms have been developed to select the most effective sirna, whereas the efficacy prediction accuracy is not so satisfactory. many existing computational methods are based on feature engineering, which may lead to biased and incomplete features. deep learning utilizes non-linear mapping operations to detect potential feature pattern and has been considered perform better than existing machine learning method.","['sirna silencing efficacy prediction based', 'deep architecture']"
"due to various environmental pollution issues, cancers have become the ""first killer"" of human beings in the 21st century and their control has become a global strategy of human health. the increasing development of emerging information technologies has provided opportunities for prevention, early detection, diagnosis, intervention, prognosis, nursing, and rehabilitation of cancers. in recent years, the literature associated with emerging technologies in cancer has grown rapidly, but few studies have used bibliometrics and a visualization approach to conduct deep mining and reveal a panorama of this field. to explore the dynamic knowledge evolution of emerging information technologies in cancer literature, we comprehensively analyzed the development status and research hotspots in this field from bibliometrics perspective. we collected 7,136 articles (2000-2017) from the web of science database and visually displayed the dynamic knowledge evolution process via the analysis on time-sequence changes, spatial distribution, knowledge base, and hotspots. much institutional cooperation occurs in this field, and research groups are relatively concentrated. bmc bioinformatics, plos one, journal of urology, scientific reports, and bioinformatics are the top five journals in this field. research hotspots are mainly concentrated in two dimensions: the disease dimension (e.g., cancer, breast cancer, and prostate cancer), and the technical dimension (e.g., robotics, machine learning, data mining, and etc.). the emerging technologies in cancer research is fast ascending and promising. this study also provides researchers with panoramic knowledge of this field, as well as research hotspots and future directions.","['tracking knowledge evolution', 'future directions', 'emerging technologies', 'cancers research', 'bibliometrics review', 'hotspots']"
this article is a summary of the quantitative imaging subgroup of the 2017 aapm practical big data workshop (pbdw-2017) on progress and challenges in big data applied to cancer treatment and research supplemented by a draft white paper following an american association of physicists in medicine forem meeting on imaging genomics in 2014.,"['aapm practical big data workshop', 'quantitative imaging', 'utilization', 'report', 'opportunities', 'challenges']"
"superresolution localization microscopy strongly relies on robust identification algorithms for accurate reconstruction of the biological systems it is used to measure. the fields of machine learning and computer vision have provided promising solutions for automated object identification, but usually rely on well represented training sets to learn object features. however, using a static training set can result in the learned identification algorithm making mistakes on data that is not well represented by the training set. here, we present a method for training an artificial neural network without providing a training set in advance. this method uses the data to be analyzed, and the fitting algorithm to train an artificial neural network tailored to that data set. we show that the same artificial neural network can learn to identify at least two types of molecular emissions: the regular point spread functions (psfs), and the astigmatism psf. simulations indicate that this method can be extremely reliable in extracting molecular emission signatures. additionally, we implemented the artificial neural network calculation to be performed on a graphics processing unit (gpu) for massively parallelized calculation which drastically reduces the time required for the identification process. by implementing the neural identification on a gpu, we allow this method of identification to be used in a real time analysis algorithm. research highlights: here, we present a machine learning algorithm for identifying point-spread functions without the need for an a priori training set. we show that this method can detect over 90% of molecules with less than 1% false positive identification in simulations. we further show that because this algorithm does not make assumptions of about the shape of molecular emission, it is compatible with models beyond the symmetric 2d gaussian.","['neural network localization identificatio', 'neural training', 'molecular imaging', 'identification algorithm']"
"industry 4.0 leaders solve problems all of the time. successful problem-solving behavioral pattern choice determines organizational and personal success, therefore a proper understanding of the problem-solving-related neurological dynamics is sure to help increase business performance. the purpose of this paper is two-fold: first, to discover relevant neurological characteristics of problem-solving behavioral patterns, and second, to conduct a characterization of two problem-solving behavioral patterns with the aid of deep-learning architectures. this is done by combining electroencephalographic non-invasive sensors that capture process owners' brain activity signals and a deep-learning soft sensor that performs an accurate characterization of such signals with an accuracy rate of over 99% in the presented case-study dataset. as a result, the deep-learning characterization of lean management (lm) problem-solving behavioral patterns is expected to help industry 4.0 leaders in their choice of adequate manufacturing systems and their related problem-solving methods in their future pursuit of strategic organizational goals.","['solving behavioral patterns using eeg sensors', '0 lean management problem', 'industry 4', 'deep learning', 'characterization']"
to obtain attenuation-corrected pet images directly from non-attenuation-corrected images using a convolutional encoder-decoder network.,"['brain pet images using', 'emission data via', 'direct attenuation correction', 'deep convolutional encoder', 'deep', 'decoder', 'da']"
this study aims to introduce as proof of concept a combination model for classification of prostate cancer using deep learning approaches. we utilized patients with prostate cancer who underwent surgical treatment representing the various conditions of disease progression. all possible combinations of significant variables from logistic regression and correlation analyses were determined from study data sets. the combination possibility and deep learning model was developed to predict these combinations that represented clinically meaningful patient's subgroups. the observed relative frequencies of different tumor stages and gleason score gls changes from biopsy to prostatectomy were available for each group. deep learning models and seven machine learning approaches were compared for the classification performance of gleason score changes and pt2 stage. deep models achieved the highest f1 scores by pt2 tumors (0.849) and gls change (0.574). combination possibility and deep learning model is a useful decision-aided tool for prostate cancer and to group patients with prostate cancer into clinically meaningful groups.,"['deep learning model', 'prostate cancer', 'combination possibility', 'clinical decision', 'aided approach']"
"low-dose ct denoising is a challenging task that has been studied by many researchers. some studies have used deep neural networks to improve the quality of low-dose ct images and achieved fruitful results. in this paper, we propose a deep neural network that uses dilated convolutions with different dilation rates instead of standard convolution helping to capture more contextual information in fewer layers. also, we have employed residual learning by creating shortcut connections to transmit image information from the early layers to later ones. to further improve the performance of the network, we have introduced a non-trainable edge detection layer that extracts edges in horizontal, vertical, and diagonal directions. finally, we demonstrate that optimizing the network by a combination of mean-square error loss and perceptual loss preserves many structural details in the ct image. this objective function does not suffer from over smoothing and blurring effects causing by per-pixel loss and grid-like artifacts resulting from perceptual loss. the experiments show that each modification to the network improves the outcome while changing the complexity of the network, minimally.","['dose ct denoising using perceptual loss', 'edge detection layer', 'deep learning', 'low']"
"capsule endoscopy has revolutionized investigation of the small bowel. however, this technique produces a video that is 8-10 hours long, so analysis is time consuming for gastroenterologists. deep convolutional neural networks (cnns) can recognize specific images among a large variety. we aimed to develop a cnn-based algorithm to assist in the evaluation of small bowel capsule endoscopy (sb-ce) images.","['xa0and normal variants', 'capsule endoscopy using', 'level identification', 'learning model', 'bowel diseases', 'small', 'gastroenterologist', 'deep']"
"domain adaptation (da) is widely used in learning problems lacking labels. recent studies show that deep adversarial da models can make markable improvements in performance, which include symmetric and asymmetric architectures. however, the former has poor generalization ability, whereas the latter is very hard to train. in this article, we propose a novel adversarial da method named adversarial residual transform networks (artns) to improve the generalization ability, which directly transforms the source features into the space of target features. in this model, residual connections are used to share features and adversarial loss is reconstructed, thus making the model more generalized and easier to train. moreover, a special regularization term is added to the loss function to alleviate a vanishing gradient problem, which enables its training process stable. a series of experiments based on amazon review data set, digits data sets, and office-31 image data sets are conducted to show that the proposed artn can be comparable with the methods of the state of the art.","['adversarial residual transform networks', 'unsupervised domain adaptation']"
"based on international diagnostic guidelines, high-resolution ct plays a central part in the diagnosis of fibrotic lung disease. in the correct clinical context, when high-resolution ct appearances are those of usual interstitial pneumonia, a diagnosis of idiopathic pulmonary fibrosis can be made without surgical lung biopsy. we investigated the use of a deep learning algorithm for provision of automated classification of fibrotic lung disease on high-resolution ct according to criteria specified in two international diagnostic guideline statements: the 2011 american thoracic society (ats)/european respiratory society (ers)/japanese respiratory society (jrs)/latin american thoracic association (alat) guidelines for diagnosis and management of idiopathic pulmonary fibrosis and the fleischner society diagnostic criteria for idiopathic pulmonary fibrosis.","['classifying fibrotic lung disease', 'resolution computed tomography', 'deep learning', 'cohort study', 'high', 'case']"
"biological targets are most commonly proteins such as enzymes, ion channels, and receptors. they are anything within a living organism to bind with some other entities (like an endogenous ligand or a drug), resulting in change in their behaviors or functions. exploring potential drug-target interactions (dtis) are crucial for drug discovery and effective drug development. computational methods were widely applied in drug-target interactions, since experimental methods are extremely time-consuming and resource-intensive. in this paper, we proposed a novel deep learning-based prediction system, with a new negative instance generation, to identify dtis. as a result, our method achieved an accuracy of 0.9800 on our created dataset. another dataset derived from drugbank was used to further assess the generalization of the model, which yielded a good performance with accuracy of 0.8814 and auc value of 0.9527 on the dataset. the outcome of our experimental results indicated that the proposed method, involving the credible negative generation, can be employed to discriminate the interactions between drugs and targets.","['convolutional neural network system', 'target interactions', 'discriminate drug']"
"small extracellular vesicles (sevs) are cell-derived vesicles of nanoscale size (~30-200\u2009nm) that function as conveyors of information between cells, reflecting the cell of their origin and its physiological condition in their content. valuable information on the shape and even on the composition of individual sevs can be recorded using transmission electron microscopy (tem). unfortunately, sample preparation for tem image acquisition is a complex procedure, which often leads to noisy images and renders automatic quantification of sevs an extremely difficult task. we present a completely deep-learning-based pipeline for the segmentation of sevs in tem images. our method applies a residual convolutional neural network to obtain fine masks and use the radon transform for splitting clustered sevs. using three manually annotated datasets that cover a natural variability typical for sev studies, we show that the proposed method outperforms two different state-of-the-art approaches in terms of detection and segmentation performance. furthermore, the diameter and roundness of the segmented vesicles are estimated with an error of less than 10%, which supports the high potential of our method in biological applications.","['transmission electron microscopy images', 'small extracellular vesicles', 'based segmentation', 'learning', 'deep']"
"the letters ""interpretation of the outputs of deep learning model trained with skin cancer dataset"" and ""automated dermatological diagnosis: hype or reality?"" highlight the opportunities, hurdles, and possible pitfalls with the development of tools that allow for automated skin lesion classification. the potential clinical impact of these advances relies on their scalability, accuracy, and generalizability across a range of diagnostic scenarios.","['skin lesions', 'automated classification', 'practice', 'pixels']"
"increased interest in the opportunities provided by artificial intelligence and machine learning has spawned a new field of health-care research. the new tools under development are targeting many aspects of medical practice, including changes to the practice of pathology and laboratory medicine. optimal design in these powerful tools requires cross-disciplinary literacy, including basic knowledge and understanding of critical concepts that have traditionally been unfamiliar to pathologists and laboratorians. this review provides definitions and basic knowledge of machine learning categories (supervised, unsupervised, and reinforcement learning), introduces the underlying concept of the bias-variance trade-off as an important foundation in supervised machine learning, and discusses approaches to the supervised machine learning study design along with an overview and description of common supervised machine learning algorithms (linear regression, logistic regression, naive bayes, k-nearest neighbor, support vector machine, random forest, convolutional neural networks).","['supervised methods', 'present landscape', 'machine learning', 'artificial intelligence', 'pathology']"
"tumor programmed death-ligand 1 (pd-l1) status is useful in determining which patients may benefit from programmed death-1 (pd-1)/pd-l1 inhibitors. however, little is known about the association between pd-l1 status and tumor histopathological patterns. using deep learning, we predicted pd-l1 status from hematoxylin and eosin (h and e) whole-slide images (wsis) of nonsmall cell lung cancer (nsclc) tumor samples.","['view deep learning model predicts nonsmall cell lung cancer programmed death', 'ligand 1 status', 'slide hematoxylin', 'eosin images', 'whole', 'multi', 'field']"
"recent advances in machine learning have given rise to deep learning, which uses hierarchical layers to build models, offering the ability to advance value-based healthcare by better predicting patient outcomes and costs of a given treatment. the purpose of this study is to compare the performance of 2 common deep learning models, traditional multilayer perceptron (mlp), and the newer dense neural network (densenet), in predicting outcomes for primary total hip arthroplasty (tha) and total knee arthroplasty (tka) as a foundation for future musculoskeletal studies seeking to utilize machine learning.","['lower extremity arthroplasty using deep learning', 'predicting inpatient payments prior', 'model architecture', 'best']"
"obesity is increasingly prevalent and associated with increased risk of developing type 2 diabetes, cardiovascular diseases, and cancer. magnetic resonance imaging (mri) is an accurate method for determination of body fat volume and distribution. however, quantifying body fat from numerous mri slices is tedious and time-consuming. here we developed a deep learning-based method for measuring visceral and subcutaneous fat in the abdominal region of mice. congenic mice only differ from c57bl/6 (b6) apoe knockout (apoe-/-) mice in chromosome 9 that is replaced by c3h/hej genome. male congenic mice had lighter body weight than b6-apoe-/- mice after being fed 14 weeks of western diet. axial and coronal t1-weighted sequencing at 1-mm-thickness and 1-mm-gap was acquired with a 7t bruker clinscan scanner. a deep learning approach was developed for segmenting visceral and subcutaneous fat based on the u-net architecture made publicly available through the open-source antsrnet library-a growing repository of well-known neural networks. the volumes of subcutaneous and visceral fat measured through our approach were highly comparable with those from manual measurements. the dice score, root-mean-square error (rmse), and correlation analysis demonstrated the similarity between two methods in quantifying visceral and subcutaneous fat. analysis with the automated method showed significant reductions in volumes of visceral and subcutaneous fat but not non-fat tissues in congenic mice compared to b6 mice. these results demonstrate the accuracy of deep learning in quantification of abdominal fat and its significance in determining body weight.","['magnetic resonance images', 'deep learning', 'based quantification', 'abdominal fat']"
"breast cancer is one of the most common cancers in women, with more than 1,300,000 cases and 450,000 deaths each year worldwide. in this context, recent studies showed that early breast cancer detection, along with suitable treatment, could significantly reduce breast cancer death rates in the long term. x-ray mammography is still the instrument of choice in breast cancer screening. in this context, the false-positive and false-negative rates commonly achieved by radiologists are extremely arduous to estimate and control although some authors have estimated figures of up to 20% of total diagnoses or more. the introduction of novel artificial intelligence (ai) technologies applied to the diagnosis and, possibly, prognosis of breast cancer could revolutionize the current status of the management of the breast cancer patient by assisting the radiologist in clinical image interpretation. lately, a breakthrough in the ai field has been brought about by the introduction of deep learning techniques in general and of convolutional neural networks in particular. such techniques require no a priori feature space definition from the operator and are able to achieve classification performances which can even surpass human experts. in this paper, we design and validate an ad hoc cnn architecture specialized in breast lesion classification from imaging data only. we explore a total of 260 model architectures in a train-validation-test split in order to propose a model selection criterion which can pose the emphasis on reducing false negatives while still retaining acceptable accuracy. we achieve an area under the receiver operatic characteristics curve of 0.785 (accuracy 71.19%) on the test set, demonstrating how an ad hoc random initialization architecture can and should be fine tuned to a specific problem, especially in biomedical applications.","['ad hoc random initialization deep neural network architecture', 'discriminating malignant breast cancer lesions', 'mammographic images']"
"although the effects of cognitive reappraisal in regulating negative emotion are generally well documented, its regulatory effects are usually not very strong because the ordinary reappraisals employed in previous studies were insufficient to overcome the mental set or response bias toward negative situations. in this study, we developed a new strategy employing creative reappraisals that provides an insightful reinterpretation of the negative stimulus. we believe this approach, through adopting a guided (creative) reappraisal rather than self-generation strategy, will greatly improve the emotion regulation effect of reappraisal through activating the neural networks representing the process of deep and structural mental representational change accompanied by the feeling of positive emotion and mental reward. the behavioral results suggested that 1) regarding the transient regulatory effect, creative reappraisal resulted in a positive rating for standardized negative pictures; 2) creative reappraisal had a long-lasting effect in reducing negative affect. in parallel with these behavioral results, the imaging data indicated that 1) creative reappraisal was specifically associated with greater engagement of the amygdala and hippocampus as well as regions in the ventral striatum, and 2) the engagement of the amygdala predicted the transient regulatory effect of creative reappraisal, while the involvement of the hippocampus and the ventral striatum predicted long-term regulatory effects. these findings suggest that the superior regulatory effect of creative reappraisal could be mediated by amygdala-based salient emotional arousal, hippocampus-based new association formation, and striatum-based mental rewarding to lead to a novel and positive experience that could be kept in long-term memory. this research indicates the key role of creative insight in reappraisal and presents a novel and highly efficient reappraisal strategy.","['superior emotional regulating effects', 'creative cognitive reappraisal']"
"in this paper, a new ensemble framework named cascade interpolation learning with double subspaces and confidence disturbance (cildc) is designed for the imbalanced classification problems. developed from the cascade forest of the deep forest which is the stacking based tree ensembles for big data issues with less hyper-parameters, cildc aims to generalize the cascade model for more base classifiers. specifically, cildc integrates base classifiers through the double subspaces strategy and the random under-sampling preprocessing. further, one simple but effective confidence disturbance technique is introduced to cildc to tune the threshold deviation for imbalanced samples. in detail, the disturbance coefficients are multiplied to various confidence vectors before interpolating in each level of cildc, and the ideal threshold can be adaptively learned through the cascade structure. furthermore, both the random forest and the naive bayes are suitable to be the base classifier for cildc. subsequently, comprehensive comparison experiments on typical imbalanced datasets demonstrate both the effectiveness and generalization of cildc.","['cascade interpolation learning', 'imbalanced problems', 'double subspaces', 'confidence disturbance']"
to determine if mammographic features from deep learning networks can be applied in breast cancer to identify groups at interval invasive cancer risk due to masking beyond using traditional breast density measures.,"['deep learning networks find unique mammographic differences', 'previous negative mammograms', 'detected cancers', 'case study', 'case', 'screen', 'interval']"
"various convolutional neural network (cnn)-based approaches have been recently proposed to improve the performance of motor imagery based-brain-computer interfaces (bcis). however, the classification accuracy of cnns is compromised when target data are distorted. specifically for motor imagery electroencephalogram (eeg), the measured signals, even from the same person, are not consistent and can be significantly distorted. to overcome these limitations, we propose to apply a capsule network (capsnet) for learning various properties of eeg signals, thereby achieving better and more robust performance than previous cnn methods. the proposed capsnet-based framework classifies the two-class motor imagery, namely right-hand and left-hand movements. the motor imagery eeg signals are first transformed into 2d images using the short-time fourier transform (stft) algorithm and then used for training and testing the capsule network. the performance of the proposed framework was evaluated on the bci competition iv 2b dataset. the proposed framework outperformed state-of-the-art cnn-based methods and various conventional machine learning approaches. the experimental results demonstrate the feasibility of the proposed approach for classification of motor imagery eeg signals.",['motor imagery eeg classification using capsule networks']
"body condition score (bcs) is a common tool for indirectly estimating the mobilization of energy reserves in the fat and muscle of cattle that meets the requirements of animal welfare and precision livestock farming for the effective monitoring of individual animals. however, previous studies on automatic bcs systems have used manual scoring for data collection, and traditional image extraction methods have limited model performance accuracy. in addition, the radio frequency identification device system commonly used in ranching has the disadvantages of misreadings and damage to bovine bodies. therefore, the aim of this research was to develop and validate an automatic system for identifying individuals and assessing bcs using a deep learning framework. this work developed a linear regression model of bcs using ultrasound backfat thickness to determine bcs for training sets and tested a system based on convolutional neural networks with 3 channels, including depth, gray, and phase congruency, to analyze the back images of 686 cows. after we performed an analysis of image model performance, online verification was used to evaluate the accuracy and precision of the system. the results showed that the selected linear regression model had a high coefficient of determination value (0.976), and the correlation coefficient between manual bcs and ultrasonic bcs was 0.94. although the overall accuracy of the bcs estimations was high (0.45, 0.77, and 0.98 within 0, 0.25, and 0.5 unit, respectively), the validation for actual bcs ranging from 3.25 to 3.5 was weak (the f1 scores were only 0.6 and 0.57, respectively, within the 0.25-unit range). overall, individual identification and bcs assessment performed well in the online measurement, with accuracies of 0.937 and 0.409, respectively. a system for individual identification and bcs assessment was developed, and a convolutional neural network using depth, gray, and phase congruency channels to interpret image features exhibited advantages for monitoring thin cows.","['provides identification via body parts', 'individual dairy cows based', 'body condition score', 'deep learning framework', 'automatic monitoring system', 'estimation']"
"sensor-based human activity recognition aims at detecting various physical activities performed by people with ubiquitous sensors. different from existing deep learning-based method which mainly extracting black-box features from the raw sensor data, we propose a hierarchical multi-view aggregation network based on multi-view feature spaces. specifically, we first construct various views of feature spaces for each individual sensor in terms of white-box features and black-box features. then our model learns a unified representation for multi-view features by aggregating views in a hierarchical context from the aspect of feature level, position level and modality level. we design three aggregation modules corresponding to each level aggregation respectively. based on the idea of non-local operation and attention, our fusion method is able to capture the correlation between features and leverage the relationship across different sensor position and modality. we comprehensively evaluate our method on 12 human activity benchmark datasets and the resulting accuracy outperforms the state-of-the-art approaches.","['based human activity recognition', 'view aggregation network', 'hierarchical multi', 'sensor']"
"rna binding proteins (rbps) determine rna process from synthesis to decay, which play a key role in rna transport, translation and degradation. therefore, exploring rbps' function from the amino acid sequence using computational methods has become one of the momentous topics in genome annotation. however, there still have some challenges: (1) shallow feature: although the sequence determines structure is self-evident, it is difficult to analyze the essential features from simple sequence. (2) poorly understand: feature-based prediction methods mainly emphasize feature extraction, while in-depth understanding of protein mysteries limits the application of feature engineering. (3) feature fusion: multi-feature fusion is often used, but the features are not well integrated. in view of these challenges, we propose a novel ensemble convolutional neural network (econvrbp) to predict rbps. in order to capture the local and global features of rna binding proteins simultaneously, first of all, one hot and conjoint triad encoding methods are used to transform amino acid sequence into local and global features, respectively. after that the local and global features are combined for further high-level feature extraction using convolutional neural networks. some experiments are constructed to evaluate our method with 10-fold cross validation and the results show that it has achieved the best performance among all the predictors so far. we correctly predicted 99% of 2875 rbps and 99% of 6782 non-rbps with accuracy of 0.99. in addition, the datasets provided by rbppred are also used to validate our models with an accuracy of 0.87. these results indicate that the econvrbp is the most excellent method at present, and will provide reliable guidance for the detection of rbps. econvrbp is available at http://47.100.203.218:3389/home.html/.","['rna binding protein prediction directly', 'improved ensemble convolutional neural networks', 'sequence', 'econvrbp']"
"building visual encoding models to accurately predict visual responses is a central challenge for current vision-based brain-machine interface techniques. to achieve high prediction accuracy on neural signals, visual encoding models should include precise visual features and appropriate prediction algorithms. most existing visual encoding models employ hand-craft visual features (e.g., gabor wavelets or semantic labels) or data-driven features (e.g., features extracted from deep neural networks (dnn)). they also assume a linear mapping between feature representations to brain activity. however, it remains unknown whether such linear mapping is sufficient for maximizing prediction accuracy.","['visual encoding model based', 'functional magnetic resonance imaging', 'deep neural networks', 'brain activity measured', 'transfer learning']"
"federated learning is an emerging technique used to prevent the leakage of private information. unlike centralized learning that needs to collect data from users and store them collectively on a cloud server, federated learning makes it possible to learn a global model while the data are distributed on the users' devices. however, compared with the traditional centralized approach, the federated setting consumes considerable communication resources of the clients, which is indispensable for updating global models and prevents this technique from being widely used. in this paper, we aim to optimize the structure of the neural network models in federated learning using a multi-objective evolutionary algorithm to simultaneously minimize the communication costs and the global model test errors. a scalable method for encoding network connectivity is adapted to federated learning to enhance the efficiency in evolving deep neural networks. experimental results on both multilayer perceptrons and convolutional neural networks indicate that the proposed optimization method is able to find optimized neural network models that can not only significantly reduce communication costs but also improve the learning performance of federated learning compared with the standard fully connected neural networks.","['objective evolutionary federated learning', 'multi']"
"digital pathology is today a widely used technology, and the digitalization of microscopic slides into whole slide images (wsis) allows the use of machine learning algorithms as a tool in the diagnostic process. in recent years, ""deep learning"" algorithms for image analysis have been applied to digital pathology with great success. the training of these algorithms requires a large volume of high-quality images and image annotations. these large image collections are a potent source of information, and to use and share the information, standardization of the content through a consistent terminology is essential. the aim of this project was to develop a pilot dataset of exhaustive annotated wsi of normal and abnormal human tissue and link the annotations to appropriate ontological information.","['driven whole slide image library', 'whole slide images', 'abnormal human tissue', 'annotated ontology', 'ontologies', 'normal', 'development', 'annotations']"
"deep convolutional neural networks (cnn) have previously been shown to be useful tools for signal decoding and analysis in a variety of complex domains, such as image processing and speech recognition. by learning from large amounts of data, the representations encoded by these deep networks are often invariant to moderate changes in the underlying feature spaces. recently, we proposed a cnn architecture that could be applied to electroencephalogram (eeg) decoding and analysis. in this article, we train our cnn model using data from prior experiments in order to later decode the p300 evoked response from an unseen, hold-out experiment. we analyze the cnn output as a function of the underlying variability in the p300 response and demonstrate that the cnn output is sensitive to the experiment-induced changes in the neural response. we then assess the utility of our approach as a means of improving the overall signal-to-noise ratio in the eeg record. finally, we show an example of how cnn-based decoding can be applied to the analysis of complex data.",['decoding p300 variability using convolutional neural networks']
"heart disease remains the leading cause of death in the united states. compared with risk assessment guidelines that require manual calculation of scores, machine learning-based prediction for disease outcomes such as mortality can be utilized to save time and improve prediction accuracy. this study built and evaluated various machine learning models to predict one-year mortality in patients diagnosed with acute myocardial infarction or post myocardial infarction syndrome in the mimic-iii database. the results of the best performing shallow prediction models were compared to a deep feedforward neural network (deep fnn) with back propagation. we included a cohort of 5436 admissions. six datasets were developed and compared. the models applying logistic model trees (lmt) and simple logistic algorithms to the combined dataset resulted in the highest prediction accuracy at 85.12% and the highest auc at .901. in addition, other factors were observed to have an impact on outcomes as well.","['post myocardial infarction syndrome', 'acute myocardial infarction', 'building computational models', 'year mortality', 'predict one', 'icu patients']"
"underwater structural damage inspection has mainly relied on diver-based visual inspection, and emerging technologies include the use of remotely operated vehicles (rovs) for improved efficiency. with the goal of performing an autonomous and robotic underwater inspection, a novel tactile imaging system for underwater inspection (tisue) is designed, prototyped, and tested in this paper. the system has two major components, including the imaging subsystem and the manipulation subsystem. the novelty lies in the imaging subsystem, which consists of an elastomer-enabled contact-based optical sensor with specifically designed artificial lighting. the completed tisue system, including optical imaging, data storage, display analytics, and a mechanical support subsystem, is further tested in a laboratory experiment. the experiment demonstrates that high-resolution and high-quality images of structural surface damage can be obtained using tactile 'touch-and-sense' imaging, even in a turbid water environment. a deep learning-based damage detection framework is developed and trained. the detection results demonstrate the similar detectability of five damage types in the obtained tactile images to images obtained from regular (land-based) structural inspection.","['underwater structural damage detection', 'tactile imaging', 'development']"
"in this paper, we propose a framework of starting points generation for freeform reflective triplet using back-propagation neural network based deep-learning. the network is trained using various system specifications and the corresponding surface data obtained by system evolution as the data set. good starting points of specific system specifications for further optimization can be generated immediately using the obtained network in general. the feasibility of this design process is validated by designing the wetherell-configuration freeform off-axis reflective triplet. the amount of time and human effort as well as the dependence on advanced design skills are significantly reduced. these results highlight the powerful ability of deep learning in the field of freeform imaging optical design.","['mirror imaging system design using neural network based deep', 'starting points', 'direct generation', 'axis three', 'learning', 'freeform']"
"mosquito control is important as mosquitoes are extremely harmful pests that spread various infectious diseases. in this research, we present the preliminary results of an automated system that detects the presence of mosquitoes via image processing using multiple deep learning networks. the fully convolutional network (fcn) and neural network-based regression demonstrated an accuracy of 84%. meanwhile, the single image classifier demonstrated an accuracy of only 52%. the overall processing time also decreased from 4.64 to 2.47 s compared to the conventional classifying network. after detection, a larvicide made from toxic protein crystals of the bacillus thuringiensis serotype israelensis bacteria was injected into static water to stop the proliferation of mosquitoes. this system demonstrates a higher efficiency than hunting adult mosquitos while avoiding damage to other insects.","['based automatic mosquito sensing', 'urban mosquito habitats', 'deep learning', 'control system']"
"deep learning models for prediction of three key lc-ms/ms properties from peptide sequences were developed. the lc-ms/ms properties or behaviors are indexed retention times (irt), ms1 or survey scan charge state distributions, and sequence ion intensities of hcd spectra. a common core deep supervised learning architecture, bidirectional long-short term memory (lstm) recurrent neural networks was used to construct the three prediction models. two featurization schemes were proposed and demonstrated to allow for efficient encoding of modifications. the irt and charge state distribution models were trained with on order of 105 data points each. an hcd sequence ion prediction model was trained with 2 × 106 experimental spectra. the irt prediction model and hcd sequence ion prediction model provide improved accuracies over the start-of-the-art models available in literature. the ms1 charge state distribution prediction model offers excellent performance. the prediction models can be used to enhance peptide identification and quantification in data-dependent acquisition and data-independent acquisition (dia) experiments as well as to assist mrm (multiple reaction monitoring) and prm (parallel reaction monitoring) experiment design.","['deep learning', 'ms properties', 'ms', 'sequence', 'prediction', 'peptides', 'lc']"
"the aims of the present study were to observe the changes of cognitive function in a pilocarpine-induced rat model of epilepsy, and to investigate the effects of hippocampal low-frequency stimulation (hip-lfs) on cognitive function in rats with pharmacoresistant epilepsy.","['frequency stimulation improves cognitive function', 'pharmacoresistant epileptic rats', 'hippocampal low']"
"saliency refers to the visual perception quality that makes objects in a scene to stand out from others and attract attention. while computational saliency models can simulate the expert's visual attention, there is little evidence about how these models perform when used to predict the cytopathologist's eye fixations. saliency models may be the key to instrumenting fast object detection on large pap smear slides under real noisy conditions, artifacts, and cell occlusions. this paper describes how our computational schemes retrieve regions of interest (roi) of clinical relevance using visual attention models. we also compare the performance of different computed saliency models as part of cell screening tasks, aiming to design a computer-aided diagnosis systems that supports cytopathologists.","['driven system models', 'deep learning', 'cell analysis', 'saliency']"
"traditionally, deep learning algorithms update the network weights, whereas the network architecture is chosen manually using a process of trial and error. in this paper, we propose two novel approaches that automatically update the network structure while also learning its weights. the novelty of our approach lies in our parameterization, where the depth, or additional complexity, is encapsulated continuously in the parameter space through control parameters that add additional complexity. we propose two methods. in tunnel networks, this selection is done at the level of a hidden unit, and in budding perceptrons, this is done at the level of a network layer; updating this control parameter introduces either another hidden unit or layer. we show the effectiveness of our methods on the synthetic two-spiral data and on three real data sets of mnist, mirflickr, and cifar, where we see that our proposed methods, with the same set of hyperparameters, can correctly adjust the network complexity to the task complexity.",['continuously constructive deep neural networks']
"we introduce deep learning technique to predict the beam propagation factor m2 of the laser beams emitting from few-mode fiber for the first time, to the best of our knowledge. the deep convolutional neural network (cnn) is trained with paired data of simulated near-field beam patterns and their calculated m2 value, aiming at learning a fast and accurate mapping from the former to the latter. the trained deep cnn can then be utilized to evaluate m2 of the fiber beams from single beam patterns. the results of simulated testing samples have shown that our scheme can achieve an averaged prediction error smaller than 2% even when up to 10 eigenmodes are involved in the fiber. the error becomes slightly larger when heavy noises are added into the input beam patterns but still smaller than 2.5%, which further proves the accuracy and robustness of our method. furthermore, the m2 estimation takes only about 5 ms for a prepared beam pattern with one forward pass, which can be adopted for real-time m2 determination with only one supporting charge-coupled device (ccd). the experimental results further prove the feasibility of our scheme. moreover, the method we proposed can be confidently extended to other kinds of beams provided that adequate training samples are accessible. deep learning paves the way to superfast and accurate m2 evaluation with very low experimental efforts.","['deep learning enabled superfast', 'accurate m2 evaluation', 'fiber beams']"
"this study reports a framework to discriminate patients with schizophrenia and normal healthy control subjects, based on magnetic resonance imaging (mri) of the brain. resting-state functional mri data from a total of 144 subjects (72 patients with schizophrenia and 72 healthy controls) was obtained from a publicly available dataset using a three-dimensional convolution neural network 3d-cnn based deep learning classification framework and ica based features.","['schizophrenia using resting', 'cnn based discrimination', 'state fmri', '3d']"
"error backpropagation is a highly effective mechanism for learning high-quality hierarchical features in deep networks. updating the features or weights in one layer, however, requires waiting for the propagation of error signals from higher layers. learning using delayed and non-local errors makes it hard to reconcile backpropagation with the learning mechanisms observed in biological neural networks as it requires the neurons to maintain a memory of the input long enough until the higher-layer errors arrive. in this paper, we propose an alternative learning mechanism where errors are generated locally in each layer using fixed, random auxiliary classifiers. lower layers could thus be trained independently of higher layers and training could either proceed layer by layer, or simultaneously in all layers using local error information. we address biological plausibility concerns such as weight symmetry requirements and show that the proposed learning mechanism based on fixed, broad, and random tuning of each neuron to the classification categories outperforms the biologically-motivated feedback alignment learning technique on the cifar10 dataset, approaching the performance of standard backpropagation. our approach highlights a potential biological mechanism for the supervised, or task-dependent, learning of feature hierarchies. in addition, we show that it is well suited for learning deep networks in custom hardware where it can drastically reduce memory traffic and data communication overheads. code used to run all learning experiments is available under https://gitlab.com/hesham-mostafa/learning-using-local-erros.git.",['deep supervised learning using local errors']
"boosting transitions of rare events is critical to simulations of chemical and biophysical dynamic systems in order to close the time scale gaps between theoretical modeling and experiments. we present a novel approach, called targeted adversarial learning optimized sampling (talos), to modify the potential energy surface in order to drive the system to a user-defined target distribution where the free-energy barrier is lowered. combining statistical mechanics and generative learning, talos formulates a competing game between a sampling engine and a virtual discriminator, enables unsupervised construction of bias potentials, and seeks for an optimal transport plan that transforms the system into a target. through multiple experiments, we show that on-the-fly training of talos benefits from the state-of-art optimization techniques in deep learning and thus is efficient, robust, and interpretable. talos is also closely connected to the actor-critic reinforcement learning and hence leads to a new way of flexibly manipulating the many-body hamiltonian systems.",['targeted adversarial learning optimized sampling']
"the doughnut-shaped beam has been widely applied in the field of super-resolution microscopic imaging, micro-nanostructure lithography, ultra-high-density storage, and laser trapping. however, how to maintain the doughnut-shaped focus inside the scattering medium becomes a challenge, due to the wavefront aberrations. here we demonstrate a machine learning based adaptive optics method to recover the doughnut-shaped focus with high speed. in our method, the relationship between the distorted doughnut-shaped intensity point spread function and the coefficients of the first 15 zernike modes for phase correction is established. experimental results show that the wavefront aberration with 101,784 optical control elements can be predicted within ~17 ms even using a personal computer, and 97.5% correction accuracy can be achieved in 200 repeated tests. besides, we successfully apply this method in the scanning microscopy theoretically. with a large number of optical control elements and fast operation speed, our method may pave the way for many important applications in bioimaging, such as deep tissue stimulated emission depletion (sted) microscopy.","['machine learning based adaptive optics', 'shaped beam', 'doughnut']"
"according to the advances of high-throughput sequencing technology, massive microbiome data accumulated from environmental investigations to human studies. the microbiome-wide association studies are to study the relationship between the microbiome and human health or environment. recently, deep neural networks (dnns) are encouraging due to their layer-wise learning ability for representation learning. however, dnns are considered as black boxes and they require a large amount of training data which makes them impractical to conduct microbiome-wide association studies directly. meanwhile, the microbiome data is high dimension with many features and noise. a single feature selection method for dealing with the kind of dataset is often unstable. in this work, we introduced a deep learning model named deep forest to conduct the microbiome-wide association studies and an ensemble feature selection method is proposed to guide microbial biomarkers' identification. the experiments showed that our ensemble feature method based on deep forest had good stability and robustness. the results of feature selection could guide the discovery of microbial biomarkers and help to diagnose microbial-related diseases. the code is available at https://github.com/microava/mwas-biomarkers.git.","['wide association studies', 'robust biomarker discovery', 'microbiome']"
"microscopic examination of peripheral blood plays an important role in the field of diagnosis and control of major diseases. peripheral leukocyte recognition by manual requires medical technicians to observe blood smears through light microscopy, using their experience and expertise to discriminate and analyze different cells, which is time-consuming, labor-intensive and subjective. the traditional systems based on feature engineering often need to ensure successful segmentation and then manually extract certain quantitative and qualitative features for recognition but still remaining a limitation of poor robustness. the classification pipeline based on convolutional neural network is of automatic feature extraction and free of segmentation but hard to deal with multiple object recognition. in this paper, we take leukocyte recognition as object detection task and apply two remarkable object detection approaches, single shot multibox detector and an incremental improvement version of you only look once. to improve recognition performance, some key factors involving these object detection approaches are explored and the detection models are generated using the train set of 14,700 annotated images. finally, we evaluate these detection models on test sets consisting of 1,120 annotated images and 7,868 labeled single object images corresponding to 11 categories of peripheral leukocytes, respectively. a best mean average precision of 93.10% and mean accuracy of 90.09% are achieved while the inference time is 53 ms per image on a nvidia gtx1080ti gpu.","['peripheral leukocyte recognition', 'deep learning approach']"
the confusion of mri sequence names could be solved if mr images were automatically identified after image data acquisition. we revealed the ability of deep learning to classify head mri sequences.,"['artificial intelligence using neural network architecture', 'radiology', 'ainna']"
"cervical cancer is increasingly threatening the health of women, then early screening and prevention of cervical cancer is very necessary. a traditional saliency cervical cancer detection method in ultrasound image, assuming that there is only one salient object, is not conductive to practical application. their effects are dependent on saliency threshold. object detection model provides a kind of new solutions for multiple salient objects. shot multibox detector can accurately detect multi-objects with different scales simultaneously except for small cervical cancer regions. to overcome this drawback, this paper presents a new multi-saliency objects detection model, appending deconvolution module embedded within attention residual module. experiments show that our proposed diagnosis algorithm achieves higher detection accuracy than comparison algorithms. also, it improves detection performance for mult-saliency cervical cancer objects with small scales, which greatly improve the diagnosis accuracy of cervical cancer.","['saliency single shot multibox detector', 'cervical cancer detection', 'ultrasonic elastography', 'diagnosis based']"
"emerging rna-based approaches to disease detection and gene therapy require rna sequences that fold into specific base-pairing patterns, but computational algorithms generally remain inadequate for these secondary structure design tasks. the eterna project has crowdsourced rna design to human video game players in the form of puzzles that reach extraordinary difficulty. here, we demonstrate that eterna participants' moves and strategies can be leveraged to improve automated computational rna design. we present an eternamoves-large repository consisting of 1.8 million of player moves on 12 of the most-played eterna puzzles as well as an eternamoves-select repository of 30,477 moves from the top 72 players on a select set of more advanced puzzles. on eternamoves-select, we present a multilayer convolutional neural network (cnn) eternabrain that achieves test accuracies of 51% and 34% in base prediction and location prediction, respectively, suggesting that top players' moves are partially stereotyped. pipelining this cnn's move predictions with single-action-playout (sap) of six strategies compiled by human players solves 61 out of 100 independent puzzles in the eterna100 benchmark. eternabrain-sap outperforms previously published rna design algorithms and achieves similar or better performance than a newer generation of deep learning methods, while being largely orthogonal to these other methods. our study provides useful lessons for future efforts to achieve human-competitive performance with automated rna design algorithms.","['scale rna videogame', 'automated rna design', 'move sets', 'strategies', 'internet', 'eternabrain']"
"generative adversarial networks have gained a lot of attention in the computer vision community due to their capability of data generation without explicitly modelling the probability density function. the adversarial loss brought by the discriminator provides a clever way of incorporating unlabeled samples into training and imposing higher order consistency. this has proven to be useful in many cases, such as domain adaptation, data augmentation, and image-to-image translation. these properties have attracted researchers in the medical imaging community, and we have seen rapid adoption in many traditional and novel applications, such as image reconstruction, segmentation, detection, classification, and cross-modality synthesis. based on our observations, this trend will continue and we therefore conducted a review of recent advances in medical imaging using the adversarial training scheme with the hope of benefiting researchers interested in this technique.","['generative adversarial network', 'medical imaging', 'review']"
"soil spectra are often measured in the laboratory, and there is an increasing number of large-scale soil spectral libraries establishing across the world. however, calibration models developed from soil libraries are difficult to apply to spectral data acquired from the field or space. transfer learning has the potential to bridge the gap and make the calibration model transferrable from one sensor to another. the objective of this study is to explore the potential of transfer learning for soil spectroscopy and its performance on soil clay content estimation using hyperspectral data. first, a one-dimensional convolutional neural network (1d-cnn) is used on land use/land cover area frame survey (lucas) mineral soils. to evaluate whether the pre-trained 1d-cnn model was transferrable, lucas organic soils were used to fine-tune and validate the model. the fine-tuned model achieved a good accuracy (coefficient of determination (r²) = 0.756, root-mean-square error (rmse)= 7.07 and ratio of percent deviation (rpd) = 2.26) for the estimation of clay content. spectral index, as suggested as a simple transferrable feature, was also explored on lucas data, but did not performed well on the estimation of clay content. then, the pre-trained 1d-cnn model was further fine-tuned by field samples collect in the study area with spectra extracted from hymap imagery, achieved an accuracy of r² = 0.601, rmse = 8.62 and rpd = 1.54. finally, the soil clay map was generated with the fine-tuned 1d-cnn model and hyperspectral data.","['soil clay content mapping using hyperspectral imagery', 'soil spectroscopy based', 'convolutional neural networks', 'transfer learning', 'application']"
"epigenetic modification has an effect on gene expression under the environmental alteration, but it does not change corresponding genome sequence. dna methylation (dnam) is one of the important epigenetic mechanisms. dnam variations could be used as epigenetic markers to predict and account for the change of many human phenotypic traits, such as cancer, diabetes, and high blood pressure. in this study, we built deep neural network (dnn) regression models to account for interindividual variation in triglyceride concentrations measured at different visits of peripheral blood samples using epigenome-wide dnam profiles.","['deep neural network based regression model', 'triglyceride concentrations prediction using epigenome', 'wide dna methylation profiles']"
"it is significant to identify rock-mineral microscopic images in geological engineering. the task of microscopic mineral image identification, which is often conducted in the lab, is tedious and time-consuming. deep learning and convolutional neural networks (cnns) provide a method to analyze mineral microscopic images efficiently and smartly. in this research, the transfer learning model of mineral microscopic images is established based on inception-v3 architecture. the four mineral image features, including k-feldspar (kf), perthite (pe), plagioclase (pl), and quartz (qz or q), are extracted using inception-v3. based on the features, the machine learning methods, logistic regression (lr), support vector machine (svm), random forest (rf), k-nearest neighbors (knn), multilayer perceptron (mlp), and gaussian naive bayes (gnb), are adopted to establish the identification models. the results are evaluated using 10-fold cross-validation. lr, svm, and mlp have a significant performance among all the models, with accuracy of about 90.0%. the evaluation result shows lr, svm, and mlp are the outstanding single models in high-dimensional feature analysis. the three models are also selected as the base models in model stacking. the lr model is also set as the meta classifier in the final prediction. the stacking model can achieve 90.9% accuracy, which is higher than all the single models. the result also shows that model stacking effectively improves model performance.","['mineral microscopic images using ensemble machine learning algorithms', 'intelligent identification', 'rock']"
"alternative pre-mrna splicing (as) is prevalent in plants and is involved in many interactions between plants and environmental stresses. however, the patterns and underlying mechanisms of as evolution in plants remain unclear. by analyzing the transcriptomes of four eudicot species, we revealed that the divergence of as is largely due to the gains and losses of as events among orthologous genes. furthermore, based on a subset of as, in which as can be directly associated with specific transcripts, we found that as that generates transcripts containing premature termination codons (ptc), are likely more conserved than those that generate non-ptc containing transcripts. this suggests that as coupled with nonsense-mediated decay (nmd) might play an important role in affecting mrna levels post-transcriptionally. to understand the mechanisms underlying the divergence of as, we analyzed the key determinants of as using a machine learning approach. we found that the presence/absence of alternative splice site (ss) within the junction, the distance between the authentic ss and the nearest alternative ss, the size of exon-exon junctions were the major determinants for both alternative 5' donor site and 3' acceptor site among the studied species, suggesting a relatively conserved as mechanism. the comparative analysis further demonstrated that variations of the identified as determinants significantly contributed to the as divergence among closely related species in both solanaceae and brassicaceae taxa. together, these results provide detailed insights into the evolution of as in plants.","['alternative splicing', 'evolution', 'eudicots']"
"protein-protein interactions are closely relevant to protein function and drug discovery. hence, accurately identifying protein-protein interactions will help us to understand the underlying molecular mechanisms and significantly facilitate the drug discovery. however, the majority of existing computational methods for protein-protein interactions prediction are focused on the feature extraction and combination of features and there have been limited gains from the state-of-the-art models. in this work, a new residue representation method named res2vec is designed for protein sequence representation. residue representations obtained by res2vec describe more precisely residue-residue interactions from raw sequence and supply more effective inputs for the downstream deep learning model. combining effective feature embedding with powerful deep learning techniques, our method provides a general computational pipeline to infer protein-protein interactions, even when protein structure knowledge is entirely unknown. the proposed method deepfe-ppi is evaluated on the s. cerevisiae and human datasets. the experimental results show that deepfe-ppi achieves 94.78% (accuracy), 92.99% (recall), 96.45% (precision), 89.62% (matthew's correlation coefficient, mcc) and 98.71% (accuracy), 98.54% (recall), 98.77% (precision), 97.43% (mcc), respectively. in addition, we also evaluate the performance of deepfe-ppi on five independent species datasets and all the results are superior to the existing methods. the comparisons show that deepfe-ppi is capable of predicting protein-protein interactions by a novel residue representation method and a deep learning classification framework in an acceptable level of accuracy. the codes along with instructions to reproduce this work are available from https://github.com/xal2019/deepfe-ppi.","['protein interaction prediction', 'feature embedding', 'deep learning', 'protein', 'integration']"
a deep learning system (dls) that could automatically detect glaucomatous optic neuropathy (gon) with high sensitivity and specificity could expedite screening for gon.,"['detect glaucomatous optic neuropathy using fundus photographs', 'deep learning system', 'validation', 'development']"
"patients with migraine show an increased presence of white matter hyperintensities (wmhs), especially deep wmhs. segmentation of small, deep wmhs is a critical issue in managing migraine care. here, we aim to develop a novel approach to segmenting deep wmhs using deep neural networks based on the u-net.","['step deep neural network', 'deep white matter hyperintensities', 'two', 'segmentation', 'migraineurs']"
"the lack of the sufficient and diverse training data is one of the main challenges limiting performances of the machine learning enabled applications in optical networks. here, we propose a deep learning based sequential data augmentation technique for the aggregate traffic data augmentation for diverse optical network scenarios. a generative adversarial network (gan) model is trained with the experimental traffic data to automatically extract the substantial characteristics of the experimental traffic data through the zero-sum game theory and then augment the traffic data adaptively. the statistical evaluation parameters of the augmented traffic are mean, variance and hurst exponent. to add comparisons, two other classical generative models including the statistical parameter configuration (spc) model and the variational autoencoder (vae) model are also adopted to generate the traffic data that are similar to the actual traffic data. the comprehensive comparisons among the proposed gan, the spc and vae show that the performances of the gan exceed those of the spc and the vae obviously. the mean and the variance of the augmented traffic data from the gan are almost equal to those of the experimental traffic data, where the average deviations are both within 2%. the hurst exponent of the augmented traffic data from the gan is respectively near 90% and 96% of those of the experimental traffic data in the access network and the core network. to estimate the similarity intuitively, the well-known k-mean algorithm is used to cluster the augmented traffic data according to the centroids determined by the corresponding experimental traffic data and the clustering accuracies are all higher than 95% for 6 kinds of typical traffic types in the optical networks. these results demonstrate that the proposed gan is able to effectively generate the traffic data that is very close to the experimental traffic data and is difficult to be distinguished for diverse traffic types. moreover, a relatively small dataset with a few hundred pieces of experimental traffic data is required and the amount of the augmented traffic data from the gan is unlimited in theory, which can be augmented as much as we need. the proposed traffic data augmentation technique also has the potential to be utilized in other sequential data augmentation applications for the optical networks.","['deep learning based adaptive sequential data augmentation technique', 'optical network traffic synthesis']"
"the ability to predict the interaction of drugs with target proteins is essential to research and development of drug. however, the traditional experimental paradigm is costly, and previous in silico prediction paradigms have been impeded by the wide range of data platforms and data scarcity.","['based transcriptome data classification', 'target interaction prediction', 'deep learning', 'drug']"
"despite rapid advances in sequencing technologies, accurately calling genetic variants present in an individual genome from billions of short, errorful sequence reads remains challenging. here we show that a deep convolutional neural network can call genetic variation in aligned next-generation sequencing read data by learning statistical relationships between images of read pileups around putative variant and true genotype calls. the approach, called deepvariant, outperforms existing state-of-the-art tools. the learned model generalizes across genome builds and mammalian species, allowing nonhuman sequencing projects to benefit from the wealth of human ground-truth data. we further show that deepvariant can learn to call variants in a variety of sequencing technologies and experimental designs, including deep whole genomes from 10x genomics and ion ampliseq exomes, highlighting the benefits of using more automated and generalizable techniques for variant calling.","['indel variant caller using deep neural networks', 'universal snp', 'small']"
"the neonatal period of a child is considered the most crucial phase of its physical development and future health. as per the world health organization, india has the highest number of pre-term births [","['5 million babies born prematurely', 'optimize neural network architectures', 'neonatal intensive care unit', 'intensive care units', 'time medical data', 'optimizing learning models', 'maximize predictive performance', 'low birth weights', 'study attempts', 'resultant complexity', 'primary concern', 'metabolic disorders', 'highly prone', 'first week', 'apneic episodes', 'babies', 'sepsis', 'real', 'prediction', 'predict']"
"recently, snake-like robots are proposed to assist experts during medical procedures on internal organs via natural orifices. despite their well-spelt advantages, applications in radiosurgery is still hindered by absence of suitable designs required for spatial navigations within clustered and confined parts of human body, and inexistence of precise and fast inverse kinematics (ik) models. in this study, a deeply-learnt damped least squares method is proposed for solving ik of spatial snake-like robot. the robot's model consists of several modules, and each module has a pair of serial-links connected with orthogonal twists. for precise control of the robot's end-effector, damped least-squares approach is used to minimize error magnitude in a function modeled over analytical jacobian of the robot. this is iteratively done until an apt joint vector needed to converge the robot to desired positions is obtained. for fast control and singularity avoidance, a deep network is built for prediction of unique damping factor required for each target point in the robot's workspace. the deep network consists of 11 x 15 array of neurons at the hidden layer, and deeply-learnt with a huge dataset of 877,500 data points generated from workspace of the snake robot. implementation results for both simulated and actual prototype of an eight-link model of the robot show the effectiveness of the proposed ik method. with error tolerance of 0.01\xa0mm, the proposed method has a very high reachability measure of 91.59% and faster mean execution time of 9.20 (±16.92) ms for convergence. in addition, the method requires an average of 33.02 (±39.60) iterations to solve the ik problem. hence, approximately 3.6 iterations can be executed in 1 ms. evaluation against popularly used ik methods shows that the proposed method has very good performance in terms of accuracy and speed, simultaneously.","['learnt damped least', 'squares', 'dl', 'deeply']"
"artificial intelligence (ai) applications have already invaded our everyday life, and the last 10 years have seen the emergence of very promising applications in the field of medicine. however, the literature dealing with the potential applications of ia in orthognathic surgery is remarkably poor to date. yet, it is very likely that due to its amazing power in image recognition ai will find tremendous applications in dento-facial deformities recognition in a near future. in this article, we point out the state-of-the-art ai applications in medicine and its potential applications in the field of orthognathic surgery. ai is a very powerful tool and it is the responsibility of the entire medical profession to achieve a positive symbiosis between clinical sense and ai.","['orthognathic surgery', 'artificial intelligence', 'applications']"
"a novel framework for the classification of lung nodules using computed tomography scans is proposed in this article. to get an accurate diagnosis of the detected lung nodules, the proposed framework integrates the following 2 groups of features: (1) appearance features modeled using the higher order markov gibbs random field model that has the ability to describe the spatial inhomogeneities inside the lung nodule and (2) geometric features that describe the shape geometry of the lung nodules. the novelty of this article is to accurately model the appearance of the detected lung nodules using a new developed seventh-order markov gibbs random field model that has the ability to model the existing spatial inhomogeneities for both small and large detected lung nodules, in addition to the integration with the extracted geometric features. finally, a deep autoencoder classifier is fed by the above 2 feature groups to distinguish between the malignant and benign nodules. to evaluate the proposed framework, we used the publicly available data from the lung image database consortium. we used a total of 727 nodules that were collected from 467 patients. the proposed system demonstrates the promise to be a valuable tool for the detection of lung cancer evidenced by achieving a nodule classification accuracy of 91.20%.","['generalized deep learning', 'based diagnostic system', 'various types', 'pulmonary nodules', 'early diagnosis']"
"transvaginal ultrasound imaging provides useful information for diagnosing endometrial pathologies and reproductive health. endometrium segmentation in transvaginal ultrasound (tvus) images is very challenging due to ambiguous boundaries and heterogeneous textures. in this study, we developed a new segmentation framework which provides robust segmentation against ambiguous boundaries and heterogeneous textures of tvus images.","['transvaginal ultrasound image using key', 'point discriminator', 'endometrium segmentation']"
"macroautophagy/autophagy functions as a quality control mechanism by degrading misfolded proteins and damaged organelles and plays an essential role in maintaining neural homeostasis. the phosphoinositide phosphatidylinositol-3-phosphate (ptdins3p) effector atg18 is essential for autophagosome formation in yeast. mammalian cells contain four atg18\xa0homologs, belonging to two subclasses, wipi1 (wd repeat domain, phosphoinositide interacting 1), wipi2 and wdr45b/wipi3 (wd repeat domain 45b), wdr45/wipi4. the role of wdr45b in autophagy and in neural homeostasis, however, remains unknown. recent human genetic studies have revealed a potential causative role of wdr45b in intellectual disability. here we demonstrated that mice deficient in wdr45b exhibit motor deficits and learning and memory defects. histological analysis reveals that wdr45b knockout (ko) mice exhibit a large number of swollen axons and show cerebellar atrophy. sqstm1- and ubiquitin-positive aggregates, which are autophagy substrates, accumulate in various brain regions in wdr45b ko mice. double ko mice, wdr45b and wdr45, die within one day after birth and exhibit more severe autophagy defects than either of the single ko mice, suggesting that these two genes act cooperatively in autophagy. our studies demonstrated that wdr45b is critical for neural homeostasis in mice. the wdr45b ko mice provide a model to study the pathogenesis of intellectual disability.abbreviations: acsf: artificial cerebrospinal fluid; amc: aminomethylcoumarin; bpan: beta-propeller protein-associated neurodegeneration; calb1: calbindin 1; cns: central nervous system; dcn: deep cerebellar nuclei; fepsp: field excitatory postsynaptic potential; ic: internal capsule; id: intellectual disability; ish: in situ hybridization; ko: knockout; ltp: long-term potentiation; mbp: myelin basic protein; mgp: medial globus pallidus; ptdins3p: phosphoinositide phosphatidylinositol-3-phosphate; wdr45b: wd repeat domain 45b; wipi1: wd repeat domain, phosphoinositide interacting 1; wt: wild type.","['maintaining neural autophagy', 'cognitive function', 'wdr45b', 'role']"
"echocardiography has a central role in the diagnosis and management of cardiovascular disease. precise and reliable echocardiographic assessment is required for clinical decision-making. even if the development of new technologies (3-dimentional echocardiography, speckle-tracking, semi-automated analysis, etc.), the final decision on analysis is strongly dependent on operator experience. diagnostic errors are a major unresolved problem. moreover, not only can cardiologists differ from one another in image interpretation, but also the same observer may come to different findings when a reading is repeated. daily high workloads in clinical practice may lead to this error, and all cardiologists require precise perception in this field. artificial intelligence (ai) has the potential to improve analysis and interpretation of medical images to a new stage compared with previous algorithms. from our comprehensive review, we believe ai has the potential to improve accuracy of diagnosis, clinical management, and patient care. although there are several concerns about the required large dataset and ""black box"" algorithm, ai can provide satisfactory results in this field. in the future, it will be necessary for cardiologists to adapt their daily practice to incorporate ai in this new stage of echocardiography.","['artificial intelligence', 'utilization', 'echocardiography']"
our objective is to develop algorithms for encoding clinical text into representations that can be used for a variety of phenotyping tasks.,"['clinical natural language processing', 'clinical text encoder', 'substance misuse', 'toward', 'pretraining', 'applications']"
"in this paper, we propose a novel multitask learning method based on the deep convolutional network. the proposed deep network has four convolutional layers, three max-pooling layers, and two parallel fully connected layers. to adjust the deep network to multitask learning problem, we propose to learn a low-rank deep network so that the relation among different tasks can be explored. we proposed to minimize the number of independent parameter rows of one fully connected layer to explore the relations among different tasks, which is measured by the nuclear norm of the parameter of one fully connected layer, and seek a low-rank parameter matrix. meanwhile, we also propose to regularize another fully connected layer by sparsity penalty so that the useful features learned by the lower layers can be selected. the learning problem is solved by an iterative algorithm based on gradient descent and back-propagation algorithms. the proposed algorithm is evaluated over benchmark datasets of multiple face attribute prediction, multitask natural language processing, and joint economics index predictions. the evaluation results show the advantage of the low-rank deep cnn model over multitask problems.","['rank deep convolutional neural network', 'multitask learning', 'low']"
"acoustic analysis of voice has the potential to expedite detection and diagnosis of voice disorders. applying an image-based, neural-network approach to analyzing the acoustic signal may be an effective means for detecting and differentially diagnosing voice disorders. the purpose of this study is to provide a proof-of-concept that embedded data within human phonation can be accurately and efficiently decoded with deep learning neural network analysis to differentiate between normal and disordered voices.","['decoding phonation', 'artificial intelligence', 'dep']"
"in times of rapid global change, anticipating vegetation changes and assessing their impacts is of key relevance to managers and policy makers. yet, predicting vegetation dynamics often suffers from an inherent scale mismatch, with abundant data and process understanding being available at a fine spatial grain, but the relevance for decision-making is increasing with spatial extent.we present a novel approach for scaling vegetation dynamics (svd), using deep learning to predict vegetation transitions. vegetation is discretized into a large number (103-106) of potential states based on its structure, composition and functioning. transition probabilities between states are estimated via a deep neural network (dnn) trained on observed or simulated vegetation transitions in combination with environmental variables. the impact of vegetation transitions on important ecological indicators is quantified by probabilistically linking attributes such as carbon storage and biodiversity to vegetation states.here, we describe the svd approach and present results of applying the framework in a meta-modelling context. we trained a dnn using simulations of a process-based forest landscape model for a complex mountain forest landscape under different climate scenarios. subsequently, we evaluated the ability of svd to project long-term vegetation dynamics and the resulting changes in forest carbon storage and biodiversity. svd captured spatial (e.g. elevational gradients) and temporal (e.g. species succession) patterns of vegetation dynamics well, and responded realistically to changing environmental conditions. in addition, we tested the computational efficiency of the approach, highlighting the utility of svd for country- to continental scale applications. svd is the-to our knowledge-first vegetation model harnessing deep neural networks. the approach has high predictive accuracy and is able to generalize well beyond training data. svd was designed to run on widely available input data (e.g. vegetation states defined from remote sensing, gridded global climate datasets) and exceeds the computational performance of currently available highly optimized landscape models by three to four orders of magnitude. we conclude that svd is a promising approach for combining detailed process knowledge on fine-grained ecosystem processes with the increasingly available big ecological datasets for improved large-scale projections of vegetation dynamics.","['vegetation transitions using deep neural networks', 'scalable model']"
"accuracy of current efficacy judgment methods for nanoformulated drug remains unstable due to the interference of nanocarriers. herein, deepscreen, a drug screening system utilizing convolutional neural network based on flow cytomerty single-cell images, is introduced. compared to existing experimental approaches, the high-throughput system has superior precision, rapidity, and anti-interference, and is cost-cutting with high accuracy. first, it can resist most disturbances from manual factors of complicated evaluation progress. in addition, class activation maps generated from deepscreen indicate that it may identify and locate the tiny variation from cell apoptosis and slight changes of cellular period caused by drug or even nanoformulated drug action at very early stages. more importantly, the excellent performance of assessment on two types of nanoformulations and fluorescent drug proves the fine generality and anti-interference of this novel system. all these privileged performances make deepscreen a very smart and promising system for drug detection.","['interference screening approach', 'nanoformulated medication', 'deep learning', 'rapid', 'deepscreen', 'anti', 'accurate']"
"the success of deep networks and recent industry involvement in brain-inspired computing is igniting a widespread interest in neuromorphic hardware that emulates the biological processes of the brain on an electronic substrate. this review explores interdisciplinary approaches anchored in machine learning theory that enable the applicability of neuromorphic technologies to real-world, human-centric tasks. we find that (1) recent work in binary deep networks and approximate gradient descent learning are strikingly compatible with a neuromorphic substrate; (2) where real-time adaptability and autonomy are necessary, neuromorphic technologies can achieve significant advantages over main-stream ones; and (3) challenges in memory technologies, compounded by a tradition of bottom-up approaches in the field, block the road to major breakthroughs. we suggest that a neuromorphic learning framework, tuned specifically for the spatial and temporal constraints of the neuromorphic substrate, will help guiding hardware algorithm co-design and deploying neuromorphic hardware for proactive learning of real-world data.","['power efficient intelligence', 'neuromorphic learning machines', 'data']"
"geometric features, such as the topological and manifold properties, are utilized to extract geometric properties. geometric methods that exploit the applications of geometrics, e.g., geometric features, are widely used in computer graphics and computer vision problems. this review presents a literature review on geometric concepts, geometric methods, and their applications in human-related analysis, e.g., human shape analysis, human pose analysis, and human action analysis. this review proposes to categorize geometric methods based on the scope of the geometric properties that are extracted: object-oriented geometric methods, feature-oriented geometric methods, and routine-based geometric methods. considering the broad applications of deep learning methods, this review also studies geometric deep learning, which has recently become a popular topic of research. validation datasets are collected, and method performances are collected and compared. finally, research trends and possible research topics are discussed.","['related analysis', 'literature review', 'geometric methods', 'human', 'applications']"
"automated clinical phenotyping is challenging because word-based features quickly turn it into a high-dimensional problem, in which the small, privacy-restricted, training datasets might lead to overfitting. pretrained embeddings might solve this issue by reusing input representation schemes trained on a larger dataset. we sought to evaluate shallow and deep learning text classifiers and the impact of pretrained embeddings in a small clinical dataset.","['2018 n2c2 shared task', 'deep learning strategies', 'clinical text classification', 'evaluating shallow']"
"deep learning has shown remarkable improvements in the analysis of medical images without the need for engineered features. in this work, we hypothesize that deep learning is complementary to traditional feature estimation. we propose a network design to include traditional structural imaging features alongside deep convolutional ones and illustrate this approach on the task of imaging-based age prediction in two separate contexts: t1-weighted brain magnetic resonance imaging (mri) (n\u202f=\u202f5121, ages 4-96, healthy controls) and computed tomography (ct) of the head (n\u202f=\u202f1313, ages 1-97, healthy controls). in brain mri, we can predict age with a mean absolute error of 4.08\u202fyears by combining raw images along with engineered structural features, compared to 5.00\u202fyears using image-derived features alone and 8.23\u202fyears using structural features alone. in head ct, we can predict age with a median absolute error of 9.99\u202fyears combining features, compared to 11.02\u202fyears with image-derived features alone and 13.28\u202fyears with structural features alone. these results show that we can complement traditional feature estimation using deep learning to improve prediction tasks. as the field of medical image processing continues to integrate deep learning, it will be important to use the new techniques to complement traditional imaging features instead of fully displacing them.","['anatomical context improves deep learning', 'brain age estimation task']"
"deep learning algorithms and in particular convolutional networks have shown tremendous success in medical image analysis applications, though relatively few methods have been applied to infant mri data due numerous inherent challenges such as inhomogenous tissue appearance across the image, considerable image intensity variability across the first year of life, and a low signal to noise setting. this paper presents methods addressing these challenges in two selected applications, specifically infant brain tissue segmentation at the isointense stage and presymptomatic disease prediction in neurodevelopmental disorders. corresponding methods are reviewed and compared, and open issues are identified, namely low data size restrictions, class imbalance problems, and lack of interpretation of the resulting deep learning solutions. we discuss how existing solutions can be adapted to approach these issues as well as how generative models seem to be a particularly strong contender to address them.","['infant brain mri analysis', 'deep learning', 'role']"
"in radiation therapy, the accurate delineation of gross tumor volume (gtv) is crucial for treatment planning. however, it is challenging for head and neck cancer (hnc) due to the morphology complexity of various organs in the head, low targets to background contrast and potential artifacts on conventional planning ct images. thus, manual delineation of gtv on anatomical images is extremely time consuming and suffers from inter-observer variability that leads to planning uncertainty. with the wide use of pet/ct imaging in oncology, complementary functional and anatomical information can be utilized for tumor contouring and bring a significant advantage for radiation therapy planning. in this study, by taking advantage of multi-modality pet and ct images, we propose an automatic gtv segmentation framework based on deep learning for hnc. the backbone of this segmentation framework is based on 3d convolution with dense connections which enables a better information propagation and takes full advantage of the features extracted from multi-modality input images. we evaluate our proposed framework on a dataset including 250 hnc patients. each patient receives both planning ct and pet/ct imaging before radiation therapy (rt). manually delineated gtv contours by radiation oncologists are used as ground truth in this study. to further investigate the advantage of our proposed dense-net framework, we also compared with the framework using 3d u-net which is the state-of-the-art in segmentation tasks. meanwhile, for each frame, the performance comparison between single modality input (pet or ct image) and multi-modality input (both pet/ct) is conducted. dice coefficient, mean surface distance (msd), 95th-percentile hausdorff distance (hd95) and displacement of mass centroid (dmc) are calculated for quantitative evaluation. the dataset is split into train (140 patients), validation (35 patients) and test (75 patients) groups to optimize the network. based on the results on independent test group, our proposed multi-modality dense-net (dice 0.73) shows better performance than the compared network (dice 0.71). furthermore, the proposed dense-net structure has less trainable parameters than the 3d u-net, which reduces the prediction variability. in conclusion, our proposed multi-modality dense-net can enable satisfied gtv segmentation for hnc using multi-modality images and yield superior performance than conventional methods. our proposed method provides an automatic, fast and consistent solution for gtv segmentation and shows potentials to be generally applied for radiation therapy planning of a variety of cancer (e.g. lung, sarcoma, liver and so on).","['neck cancer radiotherapy using deep dense multi', 'gross tumor volume segmentation', 'modality network', 'head']"
"in recent months, multiple publications have demonstrated the use of convolutional neural networks (cnn) to classify images of skin cancer as precisely as dermatologists. however, these cnns failed to outperform the international symposium on biomedical imaging (isbi) 2016 challenge which ranked the average precision for classification of dermoscopic melanoma images. accordingly, the technical progress represented by these studies is limited. in addition, the available reports are impossible to reproduce, due to incomplete descriptions of training procedures and the use of proprietary image databases or non-disclosure of used images. these factors prevent the comparison of various cnn classifiers in equal terms.","['enhanced classifier training', 'convolutional neural network', 'skin lesions', 'improve precision', 'identify images']"
"automatic segmentation of retinal images is an important task in computer-assisted medical image analysis for the diagnosis of diseases such as hypertension, diabetic and hypertensive retinopathy, and arteriosclerosis. among the diseases, diabetic retinopathy, which is the leading cause of vision detachment, can be diagnosed early through the detection of retinal vessels. the manual detection of these retinal vessels is a time-consuming process that can be automated with the help of artificial intelligence with deep learning. the detection of vessels is difficult due to intensity variation and noise from non-ideal imaging. although there are deep learning approaches for vessel segmentation, these methods require many trainable parameters, which increase the network complexity. to address these issues, this paper presents a dual-residual-stream-based vessel segmentation network (vess-net), which is not as deep as conventional semantic segmentation networks, but provides good segmentation with few trainable parameters and layers. the method takes advantage of artificial intelligence for semantic segmentation to aid the diagnosis of retinopathy. to evaluate the proposed vess-net method, experiments were conducted with three publicly available datasets for vessel segmentation: digital retinal images for vessel extraction (drive), the child heart health study in england (chase-db1), and structured analysis of retina (stare). experimental results show that vess-net achieved superior performance for all datasets with sensitivity (se), specificity (sp), area under the curve (auc), and accuracy (acc) of 80.22%, 98.1%, 98.2%, and 96.55% for drvie; 82.06%, 98.41%, 98.0%, and 97.26% for chase-db1; and 85.26%, 97.91%, 98.83%, and 96.97% for stare dataset.","['hypertensive retinopathy using artificial intelligence', 'based semantic segmentation', 'diagnosis', 'diabetic', 'aiding']"
"noninvasive behavioral tracking of animals during experiments is critical to many scientific pursuits. extracting the poses of animals without using markers is often essential to measuring behavioral effects in biomechanics, genetics, ethology, and neuroscience. however, extracting detailed poses without markers in dynamically changing backgrounds has been challenging. we recently introduced an open-source toolbox called deeplabcut that builds on a state-of-the-art human pose-estimation algorithm to allow a user to train a deep neural network with limited training data to precisely track user-defined features that match human labeling accuracy. here, we provide an updated toolbox, developed as a python package, that includes new features such as graphical user interfaces (guis), performance improvements, and active-learning-based network refinement. we provide a step-by-step procedure for using deeplabcut that guides the user in creating a tailored, reusable analysis pipeline with a graphical processing unit (gpu) in 1-12 h (depending on frame size). additionally, we provide docker environments and jupyter notebooks that can be run on cloud resources such as google colaboratory.","['3d markerless pose estimation across species', 'using deeplabcut', 'behaviors']"
"a novel method to detect and classify several classes of diseased and healthy lung tissue in ct (computed tomography), based on the fusion of riesz and deep learning features, is presented. first, discriminative parametric lung tissue texture signatures are learned from riesz representations using a one-versus-one approach. the signatures are generated for four diseased tissue types and a healthy tissue class, all of which frequently appear in the publicly available interstitial lung diseases (ild) dataset used in this article. because the riesz wavelets are steerable, they can easily be made invariant to local image rotations, a property that is desirable when analyzing lung tissue micro-architectures in ct images. second, features from deep convolutional neural networks (cnn) are computed by fine-tuning the inception v3 architecture using an augmented version of the same ild dataset. because cnn features are both deep and non-parametric, they can accurately model virtually any pattern that is useful for tissue discrimination, and they are the de facto standard for many medical imaging tasks. however, invariance to local image rotations is not explicitly implemented and can only be approximated with rotation-based data augmentation. this motivates the fusion of riesz and deep cnn features, as the two techniques are very complementary. the two learned representations are combined in a joint softmax model for final classification, where early and late feature fusion schemes are compared. the experimental results show that a late fusion of the independent probabilities leads to significant improvements in classification performance when compared to each of the separate feature representations and also compared to an ensemble of deep learning approaches.","['lung tissue classification', 'fusing learned representations', 'riesz filters', 'deep cnn']"
"forms of artificial intelligence (ai), like deep learning algorithms and neural networks, are being intensely explored for novel healthcare applications in areas such as imaging and diagnoses, risk analysis, lifestyle management and monitoring, health information management, and virtual health assistance. expected benefits in these areas are wide-ranging and include increased speed in imaging, greater insight into predictive screening, and decreased healthcare costs and inefficiency. however, ai-based clinical tools also create a host of situations wherein commonly-held values and ethical principles may be challenged. in this short column, we highlight three potentially problematic aspects of ai use in healthcare: (1) dynamic information and consent, (2) transparency and ownership, and (3) privacy and discrimination. we discuss their impact on patient/client, clinician, and health institution values and suggest ways to tackle this impact. we propose that ai-related ethical challenges may represent an opportunity for growth in organizations.","['healthcare uses', 'artificial intelligence', 'opportunities', 'growth', 'challenges']"
"a variety of simple models has been proposed to understand the collective motion of animals. these models can be insightful but may lack important elements necessary to predict the motion of each individual in the collective. adding more detail increases predictability but can make models too complex to be insightful. here we report that deep attention networks can obtain a model of collective behavior that is simultaneously predictive and insightful thanks to an organization in modules. when using simulated trajectories, the model recovers the ground-truth interaction rule used to generate them, as well as the number of interacting neighbours. for experimental trajectories of large groups of 60-100 zebrafish, danio rerio, the model obtains that interactions between pairs can approximately be described as repulsive, attractive or as alignment, but only when moving slowly. at high velocities, interactions correspond only to alignment or alignment mixed with repulsion at close distances. the model also shows that each zebrafish decides where to move by aggregating information from the group as a weighted average over neighbours. weights are higher for neighbours that are close, in a collision path or moving faster in frontal and lateral locations. the network also extracts that the number of interacting individuals is dynamical and typically in the range 8-22, with 1-10 more important ones. our results suggest that each animal decides by dynamically selecting information from the collective.","['deep attention networks reveal', 'collective motion', 'zebrafish', 'rules']"
"cancer is a genetic disease comprising multiple subtypes that have distinct molecular characteristics and clinical features. cancer subtyping helps in improving personalized treatment and making decision, as different cancer subtypes respond differently to the treatment. the increasing availability of cancer related genomic data provides the opportunity to identify molecular subtypes. several unsupervised machine learning techniques have been applied on molecular data of the tumor samples to identify cancer subtypes that are genetically and clinically distinct. however, most clustering methods often fail to efficiently cluster patients due to the challenges imposed by high-throughput genomic data and its non-linearity. in this paper, we propose a pathway-based deep clustering method (pacl) for molecular subtyping of cancer, which incorporates gene expression and biological pathway database to group patients into cancer subtypes. the main contribution of our model is to discover high-level representations of biological data by learning complex hierarchical and nonlinear effects of pathways. we compared the performance of our model with a number of benchmark clustering methods that recently have been proposed in cancer subtypes. we assessed the hypothesis that clusters (subtypes) may be associated to different survivals by logrank tests. pacl showed the lowest p-value of the logrank test against the benchmark methods. it demonstrates the patient groups clustered by pacl may correspond to subtypes which are significantly associated with distinct survival distributions. moreover, pacl provides a solution to comprehensively identify subtypes and interpret the model in the biological pathway level. the open-source software of pacl in pytorch is publicly available at https://github.com/tmallava/pacl.","['based deep clustering', 'molecular subtyping', 'pathway', 'cancer']"
"we present a quantitative study of the performance of two automatic methods for the early detection of ovarian cancer that can exploit longitudinal measurements of multiple biomarkers. the study is carried out for a subset of the data collected in the uk collaborative trial of ovarian cancer screening (ukctocs). we use statistical analysis techniques, such as the area under the receiver operating characteristic (roc) curve, for evaluating the performance of two techniques that aim at the classification of subjects as either healthy or suffering from the disease using time-series of multiple biomarkers as inputs. the first method relies on a bayesian hierarchical model that establishes connections within a set of clinically interpretable parameters. the second technique is a purely discriminative method that employs a recurrent neural network (rnn) for the binary classification of the inputs. for the available dataset, the performance of the two detection schemes is similar (the area under roc curve is 0.98 for the combination of three biomarkers) and the bayesian approach has the advantage that its outputs (parameters estimates and their uncertainty) can be further analysed by a clinical expert.","['two automatic methods', 'quantitative performance study', 'ovarian cancer', 'diagnosis']"
"selecting particles from digital micrographs is an essential step in single-particle electron cryomicroscopy (cryo-em). as manual selection of complete datasets-typically comprising thousands of particles-is a tedious and time-consuming process, numerous\xa0automatic particle pickers have been developed. however, non-ideal datasets pose a challenge to particle picking. here we present the\xa0particle picking software cryolo which is based on the deep-learning object detection system you only look once (yolo). after training the network with 200-2500 particles per dataset it automatically recognizes particles with high recall and precision while\xa0reaching a speed of up to five micrographs per second. further, we present a general\xa0cryolo network able\xa0to pick from previously unseen datasets, allowing for completely automated on-the-fly cryo-em data preprocessing during data acquisition. cryolo is available as a standalone program under http://sphire.mpg.de/ and is distributed as\xa0part of the image processing workflow in sphire.","['accurate fully automated particle picker', 'sphire', 'fast', 'em', 'cryolo', 'cryo']"
"artur yakimovich works in the field of computational virology and applies machine learning algorithms to study host-pathogen interactions. in this msphere of influence article, he reflects on two papers ""holographic deep learning for rapid optical screening of anthrax spores"" by jo et al. (y. jo, s. park, j. jung, j. yoon, et al., sci adv 3:e1700606, 2017, https://doi.org/10.1126/sciadv.1700606) and ""bacterial colony counting with convolutional neural networks in digital microbiology imaging"" by ferrari and colleagues (a. ferrari, s. lombardi, and a. signoroni, pattern recognition 61:629-640, 2017, https://doi.org/10.1016/j.patcog.2016.07.016). here he discusses how these papers made an impact on him by showcasing that artificial intelligence algorithms can be equally applicable to both classical infection biology techniques and cutting-edge label-free imaging of pathogens.","['infection biology', 'artificial intelligence', 'rise', 'msphere', 'influence']"
"that this camera-based method is sparking debate regarding its applicability to specific-species is a symptom of the complexity of wildlife assessment in light of the increasing, unprecedented amount of ecological-data, this task requires strengthening links between theorists and empiricists to profit the new opportunities offered by the method.","['abolaffio et al', 'response', '201']"
"facetto is a scalable visual analytics application that is used to discover single-cell phenotypes in high-dimensional multi-channel microscopy images of human tumors and tissues. such images represent the cutting edge of digital histology and promise to revolutionize how diseases such as cancer are studied, diagnosed, and treated. highly multiplexed tissue images are complex, comprising 109 or more pixels, 60-plus channels, and millions of individual cells. this makes manual analysis challenging and error-prone. existing automated approaches are also inadequate, in large part, because they are unable to effectively exploit the deep knowledge of human tissue biology available to anatomic pathologists. to overcome these challenges, facetto enables a semi-automated analysis of cell types and states. it integrates unsupervised and supervised learning into the image and feature exploration process and offers tools for analytical provenance. experts can cluster the data to discover new types of cancer and immune cells and use clustering results to train a convolutional neural network that classifies new cells accordingly. likewise, the output of classifiers can be clustered to discover aggregate patterns and phenotype subsets. we also introduce a new hierarchical approach to keep track of analysis steps and data subsets created by users; this assists in the identification of cell types. users can build phenotype trees and interact with the resulting hierarchical structures of both high-dimensional feature and image spaces. we report on use-cases in which domain scientists explore various large-scale fluorescence imaging datasets. we demonstrate how facetto assists users in steering the clustering and classification process, inspecting analysis results, and gaining new scientific insights into cancer biology.","['hierarchical phenotype analysis', 'channel image data', 'supervised learning', 'combining unsupervised', 'multi', 'facetto']"
"deep learning models for semantic segmentation of images require large amounts of data. in the medical imaging domain, acquiring sufficient data is a significant challenge. labeling medical image data requires expert knowledge. collaboration between institutions could address this challenge, but sharing medical data to a centralized location faces various legal, privacy, technical, and data-ownership challenges, especially among international institutions. in this study, we introduce the first use of federated learning for multi-institutional collaboration, enabling deep learning modeling without sharing patient data. our quantitative results demonstrate that the performance of federated semantic segmentation models (dice=0.852) on multimodal brain scans is similar to that of models trained by sharing data (dice=0.862). we compare federated learning with two alternative collaborative learning methods and find that they fail to match the performance of federated learning.","['institutional deep learning modeling without sharing patient data', 'brain tumor segmentation', 'feasibility study', 'multi']"
"decision-making in the mammalian brain typically involves multiple brain structures within the midbrain, thalamus, striatum, limbic system, and cortex. although task specific contributions of each brain region have been identified, neurons responding to reinforcement have been found throughout these structures. we sought to determine if any brain area, or cluster of areas, are the source of information, and if the fidelity of information varies among the areas. we recorded simultaneous field potentials (fps) in rats from seven brain regions as they completed a binary choice task. the fps of a 0.5\u202fs window following reinforcement were given as input to a classifier that attempted to predict whether or not the rat received reward on each trial. the classifier correctly categorized reward on 77% of trials. any region-specific signal could be omitted without lowering accuracy. frequencies above 40\u202fhz and signals recorded later than 0.25\u202fs following reinforcement were necessary to achieve this accuracy. further, the classifier was able to predict reinforcement outcome above chance levels when using fps from any single recorded brain region. some combinations of structures, however, were more predictive than others. analysis of fps prior to reward revealed most regions reflected the prior probability of reward. lastly, analyses of information flow suggested reinforcement information does not originate within a single structure of the network, within the resolution afforded by fp recordings. these data suggest reward delivery information is rapidly distributed non-uniformly across the network, and there is no canonical flow of information about reward events in the recorded structures.","['rat cortico', 'limbic networks', 'distributed encoding', 'striatal', 'reinforcement']"
"video recording is now ubiquitous in the study of animal behavior, but its analysis on a large scale is prohibited by the time and resources needed to manually process large volumes of data. we present a deep convolutional neural network (cnn) approach that provides a fully automated pipeline for face detection, tracking, and recognition of wild chimpanzees from long-term video records. in a 14-year dataset yielding 10 million face images from 23 individuals over 50 hours of footage, we obtained an overall accuracy of 92.5% for identity recognition and 96.2% for sex recognition. using the identified faces, we generated co-occurrence matrices to trace changes in the social network structure of an aging population. the tools we developed enable easy processing and annotation of video datasets, including those from other species. such automated analysis unveils the future potential of large-scale longitudinal video archives to address fundamental questions in behavior and conservation.","['wild using deep learning', 'chimpanzee face recognition', 'videos']"
"incorporating the knowledge encoded in the unified medical language system (umls) in deep learning methods requires learning knowledge embeddings from the knowledge graphs available in umls: the metathesaurus and the semantic network. in this paper we present a technique using generative adversarial networks (gans) for learning umls embeddings and showcase their usage in a clinical prediction model. when the umls embeddings are available, the predictions improve by up to 6.9% absolute f1 score.","['unified medical language system', 'knowledge embeddings', 'adversarial learning']"
"manually tracing regions of interest (rois) within the liver is the de facto standard method for measuring liver attenuation on computed tomography (ct) in diagnosing nonalcoholic fatty liver disease (nafld). however, manual tracing is resource intensive. to address these limitations and to expand the availability of a quantitative ct measure of hepatic steatosis, we propose the automatic liver attenuation roi-based measurement (alarm) method for automated liver attenuation estimation.","['fully automatic liver attenuation estimation combing cnn segmentation', 'morphological operations']"
"development of machine learning solutions for prediction of functional and clinical significance of cancer driver genes and mutations are paramount in modern biomedical research and have gained a significant momentum in a recent decade. in this work, we integrate different machine learning approaches, including tree based methods, random forest and gradient boosted tree (gbt) classifiers along with deep convolutional neural networks (cnn) for prediction of cancer driver mutations in the genomic datasets. the feasibility of cnn in using raw nucleotide sequences for classification of cancer driver mutations was initially explored by employing label encoding, one hot encoding, and embedding to preprocess the dna information. these classifiers were benchmarked against their tree-based alternatives in order to evaluate the performance on a relative scale. we then integrated dna-based scores generated by cnn with various categories of conservational, evolutionary and functional features into a generalized random forest classifier. the results of this study have demonstrated that cnn can learn high level features from genomic information that are complementary to the ensemble-based predictors often employed for classification of cancer mutations. by combining deep learning-generated score with only two main ensemble-based functional features, we can achieve a superior performance of various machine learning classifiers. our findings have also suggested that synergy of nucleotide-based deep learning scores and integrated metrics derived from protein sequence conservation scores can allow for robust classification of cancer driver mutations with a limited number of highly informative features. machine learning predictions are leveraged in molecular simulations, protein stability, and network-based analysis of cancer mutations in the protein kinase genes to obtain insights about molecular signatures of driver mutations and enhance the interpretability of cancer-specific classification models.","['deep convolutional neural networks', 'random forest classifiers', 'cancer driver mutations', 'biomolecular modeling', 'integration', 'classification']"
"aerial imagery is regularly used by crop researchers, growers and farmers to monitor crops during the growing season. to extract meaningful information from large-scale aerial images collected from the field, high-throughput phenotypic analysis solutions are required, which not only produce high-quality measures of key crop traits, but also support professionals to make prompt and reliable crop management decisions. here, we report airsurf, an automated and open-source analytic platform that combines modern computer vision, up-to-date machine learning, and modular software engineering in order to measure yield-related phenotypes from ultra-large aerial imagery. to quantify millions of in-field lettuces acquired by fixed-wing light aircrafts equipped with normalised difference vegetation index (ndvi) sensors, we customised airsurf by combining computer vision algorithms and a deep-learning classifier trained with over 100,000 labelled lettuce signals. the tailored platform, airsurf-lettuce, is capable of scoring and categorising iceberg lettuces with high accuracy (>98%). furthermore, novel analysis functions have been developed to map lettuce size distribution across the field, based on which associated global positioning system (gps) tagged harvest regions have been identified to enable growers and farmers to conduct precision agricultural practises in order to improve the actual yield as well as crop marketability before the harvest.","['scale aerial phenotyping', 'combining computer vision', 'precision agriculture', 'lettuce production', 'enable ultra', 'deep learning', 'case study']"
"heart failure (hf) is one of the leading causes of hospital admissions in the us. readmission within 30 days after a hf hospitalization is both a recognized indicator for disease progression and a source of considerable financial burden to the healthcare system. consequently, the identification of patients at risk for readmission is a key step in improving disease management and patient outcome. in this work, we used a large administrative claims dataset to (1) explore the systematic application of neural network-based models versus logistic regression for predicting 30 days all-cause readmission after discharge from a hf admission, and (2) to examine the additive value of patients' hospitalization timelines on prediction performance. based on data from 272,778 (49% female) patients with a mean (sd) age of 73 years (14) and 343,328 hf admissions (67% of total admissions), we trained and tested our predictive readmission models following a stratified 5-fold cross-validation scheme. among the deep learning approaches, a recurrent neural network (rnn) combined with conditional random fields (crf) model (rnncrf) achieved the best performance in readmission prediction with 0.642 auc (95% ci, 0.640-0.645). other models, such as those based on rnn, convolutional neural networks and crf alone had lower performance, with a non-timeline based model (mlp) performing worst. a competitive model based on logistic regression with lasso achieved a performance of 0.643 auc (95% ci, 0.640-0.646). we conclude that data from patient timelines improve 30 day readmission prediction, that a logistic regression with lasso has equal performance to the best neural network model and that the use of administrative data result in competitive performance compared to published approaches based on richer clinical datasets.","['neural networks versus logistic regression', 'cause readmission prediction', 'u2009days', '30']"
"recent advances in image acquisition and processing techniques, along with the success of novel deep learning architectures, have given the opportunity to develop innovative algorithms capable to provide a better characterization of neurological related diseases. in this work, we introduce a neural network based approach to classify multiple sclerosis (ms) patients into four clinical profiles. starting from their structural connectivity information, obtained by diffusion tensor imaging and represented as a graph, we evaluate the classification performances using unweighted and weighted connectivity matrices. furthermore, we investigate the role of graph-based features for a better characterization and classification of the pathology. ninety ms patients (12 clinically isolated syndrome, 30 relapsing-remitting, 28 secondary-progressive, and 20 primary-progressive) along with 24 healthy controls, were considered in this study. this work shows the great performances achieved by neural networks methods in the classification of the clinical profiles. furthermore, it shows local graph metrics do not improve the classification results suggesting that the latent features created by the neural network in its layers have a much important informative content. finally, we observe that graph weights representation of brain connections preserve important information to discriminate between clinical forms.","['multiple sclerosis clinical profiles via graph convolutional neural networks', 'classification']"
"epilepsy is a neurological illness caused by abnormal discharge of brain neurons, where epileptic seizure can lead to life-threatening emergencies. by analyzing the encephalogram (eeg) signals of patients with epilepsy, their conditions can be monitored and seizure can be detected and intervened in time. as the identification of effective features in eeg signals is important for accurate seizure detection, this paper proposes a multi-view deep feature extraction method in attempt to achieve this goal. the method first uses fast fourier transform (fft) and wavelet packet decomposition (wpd) to construct the initial multi-view features. convolutional neural network (cnn) is then used to automatically learn deep features from the initial multi-view features, which reduces the dimensionality and obtain the features with better seizure identification ability. furthermore, the multi-view takagi-sugeno-kang fuzzy system (mv-tsk-fs), an interpretable rule-based classifier, is used to construct a classification model with strong generalizability based on the deep multi-view features obtained. experimental studies show that the classification accuracy of the proposed multi-view deep feature extraction method is at least 1% higher than that of common feature extraction methods such as principal component analysis (pca), fft and wpd. the classification accuracy is also at least 4% higher than the average accuracy achieved with single-view deep features.","['based epileptic seizure detection', 'view feature learning', 'deep multi', 'eeg']"
"here we present a computational model, score of unified regulatory features (surf), that predicts functional variants in enhancer and promoter elements. surf is trained on data from massively parallel reporter assays and predicts the effect of variants on reporter expression levels. it achieved the top performance in the fifth critical assessment of genome interpretation ""regulation saturation"" challenge. we also show that features queried through regulomedb, which are direct annotations from functional genomics data, help improve prediction accuracy beyond transfer learning features from dna sequence-based deep learning models. some of the most important features include dnase footprints, especially when coupled with complementary chip-seq data. furthermore, we found our model achieved good performance in predicting allele-specific transcription factor binding events. as an extension to the current scoring system in regulomedb, we expect our computational model to prioritize variants in regulatory regions, thus help the understanding of functional variants in noncoding regions that lead to disease.","['promoter elements using regulomedb', 'predicting functional variants', 'enhancer']"
"with the development of deep learning in medical image analysis, decoding brain states from functional magnetic resonance imaging (fmri) signals has made significant progress. previous studies often utilized deep neural networks to automatically classify brain activity patterns related to diverse cognitive states. however, due to the individual differences between subjects and the variation in acquisition parameters across devices, the inconsistency in data distributions degrades the performance of cross-subject decoding. besides, most current networks were trained in a supervised way, which is not suitable for the actual scenarios in which massive amounts of data are unlabeled. to address these problems, we proposed the deep crosssubject adaptation decoding (dcad) framework to decipher the brain states. the proposed volume-based 3d feature extraction architecture can automatically learn the common spatiotemporal features of labeled source data to generate a distinct descriptor. then, the distance between the source and target distributions is minimized via an unsupervised domain adaptation (uda) method, which can help to accurately decode the cognitive states across subjects. the performance of the dcad was evaluated on task-fmri (tfmri) dataset from the human connectome project (hcp). experimental results showed that the proposed method achieved the state-of-the-art decoding performance with mean 81.9% and 84.9% accuracies under two conditions (4 brain states and 9 brain states respectively) of working memory task. our findings also demonstrated that uda can mitigate the impact of the data distribution shift, thereby providing a superior choice for increasing the performance of cross-subject decoding without depending on annotations.","['using unsupervised domain adaptation', 'decoding brain states', 'fmri signals']"
"improving imaging quality is a fundamental problem in ultrasound contrast agent imaging (ucai) research. plane wave imaging (pwi) has been deemed as a potential method for ucai due to its' high frame rate and low mechanical index. high frame rate can improve the temporal resolution of ucai. meanwhile, low mechanical index is essential to ucai since microbubbles can be easily broken under high mechanical index conditions. however, the clinical practice of ultrasound contrast agent plane wave imaging (ucpwi) is still limited by poor imaging quality for lack of transmit focus. the purpose of this study was to propose and validate a new post-processing method that combined with deep learning to improve the imaging quality of ucpwi. the proposed method consists of three stages: (1) first, a deep learning approach based on u-net was trained to differentiate the microbubble and tissue radio frequency (rf) signals; (2) then, to eliminate the remaining tissue rf signals, the bubble approximated wavelet transform (bawt) combined with maximum eigenvalue threshold was employed. bawt can enhance the uca area brightness, and eigenvalue threshold can be set to eliminate the interference areas due to the large difference of maximum eigenvalue between uca and tissue areas; (3) finally, the accurate microbubble imaging were obtained through eigenspace-based minimum variance (esbmv).","['ultrasonic microbubble imaging', 'frequency signal based', 'deep learning method', 'processing radio', 'post']"
"despite the advances in image sensors, mainstream rgb sensors are still struggling from low quantum efficiency due to the low sensitivity of the bayer color filter array. to address this issue, a sparse color sensor uses mostly panchromatic white pixels and a smaller percentage of sparse color pixels to provide better low-light photography performance than a conventional bayer rgb sensor. however, due to the lack of a proper color reconstruction method, sparse color sensors have not been developed thus far. this study proposes a deep-learning-based method for sparse color reconstruction that can realize such a sparse color sensor. the proposed color reconstruction method consists of a novel two-stage deep model followed by an adversarial training technique to reduce visual artifacts in the reconstructed color image. in simulations and experiments, visual results and quantitative comparisons demonstrate that the proposed color reconstruction method can outperform existing methods. in addition, a prototype system was developed using a hybrid color-plus-mono camera system. experiments using the prototype system reveal the feasibility of a very sparse color sensor in different lighting conditions.","['sparse color sensor', 'deep color reconstruction']"
"artificial intelligence (ai) tools have been applied to diagnose or predict disease risk from medical images with recent data disclosure actions, but few of them are designed for mobile terminals due to the limited computational power and storage capacity of mobile devices. in this work, a novel ai diagnostic system is proposed for cholelithiasis recognition on mobile devices with android platform. to this aim, a data set of ct images of cholelithiasis is firstly collected from the third hospital of shandong province, china, and then we technically use histogram equalization to preprocess these ct images. as results, a lightweight convolutional neural network is obtained in a constructive way to extract cholelith features and recognize gallstones. in terms of implementation, we compile java and c++ to adapt to the application of deep learning algorithm on mobile devices with android platform. noted that, the training task is completed offline on pc, but cholelithiasis recognition tasks are performed on mobile terminals. we evaluate and compare the performance of our mobilenetv2 with mobilenetv1, single shot detector (ssd), yolov2 and original ssd (with vgg-16) as feature extractors for object detection. it is achieved that our mobilenetv2 achieve similar accuracy rate, about 91% with the other four methods, but the number of parameters used is reduced from 36.1m (ssd 300, ssd512), 50.7m (yolov2) and 5.1m (mobilenetv1) to 4.3m (mobilenetv2). the complete process on testing mobile devices, including virtual machine, xiaomi 7 and htc one m8 can be controlled within 4 seconds in recognizing cholelithiasis as well as the degree of the disease.","['lightweight convolutional neural network', 'artificial intelligent diagnostic system', 'mobile android terminals', 'cholelithiasis']"
to explore perceptions of students and teachers about learning and teaching strategies used in the delivery of surgery module in a relatively newly established medical college. .,"['mixed methods study', 'teaching strategies', 'surgery module', 'learning', 'analysis']"
"influenced by severe ambient noises and nonstationary disturbance signals, multi-class event classification is an enormous challenge in several long-haul application fields of distributed vibration sensing technology (dvs), including perimeter security, railway safety monitoring, pipeline surveillance, etc. in this paper, a deep dual path network is introduced into solving this problem with high learning capacity. the spatial time-frequency spectrum datasets are built by utilizing the multidimensional information of dvs signal, especially the spatial domain information. with the novel datasets and a high-parameter-efficiency network, the proposed scheme presents good reliability and robustness. the feasibility is verified in an actual railway safety monitoring field test, as a proof-of-concept. seven types of real-life disturbances were implemented and their f1-scores all reached up to 97% in the test. the performance of this proposed approach is fully evaluated and discussed. the presented approach can be employed to improve the performance of dvs in actual applications.","['distributed vibration sensing using deep dual path network', 'class event classification approach', 'practical multi']"
"alternative splicing generates multiple isoforms from a single gene, greatly increasing the functional diversity of a genome. although gene functions have been well studied, little is known about the specific functions of isoforms, making accurate prediction of isoform functions highly desirable. however, the existing approaches to predicting isoform functions are far from satisfactory due to at least two reasons: (i) unlike genes, isoform-level functional annotations are scarce. (ii) the information of isoform functions is concealed in various types of data including isoform sequences, co-expression relationship among isoforms, etc.","['expression profiles via deep learning', 'predicting isoform functions', 'sequences', 'diffuse']"
"cross-modal retrieval has attracted intensive attention in recent years, where a substantial yet challenging problem is how to measure the similarity between heterogeneous data modalities. despite using modality-specific representation learning techniques, most existing shallow or deep models treat different modalities equally and neglect the intrinsic modality heterogeneity and information imbalance among images and texts. in this paper, we propose an online similarity function learning framework to learn the metric that can well reflect the cross-modal semantic relation. considering that multiple cnn feature layers naturally represent visual information from low-level visual patterns to high-level semantic abstraction, we propose a new asymmetric image-text similarity formulation which aggregates the layer-wise visual-textual similarities parameterized by different bilinear parameter matrices. to effectively learn the aggregated similarity function, we develop three different similarity combination strategies, i.e., average kernel, multiple kernel learning, and layer gating. the former two kernel-based strategies assign uniform weights on different layers to all data pairs; the latter works on the original feature representation and assigns instance-aware weights on different layers to different data pairs, and they are all learned by preserving the bi-directional relative similarity expressed by a large number of cross-modal training triplets. the experiments conducted on three public datasets well demonstrate the effectiveness of our methods.","['online asymmetric metric learning', 'layer similarity aggregation', 'modal retrieval', 'multi', 'cross']"
"multimode fibers (mmf) are remarkable high-capacity information channels. however, the mmf transmission is highly sensitive to external perturbations and environmental changes. here, we show the successful binary image transmission using deep learning through a single mmf subject to dynamic shape variations. as a proof-of-concept experiment, we find that a convolutional neural network has excellent generalization capability with various mmf transmission states to accurately predict unknown information at the other end of the mmf at any of these states. our results demonstrate that deep learning is a promising solution to address the high variability and randomness challenge of mmf based information channels. this deep-learning approach is the starting point of developing future high-capacity mmf optical systems and devices and is applicable to optical systems concerning other diffusing media.","['randomness inside multimode fibers', 'high variability', 'deep learning']"
"state-of-the-art methods to infer dense and accurate depth measurements from images rely on deep cnn models trained in an end-to-end fashion on a significant amount of data. however, despite the outstanding performance achieved, these frameworks suffer a drastic drop in accuracy when dealing with unseen environments much different, concerning appearance (e.g., synthetic vs. real) or context (e.g., indoor vs. outdoor), from those observed during the training phase. such domain shift issue is usually softened by fine-tuning on smaller sets of images with depth labels acquired in the target domain with active sensors (e.g., lidar). however, relying on such supervised labeled data is seldom feasible in practical applications. therefore, we propose an effective unsupervised domain adaptation technique enabling to overcome the domain shift problem without requiring any groundtruth label. our method, deploying much more accessible to obtain stereo pairs, leverages traditional and not learning-based stereo algorithms to produce disparity/depth labels and on confidence measures to assess their degree of reliability. with these cues, we can fine-tune deep models through a novel confidence-guided loss function, neglecting the effect of outliers gathered from the output of conventional stereo algorithms.","['unsupervised domain adaptation', 'depth prediction', 'images']"
"in qualitative or quantitative studies of structure-activity relationships (sars), machine learning (ml) models are trained to recognize structural patterns that differentiate between active and inactive compounds. understanding model decisions is challenging but of critical importance to guide compound design. moreover, the interpretation of ml results provides an additional level of model validation based on expert knowledge. a number of complex ml approaches, especially deep learning (dl) architectures, have distinctive black-box character. herein, a locally interpretable explanatory method termed shapley additive explanations (shap) is introduced for rationalizing activity predictions of any ml algorithm, regardless of its complexity. models resulting from random forest (rf), nonlinear support vector machine (svm), and deep neural network (dnn) learning are interpreted, and structural patterns determining the predicted probability of activity are identified and mapped onto test compounds. the results indicate that shap has high potential for rationalizing predictions of complex ml models.","['complex machine learning models using local approximations', 'compound activity predictions', 'shapley values', 'interpretation']"
"hashing has been widely used for large-scale approximate nearest neighbor search due to its storage and search efficiency. recent supervised hashing research has shown that deep learning-based methods can significantly outperform nondeep methods. most existing supervised deep hashing methods exploit supervisory signals to generate similar and dissimilar image pairs for training. however, natural images can have large intraclass and small interclass variations, which may degrade the accuracy of hash codes. to address this problem, we propose a novel two-stream convnet architecture, which learns hash codes with class-specific representation centers. our basic idea is that if we can learn a unified binary representation for each class as a center and encourage hash codes of images to be close to the corresponding centers, the intraclass variation will be greatly reduced. accordingly, we design a neural network that leverages label information and outputs a unified binary representation for each class. moreover, we also design an image network to learn hash codes from images and force these hash codes to be close to the corresponding class-specific centers. these two neural networks are then seamlessly incorporated to create a unified, end-to-end trainable framework. extensive experiments on three popular benchmarks corroborate that our proposed method outperforms current state-of-the-art methods.","['supervised image search', 'stream deep hashing', 'specific centers', 'two', 'class']"
radiomics allows for powerful data-mining and feature extraction techniques to guide clinical decision making. image segmentation is a necessary step in such pipelines and different techniques can significantly affect results. we demonstrate that a convolutional neural network (cnn) segmentation method performs comparably to expert manual segmentations in an established radiomics pipeline.,"['segmenting breast lesions', 'convolutional neural network', 'radiomic analysis', 'based assessment', 'task']"
"in this theory paper, we investigate training deep neural networks (dnns) for classification via minimizing the information bottleneck (ib) functional. we show that the resulting optimization problem suffers from two severe issues: first, for deterministic dnns, either the ib functional is infinite for almost all values of network parameters, making the optimization problem ill-posed, or it is piecewise constant, hence not admitting gradient-based optimization methods. second, the invariance of the ib functional under bijections prevents it from capturing properties of the learned representation that are desirable for classification, such as robustness and simplicity. we argue that these issues are partly resolved for stochastic dnns, dnns that include a (hard or soft) decision rule, or by replacing the ib functional with related, but more well-behaved cost functions. we conclude that recent successes reported about training dnns using the ib framework must be attributed to such solutions. as a side effect, our results indicate limitations of the ib framework for the analysis of dnns. we also note that rather than trying to repair the inherent problems in the ib functional, a better approach may be to design regularizers on latent representation enforcing the desired properties directly.","['information bottleneck principle', 'based classification using', 'neural network', 'learning representations']"
"serendipitous drug usage refers to the unexpected relief of comorbid diseases or symptoms when taking medication for a different known indication. historically, serendipity has contributed significantly to identifying many new drug indications. if patient-reported serendipitous drug usage in social media could be computationally identified, it could help generate and validate drug-repositioning hypotheses. we investigated deep neural network models for mining serendipitous drug usage from social media. we used the word2vec algorithm to construct word-embedding features from drug reviews posted in a webmd patient forum. we adapted and redesigned the convolutional neural network, long short-term memory network, and convolutional long short-term memory network by adding contextual information extracted from drug-review posts, information-filtering tools, medical ontology, and medical knowledge. we trained, tuned, and evaluated our models with a gold-standard dataset of 15714 sentences (447 [2.8",['scribing serendipitous drug usag']
"diabetes is responsible for considerable morbidity, healthcare utilisation and mortality in both developed and developing countries. currently, methods of treating diabetes are inadequate and costly so prevention becomes an important step in reducing the burden of diabetes and its complications. electronic health records (ehrs) for each individual or a population have become important tools in understanding developing trends of diseases. using ehrs to predict the onset of diabetes could improve the quality and efficiency of medical care. in this paper, we apply a wide and deep learning model that combines the strength of a generalised linear model with various features and a deep feed-forward neural network to improve the prediction of the onset of type 2 diabetes mellitus (t2dm).","['type 2 diabetes using wide', 'electronic health records', 'deep learning', 'predicting', 'onset']"
"this paper proposes an image-based wavefront sensing approach using deep learning, which is applicable to both point source and any extended scenes at the same time, while the training process is performed without any simulated or real extended scenes. rather than directly recovering phase information from image plane intensities, we first extract a special feature in the frequency domain that is independent of the original objects but only determined by phase aberrations (a pair of phase diversity images is needed in this process). then the deep long short-term memory (lstm) network (a variant of recurrent neural network) is introduced to establish the accurate non-linear mapping between the extracted feature image and phase aberrations. simulations and an experiment are performed to demonstrate the effectiveness and accuracy of the proposed approach. some other discussions are further presented for demonstrating the superior non-linear fitting capacity of deep lstm compared to resnet 18 (a variant of convolutional neural network) specifically for the problem encountered in this paper. the effect of the incoherency of light on the accuracy of the recovered wavefront phase is also quantitatively discussed. this work will contribute to the application of deep learning to image-based wavefront sensing and high-resolution image reconstruction.","['based wavefront sensing approach using phase diversity images', 'independent image', 'deep learning', 'object']"
"one of the main obstacles for the implementation of deep convolutional neural networks (dcnns) in the clinical pathology workflow is their low capability to overcome variability in slide preparation and scanner configuration, that leads to changes in tissue appearance. some of these variations may not be not included in the training data, which means that the models have a risk to not generalize well. addressing such variations and evaluating them in reproducible scenarios allows understanding of when the models generalize better, which is crucial for performance improvements and better dcnn models. staining normalization techniques (often based on color deconvolution and deep learning) and color augmentation approaches have shown improvements in the generalization of the classification tasks for several tissue types. domain-invariant training of dcnn's is also a promising technique to address the problem of training a single model for different domains, since it includes the source domain information to guide the training toward domain-invariant features, achieving state-of-the-art results in classification tasks. in this article, deep domain adaptation in convolutional networks (dann) is applied to computational pathology and compared with widely used staining normalization and color augmentation methods in two challenging classification tasks. the classification tasks rely on two openly accessible datasets, targeting gleason grading in prostate cancer, and mitosis classification in breast tissue. the benchmark of the different techniques and their combination in two dcnn architectures allows us to assess the generalization abilities and advantages of each method in the considered classification tasks. the code for reproducing our experiments and preprocessing the data is publicly available. quantitative and qualitative results show that the use of dann helps model generalization to external datasets. the combination of several techniques to manage color heterogeneity suggests that several methods together, such as color augmentation methods with dann training, can generalize even further. the results do not show a single best technique among the considered methods, even when combining them. however, color augmentation and dann training obtain most often the best results (alone or combined with color normalization and color augmentation). the statistical significance of the results and the embeddings visualizations provide useful insights to design dcnn that generalizes to unseen staining appearances. furthermore, in this work, we release for the first time code for dann evaluation in open access datasets for computational pathology. this work opens the possibility for further research on using dann models together with techniques that can overcome the tissue preparation differences across datasets to tackle limited generalization.","['deep convolutional neural networks', 'staining invariant features', 'improving generalization', 'computational pathology']"
"this paper introduces a fully automated, subject-specific deep-learning convolutional neural network (cnn) system for forecasting seizures using ambulatory intracranial eeg (ieeg). the system was tested on a hand-held device (mayo epilepsy assist device) in a pseudo-prospective mode using ieeg from four canines with naturally occurring epilepsy.","['seizure forecasting', 'learning', 'epilepsy', 'deep', 'canines']"
"wild birds are monitored with the important objectives of identifying their habitats and estimating the size of their populations. especially in the case of migratory bird, they are significantly recorded during specific periods of time to forecast any possible spread of animal disease such as avian influenza. this study led to the construction of deep-learning-based object-detection models with the aid of aerial photographs collected by an unmanned aerial vehicle (uav). the dataset containing the aerial photographs includes diverse images of birds in various bird habitats and in the vicinity of lakes and on farmland. in addition, aerial images of bird decoys are captured to achieve various bird patterns and more accurate bird information. bird detection models such as faster region-based convolutional neural network (r-cnn), region-based fully convolutional network (r-fcn), single shot multibox detector (ssd), retinanet, and you only look once (yolo) were created and the performance of all models was estimated by comparing their computing speed and average precision. the test results show faster r-cnn to be the most accurate and yolo to be the fastest among the models. the combined results demonstrate that the use of deep-learning-based detection methods in combination with uav aerial imagery is fairly suitable for bird detection in various environments.","['bird detection using unmanned aerial vehicle imagery', 'learning methods', 'deep', 'application']"
"for large-scale image retrieval, hashing has been extensively explored in approximate nearest neighbor search methods due to its low storage and high computational efficiency. with the development of deep learning, deep hashing methods have made great progress in image retrieval. most existing deep hashing methods cannot fully consider the intra-group correlation of hash codes, which leads to the correlation decrease problem of similar hash codes and ultimately affects the retrieval results. in this article, we propose an end-to-end siamese dilated inception hashing (sdih) method that takes full advantage of multi-scale contextual information and category-level semantics to enhance the intra-group correlation of hash codes for hash codes learning. first, a novel siamese inception dilated network architecture is presented to generate hash codes with the intra-group correlation enhancement by exploiting multi-scale contextual information and category-level semantics simultaneously. second, we propose a new regularized term, which can force the continuous values to approximate discrete values in hash codes learning and eventually reduces the discrepancy between the hamming distance and the euclidean distance. finally, experimental results in five public data sets demonstrate that sdih can outperform other state-of-the-art hashing algorithms.","['siamese dilated inception hashing', 'group correlation enhancement', 'image retrieval', 'intra']"
"reconstructing the phylogenetic relationships between species is one of the most formidable tasks in evolutionary biology. multiple methods exist to reconstruct phylogenetic trees, each with their own strengths and weaknesses. both simulation and empirical studies have identified several ""zones"" of parameter space where accuracy of some methods can plummet, even for four-taxon trees. further, some methods can have undesirable statistical properties such as statistical inconsistency and/or the tendency to be positively misleading (i.e. assert strong support for the incorrect tree topology). recently, deep learning techniques have made inroads on a number of both new and longstanding problems in biological research. in this study, we designed a deep convolutional neural network (cnn) to infer quartet topologies from multiple sequence alignments. this cnn can readily be trained to make inferences using both gapped and ungapped data. we show that our approach is highly accurate on simulated data, often outperforming traditional methods, and is remarkably robust to bias-inducing regions of parameter space such as the felsenstein zone and the farris zone. we also demonstrate that the confidence scores produced by our cnn can more accurately assess support for the chosen topology than bootstrap and posterior probability scores from traditional methods. although numerous practical challenges remain, these findings suggest that the deep learning approaches such as ours have the potential to produce more accurate phylogenetic inferences.","['multiple sequence alignments using deep learning', 'tree topologies', 'accurate inference']"
"in this paper, an effective wavelength detection approach based on long short-term memory (lstm) network is proposed for fiber bragg grating (fbg) sensor networks. the fbg sensor network utilizes a model-sharing mechanism, where the whole spectral wavelength is divided into several shareable regions and spectral overlap is allowed in each region. lstm, a representative recurrent neural network in deep learning, is applied to learn the features directly from the spectra of fbgs and build the wavelength detection model. by feeding the spectra sequentially into the well-trained model, the bragg wavelengths of fbgs can be quickly determined under overlap. the obtained lstm model can be repeatedly used without re-training to improve the multiplexing capability. the results demonstrate that the lstm-based method can realize high-accuracy and high-speed wavelength detection in the spectral overlapping situations. the proposed approach offers a flexible tool to enhance the sensing capacity of fbg sensor networks.","['sharing fiber bragg grating sensor networks using long short', 'term memory neural network', 'wavelength detection', 'model']"
"de novo peptide sequencing based on tandem mass spectrometry data is the key technology of shotgun proteomics for identifying peptides without any database and assembling unknown proteins. however, owing to the low ion coverage in tandem mass spectra, the order of certain consecutive amino acids cannot be determined if all of their supporting fragment ions are missing, which results in the low precision of de novo sequencing.","['precise de novo peptide sequencing using', 'rank framework', 'pnovo 3', 'learning']"
"estimating the future course of patients with cancer lesions is invaluable to physicians; however, current clinical methods fail to effectively use the vast amount of multimodal data that is available for cancer patients. to tackle this problem, we constructed a multimodal neural network-based model to predict the survival of patients for 20 different cancer types using clinical data, mrna expression data, microrna expression data and histopathology whole slide images (wsis). we developed an unsupervised encoder to compress these four data modalities into a single feature vector for each patient, handling missing data through a resilient, multimodal dropout method. encoding methods were tailored to each data type-using deep highway networks to extract features from clinical and genomic data, and convolutional neural networks to extract features from wsis.","['pancancer prognosis prediction', 'multimodal representation', 'deep learning']"
"objective. to evaluate pharmacy students' perceptions of the educational value of reflective portfolio and to gain an understanding of the factors that might influence these perceptions. methods. bachelor of pharmacy (bpharm) students' perceptions of using reflective portfolios were evaluated by administering the same questionnaire at the beginning of years 2, 3 and 4 of the curriculum. statistical analysis was carried out to determine the differences among the perception scores of different academic years. semi-structured interviews were completed with fourth-year students to further explore their experiences with the reflective portfolio. students' deep information processing (dip) skills were compared with those of students from another pharmacy cohort whose curriculum did not include a reflective portfolio. results. the students' perceptions of the reflective portfolio improved significantly as they progressed from year 2 to year 4 of the curriculum. the factors that contributed to a positive experience were a clear understanding of objectives and guidelines for the reflective portfolio, useful mentor feedback, a positive learning attitude and motivation, and having a user-friendly technology platform for submission of the portfolio. the students' dip skills after completing the reflective portfolio were higher than those of students who did not have a reflective portfolio assignment in their curriculum. conclusion. pharmacy students' appreciation of the educational value of a reflective portfolio increased as they progressed to their final year, and their dip skills improved. these findings support the use of a reflective portfolio as a learning tool for bpharm students' personal and professional development.","['reflective portfolios', 'processing skills', 'deep information', 'pharmacy students', 'students', 'perceptions', 'effect']"
"increasingly, autonomous agents will be required to operate on long-term missions. this will create a demand for general intelligence because feedback from a human operator may be sparse and delayed, and because not all behaviours can be prescribed. deep neural networks and reinforcement learning methods can be applied in such environments but their fixed updating routines imply an inductive bias in learning spatio-temporal patterns, meaning some environments will be unsolvable. to address this problem, this paper proposes active adaptive perception, the ability of an architecture to learn when and how to modify and selectively utilise its perception module. to achieve this, a generic architecture based on a self-modifying policy (smp) is proposed, and implemented using incremental self-improvement with the success story algorithm. the architecture contrasts to deep reinforcement learning systems which follow fixed training strategies and earlier smp studies which for perception relied either entirely on the working memory or on untrainable active perception instructions. one computationally cheap and one more expensive implementation are presented and compared to drqn, an off-policy deep reinforcement learner using experience replay and incremental self-improvement, an smp, on various non-episodic partially observable mazes. the results show that the simple instruction set leads to emergent strategies to avoid detracting corridors and rooms, and that the expensive implementation allows selectively ignoring perception where it is inaccurate.","['active adaptive perception', 'learning', 'learn']"
"peripheral vision loss results in the inability to detect objects in the peripheral visual field which affects the ability to evaluate and avoid potential hazards. a different number of assistive navigation systems have been developed to help people with vision impairments using wearable and portable devices. most of these systems are designed to search for obstacles and provide safe navigation paths for visually impaired people without any prioritisation of the degree of danger for each hazard. this paper presents a new context-aware hybrid (indoor/outdoor) hazard classification assistive technology to help people with peripheral vision loss in their navigation using computer-enabled smart glasses equipped with a wide-angle camera. our proposed system augments users' existing healthy vision with suitable, meaningful and smart notifications to attract the user's attention to possible obstructions or hazards in their peripheral field of view. a deep learning object detector is implemented to recognise static and moving objects in real time. after detecting the objects, a kalman filter multi-object tracker is used to track these objects over time to determine the motion model. for each tracked object, its motion model represents its way of moving around the user. motion features are extracted while the object is still in the user's field of vision. these features are then used to quantify the danger using five predefined hazard classes using a neural network-based classifier. the classification performance is tested on both publicly available and private datasets and the system shows promising results with up to 90% true positive rate (tpr) associated with as low as 7% false positive rate (fpr), 13% false negative rate (fnr) and an average testing mean square error (mse) of 8.8%. the provided hazard type is then translated into a smart notification to increase the user's cognitive perception using the healthy vision within the visual field. a participant study was conducted with a group of patients with different visual field defects to explore their feedback about the proposed system and the notification generation stage. the real-world outdoor evaluation of human subjects is planned to be performed in our near future work.","['aware hazard attention system', 'peripheral vision loss', 'smart context', 'help people']"
"we demonstrate the use of deep learning for fast spectral deconstruction of speckle patterns. the artificial neural network can be effectively trained using numerically constructed multispectral datasets taken from a measured spectral transmission matrix. optimized neural networks trained on these datasets achieve reliable reconstruction of both discrete and continuous spectra from a monochromatic camera image. deep learning is compared to analytical inversion methods as well as to a compressive sensing algorithm and shows favourable characteristics both in the oversampling and in the sparse undersampling (compressive) regimes. the deep learning approach offers significant advantages in robustness to drift or noise and in reconstruction speed. in a proof-of-principle demonstrator we achieve real time recovery of hyperspectral information using a multi-core, multi-mode fiber array as a random scattering medium.","['deep learning enabled real time speckle recognition', 'multimode fiber array', 'hyperspectral imaging using']"
"despite its clinical importance, detection of highly divergent or yet unknown viruses is a major challenge. when human samples are sequenced, conventional alignments classify many assembled contigs as ""unknown"" since many of the sequences are not similar to known genomes. in this work, we developed viraminer, a deep learning-based method to identify viruses in various human biospecimens. viraminer contains two branches of convolutional neural networks designed to detect both patterns and pattern-frequencies on raw metagenomics contigs. the training dataset included sequences obtained from 19 metagenomic experiments which were analyzed and labeled by blast. the model achieves significantly improved accuracy compared to other machine learning methods for viral genome classification. using 300 bp contigs viraminer achieves 0.923 area under the roc curve. to our knowledge, this is the first machine learning methodology that can detect the presence of viral sequences among raw metagenomic contigs from diverse human samples. we suggest that the proposed model captures different types of information of genome composition, and can be used as a recommendation system to further investigate sequences labeled as ""unknown"" by conventional alignment methods. exploring these highly-divergent viruses, in turn, can enhance our knowledge of infectious causes of diseases.","['raw dna sequences', 'identifying viral genomes', 'human samples', 'deep learning', 'viraminer']"
"over- and under-sedation are common in the icu, and contribute to poor icu outcomes including delirium. behavioral assessments, such as richmond agitation-sedation scale (rass) for monitoring levels of sedation and confusion assessment method for the icu (cam-icu) for detecting signs of delirium, are often used. as an alternative, brain monitoring with electroencephalography (eeg) has been proposed in the operating room, but is challenging to implement in icu due to the differences between critical illness and elective surgery, as well as the duration of sedation. here we present a deep learning model based on a combination of convolutional and recurrent neural networks that automatically tracks both the level of consciousness and delirium using frontal eeg signals in the icu. for level of consciousness, the system achieves a median accuracy of 70% when allowing prediction to be within one rass level difference across all patients, which is comparable or higher than the median technician-nurse agreement at 59%. for delirium, the system achieves an auc of 0.80 with 69% sensitivity and 83% specificity at the optimal operating point. the results show it is feasible to continuously track level of consciousness and delirium in the icu.","['critical illness using deep learning', 'automated tracking', 'level', 'delirium', 'consciousness']"
"single-cell rna sequencing (scrnaseq) data always involves various unwanted variables, which would be able to mask the true signal to identify cell-types. more efficient way of dealing with this issue is to extract low dimension information from high dimensional gene expression data to represent cell-type structure. in the past two years, several powerful matrix factorization tools were developed for scrnaseq data, such as nmf, zifa, pcmf and zinb-wave. but the existing approaches either are unable to directly model the raw count of scrnaseq data or are really time-consuming when handling a large number of cells (e.g. n>500).","['based matrix factorization method', 'detecting cell types', 'cell rnaseq data', 'efficient count', 'single', 'fast']"
"modern technology has pushed us into the information age, making it easier to generate and record vast quantities of new data. datasets can help in analyzing the situation to give a better understanding, and more importantly, decision making. consequently, datasets, and uses to which they can be put, have become increasingly valuable commodities. this article describes the dronerf dataset: a radio frequency (rf) based dataset of drones functioning in different modes, including off, on and connected, hovering, flying, and video recording. the dataset contains recordings of rf activities, composed of 227 recorded segments collected from 3 different drones, as well as recordings of background rf activities with no drones. the data has been collected by rf receivers that intercepts the drone\'s communications with the flight control module. the receivers are connected to two laptops, via pcie cables, that runs a program responsible for fetching, processing and storing the sensed rf data in a database. an example of how this dataset can be interpreted and used can be found in the related research article ""rf-based drone detection and identification using deep learning approaches: an initiative towards a large open source drone database"" (al-sa\'d et\xa0al., 2019).","['based detection', 'dronerf dataset', 'dataset', 'rf', 'identification', 'drones', 'classification']"
we aim to combine deep neural networks and engineered features (hand-crafted features based on medical domain knowledge) for cardiac arrhythmia detection from short single-lead ecg recordings.,"['combining deep neural networks', 'cardiac arrhythmia detection', 'engineered features', 'ecg recordings']"
"this paper presents a comprehensive study on the contrast transfer function of de-noising algorithms. in order to cover a broad variety of methods, 45 de-noising algorithms are chosen considering their recognized efficiency in the different application domains of image processing. advanced methods are targeted: wavelet transform-based algorithms with daubechies, symlets, curvelets, contourlets, patch-based methods such as bm3d, nl-means algorithms and deep learning approaches; in addition, classical spatial filtering methods are considered, such as wiener, median, gauss filtering, and adaptive filtering approaches such as anisotropic diffusion and synthetic aperture radar filtering. the contrast transfer function is provided for each algorithm. ranking of the set of de-noising algorithms is established according to proposed metrics. the paper provides practical methodology and novel results dedicated to the evaluation of the contrast transfer function of de-noising approaches from literature.","['contrast transfer function', 'noising algorithms', 'de']"
"falls are a prevalent problem in actual society. some falls result in injuries and the cost associated with their treatment is high. this is a complex problem that requires several steps in order to be tackled. firstly, it is crucial to develop strategies that recognize the locomotion mode, indicating the state of the subject in various situations. this article aims to develop a strategy capable of identifying normal gait, the pre-fall condition, and the fall situation, based on a wearable system (imus-based). this system was used to collect data from healthy subjects that mimicked falls. the strategy consists, essentially, in the construction and use of classifiers as tools for recognizing the locomotion modes. two approaches were explored. associative skill memories (asms) based classifier and a convolutional neural network (cnn) classifier based on deep learning. finally, these classifiers were compared, providing for a tool with a good accuracy in recognizing the locomotion modes. results have shown that the accuracy of the classifiers was quite acceptable. the cnn presented the best results with 92.71% of accuracy considering the pre-fall step different from normal steps, and 100% when not considering.","['detect falls using wearable sensors', 'strategy', 'predict', 'development']"
"for patients with chronic kidney disease (ckd), hyperkalemia is common, associated with fatal arrhythmias, and often asymptomatic, while guideline-directed monitoring of serum potassium is underused. a deep-learning model that enables noninvasive hyperkalemia screening from the electrocardiogram (ecg) may improve detection of this life-threatening condition.","['learning model', 'validation', 'screen', 'hyperkalemia', 'electrocardiogram', 'development', 'deep']"
"although the stroke volume (sv) estimation by arterial blood pressure has been widely used in clinical practice, its accuracy is questionable, especially during periods of hemodynamic instability. we aimed to create novel sv estimating model based on deep-learning (dl) method. a convolutional neural network was applied to estimate sv from arterial blood pressure waveform data recorded from liver transplantation (lt) surgeries. the model was trained using a gold standard referential sv measured via pulmonary artery thermodilution method. merging a gold standard sv and corresponding 10.24 seconds of arterial blood pressure waveform as an input/output data set with 2-senconds of sliding overlap, 484,384 data sets from 34 lt surgeries were used for training and validation of dl model. the performance of dl model was evaluated by correlation and concordance analyses in another 491,353 data sets from 31 lt surgeries. we also evaluated the performance of pre-existing commercialized model (ev1000), and the performance results of dl model and ev1000 were compared. the dl model provided an acceptable performance throughout the surgery (r = 0.813, concordance rate = 74.15%). during the reperfusion phase, where the most severe hemodynamic instability occurred, dl model showed superior correlation (0.861; 95% confidence interval, (ci), 0.855-0.866 vs. 0.570; 95% ci, 0.556-0.584, p < 0.001) and higher concordance rate (90.6% vs. 75.8%) over ev1000. in conclusion, the dl-based model was superior for estimating intraoperative sv and thus might guide physicians to precise intraoperative hemodynamic management. moreover, the dl model seems to be particularly promising because it outperformed ev1000 in circumstance of rapid hemodynamic changes where physicians need most help.","['based stroke volume estimation outperforms conventional arterial contour method', 'hemodynamic instability', 'deep learning', 'patients']"
"enhanced technology in computer and internet has driven scale and quality of data to be improved in various areas including healthcare sectors. machine learning (ml) has played a pivotal role in efficiently analyzing those big data, but a general misunderstanding of ml algorithms still exists in applying them (e.g., ml techniques can settle a problem of small sample size, or deep learning is the ml algorithm). this paper reviewed the research of diagnosing mental illness using ml algorithm and suggests how ml techniques can be employed and worked in practice.","['machine learning algorithms', 'diagnosing mental illness', 'review']"
"two-dimensional phase unwrapping algorithms are widely used in optical metrology and measurements. the high noise from interference measurements, however, often leads to the failure of conventional phase unwrapping algorithms. in this paper, we propose a deep convolutional neural network (dcnn) based method to perform rapid and robust two-dimensional phase unwrapping. in our approach, we employ a dcnn architecture, deeplabv3+, with noise suppression and strong feature representation capabilities. the employed dcnn is first used to perform semantic segmentation to obtain the segmentation result of the wrapped phase map. we then combine the wrapped phase map with the segmentation result to generate the unwrapped phase. we benchmarked our results by comparing them with well-established methods. the reported approach out-performed the conventional path-dependent and path-independent algorithms. we also tested the robustness of the reported approach using interference measurements from optical metrology setups. our results, again, clearly out-performed the conventional phase unwrap algorithms. the reported approach may find applications in optical metrology and microscopy imaging.","['dimensional phase unwrapping via deep learning', 'robust two', 'rapid']"
"the analysis of primary care data plays an important role in understanding health at an individual and population level. currently the utilization of computerized medical records is low due to the complexities, heterogeneities and veracity associated with these data. we present a deep learning methodology that clusters 11,000 records in an unsupervised manner identifying non-linear patterns in the data. this provides a useful tool for visualization as well as identify features driving the formation of clusters. further analysis reveal the features that differentiate sub-groups that can aid clinical decision making. our results uncover subsets that contain the highest proportion of missing data, specifically episode type, as well as the sources that provide the most complete data.","['primary care computerised medical records', 'deep learning', 'analysis']"
"convolutional neural network (cnn) models have the potential to improve plant disease phenotyping where the standard approach is visual diagnostics requiring specialized training. in scenarios where a cnn is deployed on mobile devices, models are presented with new challenges due to lighting and orientation. it is essential for model assessment to be conducted in real world conditions if such models are to be reliably integrated with computer vision products for plant disease phenotyping. we train a cnn object detection model to identify foliar symptoms of diseases in cassava (manihot esculenta crantz). we then deploy the model in a mobile app and test its performance on mobile images and video of 720 diseased leaflets in an agricultural field in tanzania. within each disease category we test two levels of severity of symptoms-mild and pronounced, to assess the model performance for early detection of symptoms. in both severities we see a decrease in performance for real world images and video as measured with the f-1 score. the f-1 score dropped by 32% for pronounced symptoms in real world images (the closest data to the training data) due to a decrease in model recall. if the potential of mobile cnn models are to be realized our data suggest it is crucial to consider tuning recall in order to achieve the desired performance in real world settings. in addition, the varied performance related to different input data (image or video) is an important consideration for design in real world applications.","['based deep learning model', 'cassava disease diagnosis', 'mobile']"
"the idea of artificial intelligence (ai) has a long history. it turned out, however, that reaching intelligence at human levels is more complicated than originally anticipated. currently, we are experiencing a renewed interest in ai, fueled by an enormous increase in computing power and an even larger increase in data, in combination with improved ai technologies like deep learning. healthcare is considered the next domain to be revolutionized by artificial intelligence. while ai approaches are excellently suited to develop certain algorithms, for biomedical applications there are specific challenges. we propose six recommendations-the 6rs-to improve ai projects in the biomedical space, especially clinical health care, and to facilitate communication between ai scientists and medical doctors: (1) relevant and well-defined clinical question first; (2) right data (ie, representative and of good quality); (3) ratio between number of patients and their variables should fit the ai method; (4) relationship between data and ground truth should be as direct and causal as possible; (5) regulatory ready; enabling validation; and (6) right ai method.","['clinical health care applications', 'artificial intelligence', 'viewpoint']"
to develop a head and neck normal structures autocontouring tool that could be used to automatically detect the errors in autocontours from a clinically validated autocontouring tool.,"['contouring errors using convolutional neural networks', 'automatic detection']"
"the purpose of this research was to implement a deep learning network to overcome two of the major bottlenecks in improved image reconstruction for clinical positron emission tomography (pet). these are the lack of an automated means for the optimization of advanced image reconstruction algorithms, and the computational expense associated with these state-of-the art methods. we thus present a novel end-to-end pet image reconstruction technique, called deeppet, based on a deep convolutional encoder-decoder network, which takes pet sinogram data as input and directly and quickly outputs high quality, quantitative pet images. using simulated data derived from a whole-body digital phantom, we randomly sampled the configurable parameters to generate realistic images, which were each augmented to a total of more than 291,000 reference images. realistic pet acquisitions of these images were simulated, resulting in noisy sinogram data, used for training, validation, and testing the deeppet network. we demonstrated that deeppet generates higher quality images compared to conventional techniques, in terms of relative root mean squared error (11%/53% lower than ordered subset expectation maximization (osem)/filtered back-projection (fbp), structural similarity index (1%/11% higher than osem/fbp), and peak signal-to-noise ratio (1.1/3.8\xa0db higher than osem/fbp). in addition, we show that deeppet reconstructs images 108 and 3 times faster than osem and fbp, respectively. finally, deeppet was successfully applied to real clinical data. this study shows that an end-to-end encoder-decoder network can produce high quality pet images at a fraction of the time compared to conventional methods.","['pet image reconstruction inverse problem', 'directly solving', 'deep encoder', 'decoder network', 'deeppet']"
"deep learning architectures have recently demonstrated their power in predicting dna- and rna-binding specificity. existing methods fall into three classes: some are based on convolutional neural networks (cnns), others use recurrent neural networks (rnns) and others rely on hybrid architectures combining cnns and rnns. however, based on existing studies the relative merit of the various architectures remains unclear.","['rna sequence binding specificities', 'deep learning architectures', 'comprehensive evaluation', 'prediction', 'dna']"
"the provision of online educational courses has soared since the creation of the world wide web, with most universities offering some degree of distance-based programs. the social constructivist pedagogy is widely accepted as the framework to provide education, but it largely relies on the face-to-face presence of students and faculty to foster a learning environment. the concern with online courses is that this physical interaction is removed, and therefore learning may be diminished.","['student interaction', 'online master', 'content analysis', 'survey', 'faculty', 'course']"
"exploiting reinforcement learning (rl) for traffic congestion reduction is a frontier topic in intelligent transportation research. the difficulty in this problem stems from the inability of the rl agent simultaneously monitoring multiple signal lights when taking into account complicated traffic dynamics in different regions of a traffic system. such challenge is even more outstanding when forming control decisions on a large-scale traffic grid, where the rl action space grows exponentially with the number of intersections within the traffic grid. in this paper, we tackle such a problem by proposing a cooperative deep reinforcement learning (coder) framework. the intuition behind coder is to decompose the original difficult rl task as a number of subproblems with relatively easy rl goals. accordingly, we implement coder with multiple regional agents and a centralized global agent. each regional agent learns its own rl policy and value functions over a small region with limited actions. then, the centralized global agent hierarchically aggregates rl achievements from different regional agents and forms the final q-function over the entire large-scale traffic grid. the experimental investigations demonstrate that the proposed coder could reduce on average 30% congestions in terms of the number of waiting vehicles during high density traffic flows in simulations.","['scale traffic grid signal control', 'cooperative deep reinforcement learning', 'large']"
"commercially available health monitors rely on rigid electronic housing coupled with aggressive adhesives and conductive gels, causing discomfort and inducing skin damage. also, research-level skin-wearable devices, while excelling in some aspects, fall short as concept-only presentations due to the fundamental challenges of active wireless communication and integration as a single device platform. here, an all-in-one, wireless, stretchable hybrid electronics with key capabilities for real-time physiological monitoring, automatic detection of signal abnormality via deep-learning, and a long-range wireless connectivity (up to 15 m) is introduced. the strategic integration of thin-film electronic layers with hyperelastic elastomers allows the overall device to adhere and deform naturally with the human body while maintaining the functionalities of the on-board electronics. the stretchable electrodes with optimized structures for intimate skin contact are capable of generating clinical-grade electrocardiograms and accurate analysis of heart and respiratory rates while the motion sensor assesses physical activities. implementation of convolutional neural networks for real-time physiological classifications demonstrates the feasibility of multifaceted analysis with a high clinical relevance. finally, in vivo demonstrations with animals and human subjects in various scenarios reveal the versatility of the device as both a health monitor and a viable research tool.","['stretchable hybrid electronics', 'ambulatory physiological monitoring', 'wireless', 'smart', 'one', 'connected']"
"the incidence of skin tumors has steadily increased. although most are benign and do not affect survival, some of the more malignant skin tumors present a lethal threat if a delay in diagnosis permits them to become advanced. ideally, an inspection by an expert dermatologist would accurately detect malignant skin tumors in the early stage; however, it is not practical for every single patient to receive intensive screening by dermatologists. to overcome this issue, many studies are ongoing to develop dermatologist-level, computer-aided diagnostics. whereas, many systems that can classify dermoscopic images at this dermatologist-equivalent level have been reported, a much fewer number of systems that can classify conventional clinical images have been reported thus far. recently, the introduction of deep-learning technology, a method that automatically extracts a set of representative features for further classification has dramatically improved classification efficacy. this new technology has the potential to improve the computer classification accuracy of conventional clinical images to the level of skilled dermatologists. in this review, this new technology and present development of computer-aided skin tumor classifiers will be summarized.","['aided skin tumor classifiers', 'deep learning', 'possibility', 'computer', 'based']"
"for ai researchers, access to a large and well-curated dataset is crucial. working in the field of breast radiology, our aim was to develop a high-quality platform that can be used for evaluation of networks aiming to predict breast cancer risk, estimate mammographic sensitivity, and detect tumors. our dataset, cohort of screen-aged women (csaw), is a population-based cohort of all women 40 to 74\xa0years of age invited to screening in the stockholm region, sweden, between 2008 and 2015. all women were invited to mammography screening every 18 to 24\xa0months free of charge. images were collected from the pacs of the three breast centers that completely cover the region. dicom metadata were collected together with the images. screening decisions and clinical outcome data were collected by linkage to the regional cancer center registers. incident cancer cases, from one center, were pixel-level annotated by a radiologist. a separate subset for efficient evaluation of external networks was defined for the uptake area of one center. the collection and use of the dataset for the purpose of ai research has been approved by the ethical review board. csaw included 499,807 women invited to screening between 2008 and 2015 with a total of 1,182,733 completed screening examinations. around 2 million mammography images have currently been collected, including all images for women who developed breast cancer. there were 10,582 women diagnosed with breast cancer; for 8463, it was their first breast cancer. clinical data include biopsy-verified breast cancer diagnoses, histological origin, tumor size, lymph node status, elston grade, and receptor status. one thousand eight hundred ninety-one images of 898 women had tumors pixel level annotated including any tumor signs in the prior negative screening mammogram. our dataset has already been used for evaluation by several research groups. we have defined a high-volume platform for training and evaluation of deep neural networks in the domain of mammographic imaging.","['million mammography image dataset', 'deep neural networks', 'based screening cohort', 'aged women', 'cohort', 'training', 'screen', 'population', 'multi', 'evaluation', 'csa']"
"neurons in parasubiculum (pas), presubiculum (prs), and medial entorhinal cortex (mec) code for place (grid cells) and head direction. directional input has been shown to be important for stable grid cell properties in mec, and pas and prs have been postulated to provide this information to mec. in line with this, head direction cells in those brain areas are present at postnatal day 11 (p11), having directional tuning that stabilizes shortly after eye opening, which is before premature grid cells emerge in mec at p16. whether functional connectivity between these structures exists at those early postnatal stages is unclear. using anatomical tracing, voltage-sensitive dye imaging and single-cell patch recordings in female and male rat brain slices between p2 and p61, we determined when the pathways from pas and prs to mec emerge, become functional, and how they develop. anatomical connections from pas and prs to superficial mec emerge between p4 and p6. monosynaptic connectivity from pas and prs to superficial mec was measurable from p9 to p10 onward, whereas connectivity with deep mec was measurable from p11 to p12. from p14/p15 on, reactivity of mec neurons to parasubicular and presubicular inputs becomes adult-like and continues to develop until p28-p30. the maturation of the efficacy of both inputs between p9 and p21 is paralleled by maturation of morphological properties, changes in intrinsic properties of mec principal neurons, and changes in the gabaergic network of mec. in conclusion, synaptic projections from pas and prs to mec become functional and adult-like before the emergence of grid cells in mec.significance statement head direction information, crucial for grid cells in medial entorhinal cortex (mec), is thought to enter mec via parasubiculum (pas) and presubiculum (prs). unraveling the development of functional connections between pas, prs, and mec is key to understanding how spatial navigation, an important cognitive function, may evolve. to gain insight into the development, we used anatomical tracing techniques, voltage-sensitive dye imaging, and single-cell recordings. the combined data led us to conclude that synaptic projections from pas and prs to mec become functional and adult-like before eye opening, allowing crucial head direction information to influence place encoding before the emergence of grid cells in rat mec.","['medial entorhinal cortex', 'postnatal development', 'functional projections', 'rat', 'presubiculum', 'parasubiculum']"
"scoring functions play an important role in structure-based virtual screening. it has been widely accepted that target-specific scoring functions (tssfs) may achieve better performance compared with universal scoring functions in actual drug research and development processes. a method that can effectively construct tssfs will be of great value to drug design and discovery. in this work, we proposed a deep learning-based model named deepscore to achieve this goal. deepscore adopted the form of pmf scoring function to calculate protein-ligand binding affinity. however, different from pmf scoring function, in deepscore, the score for each protein-ligand atom pair was calculated using a feedforward neural network. our model significantly outperformed glide gscore on validation data set dud-e. the average roc-auc on 102 targets was 0.98. we also combined gscore and deepscore together using a consensus method and put forward a consensus model named deepscorecs. the comparison results showed that deepscore outperformed other machine learning-based tssfs building methods. furthermore, we presented a strategy to visualize the prediction of deepscore. all of these results clearly demonstrated that deepscore would be a useful model in constructing tssfs and represented a novel way incorporating deep learning and drug design.","['specific scoring functions using deep learning methods', 'virtual screening ability', 'target', 'improving']"
"artificial intelligence-based unsupervised deep learning (dl) is widely used to mine multimodal big data. however, there are few applications of this technology to cancer genomics. we aim to develop dl models to extract deep features from the breast cancer gene expression data and copy number alteration (cna) data separately and jointly. we hypothesize that the deep features are associated with patients' clinical characteristics and outcomes. two unsupervised denoising autoencoders (das) were developed to extract deep features from tcga (the cancer genome atlas) breast cancer gene expression and cna data separately and jointly. a heat map was used to view and cluster patients into subgroups based on these dl features. fisher's exact test and pearson' chi-square test were applied to test the associations of patients' groups and clinical information. survival differences between the groups were evaluated by kaplan⁻meier (km) curves. associations between each of the features and patient's overall survival were assessed using cox's proportional hazards (cox-ph) model and a risk score for each feature set from the different omics data sets was generated from the survival regression coefficients. the risk scores for each feature set were binarized into high- and low-risk patient groups to evaluate survival differences using km curves. furthermore, the risk scores were traced back to their gene level das weights so that the three gene lists for each of the genomic data points were generated to perform gene set enrichment analysis. patients were clustered into two groups based on concatenated features from the gene expression and cna data and these two groups showed different overall survival rates (p-value = 0.049) and different er (estrogen receptor) statuses (p-value = 0.002, or (odds ratio) = 0.626). all the risk scores from the gene expression and cna data and their concatenated one were significantly associated with breast cancer survival. the patients with the high-risk group were significantly associated with patients' worse outcomes (p-values ≤ 0.0023). the concatenated risk score was enriched by the amp-activated protein kinase (ampk) signaling pathway, the regulation of dna-templated transcription, the regulation of nucleic acid-templated transcription, the regulation of apoptotic process, the positive regulation of gene expression, the positive regulation of cell proliferation, heart morphogenesis, the regulation of cellular macromolecule biosynthetic process, with fdr (false discovery rate) less than 0.05. we confirmed das can effectively extract meaningful genomic features from genomic data and concatenating multiple data sources can improve the significance of the features associated with breast cancer patients' clinical characteristics and outcomes.","['deep genomic features extracted', 'denoising autoencoders', 'breast cancer', 'association analysis']"
we propose a novel optical computing architecture for massive parallel matrix manipulation based on reconfigurable time-wavelength plane manipulation and and dispersed time delay. two linear weighting methods in either wavelength or time domain are proposed and validated. we perform the autocorrelation function of a 7-bit m-sequence with the speed at 1.18×1011 multiplications and accumulations per second (macs/s) and a multiplication of a 4 × 4 matrix and a 4 × 1 vector at 2.69×109 macs/s. the edge extraction of 32 × 32 binary images is also realized in simulation by optical 2d convolution at 5×108 macs/s. the proposed optical computing unit can be a key building block to process complex computing tasks with advanced deep learning algorithms and it is promising for the future photonic neural network circuits.,"['wavelength plane manipulation', 'programmable matrix operation', 'dispersed time delay', 'reconfigurable time']"
"owing to improvements in image recognition via deep learning, machine-learning algorithms could eventually be applied to automated medical diagnoses that can guide clinical decision-making. however, these algorithms remain a 'black box' in terms of how they generate the predictions from the input data. also, high-performance deep learning requires large, high-quality training datasets. here, we report the development of an understandable deep-learning system that detects acute intracranial haemorrhage (ich) and classifies five ich subtypes from unenhanced head computed-tomography scans. by using a dataset of only 904 cases for algorithm training, the system achieved a performance similar to that of expert radiologists in two independent test datasets containing 200 cases (sensitivity of 98% and specificity of 95%) and 196 cases (sensitivity of 92% and specificity of 95%). the system includes an attention map and a prediction basis retrieved from training data to enhance explainability, and an iterative process that mimics the workflow of radiologists. our approach to algorithm development can facilitate the development of deep-learning systems for a variety of clinical applications and accelerate their adoption into clinical practice.","['acute intracranial haemorrhage', 'small datasets', 'learning algorithm', 'explainable deep', 'detection']"
"dna methylation plays an important role in the regulation of some biological processes. up to now, with the development of machine learning models, there are several sequence-based deep learning models designed to predict dna methylation states, which gain better performance than traditional methods like random forest and svm. however, convolutional network based deep learning models that use one-hot encoding dna sequence as input may discover limited information and cause unsatisfactory prediction performance, so more data and model structures of diverse angles should be considered. in this work, we proposed a hybrid sequence-based deep learning model with both medip-seq data and histone information to predict dna methylated cpg states (mhcpg). we combined both medip-seq data and histone modification data with sequence information and implemented convolutional network to discover sequence patterns. in addition, we used statistical data gained from previous three input data and adopted a 3-layer feedforword neuron network to extract more high-level features. we compared our method with traditional predicting methods using random forest and other previous methods like cpgenie and deepcpg, the result showed that mhcpg exceeded the other approaches and gained more satisfactory performance.","['predicting dna methylation states', 'hybrid information based deep', 'learning model']"
"since 2017, an increasing amount of attention has been paid to the supervised deep learning-based macromolecule in situ structural classification (i.e. subtomogram classification) in cellular electron cryo-tomography (cect) due to the substantially higher scalability of deep learning. however, the success of such supervised approach relies heavily on the availability of large amounts of labeled training data. for cect, creating valid training data from the same data source as prediction data is usually laborious and computationally intensive. it would be beneficial to have training data from a separate data source where the annotation is readily available or can be performed in a high-throughput fashion. however, the cross data source prediction is often biased due to the different image intensity distributions (a.k.a. domain shift).","['cross data source macromolecule', 'situ structural classification', 'cellular electron cryo', 'adversarial domain adaptation', 'tomograms']"
"sleep is a vital need, forcing us to spend a large portion of our life unable to interact with the external world. current models interpret such extreme vulnerability as the price to pay for optimal learning. sleep would limit external interferences on memory consolidation1-3 and allow neural systems to reset through synaptic downscaling4. yet, the sleeping brain continues generating neural responses to external events5,6, revealing the preservation of cognitive processes ranging from the recognition of familiar stimuli to the formation of new memory representations7-15. why would sleepers continue processing external events and yet remain unresponsive? here we hypothesized that sleepers enter a 'standby mode' in which they continue tracking relevant signals, finely balancing the need to stay inward for memory consolidation with the ability to rapidly awake when necessary. using electroencephalography to reconstruct competing streams in a multitalker environment16, we demonstrate that the sleeping brain amplifies meaningful speech compared to irrelevant signals. however, the amplification of relevant stimuli was transient and vanished during deep sleep. the effect of sleep depth could be traced back to specific oscillations, with k-complexes promoting relevant information in light sleep, whereas slow waves actively suppress relevant signals in deep sleep. thus, the selection of relevant stimuli continues to operate during sleep but is strongly modulated by specific brain rhythms.","['sleepers track informative speech', 'multitalker environment']"
"the paris system for urine cytopathology (the paris system) has succeeded in making the analysis of liquid-based urine preparations more reproducible. any algorithm seeking to automate this system must accurately estimate the nuclear-to-cytoplasmic (n:c) ratio and produce a qualitative ""atypia score."" the authors propose a hybrid deep-learning and morphometric model that reliably automates the paris system.",['2018 cancer cytopathology young investigator']
"healthcare is undergoing a transformation, and it is imperative to leverage new technologies to generate new data and support the advent of precision medicine (pm). recent scientific breakthroughs and technological advancements have improved our understanding of disease pathogenesis and changed the way we diagnose and treat disease leading to more precise, predictable and powerful health care that is customized for the individual patient. genetic, genomics, and epigenetic alterations appear to be contributing to different diseases. deep clinical phenotyping, combined with advanced molecular phenotypic profiling, enables the construction of causal network models in which a genomic region is proposed to influence the levels of transcripts, proteins, and metabolites. phenotypic analysis bears great importance to elucidat the pathophysiology of networks at the molecular and cellular level. digital biomarkers (bms) can have several applications beyond clinical trials in diagnostics-to identify patients affected by a disease or to guide treatment. digital bms present a big opportunity to measure clinical endpoints in a remote, objective and unbiased manner. however, the use of ""omics"" technologies and large sample sizes have generated massive amounts of data sets, and their analyses have become a major bottleneck requiring sophisticated computational and statistical methods. with the wealth of information for different diseases and its link to intrinsic biology, the challenge is now to turn the multi-parametric taxonomic classification of a disease into better clinical decision-making by more precisely defining a disease. as a result, the big data revolution has provided an opportunity to apply artificial intelligence (ai) and machine learning algorithms to this vast data set. the advancements in digital health opportunities have also arisen numerous questions and concerns on the future of healthcare practices in particular with what regards the reliability of ai diagnostic tools, the impact on clinical practice and vulnerability of algorithms. ai, machine learning algorithms, computational biology, and digital bms will offer an opportunity to translate new data into actionable information thus, allowing earlier diagnosis and precise treatment options. a better understanding and cohesiveness of the different components of the knowledge network is a must to fully exploit the potential of it.","['precision medicine paving', 'patients centric care', 'new technologies', 'new era', 'innovation']"
"we propose reinforcement learning on simple networks consisting of random connections of spiking neurons (both recurrent and feed-forward) that can learn complex tasks with very little trainable parameters. such sparse and randomly interconnected recurrent spiking networks exhibit highly non-linear dynamics that transform the inputs into rich high-dimensional representations based on the current and past context. the random input representations can be efficiently interpreted by an output (or readout) layer with trainable parameters. systematic initialization of the random connections and training of the readout layer using q-learning algorithm enable such small random spiking networks to learn optimally and achieve the same learning efficiency as humans on complex reinforcement learning (rl) tasks like atari games. in fact, the sparse recurrent connections cause these networks to retain fading memory of past inputs, thereby enabling them to perform temporal integration across successive rl time-steps and learn with partial state inputs. the spike-based approach using small random recurrent networks provides a computationally efficient alternative to state-of-the-art deep reinforcement learning networks with several layers of trainable parameters.","['complexity liquid state machines', 'reinforcement learning', 'low']"
"electroencephalography (eeg) monitors brain activity during sleep and is used to identify sleep disorders. in sleep medicine, clinicians interpret raw eeg signals in so-called sleep stages, which are assigned by experts to every 30s window of signal. for diagnosis, they also rely on shorter prototypical micro-architecture events which exhibit variable durations and shapes, such as spindles, k-complexes or arousals. annotating such events is traditionally performed by a trained sleep expert, making the process time consuming, tedious and subject to inter-scorer variability. to automate this procedure, various methods have been developed, yet these are event-specific and rely on the extraction of hand-crafted features.","['detect multiple sleep micro', 'deep learning approach', 'eeg signal', 'events', 'dosed']"
"human falls are a global public health issue resulting in over 37.3 million severe injuries and 646,000 deaths yearly. falls result in direct financial cost to health systems and indirectly to society productivity. unsurprisingly, human fall detection and prevention are a major focus of health research. in this article, we consider deep learning for fall detection in an iot and fog computing environment. we propose a convolutional neural network composed of three convolutional layers, two maxpool, and three fully-connected layers as our deep learning model. we evaluate its performance using three open data sets and against extant research. our approach for resolving dimensionality and modelling simplicity issues is outlined. accuracy, precision, sensitivity, specificity, and the matthews correlation coefficient are used to evaluate performance. the best results are achieved when using data augmentation during the training process. the paper concludes with a discussion of challenges and future directions for research in this domain.","['based human fall detection using convolutional neural networks', 'accelerometer']"
"soil moisture is one of the main factors in agricultural production and hydrological cycles, and its precise prediction is important for the rational use and management of water resources. however, soil moisture involves complex structural characteristics and meteorological factors, and it is difficult to establish an ideal mathematical model for soil moisture prediction. existing prediction models have problems such as prediction accuracy, generalization, and multi-feature processing capability, and prediction performance must improve. based on this, taking the beijing area as the research object, the deep learning regression network (dnnr) with big data fitting capability was proposed to construct a soil moisture prediction model. by integrating the dataset, analyzing the time series of the predictive variables, and clarifying the relationship between features and predictive variables through the taylor diagram, selected meteorological parameters can provide effective weights for moisture prediction. test results prove that the deep learning model is feasible and effective for soil moisture prediction. its' good data fitting and generalization capability can enrich the input characteristics while ensuring high accuracy in predicting the trends and values of soil moisture data and provides an effective theoretical basis for water-saving irrigation and drought control.","['soil moisture prediction model based', 'deep learning', 'research']"
"the cerebellum with its layered structure and stereotyped and conserved connectivity has long puzzled neurobiologists. while it is well established that the cerebellum functions in regulating balance, motor coordination and motor learning, how it achieves these end results has not been very clear. recent technical advances have made it possible to tease apart the contributions of cerebellar cell types to movement in behaving animals. we review these studies focusing on the three major cerebellar cell types, namely: granule cells, purkinje neurons and the cells of the deep cerebellar nuclei. further, we also review our current understanding of cortico-cerebellar and basal ganglia-cerebellar interactions that play vital roles in motor planning and motor learning.","['instructional control', 'predictive', 'movement', 'contributions', 'cerebellum']"
"long non-coding rnas (lncrnas) play a crucial role in the pathogenesis and development of complex diseases. predicting potential lncrna-disease associations can improve our understanding of the molecular mechanisms of human diseases and help identify biomarkers for disease diagnosis, treatment, and prevention. previous research methods have mostly integrated the similarity and association information of lncrnas and diseases, without considering the topological structure information among these nodes, which is important for predicting lncrna-disease associations. we propose a method based on information flow propagation and convolutional neural networks, called ldapred, to predict disease-related lncrnas. ldapred not only integrates the similarities, associations, and interactions among lncrnas, diseases, and mirnas, but also exploits the topological structures formed by them. in this study, we construct a dual convolutional neural network-based framework that comprises the left and right sides. the embedding layer on the left side is established by utilizing lncrna, mirna, and disease-related biological premises. on the right side of the frame, multiple types of similarity, association, and interaction relationships among lncrnas, diseases, and mirnas are calculated based on information flow propagation on the bi-layer networks, such as the lncrna-disease network. they contain the network topological structure and they are learned by the right side of the framework. the experimental results based on five-fold cross-validation indicate that ldapred performs better than several state-of-the-art methods. case studies on breast cancer, colon cancer, and osteosarcoma further demonstrate ldapred's ability to discover potential lncrna-disease associations.","['information flow propagation', 'convolutional neural network', 'method based', 'associated lncrnas', 'prediction', 'ldapred', 'disease']"
"coherent beam combining is a method to scale the peak and average power levels of laser systems beyond the limit of a single emitter system. this is achieved by stabilizing the relative optical phase of multiple lasers and combining them. we investigated the use of reinforcement learning (rl) and neural networks (nn) in this domain. starting from a randomly initialized neural network, the system converged to a phase stabilization policy, which was comparable to a software implemented proportional-integral-derivative (pid) controller. furthermore, we demonstrate the capability of neural networks to predict relative phase noise, which is one potential advantage of this method.","['coherent beam combining applications', 'deep reinforcement learning']"
"a shareable repository of clinical notes is critical for advancing natural language processing (nlp) research, and therefore a goal of many nlp researchers is to create a shareable repository of clinical notes, that has breadth (from multiple institutions) as well as depth (as much individual data as possible).","['art deep learning based parsers', 'parsing clinical text using', 'systematic comparison', 'state']"
"artificial intelligence (ai) techniques such as deep learning (dl) for computational imaging usually require to experimentally collect a large set of labeled data to train a neural network. here we demonstrate that a practically usable neural network for computational imaging can be trained by using simulation data. we take computational ghost imaging (cgi) as an example to demonstrate this method. we develop a one-step end-to-end neural network, trained with simulation data, to reconstruct two-dimensional images directly from experimentally acquired one-dimensional bucket signals, without the need of the sequence of illumination patterns. this is in particular useful for image transmission through quasi-static scattering media as little care is needed to take to simulate the scattering process when generating the training data. we believe that the concept of training using simulation data can be used in various dl-based solvers for general computational imaging.","['computational ghost imaging', 'learning approach', 'end deep', 'learning', 'end', 'simulation']"
"alzheimer's disease (ad) is the most common form of progressive and irreversible dementia, and accurate diagnosis of ad at its prodromal stage is clinically important. currently, computer-aided diagnosis of ad and mild cognitive impairment (mci) using 18f-fluorodeoxy-glucose positron emission tomography (18f-fdg pet) imaging is usually based on low-level imaging features or deep learning methods, which have difficulties in achieving sufficient classification accuracy or lack clinical significance. this research therefore aimed to implement a new feature extraction method known as radiomics, to improve the classification accuracy and discover high-order features that can reveal pathological information.","['brain neuron degeneration disease using 18f', 'novel feature extraction method', 'mild cognitive impairment', 'fdg pet imaging', 'disease', 'radiomics', 'implementation', 'alzheimer']"
"a fully convolutional network (fcn) based deep architecture called dual path u-net (dpu-net) is proposed for automatic segmentation of the lumen and media-adventitia in intravascular ultrasound (ivus) frames, which is crucial for diagnosis of many cardiovascular diseases and also for facilitating 3d reconstructions of human arteries. one of the most prevalent problems in medical image analysis is the lack of training data. to overcome this limitation, we propose a twofold solution. first, we introduce a deep architecture that is able to learn using a small number of training images and still achieves a high degree of generalization ability. second, we strengthen the proposed dpu-net by having a real-time augmentor control the image augmentation process. our real-time augmentor contains specially-designed operations that simulate three types of ivus artifacts and integrate them into the training images. we exhaustively assessed our twofold contribution over balocco's standard publicly available ivus 20\u202fmhz and 40\u202fmhz b-mode dataset, which contain 109 training image, 326 test images and 19 training images, 59 test images, respectively. models are trained from scratch with the training images provided and evaluated with two commonly used metrics in the ivus segmentation literature, namely jaccard measure (jm) and hausdorff distance (hd). experimental results show that dpu-net achieves 0.87 jm, 0.82\u202fmm hd and 0.86 jm, 1.07\u202fmm hd over 40\u202fmhz dataset for segmenting the lumen and the media, respectively. also, dpu-net achieves 0.90 jm, 0.25\u202fmm hd and 0.92 jm, 0.30\u202fmm hd over 20\u202fmhz images for segmenting the lumen and the media, respectively. in addition, dpu-net outperforms existing methods by 8-15% in terms of hd distance. dpu-net also shows a strong generalization property for predicting images in the test sets that contain a significant amount of major artifacts such as bifurcations, shadows, and side branches that are not common in the training set. furthermore, dpu-net runs within 0.03\u202fs to segment each frame with a single modern gpu (nvidia gtx 1080). the proposed work leverages modern deep learning-based method for segmentation of lumen and the media vessel walls in both 20\u202fmhz and 40\u202fmhz ivus b-mode images and achieves state-of-the-art results without any manual intervention. the code is available online at https://github.com/kulbear/ivus-ultrasonic.","['intravascular ultrasound images using dual path u', 'robust segmentation', 'arterial walls', 'net']"
"in this work, we propose restocnet, a residual stochastic multilayer convolutional spiking neural network (snn) composed of binary kernels, to reduce the synaptic memory footprint and enhance the computational efficiency of snns for complex pattern recognition tasks. restocnet consists of an input layer followed by stacked convolutional layers for hierarchical input feature extraction, pooling layers for dimensionality reduction, and fully-connected layer for inference. in addition, we introduce residual connections between the stacked convolutional layers to improve the hierarchical feature learning capability of deep snns. we propose spike timing dependent plasticity (stdp) based probabilistic learning algorithm, referred to as hybrid-stdp (hb-stdp), incorporating hebbian and anti-hebbian learning mechanisms, to train the binary kernels forming restocnet in a layer-wise unsupervised manner. we demonstrate the efficacy of restocnet and the presented hb-stdp based unsupervised training methodology on the mnist and cifar-10 datasets. we show that residual connections enable the deeper convolutional layers to self-learn useful high-level input features and mitigate the accuracy loss observed in deep snns devoid of residual connections. the proposed restocnet offers >20 × kernel memory compression compared to full-precision (32-bit) snn while yielding high enough classification accuracy on the chosen pattern recognition tasks.","['residual stochastic binary convolutional spiking neural network', 'efficient neuromorphic computing', 'restocnet', 'memory']"
"deep learning tools have been a new way for privacy attacks on remote sensing images. however, since labeled data of privacy objects in remote sensing images are less, the samples for training are commonly small. besides, traditional deep neural networks have a huge amount of parameters which leads to over complexity of models and have a great heavy of computation. they are not suitable for small sample image classification task. a sparse method for deep neural network is proposed to reduce the complexity of deep learning model with small samples. a singular value decomposition algorithm is employed to reduce the dimensions of the output feature map of the upper convolution layers, which can alleviate the input burden of the current convolution layer, and decrease a large number of parameters of the deep neural networks, and then restrain the number of redundant or similar feature maps generated by the over-complete schemes in deep learning. experiments with two remote sensing image data sets ucmlu and whurs show that the image classification accuracy with our sparse model is better than the plain model,which is improving the accuracy by 3%,besides, its convergence speed is faster.","['sparse deep learning model', 'remote sensing images', 'privacy attack']"
"random phase encoding (rpe) techniques for image encryption have drawn increasing attention during the past decades. we demonstrate in this contribution that the rpe-based optical cryptosystems are vulnerable to the chosen-plaintext attack (cpa) with deep learning strategy. a deep neural network (dnn) model is employed and trained to learn the working mechanism of optical cryptosystems, and finally obtaining a certain optimized dnn that acts as a decryption system. numerical simulations were carried out to verify its feasibility and reliability of not only the classical double rpe (drpe) scheme but also the security-enhanced tripe rpe (trpe) scheme. the results further indicate the possibility of reconstructing images (plaintexts) outside the original data set.","['based optical cryptosystem via deep learning', 'random', 'phase', 'encoding', 'cryptanalysis']"
"rotator cuff muscle tear is one of the most frequent reason of operations in orthopedic surgery. there are several clinical indicators such as goutallier grade and occupation ratio in the diagnosis and surgery of these diseases, but subjective intervention of the diagnosis is an obstacle in accurately detecting the correct region.","['supraspinous fossa using deep learning', 'automatic muscle atrophy measuring algorithm', 'supraspinatus', 'ratio', 'development', 'calculate']"
"amyotrophic lateral sclerosis (als) is a neurodegenerative disease caused by aberrations in the genome. while several disease-causing variants have been identified, a major part of heritability remains unexplained. als is believed to have a complex genetic basis where non-additive combinations of variants constitute disease, which cannot be picked up using the linear models employed in classical genotype-phenotype association studies. deep learning on the other hand is highly promising for identifying such complex relations. we therefore developed a deep-learning based approach for the classification of als patients versus healthy individuals from the dutch cohort of the project mine dataset. based on recent insight that regulatory regions harbor the majority of disease-associated variants, we employ a two-step approach: first promoter regions that are likely associated to als are identified, and second individuals are classified based on their genotype in the selected genomic regions. both steps employ a deep convolutional neural network. the network architecture accounts for the structure of genome data by applying convolution only to parts of the data where this makes sense from a genomics perspective.","['predicting amyotrophic lateral sclerosis', 'deep neural networks', 'genome data', 'using', 'structure', 'genotype', 'design']"
"the south american arowanas (osteoglossiformes, osteoglossidae, osteoglossum) are emblematic species widely distributed in the amazon and surrounding basins. arowana species are under strong anthropogenic pressure as they are extensively exploited for ornamental and food purposes. until now, limited genetic and cytogenetic information has been available, with only a few studies reporting to their genetic diversity and population structure. in the present study, cytogenetic and dartseq-derived single nucleotide polymorphism (snp) data were used to investigate the genetic diversity of the two osteoglossum species, the silver arowana o. bicirrhosum, and the black arowana o. ferreirai. both species differ in their 2n (with 2n = 54 and 56 for o. ferreirai and o. bicirrhosum, respectively) and in the composition and distribution of their repetitive dna content, consistent with their taxonomic status as different species. our genetic dataset was coupled with contemporary and paleogeographic niche modeling, to develop concurrent demographic models that were tested against each other with a deep learning approach in o. bicirrhosum. our genetic results reveal that o. bicirrhosum colonized the tocantins-araguaia basin from the amazon basin about one million years ago. in addition, we highlighted a higher genetic diversity of o. bicirrhosum in the amazon populations in comparison to those from the tocantins-araguaia basin.","['south american arowanas', 'interspecific genetic differences', 'historical demography', 'osteoglossu', 'osteoglossiformes', 'osteoglossidae']"
"prioritization of cancer-related genes from gene expression profiles and proteomic data is vital to improve the targeted therapies research. although computational approaches have been complementing high-throughput biological experiments on the understanding of human diseases, it still remains a big challenge to accurately discover cancer-related proteins/genes via automatic learning from large-scale protein/gene expression data and protein-protein interaction data. most of the existing methods are based on network construction combined with gene expression profiles, which ignore the diversity between normal samples and disease cell lines. in this study, we introduced a deep learning model based on a sparse auto-encoder to learn the specific characteristics of protein interactions in cancer cell lines integrated with protein expression data. the model showed learning ability to identify cancer-related proteins/genes from the input of different protein expression profiles by extracting the characteristics of protein interaction information, which could also predict cancer-related protein combinations. comparing with other reported methods including differential expression and network-based methods, our model got the highest area under the curve value (>0.8) in predicting cancer-related genes. our study prioritized ~500 high-confidence cancer-related genes; among these genes, 211 already known cancer drug targets were found, which supported the accuracy of our method. the above results indicated that the proposed auto-encoder model could computationally prioritize candidate proteins/genes involved in cancer and improve the targeted therapies research.","['deep learning model based', 'drug target combinations', 'sparse auto', 'related genes', 'prioritizing cancer', 'encoder']"
"control of blood glucose is essential for diabetes management. current digital therapeutic approaches for subjects with type 1 diabetes mellitus such as the artificial pancreas and insulin bolus calculators leverage machine learning techniques for predicting subcutaneous glucose for improved control. deep learning has recently been applied in healthcare and medical research to achieve state-of-the-art results in a range of tasks including disease diagnosis, and patient state prediction among others. in this paper, we present a deep learning model that is capable of forecasting glucose levels with leading accuracy for simulated patient cases (root-mean-square error (rmse) = 9.38\xa0 ± 0.71 [mg/d","['xa0 ± 2', 'min horizon', 'min horizo', 'rmse', 'mg', 'er', 'dl', '87', '60', '30', '25', '18']"
"could an overly deep sedation be anticipated from electroencephalogram (eeg) patterns? we report here motifs hidden in the eeg signal that predict the appearance of iso-electric suppressions (ies), observed during epileptic encephalopathies, drug intoxications, comatose, brain death or during anesthetic over-dosage that are considered to be detrimental. to show that ies occurrences can be predicted from eeg traces dynamics, we focus on transient suppression of the alpha rhythm (8-14\u2009hz) recorded for 80 patients, that had a propofol target controlled infusion of 5\u2009μg/ml during a general anesthesia. we found that the first time of appearance as well as changes in duration of these alpha-suppressions (αs) are two parameters that anticipate the appearance of ies. using machine learning, we predicted ies appearance from the first 10\u2009min of eeg (auc of 0.93). to conclude, transient motifs in the alpha rhythm predict ies during anesthesia and can be used to identify patients, with higher risks of post-operative complications.","['alpha rhythm collapse predicts iso', 'electric suppressions', 'anesthesia']"
"over 600 myr of evolutionary divergence between vertebrates and invertebrates is associated with considerable neuroanatomical variation both across and within these lineages. by contrast, valence encoding is an important behavioural trait that is evolutionarily conserved across vertebrates and invertebrates, and enables individuals to distinguish between positive (potentially beneficial) and negative (potentially harmful) situations. we tested the hypothesis that social interactions of positive and negative valence are modularly encoded in the honeybee brain (i.e. encoded in different cellular subpopulations) as in vertebrate brains. in vertebrates, neural activation patterns are distributed across distinct parts of the brain, suggesting that discrete circuits encode positive or negative stimuli. evidence for this hypothesis would suggest a deep homology of neural organization between insects and vertebrates for valence encoding, despite vastly different brain sizes. alternatively, overlapping localization of valenced social information in the brain would imply a 're-use' of circuitry in response to positive and negative social contexts, potentially to overcome the energetic constraints of a tiny brain. we used immediate early gene expression to map positively and negatively valenced social interactions in the brain of the western honeybee apis mellifera. we found that the valence of a social signal is represented by distinct anatomical subregions of the mushroom bodies, an invertebrate sensory neuropil associated with social behaviour, multimodal sensory integration, learning and memory. our results suggest that the modularization of valenced social information in the brain is a fundamental property of neuroanatomical organization.","['mushroom body kenyon cells', 'social information', 'honeybee brain', 'different subpopulations', 'valence', 'encoded']"
"currently available risk prediction methods are limited in their ability to deal with complex, heterogeneous, and longitudinal data such as that available in primary care records, or in their ability to deal with multiple competing risks. this paper develops a novel deep learning approach that is able to successfully address current limitations of standard statistical approaches such as landmarking and joint modeling. our approach, which we call dynamic-deephit, flexibly incorporates the available longitudinal data comprising various repeated measurements (rather than only the last available measurements) in order to issue dynamically updated survival predictions for one or multiple competing risk(s). dynamic-deephit learns the time-to-event distributions without the need to make any assumptions about the underlying stochastic models for the longitudinal and the time-to-event processes. thus, unlike existing works in statistics, our method is able to learn data-driven associations between the longitudinal data and the various associated risks without underlying model specifications. we demonstrate the power of our approach by applying it to a real-world longitudinal dataset from the u.k. cystic fibrosis registry, which includes a heterogeneous cohort of 5883 adult patients with annual follow-ups between 2009 to 2015. the results show that dynamic-deephit provides a drastic improvement in discriminating individual risks of different forms of failures due to cystic fibrosis. furthermore, our analysis utilizes post-processing statistics that provide clinical insight by measuring the influence of each covariate on risk predictions and the temporal importance of longitudinal measurements, thereby enabling us to identify covariates that are influential for different competing risks.","['deep learning approach', 'competing risks based', 'dynamic survival analysis', 'longitudinal data', 'dynamic', 'deephit']"
"recent years have witnessed increasing popularity and development of deep learning spanning through various fields. deep networks, and in particular convolutional neural network (cnn) have also achieved many state-of-the-art competition results in the intelligent fault diagnosis of mechanical systems. however, most of the existing studies have been performed with the assumption that the same distribution holds for both the training data and the test data, which is not in accord with situations in real diagnosis tasks. to tackle this problem, a transfer learning framework based on pre-trained cnn, which leverages the knowledge learned from the training data to facilitate diagnosing a new but similar task, is presented in this work. first, the cnn is trained on large datasets to learn the hierarchical features from the raw data. then, the architecture and weights of the pre-trained cnn are transferred to new tasks with proper fine-tuning instead of training a network from scratch. to adapt the pre-trained cnn in a specific case, three transfer learning strategies are discussed and compared to investigate the applicability as well as the significance of feature transferability from the different levels of a deep structure. the case studies show that the proposed framework can transfer the features of the pre-trained cnn to boost the diagnosis performance on unseen machine conditions in terms of diverse working conditions and fault types.","['diagnosing unseen machine conditions', 'deep convolutional neural networks', 'learning transferable features']"
"automated emotion recognition plays a vital role in problem solving, decision making and social activities of human life. an emotion is a set of reactions and experience to a given conditions, which are modeled as a linear combination of arousal and valence dimensions. emotional pattern recognition based on physiological signals is a relatively new and fast growing area of research. several physiological signals such as ecg, eeg, and emg have been used for emotion recognition. analysis of electrodermal activity (eda) signals is one of the popular technique for emotion state analysis. in this work, an attempt is made to discriminate arousal-valence dimensions using eda signals and multiscale one dimensional convolution neural network (mcnn). for this, eda signals are obtained from publically available online deap database. these signals are normalized using channel normalization and subjected to mcnn for event-related robust features and classification. k-fold cross validation is used to investigate the performance of classifier. the result shows that the mcnn are able to discriminate the emotional states in arousal/valence dimensions. the proposed approach obtained an overall classification accuracy of 83.75% and 81.25% for arousal and valence scale, respectively. the network yields better classification performance for arousal scale then valence diemension. this might be due to the fact that arousal represent the intensity of emotions. the result also show that the proposed approach is better than the conventional hand-crafted feature based approach. thus, it appears that the proposed approach can be used to differentiate autonomic and clinical conditions.","['emotion recognition using electrodermal activity signals', 'multiscale deep convolution neural network']"
"ultrashort echo time (ute) proton mri has gained popularity for assessing lung structure and function in pulmonary imaging; however, the development of rapid biomarker extraction and regional quantification has lagged behind due to labor-intensive lung segmentation.","['lung function quantification using ute proton mri', 'deep convolutional neural networks', 'multiplane consensus labeling']"
"deep neural networks have been successfully applied to diverse fields of computer vision. however, they only outperform human capacities in a few cases.","['deep neural networks outperform human expert', 'characterizing bioleaching bacterial biofilm composition', 'capacity']"
"the stoichiometry of protein complexes is precisely regulated in cells and is fundamental to protein function. singe-molecule fluorescence imaging based photobleaching event counting is a new approach for protein stoichiometry determination under physiological conditions. due to the interference of the high noise level and photoblinking events, accurately extracting real bleaching steps from single-molecule fluorescence traces is still a challenging task. here, we develop a novel method of using convolutional and long-short-term memory deep learning neural network (cldnn) for photobleaching event counting. we design the\xa0 convolutional layers\xa0to accurately extract features of steplike photobleaching drops and long-short-term memory (lstm) recurrent layers to distinguish between photobleaching and photoblinking events. compared with traditional algorithms, cldnn shows higher accuracy with at least 2 orders of magnitude improvement of efficiency, and it does not require user-specified parameters. we have verified our cldnn method using experimental data from imaging of single dye-labeled molecules in vitro and epidermal growth factor receptors (egfr) on cells. our cldnn method is expected to provide a new strategy to stoichiometry study and time series analysis in chemistry.","['molecule fluorescence imaging traces via deep learning', 'automated stoichiometry analysis', 'single']"
"the interaction between viral proteins and small molecule compounds is the basis of drug design. therefore, it is a fundamental challenge to identify viral proteins according to their amino acid sequences in the field of biopharmaceuticals. the traditional prediction methods su er from the data imbalance problem and take too long computation time. to this end, this paper proposes a deep learning framework for virus protein identifying. in the framework, we employ temporal convolutional network(tcn) instead of recurrent neural network(rnn) for feature extraction to improve computation e ciency. we also customize the cost-sensitive loss function of tcn and introduce the misclassification cost of training samples into the weight update of gradient boosting decision tree(gbdt) to address data imbalance problem. experiment results show that our framework not only outperforms traditional data imbalance methods but also greatly reduces the computation time with slight performance enhancement.","['viral protein identifying framework based', 'temporal convolutional network']"
"the topological landscape of gene interaction networks provides a rich source of information for inferring functional patterns of genes or proteins. however, it is still a challenging task to aggregate heterogeneous biological information such as gene expression and gene interactions to achieve more accurate inference for prediction and discovery of new gene interactions. in particular, how to generate a unified vector representation to integrate diverse input data is a key challenge addressed here.","['gene network inference', 'deep learning framework', 'aggregating biological information', 'gne']"
"clinical named entity recognition (cner) is a fundamental and crucial task for clinical and translation research. in recent years, deep learning methods have achieved significant success in cner tasks. however, these methods depend greatly on recurrent neural networks (rnns), which maintain a vector of hidden activations that are propagated through time, thus causing too much time to train models. in this paper, we propose a residual dilated convolutional neural network with the conditional random field (rd-cnn-crf) for the chinese cner, which makes the model asynchronous in computation and thus speeding up the training period dramatically. to be more specific, chinese characters and dictionary features are first projected into dense vector representations, then they are fed into the residual dilated convolutional neural network to capture contextual features. finally, a conditional random field is employed to capture dependencies between neighboring tags and obtain the optimal tag sequence for the entire sequence. computational results on the ccks-2017 task 2 benchmark dataset show that our proposed rd-cnn-crf method competes favorably with state-of-the-art rnn-based methods both in terms of computational performance and training time.","['chinese clinical named entity recognition using residual dilated convolutional neural network', 'conditional random field']"
"despite advances in artificial intelligence (ai), its application in medical imaging has been burdened and limited by expert-generated labels. we used images from optical coherence tomography angiography (octa), a relatively new imaging modality that measures retinal blood flow, to train an ai algorithm to generate flow maps from standard optical coherence tomography (oct) images, exceeding the ability and bypassing the need for expert labeling. deep learning was able to infer flow from single structural oct images with similar fidelity to octa and significantly better than expert clinicians (p\u2009<\u20090.00001). our model allows generating flow maps from large volumes of previously collected oct data in existing clinical trials and clinical practice. this finding demonstrates a novel application of ai to medical imaging, whereby subtle regularities between different modalities are used to image the same body part and ai is used to generate detailed inferences of tissue function from structure imaging.","['structural optical coherence tomography', 'generating retinal flow maps', 'artificial intelligence']"
"perivascular spaces (pvs) in the human brain are related to various brain diseases. however, it is difficult to quantify them due to their thin and blurry appearance. in this paper, we introduce a deep-learning-based method, which can enhance a magnetic resonance (mr) image to better visualize the pvs. to accurately predict the enhanced image, we propose a very deep 3d convolutional neural network that contains densely connected networks with skip connections. the proposed networks can utilize rich contextual information derived from low-level to high-level features and effectively alleviate the gradient vanishing problem caused by the deep layers. the proposed method is evaluated on 17 7t mr images by a twofold cross-validation. the experiments show that our proposed network is much more effective to enhance the pvs than the previous pvs enhancement methods.","['perivascular spaces using densely connected deep convolutional neural network', 'enhancement']"
"accurate segmentation of cardiac bi-ventricle (cbv) from magnetic resonance (mr) images has a great significance to analyze and evaluate the function of the cardiovascular system. however, the complex structure of cbv image makes fully automatic segmentation as a well-known challenge. in this paper, we propose an improved end-to-end encoder-decoder network for cbv segmentation from the pixel level view (cardiac-deepied). in our framework, we explicitly solve the high variability of complex cardiac structures through an improved encoder-decoder architecture which consists of fire dilated modules and d-fire dilated modules. this improved encoder-decoder architecture has the advantages of being capable of obtaining semantic task-aware representation and preserving fine-grained information. in addition, our method can dynamically capture potential spatiotemporal correlations between consecutive cardiac mr images through specially designed convolutional long-term and short-term memory structure; it can simulate spatiotemporal contexts between consecutive frame images. the combination of these modules enables the entire network to get an accurate, robust segmentation result. the proposed method is evaluated on the 145 clinical subjects with leave-one-out cross-validation. the average dice metric (dm) is up to 0.96 (left ventricle), 0.89 (myocardium), and 0.903 (right ventricle). the performance of our method outperforms state-of-the-art methods. these results demonstrate the effectiveness and advantages of our method for cbv regions segmentation at the pixel-level. it also reveals the proposed automated segmentation system can be embedded into the clinical environment to accelerate the quantification of cbv and expanded to volume analysis, regional wall thickness analysis, and three lv dimensions analysis.","['ventricle using improved end', 'level deep segmentation', 'end encoder', 'decoder network', 'automatic pixel', 'cardiac bi', 'cardiac', 'deepied']"
"visual recognition under adverse conditions is a very important and challenging problem of high practical value, due to the ubiquitous existence of quality distortions during image acquisition, transmission, or storage. while deep neural networks have been extensively exploited in the techniques of low-quality image restoration and high-quality image recognition tasks respectively, few studies have been done on the important problem of recognition from very low-quality images. this paper proposes a deep learning based framework for improving the performance of image and video recognition models under adverse conditions, using robust adverse pre-training or its aggressive variant. the robust adverse pre-training algorithms leverage the power of pre-training and generalizes conventional unsupervised pre-training and data augmentation methods. we further develop a transfer learning approach to cope with real-world datasets of unknown adverse conditions. the proposed framework is comprehensively evaluated on a number of image and video recognition benchmarks, and obtains significant performance improvements under various single or mixed adverse conditions. our visualization and analysis further add to the explainability of results.","['adverse conditions via deep networks', 'enhance visual recognition']"
"we propose a novel end-to-end approach, namely, the semantic-containing double-level embedding bi-lstm model (scde-bi-lstm), to solve the three key problems of q&a matching in the chinese medical field. in the similarity calculation of the q&a core module, we propose a text similarity calculation method that contains semantic information, to solve the problem that previous q&a methods do not incorporate the deep information of a sentence into the similarity calculations. for the sentence vector representation module, we present a double-level embedding sentence representation method to reduce the error caused by chinese medical word segmentation. in addition, due to the problem of the attention mechanism tending to cause backward deviation of the features, we propose an improved algorithm based on bi-lstm in the feature extraction stage. the q&a framework proposed in this paper not only retains important timing features but also loses low-frequency features and noise. additionally, it is applicable to different domains. to verify the framework, extensive chinese medical q&a corpora are created. we run several state-of-the-art q&a methods as contrastive experiments on the medical corpora and the current popular insuranceqa dataset under different performance measures. the experimental results on the medical corpora show that our framework significantly outperforms several strong baselines and achieves an improvement of top-1 accuracy of up to 14%, reaching 79.15%.","['level embedding bi', 'containing double', 'based semantic', 'answer matching', 'question', 'lstm', 'iarnn']"
"deep learning has been successfully used in numerous applications because of its outstanding performance and the ability to avoid manual feature engineering. one such application is electroencephalogram (eeg)-based brain-computer interface (bci), where multiple convolutional neural network (cnn) models have been proposed for eeg classification. however, it has been found that deep learning models can be easily fooled with adversarial examples, which are normal examples with small deliberate perturbations. this paper proposes an unsupervised fast gradient sign method (ufgsm) to attack three popular cnn classifiers in bcis, and demonstrates its effectiveness. we also verify the transferability of adversarial examples in bcis, which means we can perform attacks even without knowing the architecture and parameters of the target models, or the datasets they were trained on. to the best of our knowledge, this is the first study on the vulnerability of cnn classifiers in eeg-based bcis, and hopefully will trigger more attention on the security of bci systems.","['cnn classifiers', 'based bcis', 'vulnerability', 'eeg']"
"a 17-year-old male, who was involved in a baseball club, presented to our emergency department with the complaint of gradual onset of swelling of his right arm. contrast-enhanced computed tomography showed obstruction of the proximal portion of the right subclavian vein and pulmonary thromboembolism. venography confirmed an occluded right subclavian vein. the patient was diagnosed with right subclavian vein thrombosis, which is referred to as paget-schroetter syndrome (pss). an ultrasonography for the affected subclavian vein was helpful not only for making an accurate diagnosis of pss, but also for verifying dynamic venous flow changes depending on the forearm position. <learning objective: this paper aims to describe the usefulness of ultrasonography. a 17-year-old male was diagnosed with paget-schroetter syndrome (pss). in this case, we found ultrasonography is important for verifying dynamic venous flow changes depending on the forearm position. holding the forearm in a pronated and downward position may have been critical for maintaining good venous flow with prompt resolution of symptoms. ultrasonography may play a crucial role in assessing an appropriate treatment strategy for pss.>.","['schroetter syndrome accompanied', 'pulmonary thromboembolism', 'case report', 'paget']"
"messenger rna subcellular localization mechanisms play a crucial role in post-transcriptional gene regulation. this trafficking is mediated by trans-acting rna-binding proteins interacting with cis-regulatory elements called zipcodes. while new sequencing-based technologies allow the high-throughput identification of rnas localized to specific subcellular compartments, the precise mechanisms at play, and their dependency on specific sequence elements, remain poorly understood.","['mrna subcellular localization using deep recurrent neural networks', 'prediction']"
to identify the feasibility of using a deep convolutional neural network (dcnn) for the detection and localization of hip fractures on plain frontal pelvic radiographs (pxrs). hip fracture is a leading worldwide health problem for the elderly. a missed diagnosis of hip fracture on radiography leads to a dismal prognosis. the application of a dcnn to pxrs can potentially improve the accuracy and efficiency of hip fracture diagnosis.,"['plain pelvic radiographs', 'deep learning algorithm', 'hip fractures', 'visualization', 'detection', 'application']"
"although dna sequence plays a crucial role in establishing the unique epigenome of a cell type, little is known about the sequence determinants that lead to the unique epigenomes of different cell types produced during cell differentiation. to fill this gap, we employed two types of deep convolutional neural networks (cnns) constructed for each of differentially related cell types and for each of histone marks measured in the cells, to learn the sequence determinants of various histone modification patterns in each cell type.","['cell differentiation using deep learning', 'deciphering epigenomic code']"
"we aimed to establish a high-performing and robust classification strategy, using magnetic resonance imaging (mri), along with combinations of feature extraction and selection in human and machine learning using radiomics or deep features by employing a small dataset. using diffusion and contrast-enhanced t1-weighted mr images obtained from patients with glioblastomas and primary central nervous system lymphomas, classification task was assigned to a combination of radiomic features and (1) supervised machine learning after feature selection or (2) multilayer perceptron (mlp) network; or mr image input without radiomic feature extraction to (3) two neuro-radiologists or (4) an end-to-end convolutional neural network (cnn). the results showed similar high performance in generalized linear model (glm) classifier and mlp using radiomics features in the internal validation set, but mlp network remained robust in the external validation set obtained using different mri protocols. cnn showed the lowest performance in both validation sets. our results reveal that a combination of radiomic features and mlp network classifier serves a high-performing and generalizable model for classification task for a small dataset with heterogeneous mri protocols.","['primary central nervous system lymphoma', 'robust mri classification strategy', 'multilayer perceptron network classifier', 'radiomic features', 'distinguishing glioblastoma']"
"precisely segmented lung fields restrict the region-of-interest from which radiological patterns are searched, and is thus an indispensable prerequisite step in any chest radiographic cadx system. recently, a number of deep learning-based approaches have been proposed to implement this step. however, deep learning has its own limitations and cannot be used in resource-constrained settings. medical systems generally have limited ram, computational power, storage, and no gpus. they are thus not always suited for running deep learning-based models. shallow learning-based models with appropriately selected features give comparable performance but with modest resources. the present paper thus proposes a shallow learning-based method that makes use of 40 radiomic features to segment lung fields from chest radiographs. a distance regularized level set evolution (drlse) method along with other post-processing steps are used to refine its output. the proposed method is trained and tested using publicly available jsrt dataset. the testing results indicate that the performance of the proposed method is comparable to the state-of-the-art deep learning-based lung field segmentation (lfs) methods and better than other lfs methods.","['radiomic feature', 'lung fields', 'chest radiographs', 'based approach', 'segmentation']"
"as the most abundant mammalian mrna methylation, n6-methyladenosine (m6a) exists in >25% of human mrnas and is involved in regulating many different aspects of mrna metabolism, stem cell differentiation and diseases like cancer. however, our current knowledge about dynamic changes of m6a levels and how the change of m6a levels for a specific gene can play a role in certain biological processes like stem cell differentiation and diseases like cancer is largely elusive.","['functional differential m6a methylation genes', 'm6a', 'prioritization', 'identification', 'fundmdeep']"
"deep learning techniques have been extensively used in computerized pulmonary nodule analysis in recent years. many reported studies still utilized hybrid methods for diagnosis, in which convolutional neural networks (cnns) are used only as one part of the pipeline, and the whole system still needs either traditional image processing modules or human intervention to obtain final results. in this paper, we introduced a fast and fully-automated end-to-end system that can efficiently segment precise lung nodule contours from raw thoracic ct scans. our proposed system has four major modules: candidate nodule detection with faster regional-cnn (r-cnn), candidate merging, false positive (fp) reduction with cnn, and nodule segmentation with customized fully convolutional neural network (fcn). the entire system has no human interaction or database specific design. the average runtime is about 16\u2009s per scan on a standard workstation. the nodule detection accuracy is 91.4% and 94.6% with an average of 1 and 4 false positives (fps) per scan. the average dice coefficient of nodule segmentation compared to the groundtruth is 0.793.","['thoracic ct scans using deep convolutional neural networks', 'pulmonary nodules', 'automated detection', 'segmentation', 'fully', 'fast']"
"fine needle aspiration cytology (fnac) entails using a narrow gauge (25-22\u202fg) needle to collect a sample of a lesion for microscopic examination. it allows a minimally invasive, rapid diagnosis of tissue but does not preserve its histological architecture. fnac is commonly used for diagnosis of breast cancer, with traditional practice being based on the subjective visual assessment of the breast cytopathology cell samples under a microscope to evaluate the state of various cytological features. therefore, there are many challenges in maintaining consistency and reproducibility of findings. however, the advent of digital imaging and computational aid in diagnosis can improve the diagnostic accuracy and reduce the effective workload of pathologists. this paper presents a comparison of various deep convolutional neural network (cnn) based fine-tuned transfer learned classification approach for the diagnosis of the cell samples. the proposed approach has been tested using vgg16, vgg19, resnet-50 and googlenet-v3 (aka inception v3) architectures of cnn on an image dataset of 212 images (99 benign and 113 malignant), later augmented and cleansed to 2120 images (990 benign and 1130 malignant), where the network was trained using images of 80% cell samples and tested on the rest. this paper presents a comparative assessment of the models giving a new dimension to fnac study where googlenet-v3 (fine-tuned) achieved an accuracy of 96.25% which is highly satisfactory.","['breast fnac images', 'comparative assessment', 'cnn architectures', 'classification']"
"cultural heritage sites, apart from being the tangible link to a country's history and culture, actively contribute to the national economy, offering a foundation upon which cultural tourism can develop. this importance at the cultural and economic level, advocates for the need for preservation of cultural heritage sites for the future generations. to this end, advanced monitoring systems harnessing the power of sensors are deployed near the sites to collect data which can fuel systems and processes aimed at protection and preservation. in this paper we present the use of acoustic sensors for safeguarding cultural sites located in rural or urban areas, based on a novel data flow framework. we developed and deployed wireless acoustic sensors networks that record audio signals, which are transferred to a modular cloud platform to be processed using an efficient deep learning algorithm (f1-score: 0.838) to identify audio sources of interest for each site, taking into account the materials the assets are made of. the extracted information is presented exploiting the designed storm audio signal ontology and then fused with spatiotemporal information using semantic rules. the results of this work give valuable insight to the cultural experts and are publicly available using the linked open data format.","['acoustic sensor data flow', 'cultural heritage monitoring', 'safeguarding']"
to determine if deep learning networks could be trained to forecast future 24-2 humphrey visual fields (hvfs).,['forecasting future humphrey visual fields using deep learning']
"the field of brain-computer interfaces is poised to advance from the traditional goal of controlling prosthetic devices using brain signals to combining neural decoding and encoding within a single neuroprosthetic device. such a device acts as a 'co-processor' for the brain, with applications ranging from inducing hebbian plasticity for rehabilitation after brain injury to reanimating paralyzed limbs and enhancing memory. we review recent progress in simultaneous decoding and encoding for closed-loop control and plasticity induction. to address the challenge of multi-channel decoding and encoding, we introduce a unifying framework for developing brain co-processors based on artificial neural networks and deep learning. these 'neural co-processors' can be used to jointly optimize cost functions with the nervous system to achieve desired behaviors ranging from targeted neuro-rehabilitation to augmentation of brain function.","['towards neural co', 'computer interfaces', 'combining decoding', 'processors', 'encoding', 'brain']"
"background and purpose - artificial intelligence has rapidly become a powerful method in image analysis with the use of convolutional neural networks (cnns). we assessed the ability of a cnn, with a fast object detection algorithm previously identifying the regions of interest, to detect distal radius fractures (drfs) on anterior-posterior (ap) wrist radiographs. patients and methods - 2,340 ap wrist radiographs from 2,340 patients were enrolled in this study. we trained the cnn to analyze wrist radiographs in the dataset. feasibility of the object detection algorithm was evaluated by intersection of the union (iou). the diagnostic performance of the network was measured by area under the receiver operating characteristics curve (auc), accuracy, sensitivity, specificity, and youden index; the results were compared with those of medical professional groups. results - the object detection model achieved a high average iou, and none of the ious had a value less than 0.5. the auc of the cnn for this test was 0.96. the network had better performance in distinguishing images with drfs from normal images compared with a group of radiologists in terms of the accuracy, sensitivity, specificity, and youden index. the network presented a similar diagnostic performance to that of the orthopedists in terms of these variables. interpretation - the network exhibited a diagnostic ability similar to that of the orthopedists and a performance superior to that of the radiologists in distinguishing ap wrist radiographs with drfs from normal images under limited conditions. further studies are required to determine the feasibility of applying our method as an auxiliary in clinical practice under extended conditions.","['distal radius fractures', 'convolutional neural network', 'artificial intelligence detection', 'professional assessments', 'comparison']"
"one of the main objectives of active and assisted living (aal) environments is to ensure that elderly and/or disabled people perform/live well in their immediate environments; this can be monitored by among others the recognition of emotions based on non-highly intrusive sensors such as electrodermal activity (eda) sensors. however, designing a learning system or building a machine-learning model to recognize human emotions while training the system on a specific group of persons and testing the system on a totally a new group of persons is still a serious challenge in the field, as it is possible that the second testing group of persons may have different emotion patterns. accordingly, the purpose of this paper is to contribute to the field of human emotion recognition by proposing a convolutional neural network (cnn) architecture which ensures promising robustness-related results for both subject-dependent and subject-independent human emotion recognition. the cnn model has been trained using a grid search technique which is a model hyperparameter optimization technique to fine-tune the parameters of the proposed cnn architecture. the overall concept's performance is validated and stress-tested by using mahnob and deap datasets. the results demonstrate a promising robustness improvement regarding various evaluation metrics. we could increase the accuracy for subject-independent classification to 78% and 82% for mahnob and deap respectively and to 81% and 85% subject-dependent classification for mahnob and deap respectively (4 classes/labels). the work shows clearly that while using solely the non-intrusive eda sensors a robust classification of human emotion is possible even without involving additional/other physiological signals.","['independent human emotion recognition using electrodermal activity sensors', 'learning model', 'subject', 'deep']"
"clinical text classification is an fundamental problem in medical natural language processing. existing studies have cocnventionally focused on rules or knowledge sources-based feature engineering, but only a limited number of studies have exploited effective representation learning capability of deep learning methods.","['guided convolutional neural networks', 'clinical text classification', 'based features', 'rule', 'knowledge']"
"mammography is successfully used as an effective screening tool for cancer diagnosis. a calcification cluster on mammography is a primary sign of cancer. early researches have proved the diagnostic value of the calcification, yet their performance is highly dependent on handcrafted image descriptors. characterizing the calcification mammography in an automatic and robust way remains a challenge. in this paper, the calcification was characterized by descriptors obtained from deep learning and handcrafted descriptors. we compared the performances of different image feature sets on digital mammograms. the feature sets included the deep features alone, the handcrafted features, their combination, and the filtered deep features. experimental results have demonstrated that the deep features outperform handcrafted features, but the handcrafted features can provide complementary information for deep features. we achieved a classification precision of 89.32% and sensitivity of 86.89% using the filtered deep features, which is the best performance among all the feature sets.","['breast microcalcification diagnosis using deep convolutional neural network', 'digital mammograms']"
"studying a common architecture reflecting both brain's structural and functional organizations across individuals and populations in a hierarchical way has been of significant interest in the brain mapping field. recently, deep learning models exhibited ability in extracting meaningful hierarchical structures from brain imaging data, e.g., fmri and dti. however, deep learning models have been rarely used to explore the relation between brain structure and function yet. in this paper, we proposed a novel multimodal deep believe network (dbn) model to discover and quantitatively represent the hierarchical organizations of common and consistent brain networks from both fmri and dti data. a prominent characteristic of dbn is that it is capable of extracting meaningful features from complex neuroimaging data with a hierarchical manner. with our proposed dbn model, three hierarchical layers with hundreds of common and consistent brain networks across individual brains are successfully constructed through learning a large dimension of representative features from fmri/dti data.",['discovering hierarchical common brain networks via multimodal deep belief network']
"artificial intelligence (ai), represented by deep learning, can be used for real-life problems and is applied across all sectors of society including medical and dental field. the purpose of this study is to review articles about deep learning that were applied to the field of oral and maxillofacial radiology.","['deep learning', 'overview', 'field', 'dentistry']"
"deep brain stimulation (dbs) is a circuit-oriented treatment for mental disorders. unfortunately, even well-conducted psychiatric dbs clinical trials have yielded inconsistent symptom relief, in part because dbs' mechanism(s) of action are unclear. one clue to those mechanisms may lie in the efficacy of ventral internal capsule/ventral striatum (vcvs) dbs in both major depression (mdd) and obsessive-compulsive disorder (ocd). mdd and ocd both involve deficits in cognitive control. cognitive control depends on prefrontal cortex (pfc) regions that project into the vcvs. here, we show that vcvs dbs' effect is explained in part by enhancement of pfc-driven cognitive control. dbs improves human subjects' performance on a cognitive control task and increases theta (5-8hz) oscillations in both medial and lateral pfc. the theta increase predicts subjects' clinical outcomes. our results suggest a possible mechanistic approach to dbs therapy, based on tuning stimulation to optimize these neurophysiologic phenomena.","['internal capsule enhances human cognitive control', 'prefrontal cortex function', 'deep brain stimulation']"
"a multiuser detection (mud) algorithm based on deep learning network is proposed for the satellite mobile communication system. due to relative motion between the satellite and users, multiple access interference (mui) introduced by multipath fading channel reduces system performance. the proposed mud algorithm based on deep learning network firstly establishes the cinr optimal loss function according to the multiuser access mode and then obtains the best multiuser detection weight through the steepest gradient iteration. multilayer nonlinear learning obtains interference cancellation sharing weights to achieve maximum signal-to-noise ratio through gradient iteration, which is superior than the traditional serial interference cancellation algorithm and parallel interference cancellation algorithm. then, the weights with multiuser detection through multilayer network forward learning iteration are obtained with traditional multiuser detecting quality characteristics. the proposed multiuser access detection based on deep learning network algorithm improves the mud accuracy and reduces the number of traditional multiusers. the performance of the satellite multifading uplink system shows that the proposed deep learning network can provide high precision and better iteration times.","['satellite mobile communication system', 'deep learning network', 'multiuser detection']"
"root and butt-rot (rbr) has a significant impact on both the material and economic outcome of timber harvesting, and therewith on the individual forest owner and collectively on the forest and wood processing industries. an accurate recording of the presence of rbr during timber harvesting would enable a mapping of the location and extent of the problem, providing a basis for evaluating spread in a climate anticipated to enhance pathogenic growth in the future. therefore, a system to automatically identify and detect the presence of rbr would constitute an important contribution to addressing the problem without increasing workload complexity for the machine operator. in this study, we developed and evaluated an approach based on rgb images to automatically detect tree stumps and classify them as to the absence or presence of rot. furthermore, since knowledge of the extent of rbr is valuable in categorizing logs, we also classify stumps into three classes of infestation; rot = 0%, 0% < rot < 50% and rot ≥ 50%. in this work we used deep-learning approaches and conventional machine-learning algorithms for detection and classification tasks. the results showed that tree stumps were detected with precision rate of 95% and recall of 80%. using only the correct output (tp) of the stump detector, stumps without and with rbr were correctly classified with accuracy of 83.5% and 77.5%, respectively. classifying rot into three classes resulted in 79.4%, 72.4%, and 74.1% accuracy for stumps with rot = 0%, 0% < rot < 50%, and rot ≥ 50%, respectively. with some modifications, the developed algorithm could be used either during the harvesting operation to detect rbr regions on the tree stumps or as an rbr detector for post-harvest assessment of tree stumps and logs.","['rot', 'root', 'rb', 'detection', 'classification', 'butt']"
"competence in cataract surgery is a public health necessity, and videos of cataract surgery are routinely available to educators and trainees but currently are of limited use in training. machine learning and deep learning techniques can yield tools that efficiently segment videos of cataract surgery into constituent phases for subsequent automated skill assessment and feedback.","['cataract surgery using machine learning', 'deep learning techniques', 'automated identification', 'videos', 'phases', 'assessment']"
"we aim to evaluate the effectiveness of advanced deep learning models (eg, capsule network [capne","['dversarial training', 'adv']"
"we analyze how accurately supervised machine learning techniques can predict the lowest energy levels of one-dimensional noninteracting ultracold atoms subject to the correlated disorder due to an optical speckle field. deep neural networks with different numbers of hidden layers and neurons per layer are trained on large sets of instances of the speckle field, whose energy levels have been preventively determined via a high-order finite difference technique. the fourier components of the speckle field are used as the feature vector to represent the speckle-field instances. a comprehensive analysis of the details that determine the possible success of supervised machine learning tasks, namely the depth and the width of the neural network, the size of the training set, and the magnitude of the regularization parameter, is presented. it is found that ground state energies of previously unseen instances can be predicted with an essentially negligible error given a computationally feasible number of training instances. first and second excited state energies can be predicted too, albeit with slightly lower accuracy and using more layers of hidden neurons. we also find that a three-layer neural network is remarkably resilient to gaussian noise added to the training-set data (up to 10% noise level), suggesting that cold-atom quantum simulators could be used to train artificial neural networks.","['supervised machine learning', 'ultracold atoms', 'speckle disorder']"
"deep learning (dl)-based semantic segmentation methods have been providing state-of-the-art performance in the past few years. more specifically, these techniques have been successfully applied in medical image classification, segmentation, and detection tasks. one dl technique, u-net, has become one of the most popular for these applications. we propose a recurrent u-net model and a recurrent residual u-net model, which are named ru-net and r2u-net, respectively. the proposed models utilize the power of u-net, residual networks, and recurrent convolutional neural networks. there are several advantages to using these proposed architectures for segmentation tasks. first, a residual unit helps when training deep architectures. second, feature accumulation with recurrent residual convolutional layers ensures better feature representation for segmentation tasks. third, it allows us to design better u-net architectures with the same number of network parameters with better performance for medical image segmentation. the proposed models are tested on three benchmark datasets, such as blood vessel segmentation in retinal images, skin cancer segmentation, and lung lesion segmentation. the experimental results show superior performance on segmentation tasks compared to equivalent models, including a variant of a fully connected convolutional neural network called segnet, u-net, and residual u-net.","['recurrent residual u', 'medical image segmentation', 'net']"
"drawing inspiration from haptic exploration of objects by humans, the current work proposes a novel framework for robotic tactile object recognition, where visual information in the form of a set of visually interesting points is employed to guide the process of tactile data acquisition. neuroscience research confirms the integration of cutaneous data as a response to surface changes sensed by humans with data from joints, muscles, and bones (kinesthetic cues) for object recognition. on the other hand, psychological studies demonstrate that humans tend to follow object contours to perceive their global shape, which leads to object recognition. in compliance with these findings, a series of contours are determined around a set of 24 virtual objects from which bimodal tactile data (kinesthetic and cutaneous) are obtained sequentially and by adaptively changing the size of the sensor surface according to the object geometry for each object. a virtual force sensing resistor array (fsr) is employed to capture cutaneous cues. two different methods for sequential data classification are then implemented using convolutional neural networks (cnn) and conventional classifiers, including support vector machines and k-nearest neighbors. in the case of conventional classifiers, we exploit contourlet transformation to extract features from tactile images. in the case of cnn, two networks are trained for cutaneous and kinesthetic data and a novel hybrid decision-making strategy is proposed for object recognition. the proposed framework is tested both for contours determined blindly (randomly determined contours of objects) and contours determined using a model of visual attention. trained classifiers are tested on 4560 new sequential tactile data and the cnn trained over tactile data from object contours selected by the model of visual attention yields an accuracy of 98.97% which is the highest accuracy among other implemented approaches.","['visual guidance', 'tactile data', 'object recognition', 'deep learning', 'application']"
"deep generative models have demonstrated their effectiveness in learning latent representation and modeling complex dependencies of time series. in this article, we present a smoothness-inducing sequential variational auto-encoder (vae) (sisvae) model for the robust estimation and anomaly detection of multidimensional time series. our model is based on vae, and its backbone is fulfilled by a recurrent neural network to capture latent temporal structures of time series for both the generative model and the inference model. specifically, our model parameterizes mean and variance for each time-stamp with flexible neural networks, resulting in a nonstationary model that can work without the assumption of constant noise as commonly made by existing markov models. however, such flexibility may cause the model fragile to anomalies. to achieve robust density estimation which can also benefit detection tasks, we propose a smoothness-inducing prior over possible estimations. the proposed prior works as a regularizer that places penalty at nonsmooth reconstructions. our model is learned efficiently with a novel stochastic gradient variational bayes estimator. in particular, we study two decision criteria for anomaly detection: reconstruction probability and reconstruction error. we show the effectiveness of our model on both synthetic data sets and public real-world benchmarks.","['inducing sequential variational auto', 'time series', 'anomaly detection', 'smoothness', 'encoder']"
"terminal duct lobular unit (tdlu) involution is the regression of milk-producing structures in the breast. women with less tdlu involution are more likely to develop breast cancer. a major bottleneck in studying tdlu involution in large cohort studies is the need for labor-intensive manual assessment of tdlus. we developed a computational pathology solution to automatically capture tdlu involution measures. whole slide images (wsis) of benign breast biopsies were obtained from the nurses' health study. a set of 92 wsis was annotated for acini, tdlus and adipose tissue to train deep convolutional neural network (cnn) models for detection of acini, and segmentation of tdlus and adipose tissue. these networks were integrated into a single computational method to capture tdlu involution measures including number of tdlus per tissue area, median tdlu span and median number of acini per tdlu. we validated our method on 40 additional wsis by comparing with manually acquired measures. our cnn models detected acini with an f1 score of 0.73±0.07, and segmented tdlus and adipose tissue with dice scores of 0.84±0.13 and 0.87±0.04, respectively. the inter-observer icc scores for manual assessments on 40 wsis of number of tdlus per tissue area, median tdlu span, and median acini count per tdlu were 0.71, 0.81 and 0.73, respectively. intra-observer reliability was evaluated on 10/40 wsis with icc scores of >0.8. inter-observer icc scores between automated results and the mean of the two observers were: 0.80 for number of tdlus per tissue area, 0.57 for median tdlu span, and 0.80 for median acini count per tdlu. tdlu involution measures evaluated by manual and automated assessment were inversely associated with age and menopausal status. we developed a computational pathology method to measure tdlu involution. this technology eliminates the labor-intensiveness and subjectivity of manual tdlu assessment, and can be applied to future breast cancer risk studies.","['breast terminal duct lobular unit involution', 'breast cancer risk', 'towards automated prediction', 'deep learning assessment']"
"prior research in falls risk classification using inertial sensors has relied on the use of engineered features, which has resulted in a feature space containing hundreds of features that are likely redundant and possibly irrelevant. in this paper, we propose using fully convolutional neural networks (fcnns) to classify older adults at low or high risk of falling using inertial sensor data collected from a smartphone. due to the limited nature of older adult inertial gait datasets, we first pre-train the fcnn models using a publicly available dataset for pedestrian activity recognition. then via transfer learning, we train the network for falls risk classification. we show that via transfer learning, our falls risk classifier obtains an area under the receiver operating characteristic curve of 93.3%, which is 10.6% higher than the equivalent model trained without the use of transfer learning. additionally, we show that our method outperforms other standard machine learning classifiers trained on features developed in prior research.","['older adults using deep neural networks', 'falls risk classification', 'transfer learning']"
"the automatic detection of atrial fibrillation (af) is crucial for its association with the risk of embolic stroke. most of the existing af detection methods usually convert 1d time-series electrocardiogram (ecg) signal into 2d spectrogram to train a complex af detection system, which results in heavy training computation and high implementation cost. this paper proposes an af detection method based on an end-to-end 1d convolutional neural network (cnn) architecture to raise the detection accuracy and reduce network complexity. by investigating the impact of major components of a convolutional block on detection accuracy and using grid search to obtain optimal hyperparameters of the cnn, we develop a simple, yet effective 1d cnn. since the dataset provided by physionet challenge 2017 contains ecg recordings with different lengths, we also propose a length normalization algorithm to generate equal-length records to meet the requirement of cnn. experimental results and analysis indicate that our method of 1d cnn achieves an average f1 score of 78.2%, which has better detection accuracy with lower network complexity, as compared with the existing deep learning-based methods.","['atrial fibrillation using 1d convolutional neural network', 'detection']"
"actinic keratosis (ak) is one of the most common precancerous skin lesions, which is easily confused with benign keratosis (bk). at present, the diagnosis of ak mainly depends on histopathological examination, and ignorance can easily occur in the early stage, thus missing the opportunity for treatment. in this study, we designed a shallow convolutional neural network (cnn) named actinic keratosis deep learning (ak-dl) and further developed an intelligent diagnostic system for ak based on the ios platform. after data preprocessing, the ak-dl model was trained and tested with ak and bk images from dataset ham10000. we further compared it with mainstream deep cnn models, such as alexnet, googlenet, and resnet, as well as traditional medical image processing algorithms. our results showed that the performance of ak-dl was better than the mainstream deep cnn models and traditional medical image processing algorithms based on the ak dataset. the recognition accuracy of ak-dl was 0.925, the area under the receiver operating characteristic curve (auc) was 0.887, and the training time was only 123.0 s. an ios app of intelligent diagnostic system was developed based on the ak-dl model for accurate and automatic diagnosis of ak. our results indicate that it is better to employ a shallow cnn in the recognition of ak.","['shallow neural network model', 'deep neural networks', 'diagnosing actinic keratosis', 'better performance', 'dl', 'ak']"
"high-speed railways have been one of the most popular means of transportation all over the world. as an important part of the high-speed railway power supply system, the overhead catenary system (ocs) directly influences the stable operation of the railway, so regular inspection and maintenance are essential. now manual inspection is too inefficient and high-cost to fit the requirements for high-speed railway operation, and automatic inspection becomes a trend. the 3d information in the point cloud is useful for geometric parameter measurement in the catenary inspection. thus it is significant to recognize the components of ocs from the point cloud data collected by the inspection equipment, which promotes the automation of parameter measurement. in this paper, we present a novel method based on deep learning to recognize point clouds of ocs components. the method identifies the context of each single frame point cloud by a convolutional neural network (cnn) and combines some single frame data based on classification results, then inputs them into a segmentation network to identify ocs components. to verify the method, we build a point cloud dataset of ocs components that contains eight categories. the experimental results demonstrate that the proposed method can detect ocs components with high accuracy. our work can be applied to the real ocs components detection and has great practical significance for ocs automatic inspection.","['lidar point cloud recognition', 'overhead catenary system', 'deep learning']"
"the psoas-major muscle has been reported as a predictive factor of sarcopenia. the cross-sectional area (csa) of the psoas-major muscle in axial images has been indicated to correlate well with the whole-body skeletal muscle mass. in this study, we evaluated the segmentation accuracy of low-dose x-ray computed tomography (ct) images of the psoas-major muscle using the u-net convolutional neural network, which is a deep-learning technique. deep learning has been recently known to outperform conventional image-segmentation techniques. we used fivefold cross validation to validate the segmentation performance (n\u2009=\u2009100) of the psoas-major muscle. for the intersection over union and csa ratio, segmentation accuracies of 86.0 and 103.1%, respectively, were achieved. these results suggest that the u-net network is competitive compared with the previous methods. therefore, the proposed technique is useful for segmenting the psoas-major muscle even in low-dose ct images.","['major muscle using deep convolutional neural networks', 'dose ct images', 'automated segmentation', '2d low', 'psoas']"
"there is an increasing demand for acquiring details of food nutrients especially among those who are sensitive to food intakes and weight changes. to meet this need, we propose a new approach based on deep learning that precisely estimates the composition of carbohydrates, proteins, and fats from hyperspectral signals of foods obtained by using low-cost spectrometers. specifically, we develop a system consisting of multiple deep neural networks for estimating food nutrients followed by detecting and discarding estimation anomalies. our comprehensive performance evaluation demonstrates that the proposed system can maximize estimation accuracy by automatically identifying wrong estimations. as such, if consolidated with the capability of reinforcement learning, it will likely be positioned as a promising means for personalized healthcare in terms of food safety.","['hyperspectral signals based', 'deep neural networks', 'food nutrients', 'estimating', 'composition']"
"left ventricular ejection fraction (lvef) is one of the key metrics to assess the heart functionality, and cardiac ultrasound (echo) is a standard imaging modality for ef measurement. there is an emerging interest to exploit the point-of-care ultrasound (pocus) usability due to low cost and ease of access. in this work, we aim to present a computationally efficient mobile application for accurate lvef estimation.","['automatic biplane left ventricular ejection fraction estimation', 'care ultrasound using multi', 'task learning', 'mobile point', 'adversarial training']"
the purpose of this study was to develop an automatic tracking method for the muscle cross-sectional area (csa) on ultrasound (us) images using a convolutional neural network (cnn). the performance of the proposed method was evaluated and compared with that of the state-of-the art muscle segmentation method.,"['sectional area using convolutional neural networks', 'muscle cross', 'automatic tracking', 'ultrasound']"
"this paper presents a hierarchical deep reinforcement learning (drl) method for the scheduling of energy consumptions of smart home appliances and distributed energy resources (ders) including an energy storage system (ess) and an electric vehicle (ev). compared to q-learning algorithms based on a discrete action space, the novelty of the proposed approach is that the energy consumptions of home appliances and ders are scheduled in a continuous action space using an actor-critic-based drl method. to this end, a two-level drl framework is proposed where home appliances are scheduled at the first level according to the consumer's preferred appliance scheduling and comfort level, while the charging and discharging schedules of ess and ev are calculated at the second level using the optimal solution from the first level along with the consumer environmental characteristics. a simulation study is performed in a single home with an air conditioner, a washing machine, a rooftop solar photovoltaic system, an ess, and an ev under a time-of-use pricing. numerical examples under different weather conditions, weekday/weekend, and driving patterns of the ev confirm the effectiveness of the proposed approach in terms of total cost of electricity, state of energy of the ess and ev, and consumer preference.","['hierarchical deep reinforcement learning approach', 'energy storage system', 'energy management', 'smart home', 'home appliances', 'electric vehicle']"
"automated electrocardiogram (ecg) analysis for arrhythmia detection plays a critical role in early prevention and diagnosis of cardiovascular diseases. extracting powerful features from raw ecg signals for fine-grained diseases classification is still a challenging problem today due to variable abnormal rhythms and noise distribution. for ecg analysis, the previous research works depend mostly on heartbeat or single scale signal segments, which ignores underlying complementary information of different scales. in this paper, we formulate a novel end-to-end deep multi-scale fusion convolutional neural network (dmsfnet) architecture for multi-class arrhythmia detection. our proposed approach can effectively capture abnormal patterns of diseases and suppress noise interference by multi-scale feature extraction and cross-scale information complementarity of ecg signals. the proposed method implements feature extraction for signal segments with different sizes by integrating multiple convolution kernels with different receptive fields. meanwhile, joint optimization strategy with multiple losses of different scales is designed, which not only learns scale-specific features, but also realizes cumulatively multi-scale complementary feature learning during the learning process. in our work, we demonstrate our dmsfnet on two open datasets (cpsc_2018 and physionet/cinc_2017) and deliver the state-of-art performance on them. among them, cpsc_2018 is a 12-lead ecg dataset and cinc_2017 is a single-lead dataset. for these two datasets, we achieve the f1 score 82.8% and 84.1% which are higher than previous state-of-art approaches respectively. the results demonstrate that our end-to-end dmsfnet has outstanding performance for feature extraction from a broad range of distinct arrhythmias and elegant generalization ability for effectively handling ecg signals with different leads.","['scale fusion neural network', 'class arrhythmia detection', 'deep multi', 'multi']"
"multi-echo saturation recovery sequence can provide redundant information to synthesize multi-contrast magnetic resonance imaging. traditional synthesis methods, such as ge's magic platform, employ a model-fitting approach to generate parameter-weighted contrasts. however, models' over-simplification, as well as imperfections in the acquisition, can lead to undesirable reconstruction artifacts, especially in t2-flair contrast. to improve the image quality, in this study, a multi-task deep learning model is developed to synthesize multi-contrast neuroimaging jointly using both signal relaxation relationships and spatial information. compared with previous deep learning-based synthesis, the correlation between different destination contrast is utilized to enhance reconstruction quality. to improve model generalizability and evaluate clinical significance, the proposed model was trained and tested on a large multi-center dataset, including healthy subjects and patients with pathology. results from both quantitative comparison and clinical reader study demonstrate that the multi-task formulation leads to more efficient and accurate contrast synthesis than previous methods.","['task deep generative model', 'contrast magnetic resonance imaging', 'echo acquisition using multi', 'quality multi', 'synthesize high', 'multi']"
"by localizing microbubbles (mbs) in the vasculature, ultrasound localization microscopy (ulm) has recently been proposed, which greatly improves the spatial resolution of ultrasound (us) imaging and will be helpful for clinical diagnosis. nevertheless, several challenges remain in fast ulm imaging. the main problems are that current localization methods used to implement fast ulm imaging, e.g., a previously reported localization method based on sparse recovery (cs-ulm), suffer from long data-processing time and exhaustive parameter tuning (optimization). to address these problems, in this paper, we propose a ulm method based on deep learning, which is achieved by using a modified sub-pixel convolutional neural network (cnn), termed as mspcn-ulm. simulations and in vivo experiments are performed to evaluate the performance of mspcn-ulm. simulation results show that even if under high-density condition (6.4 mbs/mm2), a high localization precision ( 28 lm in the lateral direction and 24 lm in the axial direction) and a high localization reliability (jaccard index of 0.66) can be obtained by mspcn-ulm, compared to cs-ulm. the in vivo experimental results indicate that with plane wave scan at a transmit center frequency of 15.625 mhz, microvessels with diameters of 17 lm can be detected and adjacent microvessels with a distance of 42 lm can be separated. furthermore, when using gpu acceleration, the data-processing time of mspcn-ulm can be shortened to 6 sec/frame in the simulations and 23 sec/frame in the in vivo experiments, which is 3-4 orders of magnitude faster than cs-ulm. finally, once the network is trained,mspcn-ulm does not need parameter tuning to implement ulm. as a result, mspcn-ulm opens the door to implement ulm with fast data-processing speed, high imaging accuracy, short data-acquisition time, and high flexibility (robustness to parameters) characteristics.","['ultrasound localization microscopy', 'deep learning']"
"for the development of intelligent transportation systems, if real-time information on the number of people on buses can be obtained, it will not only help transport operators to schedule buses but also improve the convenience for passengers to schedule their travel times accordingly. this study proposes a method for estimating the number of passengers on a bus. the method is based on deep learning to estimate passenger occupancy in different scenarios. two deep learning methods are used to accomplish this: the first is a convolutional autoencoder, mainly used to extract features from crowds of passengers and to determine the number of people in a crowd; the second is the you only look once version 3 architecture, mainly for detecting the area in which head features are clearer on a bus. the results obtained by the two methods are summed to calculate the current passenger occupancy rate of the bus. to demonstrate the algorithmic performance, experiments for estimating the number of passengers at different bus times and bus stops were performed. the results indicate that the proposed system performs better than some existing methods.","['bus using deep learning', 'passengers', 'number', 'estimation']"
electronic health records (ehrs) conceal a hidden knowledge that could be mined with data science tools. this is relevant for n.n. burdenko neurosurgery center taking the advantage of a large ehrs archive collected for a period between 2000 and 2017. this study was aimed at testing the informativeness of neurosurgical operative reports for predicting the duration of postoperative stay in a hospital using deep learning techniques. the recurrent neuronal networks (gru) were applied to the word-embedded texts in our experiments. the mean absolute error of prediction in 90% of cases was 2.8 days. these results demonstrate the potential utility of narrative medical texts as a substrate for decision support technologies in neurosurgery.,"['101 654 operative reports', 'postoperative hospital stay', 'deep learning based', 'prediction', 'neurosurgery']"
"deep learning erfährt in den zurückliegenden jahren eine immer größer werdende aufmerksamkeit und wird für zahlreiche fragestellungen genutzt. da bildanalyse eine der stärken von deep learning ist, liegt der schluss nahe, auch pathologische fragestellungen hiermit zu bearbeiten. ziel dieser arbeit ist es, aus der allgemeinen pathologie mögliche deep-learning-ansätze zu identifizieren, die in der ophthalmopathologie genutzt werden könnten. zudem soll anhand der daten eines jahres der anteil der potenziell interessanten präparate für deep learning sowie der notwendige aufwand abgeschätzt werden.","['ophthalmic pathology ].', 'deep learning', 'pathology', 'challenges', 'applications']"
"we investigate the application of deep learning to biocuration tasks that involve classification of text associated with biomedical evidence in primary research articles. we developed a large-scale corpus of molecular papers derived from pubmed and pubmed central open access records and used it to train deep learning word embeddings under the glove, fasttext and elmo algorithms. we applied those models to a distant supervised method classification task based on text from figure captions or fragments surrounding references to figures in the main text using a variety or models and parameterizations. we then developed document classification (triage) methods for molecular interaction papers by using deep learning mechanisms of attention to aggregate classification-based decisions over selected paragraphs in the document. we were able to obtain triage performance with an accuracy of 0.82 using a combined convolutional neural network, bi-directional long short-term memory architecture augmented by attention to produce a single decision for triage. in this work, we hope to encourage biocuration systems developers to apply deep learning methods to their specialized tasks by repurposing large-scale word embedding to apply to their data.","['open access biomedical literature', 'building deep learning models', 'evidence classification']"
"image clustering is more challenging than image classification. without supervised information, current deep learning methods are difficult to be directly applied to image clustering problems. image clustering needs to deal with three main problems: 1) the curse of dimensionality caused by highdimensional image data; 2) extracting the effective image features; 3) combining feature extraction, dimensionality reduction and clustering. in this paper, we propose a new clustering framework called deep embedded dimensionality reduction clustering (derc) via probability-based triplet loss, which effectively solves the above issues. to the best of our knowledge, the derc is the first framework that effectively combines image embedding, dimensionality reduction, and clustering into the image clustering process. we also propose to incorporate a novel probability-based triplet loss measure to retrain the derc network as a unified framework. by integrating the reconstruction loss and the probability-based triplet loss, we can improve the image clustering accuracy. extensive experiments show that our proposed methods outperform state-of-the-art methods on many commonly used datasets.","['image clustering via deep embedded dimensionality reduction', 'based triplet loss', 'probability']"
"single-particle cryoelectron microscopy (cryo-em) continues to grow into a mainstream structural biology technique. recent developments in data collection strategies alongside new sample preparation devices herald a future where users will collect multiple datasets per microscope session. to make cryo-em data processing more automatic and user-friendly, we have developed an automatic pipeline for cryo-em data preprocessing and assessment using a combination of deep-learning and image-analysis tools. we have verified the performance of this pipeline on a number of datasets and extended its scope to include sample screening by the user-free assessment of the qualities of a series of datasets under different conditions. we propose that our workflow provides a decision-free solution for cryo-em, making data preprocessing more generalized and robust in the high-throughput era as well as more convenient for users from a range of backgrounds.","['free preprocessing routines', 'throughput cryo', 'em enabled', 'user', 'high']"
"traditional methods for drug discovery are time-consuming and expensive, so efforts are being made to repurpose existing drugs. to find new ways for drug repurposing, many computational approaches have been proposed to predict drug-target interactions (dtis). however, due to the high-dimensional nature of the data sets extracted from drugs and targets, traditional machine learning approaches, such as logistic regression analysis, cannot analyze these data sets efficiently. to overcome this issue, we propose lasso (least absolute shrinkage and selection operator)-based regularized linear classification models and a lasso-dnn (deep neural network) model based on lasso feature selection to predict dtis. these methods are demonstrated for repurposing drugs for breast cancer treatment.","['target interaction network using deep learning model', 'predicting drug']"
"in this study, a novel illuminant color estimation framework is proposed for computational color constancy, which incorporates the high representational capacity of deep-learningbased models and the great interpretability of assumptionbased models. the well-designed building block, feature map reweight unit (rewu), helps to achieve comparative accuracy on benchmark datasets with respect to prior state-of-the-art deep learning based models while requiring more compact model size and cheaper computational cost. in addition to local color estimation, a confidence estimation branch is also included such that the model is able to simultaneously produce point estimate and its uncertainty estimate, which provides useful clues for local estimates aggregation and multiple illumination estimation. the source code and the dataset have been made available1.","['reweighting image feature maps', 'color constancy']"
"this paper focuses on data fusion, which is fundamental to one of the most important modules in any autonomous system: perception. over the past decade, there has been a surge in the usage of smart/autonomous mobility systems. such systems can be used in various areas of life like safe mobility for the disabled, senior citizens, and so on and are dependent on accurate sensor information in order to function optimally. this information may be from a single sensor or a suite of sensors with the same or different modalities. we review various types of sensors, their data, and the need for fusion of the data with each other to output the best data for the task at hand, which in this case is autonomous navigation. in order to obtain such accurate data, we need to have optimal technology to read the sensor data, process the data, eliminate or at least reduce the noise and then use the data for the required tasks. we present a survey of the current data processing techniques that implement data fusion using different sensors like lidar that use light scan technology, stereo/depth cameras, red green blue monocular (rgb) and time-of-flight (tof) cameras that use optical technology and review the efficiency of using fused data from multiple sensors rather than a single sensor in autonomous navigation tasks like mapping, obstacle detection, and avoidance or localization. this survey will provide sensor information to researchers who intend to accomplish the task of motion control of a robot and detail the use of lidar and cameras to accomplish robot navigation.","['vision based sensor integration', 'datafusion techniques', 'autonomous navigation', 'survey', 'laser']"
"accurate interpretation of hip mri is time-intensive and difficult, prone to inter- and intrareviewer variability, and lacks a universally accepted grading scale to evaluate morphological abnormalities.","['aided detection ai reduces interreader variability', 'grading hip abnormalities', 'mri', 'computer']"
"model-free reinforcement learning is a powerful and efficient machine-learning paradigm which has been generally used in the robotic control domain. in the reinforcement learning setting, the value function method learns policies by maximizing the state-action value (q value), but it suffers from inaccurate q estimation and results in poor performance in a stochastic environment. to mitigate this issue, we present an approach based on the actor-critic framework, and in the critic branch we modify the manner of estimating q-value by introducing the advantage function, such as dueling network, which can estimate the action-advantage value. the action-advantage value is independent of state and environment noise, we use it as a fine-tuning factor to the estimated q value. we refer to this approach as the actor-dueling-critic (adc) network since the frame is inspired by the dueling network. furthermore, we redesign the dueling network part in the critic branch to make it adapt to the continuous action space. the method was tested on gym classic control environments and an obstacle avoidance environment, and we design a noise environment to test the training stability. the results indicate the adc approach is more stable and converges faster than the ddpg method in noise environments.","['reinforcement learning', 'critic method', 'dueling', 'actor']"
"instance transfer approaches consider source and target data together during the training process, and borrow examples from the source domain to augment the training data, when there is limited or no label in the target domain. among them, boosting-based transfer learning methods (e.g., tradaboost) are most widely used. when dealing with more complex data, we may consider the more complex hypotheses (e.g., a decision tree with deeper layers). however, with the fixed and high complexity of the hypotheses, tradaboost and its variants may face the overfitting problems. even worse, in the transfer learning scenario, a decision tree with deep layers may overfit different distribution data in the source domain. in this paper, we propose a new instance transfer learning method, i.e., deep decision tree transfer boosting (dtrboost), whose weights are learned and assigned to base learners by minimizing the data-dependent learning bounds across both source and target domains in terms of the rademacher complexities. this guarantees that we can learn decision trees with deep layers without overfitting. the theorem proof and experimental results indicate the effectiveness of our proposed method.",['deep decision tree transfer boosting']
"due to the complex visual environment, such as lighting variations, shadows, and limitations of vision, the accuracy of vacant parking slot detection for the park assist system (pas) with a standalone around view monitor (avm) needs to be improved. to address this problem, we propose a vacant parking slot detection method based on deep learning, namely vps-net. vps-net converts the vacant parking slot detection into a two-step problem, including parking slot detection and occupancy classification. in the parking slot detection stage, we propose a parking slot detection method based on yolov3, which combines the classification of the parking slot with the localization of marking points so that various parking slots can be directly inferred using geometric cues. in the occupancy classification stage, we design a customized network whose size of convolution kernel and number of layers are adjusted according to the characteristics of the parking slot. experiments show that vps-net can detect various vacant parking slots with a precision rate of 99.63% and a recall rate of 99.31% in the ps2.0 dataset, and has a satisfying generalizability in the psv dataset. by introducing a multi-object detection network and a classification network, vps-net can detect various vacant parking slots robustly.","['vacant parking slot detection', 'around view image based', 'deep learning']"
"renal cancer is one of the 10 most common cancers in human beings. the laparoscopic partial nephrectomy (lpn) is an effective way to treat renal cancer. localization and delineation of the renal tumor from pre-operative ct angiography (cta) is an important step for lpn surgery planning. recently, with the development of the technique of deep learning, deep neural networks can be trained to provide accurate pixel-wise renal tumor segmentation in cta images. however, constructing the training dataset with a large amount of pixel-wise annotations is a time-consuming task for the radiologists. therefore, weakly-supervised approaches attract more interest in research.","['supervised convolutional neural networks', 'renal tumor segmentation', 'abdominal cta images', 'weakly']"
"for stage-i lung adenocarcinoma, the 5-years disease-free survival (dfs) rates of non-invasive adenocarcinoma (non-ia) is different with invasive adenocarcinoma (ia). this study aims to develop ct image based artificial intelligence (ai) schemes to classify between non-ia and ia nodules, and incorporate deep learning (dl) and radiomics features to improve the classification performance. we collect 373 surgical pathological confirmed ground-glass nodules (ggns) from 323 patients in two centers. it involves 205 non-ia (including 107 adenocarcinoma in situ and 98 minimally invasive adenocarcinoma), and 168 ia. we first propose a recurrent residual convolutional neural network based on u-net to segment the ggns. then, we build two schemes to classify between non-ia and ia namely, dl scheme and radiomics scheme, respectively. third, to improve the classification performance, we fuse the prediction scores of two schemes by applying an information fusion method. finally, we conduct an observer study to compare our scheme performance with two radiologists by testing on an independent dataset. comparing with dl scheme and radiomics scheme (the area under a receiver operating characteristic curve (auc): 0.83 ± 0.05, 0.87 ± 0.04), our new fusion scheme (auc: 0.90 ± 0.03) significant improves the risk classification performance (p < 0.05). in a comparison with two radiologists, our new model yields higher accuracy of 80.3%. the kappa value for inter-radiologist agreement is 0.6. it demonstrates that applying ai method is an effective way to improve the invasiveness risk prediction performance of ggns. in future, fusion of dl and radiomics features may have a potential to handle the classification task with limited dataset in medical imaging.","['radiomics features', 'lung adenocarcinomas', 'invasiveness risk', 'glass nodules', 'deep learning', 'ct scan', 'stage', 'predict', 'ground', 'fusion', 'comparison']"
"as a hot topic in brain disease prognosis, predicting clinical measures of subjects based on brain magnetic resonance imaging (mri) data helps to assess the stage of pathology and predict future development of the disease. due to incomplete clinical labels/scores, previous learning-based studies often simply discard subjects without ground-truth scores. this would result in limited training data for learning reliable and robust models. also, existing methods focus only on using hand-crafted features (e.g., image intensity or tissue volume) of mri data, and these features may not be well coordinated with prediction models. in this paper, we propose a weakly supervised densely connected neural network (wisednn) for brain disease prognosis using baseline mri data and incomplete clinical scores. specifically, we first extract multiscale image patches (located by anatomical landmarks) from mri to capture local-to-global structural information of images, and then develop a weakly supervised densely connected network for task-oriented extraction of imaging features and joint prediction of multiple clinical measures. a weighted loss function is further employed to make full use of all available subjects (even those without ground-truth scores at certain time-points) for network training. the experimental results on 1469 subjects from both adni-1 and adni-2 datasets demonstrate that our proposed method can efficiently predict future clinical measures of subjects.","['brain disease prognosis using mri', 'weakly supervised deep learning', 'incomplete clinical scores']"
"the management of livestock in extensive production systems may be challenging, especially in large areas. using unmanned aerial vehicles (uavs) to collect images from the area of interest is quickly becoming a viable alternative, but suitable algorithms for extraction of relevant information from the images are still rare. this article proposes a method for counting cattle which combines a deep learning model for rough animal location, color space manipulation to increase contrast between animals and background, mathematical morphology to isolate the animals and infer the number of individuals in clustered groups, and image matching to take into account image overlap. using nelore and canchim breeds as a case study, the proposed approach yields accuracies over 90% under a wide variety of conditions and backgrounds.","['background contrast changes', 'uav images', 'counting cattle', 'clustered animals', 'dealing', 'animal']"
"an accurate estimation of pm2.5 (fine particulate matters with diameters\u202f≤\u202f2.5\u202fμm) concentration is critical for health risk assessment and generating air pollution control strategies. in this study, a hybrid remote sensing and machine learning approach, named rsrf model is proposed to estimate daily ground-level pm2.5 concentrations, which integrates random forest (rf), one of machine learning (ml) models, and aerosol optical depth (aod), one of remote sensing (rs) products. the proposed rsrf model provides an opportunity for an adequate characterization of real-time spatiotemporal pm2.5 distributions at uninhabited places and complex surfaces. it also offers advantages in handling complicated non-linear relationships among a large number of meteorological, environmental and air pollutant factors, as well as ever-increasing environmental data sets. the applicability of the proposed rsrf model is tested in the beijing-tianjin-hebei region (bth region) during 2015-2017. deep blue (db) aod from aqua-retrieved collection 6.1 (c_61) aerosol products of moderate resolution imaging spectroradiometer (modis) is validated with aerosol robotic network. the validation results indicate c_61 db aod has a high correlation with ground based aod in the bth region. the proposed rsrf model performed well in characterizing spatiotemporal variations of annual and seasonal pm2.5 concentrations. it not only is useful to quantify the relationships between pm2.5 and relevant factors such as db aod, meteorological and air pollutant variables, but also can provide decision support for air pollution control at a regional environment during haze periods.","['machine learning approach', 'hybrid remote sensing', 'predicting ground', 'level pm2', 'hebei region', '5 concentrations', 'tianjin', 'beijing']"
"lung cancer is one of the main causes of cancer-related death in the world. the identification and characteristics of malignant cells are essential for the diagnosis and treatment of primary or metastatic cancers. deep learning is a new field of artificial intelligence, which can be used for computer aided diagnosis and scientific research of lung cancer pathology by analyzing and learning through establishment and simulation of human brain. in this review, we will introduce the application, progress and problems of deep learning in pathology of lung cancer and make prospects for its future development.","['deep learning model', 'tumor pathology', 'new trend', 'lung cancer', 'aided diagnosis', 'computer']"
"we propose a deep autoencoder with graph topology inference and filtering to achieve compact representations of unorganized 3d point clouds in an unsupervised manner. many previous works discretize 3d points to voxels and then use lattice-based methods to process and learn 3d spatial information; however, this leads to inevitable discretization errors. in this work, we try to handle raw 3d points without such compromise. the proposed networks follow the autoencoder framework with a focus on designing the decoder. the encoder of the proposed networks adopts similar architectures as in pointnet, which is a well-acknowledged method for supervised learning of 3d point clouds. the decoder of the proposed networks involves three novel modules: the folding module, the graph-topology-inference module, and the graph-filtering module. the folding module folds a canonical 2d lattice to the underlying surface of a 3d point cloud, achieving coarse reconstruction; the graph-topology-inference module learns a graph topology to represent pairwise relationships between 3d points, pushing the latent code to preserve both coordinates and pairwise relationships of points in 3d point clouds; and the graph-filtering module couples the above two modules, refining the coarse reconstruction through a learnt graph topology to obtain the final reconstruction. the proposed decoder leverages a learnable graph topology to push the codeword to preserve representative features and further improve the unsupervised-learning performance. we further provide theoretical analyses of the proposed architecture. we provide an upper bound for the reconstruction loss and further show the superiority of graph smoothness over spatial smoothness as a prior to model 3d point clouds. in the experiments, we validate the proposed networks in three tasks, including 3d point cloud reconstruction, visualization, and transfer classification. the experimental results show that (1) the proposed networks outperform the state-of-the-art methods in various tasks, including reconstruction and transfer classification; (2) a graph topology can be inferred as auxiliary information without specific supervision on graph topology inference; (3) graph filtering refines the reconstruction, leading to better performances; and (4) designing a powerful decoder could improve the unsupervised-learning performance, just like a powerful encoder.","['3d point clouds via graph topology inference', 'deep unsupervised learning', 'filtering']"
"in this paper, we propose a deep learning approach for image registration by predicting deformation from image appearance. since obtaining ground-truth deformation fields for training can be challenging, we design a fully convolutional network that is subject to dual-guidance: (1) ground-truth guidance using deformation fields obtained by an existing registration method; and (2) image dissimilarity guidance using the difference between the images after registration. the latter guidance helps avoid overly relying on the supervision from the training deformation fields, which could be inaccurate. for effective training, we further improve the deep convolutional network with gap filling, hierarchical loss, and multi-source strategies. experiments on a variety of datasets show promising registration accuracy and efficiency compared with state-of-the-art methods.","['brain image registration using dual', 'supervised fully convolutional networks', 'birnet']"
"three-dimensional culture systems that allow generation of monolayered epithelial cell spheroids are widely used to study epithelial function in vitro. epithelial spheroid formation is applied to address cellular consequences of (mono)-genetic disorders, that is, ciliopathies, in toxicity testing, or to develop treatment options aimed to restore proper epithelial cell characteristics and function. with the potential of a high-throughput method, the main obstacle to efficient application of the spheroid formation assay so far is the laborious, time-consuming, and bias-prone analysis of spheroid images by individuals. hundredths of multidimensional fluorescence images are blinded, rated by three persons, and subsequently, differences in ratings are compared and discussed. here, we apply supervised learning and compare strategies based on machine learning versus deep learning. while deep learning approaches can directly process raw image data, machine learning requires transformed data of features extracted from fluorescence images. we verify the accuracy of both strategies on a validation data set, analyse an experimental data set, and observe that different strategies can be very accurate. deep learning, however, is less sensitive to overfitting and experimental batch-to-batch variations, thus providing a rather powerful and easily adjustable classification tool.","['supervised learning strategies', 'epithelial cell spheroids', 'classify polarity', '3d culture', 'comparison', 'application']"
"uncertainty of labels in clinical data resulting from intra-observer variability can have direct impact on the reliability of assessments made by deep neural networks. in this paper, we propose a method for modelling such uncertainty in the context of 2d echocardiography (echo), which is a routine procedure for detecting cardiovascular disease at point-of-care. echo imaging quality and acquisition time is highly dependent on the operator's experience level. recent developments have shown the possibility of automating echo image quality quantification by mapping an expert's assessment of quality to the echo image via deep learning techniques. nevertheless, the observer variability in the expert's assessment can impact the quality quantification accuracy. here, we aim to model the intra-observer variability in echo quality assessment as an aleatoric uncertainty modelling regression problem with the introduction of a novel method that handles the regression problem with categorical labels. a key feature of our design is that only a single forward pass is sufficient to estimate the level of uncertainty for the network output. compared to the 0.11±0.09 absolute error (in a scale from 0 to 1) archived by the conventional regression method, the proposed method brings the error down to 0.09±0.08, where the improvement is statistically significant and equivalents to 5.7% test accuracy improvement. the simplicity of the proposed approach means that it could be generalized to other applications of deep learning in medical imaging, where there is often uncertainty in clinical labels.","['2d echocardiography quality assessment', 'modelling label uncertainty', 'deep neural networks', 'observer variability', 'automatic estimation', 'intra']"
"breast cancer is one of the leading causes of cancer death among women in worldwide. early diagnosis of breast cancer improves the chance of survival by aiding proper clinical treatments. the digital mammography examination helps in diagnosing the breast cancer at its earlier stage. in this paper, multiscale all convolutional neural network (ma-cnn) is developed to assist the radiologist in diagnosing the breast cancer effectively. ma-cnn is a convolutional neural network-based approach that classifies mammogram images accurately. convolutional neural networks are excellent in extracting the task specific features, since the feature learning is associated with classification task in order to attain the improved performance. the proposed approach automatically categorizes the mammographic images on mini-mias dataset into normal, malignant and benign classes. this model improves the accuracy of the classification system by fusing the wider context of information using multiscale filters without negotiating the computation speed. experimental results show that ma-cnn is a powerful tool for diagnosing breast cancer by means of classifying the mammogram images with overall sensitivity of 96% and 0.99 auc.","['mammogram images using multiscale', 'convolutional neural network', 'cn', 'classification']"
"background cardiac mri is limited by long acquisition times, yet faster acquisition of smaller-matrix images reduces spatial detail. deep learning (dl) might enable both faster acquisition and higher spatial detail via super-resolution. purpose to explore the feasibility of using dl to enhance spatial detail from small-matrix mri acquisitions and evaluate its performance against that of conventional image upscaling methods. materials and methods short-axis cine cardiac mri examinations performed between january 2012 and december 2018 at one institution were retrospectively collected for algorithm development and testing. convolutional neural networks (cnns), a form of dl, were trained to perform super resolution in image space by using synthetically generated low-resolution data. there were 70%, 20%, and 10% of examinations allocated to training, validation, and test sets, respectively. cnns were compared against bicubic interpolation and fourier-based zero padding by calculating the structural similarity index (ssim) between high-resolution ground truth and each upscaling method. means and standard deviations of the ssim were reported, and statistical significance was determined by using the wilcoxon signed-rank test. for evaluation of clinical performance, left ventricular volumes were measured, and statistical significance was determined by using the paired student t test. results for cnn training and retrospective analysis, 400 mri scans from 367 patients (mean age, 48 years ± 18; 214 men) were included. all cnns outperformed zero padding and bicubic interpolation at upsampling factors from two to 64 (p < .001). cnns outperformed zero padding on more than 99.2% of slices (9828 of 9907). in addition, 10 patients (mean age, 51 years ± 22; seven men) were prospectively recruited for super-resolution mri. super-resolved low-resolution images yielded left ventricular volumes comparable to those from full-resolution images (p > .05), and super-resolved full-resolution images appeared to further enhance anatomic detail. conclusion deep learning outperformed conventional upscaling methods and recovered high-frequency spatial information. although training was performed only on short-axis cardiac mri examinations, the proposed strategy appeared to improve quality in other imaging planes.","['deep learning single', 'multiframe super', 'cardiac mri', 'resolution', 'frame']"
"the forming limit curve (flc) is used to model the onset of sheet metal instability during forming processes e.g., in the area of finite element analysis, and is usually determined by evaluation of strain distributions, derived with optical measurement systems during nakajima tests. current methods comprise of the standardized din en iso 12004-2 or time-dependent approaches that heuristically limit the evaluation area to a fraction of the available information and show weaknesses in the context of brittle materials without a pronounced necking phase. to address these limitations, supervised and unsupervised pattern recognition methods were introduced recently. however, these approaches are still dependent on prior knowledge, time, and localization information. this study overcomes these limitations by adopting a siamese convolutional neural network (cnn), as a feature extractor. suitable features are automatically learned using the extreme cases of the homogeneous and inhomogeneous forming phase in a supervised setup. using robust student's t mixture models, the learned features are clustered into three distributions in an unsupervised manner that cover the complete forming process. due to the location and time independency of the method, the knowledge learned from formed specimen up until fracture can be transferred on to other forming processes that were prematurely stopped and assessed using metallographic examinations, enabling probabilistic cluster membership assignments for each frame of the forming sequence. the generalization of the method to unseen materials is evaluated in multiple experiments, and additionally tested on an aluminum alloy aa5182, which is characterized by portevin-le chatlier effects.","['sheet metal forming using deep learning', 'forming limits', 'determination']"
"achieving high signal-to-noise ratio in chemical and biological sensors enables accurate detection of target analytes. unfortunately, below the limit of detection (lod), it becomes difficult to detect the presence of small amounts of analytes and extract useful information via any of the conventional methods. in this work, we examine the possibility of extracting ""hidden signals"" using deep neural network to enhance gas sensing below the lod region. as a test case system, we conduct experiments for h2 sensing in six different metallic channels (au, cu, mo, ni, pt, pd) and demonstrate that deep neural network can enhance the sensing capabilities for h2 concentration below the lod. we demonstrate that this technique could be universally used for different types of sensors and target analytes. our approach can extract new information from the hidden signals, which can be crucial for next-generation chemical sensing applications and analytical chemistry.","['chemical sensors using deep learning', 'finding hidden signals']"
"extensive studies have shown that many animals' capability of forming spatial representations for self-localization, path planning, and navigation relies on the functionalities of place and head-direction (hd) cells in the hippocampus. although there are numerous hippocampal modeling approaches, only a few span the wide functionalities ranging from processing raw sensory signals to planning and action generation. this paper presents a vision-based navigation system that involves generating place and hd cells through learning from visual images, building topological maps based on learned cell representations and performing navigation using hierarchical reinforcement learning. first, place and hd cells are trained from sequences of visual stimuli in an unsupervised learning fashion. a modified slow feature analysis (sfa) algorithm is proposed to learn different cell types in an intentional way by restricting their learning to separate phases of the spatial exploration. then, to extract the encoded metric information from these unsupervised learning representations, a self-organized learning algorithm is adopted to learn over the emerged cell activities and to generate topological maps that reveal the topology of the environment and information about a robot's head direction, respectively. this enables the robot to perform self-localization and orientation detection based on the generated maps. finally, goal-directed navigation is performed using reinforcement learning in continuous state spaces which are represented by the population activities of place cells. in particular, considering that the topological map provides a natural hierarchical representation of the environment, hierarchical reinforcement learning (hrl) is used to exploit this hierarchy to accelerate learning. the hrl works on different spatial scales, where a high-level policy learns to select subgoals and a low-level policy learns over primitive actions to specialize on the selected subgoals. experimental results demonstrate that our system is able to navigate a robot to the desired position effectively, and the hrl shows a much better learning performance than the standard rl in solving our navigation tasks.","['hierarchical reinforcement learning', 'combining unsupervised learning', 'based robot navigation', 'vision']"
"alzheimer's disease (ad) is one of the leading causes of death in developed countries. from a research point of view, impressive results have been reported using computer-aided algorithms, but clinically no practical diagnostic method is available. in recent years, deep models have become popular, especially in dealing with images. since 2013, deep learning has begun to gain considerable attention in ad detection research, with the number of published papers in this area increasing drastically since 2017. deep models have been reported to be more accurate for ad detection compared to general machine learning techniques. nevertheless, ad detection is still challenging, and for classification, it requires a highly discriminative feature representation to separate similar brain patterns. this paper reviews the current state of ad detection using deep learning. through a systematic literature review of over 100 articles, we set out the most recent findings and trends. specifically, we review useful biomarkers and features (personal information, genetic data, and brain scans), the necessary pre-processing steps, and different ways of dealing with neuroimaging data originating from single-modality and multi-modality studies. deep models and their performance are described in detail. although deep learning has achieved notable performance in detecting ad, there are several limitations, especially regarding the availability of datasets and training procedures.","['systematic literature review', 'detect alzheimer', 'deep learning', 'neuroimaging', 'disease']"
"a deep neural network was developed for magnetic resonance fingerprinting (mrf) quantification. this study aimed at extending previous studies of deep learning mrf to in vivo applications, allowing sub-second computation time for large-scale data.","['fast deep learning quantification', 'magnetic resonance fingerprinting', 'vivo', 'development']"
"in this paper we present a technique based on deep reinforcement learning that allows for numerical analytic continuation of integrals that are often encountered in one-loop diagrams in quantum field theory. to extract certain quantities of two-point functions, such as spectral densities, mass poles or multiparticle thresholds, it is necessary to perform an analytic continuation of the correlator in question. at one-loop level in euclidean space, this results in the necessity to deform the integration contour of the loop integral in the complex plane of the square of the loop momentum, to avoid nonanalyticities in the integration plane. using a toy model for which an exact solution is known, we train a reinforcement learning agent to perform the required contour deformations. our study shows great promise for an agent to be deployed in iterative numerical approaches used to compute nonperturbative two-point functions, such as the quark propagator dyson-schwinger equation, or more generally, fredholm equations of the second kind, in the complex domain.","['quantum field theory', 'deep reinforcement learning', 'loop diagrams', 'complex evaluation', 'one']"
"there is clinical evidence that suppressing the bone structures in chest x-rays (cxrs) improves diagnostic value, either for radiologists or computer-aided diagnosis. however, bone-free cxrs are not always accessible. we hereby propose a coarse-to-fine cxr bone suppression approach by using structural priors derived from unpaired computed tomography (ct) images. in the low-resolution stage, we use the digitally reconstructed radiograph (drr) image that is computed from ct as a bridge to connect ct and cxr. we then perform cxr bone decomposition by leveraging the drr bone decomposition model learned from unpaired cts and domain adaptation between cxr and drr. to further mitigate the domain differences between cxrs and drrs and speed up the learning convergence, we perform all the aboved operations in laplacian of gaussian (log) domain. after obtaining the bone decomposition result in drr, we upsample it to a high resolution, based on which the bone region in the original high-resolution cxr is cropped and processed to produce a high-resolution bone decomposition result. finally, such a produced bone image is subtracted from the original high-resolution cxr to obtain the bone suppression result. we conduct experiments and clinical evaluations based on two benchmarking cxr databases to show that (i) the proposed method outperforms the state-of-the-art unsupervised cxr bone suppression approaches; (ii) the cxrs with bone suppression are instrumental to radiologists for reducing their false-negative rate of lung diseases from 15% to 8%; and (iii) state-of-the-art disease classification performances are achieved by learning a deep network that takes the original cxr and its bone-suppressed image as inputs.","['ray bone suppression using unpaired ct structural priors', 'resolution chest x', 'high']"
"magnetic resonance electrical properties tomography (mr-ept) is a technique used to estimate the conductivity and permittivity of tissues from mr measurements of the transmit magnetic field. different reconstruction methods are available; however, all these methods present several limitations, which hamper the clinical applicability. standard helmholtz-based mr-ept methods are severely affected by noise. iterative reconstruction methods such as contrast source inversion electrical properties tomography (csi-ept) are typically time-consuming and are dependent on their initialization. deep learning (dl) based methods require a large amount of training data before sufficient generalization can be achieved. here, we investigate the benefits achievable using a hybrid approach, that is, using mr-ept or dl-ept as initialization guesses for standard 3d csi-ept. using realistic electromagnetic simulations at 3 and 7\xa0t, the accuracy and precision of hybrid csi reconstructions are compared with those of standard 3d csi-ept reconstructions. our results indicate that a hybrid method consisting of an initial dl-ept reconstruction followed by a 3d csi-ept reconstruction would be beneficial. dl-ept combined with standard 3d csi-ept exploits the power of data-driven dl-based ept reconstructions, while the subsequent csi-ept facilitates a better generalization by providing data consistency.","['based electrical properties tomography', '3d contrast source inversion', 'combining deep learning', 'mr']"
"microscopy image analysis is a major bottleneck in quantification of single-cell microscopy data, typically requiring human oversight and curation, which limit both accuracy and throughput. to address this, we developed a deep learning-based image analysis pipeline that performs segmentation, tracking, and lineage reconstruction. our analysis focuses on time-lapse movies of escherichia coli cells trapped in a ""mother machine"" microfluidic device, a scalable platform for long-term single-cell analysis that is widely used in the field. while deep learning has been applied to cell segmentation problems before, our approach is fundamentally innovative in that it also uses machine learning to perform cell tracking and lineage reconstruction. with this framework we are able to get high fidelity results (1% error rate), without human intervention. further, the algorithm is fast, with complete analysis of a typical frame containing ~150 cells taking <700msec. the framework is not constrained to a particular experimental set up and has the potential to generalize to time-lapse images of other organisms or different experimental configurations. these advances open the door to a myriad of applications including real-time tracking of gene expression and high throughput analysis of strain libraries at single-cell resolution.","['lineage reconstruction using deep learning', 'automated cell segmentation', 'tracking', 'delta']"
"how to transform a mixed flow of sensory and motor information into memory state of self-location and to build map representations of the environment are central questions in the navigation research. studies in neuroscience have shown that place cells in the hippocampus of the rodent brains form dynamic cognitive representations of locations in the environment. we propose a neural-network model called sensory-motor integration network model (seminet) to learn cognitive map representations by integrating sensory and motor information while an agent is exploring a virtual environment. this biologically inspired model consists of a deep neural network representing visual features of the environment, a recurrent network of place units encoding spatial information by sensorimotor integration, and a secondary network to decode the locations of the agent from spatial representations. the recurrent connections between the place units sustain an activity bump in the network without the need of sensory inputs, and the asymmetry in the connections propagates the activity bump in the network, forming a dynamic memory state which matches the motion of the agent. a competitive learning process establishes the association between the sensory representations and the memory state of the place units, and is able to correct the cumulative path-integration errors. the simulation results demonstrate that the network forms neural codes that convey location information of the agent independent of its head direction. the decoding network reliably predicts the location even when the movement is subject to noise. the proposed seminet thus provides a brain-inspired neural-network model for \\nobreak cognitive map updated by both self-motion cues and visual cues.","['learning cognitive map representations', 'motor integration', 'sensory', 'navigation']"
"in the last decade, deep artificial neural networks have achieved astounding performance in many natural language-processing tasks. given the high productivity of language, these models must possess effective generalization abilities. it is widely assumed that humans handle linguistic productivity by means of algebraic compositional rules: are deep networks similarly compositional? after reviewing the main innovations characterizing current deep language-processing networks, i discuss a set of studies suggesting that deep networks are capable of subtle grammar-dependent generalizations, but also that they do not rely on systematic compositional rules. i argue that the intriguing behaviour of these devices (still awaiting a full understanding) should be of interest to linguists and cognitive scientists, as it offers a new perspective on possible computational strategies to deal with linguistic productivity beyond rule-based compositionality, and it might lead to new insights into the less systematic generalization patterns that also appear in natural language. this article is part of the theme issue 'towards mechanistic models of meaning composition'.","['modern artificial neural networks', 'linguistic generalization', 'compositionality']"
"epilepsy is a neurological disorder characterized by sudden and unpredictable epileptic seizures, which incurs significant negative impacts on patients' physical, psychological and social health. a practical approach to assist with the clinical assessment and treatment planning for patients is to process magnetoencephalography (meg) data to identify epileptogenic zones. as a widely accepted biomarker of epileptic foci, epileptic meg spikes need to be precisely detected. given that the visual inspection of spikes is time consuming, an automatic and efficient system with adequate accuracy for spike detection is valuable in clinical practice. however, current approaches for meg spike autodetection are dependent on hand-engineered features. here, we propose a novel multiview epileptic meg spikes detection algorithm based on a deep learning network (ems-net) to accurately and efficiently recognize the spike events from meg raw data. the results of the leave-k-subject-out validation tests for multiple datasets (i.e., balanced and realistic datasets) showed that ems-net achieved state-of-the-art classification performance (i.e., accuracy: 91.82% -99.89%; precision: 91.90% -99.45%; sensitivity: 91.61% -99.53%; specificity: 91.60% -99.96%; f1 score: 91.70% -99.48%; and area under the curve: 0.9688 -0.9998).","['autodetecting epileptic magnetoencephalography spikes', 'deep learning method', 'net', 'ems']"
"identifying hepatotoxicity as early as possible is significant in drug development. in this study, we developed a drug-induced hepatotoxicity prediction model taking account of both the biological context and the computational efficacy based on toxicogenomics data. specifically, we proposed a novel gene selection algorithm considering gene's participation, named biocb, to choose the discriminative genes and make more efficient prediction. then instead of using the raw gene expression levels to characterize each drug, we developed a two-dimensional biological process feature pattern map to represent each drug. then we employed two strategies to handle the maps and identify the hepatotoxicity, the direct use of maps, named two-dim branch, and vectorization of maps, named one-dim branch. the two strategies subsequently used the deep convolutional neural networks and lightgbm as predictors, respectively. additionally, we here for the first time proposed a stacked vectorized gene matrix, which was more predictive than the raw gene matrix. results validated on both in vivo and in vitro data from two public data sets, the tg-gates and drugmatrix, show that the proposed one-dim branch outperforms the deep framework, the two-dim branch, and has achieved high accuracy and efficiency. the implementation of the proposed method is available at https://github.com/ransulab/hepatotoxicity.","['induced hepatotoxicity based', 'diverse classification strategies', 'biological feature maps', 'predicting drug']"
"skin disease is the most common problem between people. due to pollution and deployment of ozone layer, harmful uv rays of sun burn the skin and develop various types of skin diseases. nowadays, machine learning and deep learning algorithms are generally used for diagnosis for various kinds of diseases. in this study, we have applied three feature extraction techniques univariate feature selection, feature importance, and correlation matrix with heat map to find the optimum data subset of erythemato-squamous disease. four classification techniques gaussian naïve bayesian (nb), decision tree (dt), support vector machine (svm), and random forest are used for measuring the performance of model. stacking ensemble technique is then applied to enhance the prediction performance of the model. the proposed method used for measuring the performance of the model. it is finding that the optimal subset of the erythemato-squamous disease is performed well in the case of correlation and heat map feature selection techniques. the mean value, slandered deviation, root mean square error, kappa statistical error, and area under receiver operating characteristics and accuracy are calculated for demonstrating the effectiveness of the proposed model. the feature selection techniques applied with staking ensemble technique gives the better result as compared to individual machine learning techniques. the obtained results show that the performance of proposed model is higher than previous results obtained by researchers.","['three different feature selection techniques using stacking ensemble method', 'skin disease', 'prediction']"
"neonatal sleep analysis at the neonatal intensive care units (nicu) is critical for the diagnosis of any brain growth risks during the early stages of life. in this paper, an investigation is carried out on the use of a long short-term memory (lstm) learning system in automatic sleep stage scoring in neonates. the developed algorithm automatically classifies sleep stages based on inputs from a single channel eeg recording. up to this date, only a single study have developed an approach for automatic sleep stage scoring in neonatal sleep signals using deep neural network (dnn). a total of 5095 sleep stages signals acquired from eeg recordings of the university of pittsburgh are used in this study. the sleep stages are annotated by a medical doctor from the pediatric neurology department of case western reserve university for three neonatal sleep stages including the awake (w), active sleep (as), and quiet sleep (qs) stages on every 60-s epoch. the signals are pre-processed through normalization and filtering. the resulted signals are divided following 4-, 6-, and 10-fold cross-validation schemes. the training and classification process is done using a bi-directional lstm network classifier built with pre-defined training parameters. at the end, the developed algorithm is evaluated along with a complete summary table that reports the results of this study and other state-of-the-art studies. the current study achieved high levels of cohen's kappa (κ), accuracy, and f1 score with 91.37%, 96.81%, and 94.43%, respectively. based on the confusion matrix, the overall true positives percentage reached 95.21%. the developed algorithm gave promising results in automatic sleep stage scoring in neonatal sleep signals. future work include lstm architecture and training parameters improvements to enhance the overall accuracy of the classifier.","['neonatal sleep stage identification using long short', 'term memory learning system']"
"the inputs to the outputs of nonlinear systems can be modeled using machine and deep learning approaches, among which artificial neural networks (anns) are a promising option. however, noisy signals affect ann modeling negatively; hence, it is important to investigate these signals prior to the modeling. herein, two customized and simple approaches, visual inspection and absolute correlation, are proposed to examine the relationship between the inputs and outputs of a nonlinear system. the system under consideration uses biosignals from surface electromyography as inputs and human finger joint angles as outputs, acquired from eight intact participants performing movements and grasping tasks in dynamic conditions. furthermore, the results of these approaches are tested using the standard mutual information measure. hence, the system dimensionality is reduced, and the ann learning (convergence) is accelerated, where the most informative inputs are selected for the next phase. subsequently, four ann types, i.e., feedforward, cascade-forward, radial basis function, and generalized regression anns, are used to perform the modeling. finally, the performance of the anns is compared with findings from the signal analysis. results indicate a high level of consistency among all the aforementioned signal pre-analysis techniques from one side, and they also indicate that these techniques match the ann performances from the other side. as an example, for a certain movement set, the ann models resulted in the rotation estimation accuracy of the joints in the following descending order: carpometacarpal, metacarpophalangeal, proximal interphalangeal, and distal interphalangeal. this information has been indicated in the signal pre-analysis step. therefore, this step is crucial in input-output variable selections prior to machine-/deep-learning-based modeling approaches.","['finger joint angles via signal pre', 'artificial neural networks', 'mapping semg', 'investigation techniques', 'prediction', 'performance']"
"alzheimer's disease (ad) is a progressive and irreversible brain degenerative disorder. mild cognitive impairment (mci) is a clinical precursor of ad. although some treatments can delay its progression, no effective cures are available for ad. accurate early-stage diagnosis of ad is vital for the prevention and intervention of the disease progression. hippocampus is one of the first affected brain regions in ad. to help ad diagnosis, the shape and volume of the hippocampus are often measured using structural magnetic resonance imaging (mri). however, these features encode limited information and may suffer from segmentation errors. additionally, the extraction of these features is independent of the classification model, which could result in sub-optimal performance. in this study, we propose a multi-model deep learning framework based on convolutional neural network (cnn) for joint automatic hippocampal segmentation and ad classification using structural mri data. firstly, a multi-task deep cnn model is constructed for jointly learning hippocampal segmentation and disease classification. then, we construct a 3d densely connected convolutional networks (3d densenet) to learn features of the 3d patches extracted based on the hippocampal segmentation results for the classification task. finally, the learned features from the multi-task cnn and densenet models are combined to classify disease status. our method is evaluated on the baseline t1-weighted structural mri data collected from 97 ad, 233 mci, 119 normal control (nc) subjects in the alzheimer's disease neuroimaging initiative (adni) database. the proposed method achieves a dice similarity coefficient of 87.0% for hippocampal segmentation. in addition, the proposed method achieves an accuracy of 88.9% and an auc (area under the roc curve) of 92.5% for classifying ad vs. nc subjects, and an accuracy of 76.2% and an auc of 77.5% for classifying mci vs. nc subjects. our empirical study also demonstrates that the proposed multi-model method outperforms the single-model methods and several other competing methods.","['model deep convolutional neural network', 'automatic hippocampus segmentation', 'multi', 'disease', 'classification', 'alzheimer']"
"accurately and precisely characterizing the morphology of small pulmonary structures from computed tomography (ct) images, such as airways and vessels, is becoming of great importance for diagnosis of pulmonary diseases. the smaller conducting airways are the major site of increased airflow resistance in chronic obstructive pulmonary disease (copd), while accurately sizing vessels can help identify arterial and venous changes in lung regions that may determine future disorders. however, traditional methods are often limited due to image resolution and artifacts. we propose a convolutional neural regressor (cnr) that provides cross-sectional measurement of airway lumen, airway wall thickness, and vessel radius. cnr is trained with data created by a generative model of synthetic structures which is used in combination with simulated and unsupervised generative adversarial network (simgan) to create simulated and refined airways and vessels with known ground-truth. for validation, we first use synthetically generated airways and vessels produced by the proposed generative model to compute the relative error and directly evaluate the accuracy of cnr in comparison with traditional methods. then, in-vivo validation is performed by analyzing the association between the percentage of the predicted forced expiratory volume in one second (fev1%) and the value of the pi10 parameter, two well-known measures of lung function and airway disease, for airways. for vessels, we assess the correlation between our estimate of the small-vessel blood volume and the lungs' diffusing capacity for carbon monoxide (dlco). the results demonstrate that convolutional neural networks (cnns) provide a promising direction for accurately measuring vessels and airways on chest ct images with physiological correlates.","['vessel morphology quantification', 'chest ct images', 'based airway', 'generative']"
"assessing the well-being of an animal is hindered by the limitations of efficient communication between humans and animals. instead of direct communication, a variety of parameters are employed to evaluate the well-being of an animal. especially in the field of biomedical research, scientifically sound tools to assess pain, suffering, and distress for experimental animals are highly demanded due to ethical and legal reasons. for mice, the most commonly used laboratory animals, a valuable tool is the mouse grimace scale (mgs), a coding system for facial expressions of pain in mice. we aim to develop a fully automated system for the surveillance of post-surgical and post-anesthetic effects in mice. our work introduces a semi-automated pipeline as a first step towards this goal. a new data set of images of black-furred laboratory mice that were moving freely is used and provided. images were obtained after anesthesia (with isoflurane or ketamine/xylazine combination) and surgery (castration). we deploy two pre-trained state of the art deep convolutional neural network (cnn) architectures (resnet50 and inceptionv3) and compare to a third cnn architecture without pre-training. depending on the particular treatment, we achieve an accuracy of up to 99% for the recognition of the absence or presence of post-surgical and/or post-anesthetic effects on the facial expression.","['laboratory mice using deep learning', 'fully automated surveillance', 'facial expression analysis', 'well', 'towards', 'status', 'starting']"
"over 200 million malaria cases globally lead to half a million deaths annually. accurate malaria diagnosis remains a challenge. automated imaging processing approaches to analyze thick blood films (tbf) could provide scalable solutions, for urban healthcare providers in the holoendemic malaria sub-saharan region. although several approaches have been attempted to identify malaria parasites in tbf, none have achieved negative and positive predictive performance suitable for clinical use in the west sub-saharan region. while malaria parasite object detection remains an intermediary step in achieving automatic patient diagnosis, training state-of-the-art deep-learning object detectors requires the human-expert labor-intensive process of labeling a large dataset of digitized tbf. to overcome these challenges and to achieve a clinically usable system, we show a novel approach. it leverages routine clinical-microscopy labels from our quality-controlled malaria clinics, to train a deep malaria convolutional neural network classifier (deepmcnn) for automated malaria diagnosis. our system also provides total malaria parasite (mp) and white blood cell (wbc) counts allowing parasitemia estimation in mp/μl, as recommended by the who. prospective validation of the deepmcnn achieves sensitivity/specificity of 0.92/0.90 against expert-level malaria diagnosis. our approach ppv/npv performance is of 0.92/0.90, which is clinically usable in our holoendemic settings in the densely populated metropolis of ibadan. it is located within the most populous african country (nigeria) and with one of the largest burdens of plasmodium falciparum malaria. our openly available method is of importance for strategies aimed to scale malaria diagnosis in urban regions where daily assessment of thousands of specimens is required.","['level automated malaria diagnosis', 'routine blood films', 'deep neural networks', 'expert']"
"cross-media search from large-scale social network big data has become increasingly valuable in our daily life because it can support querying different data modalities. deep hash networks have shown high potential in achieving efficient and effective cross-media search performance. however, due to the fact that social network data often exhibit text sparsity, diversity, and noise characteristics, the search performance of existing methods often degrades when dealing with this data. in order to address this problem, this article proposes a novel end-to-end cross-media semantic correlation learning model based on a deep hash network and semantic expansion for social network cross-media search (dhns). the approach combines deep network feature learning and hash-code quantization learning for multimodal data into a unified optimization architecture, which successfully preserves both intramedia similarity and intermedia correlation, by minimizing both cross-media correlation loss and binary hash quantization loss. in addition, our approach realizes semantic relationship expansion by constructing the image-word relation graph and mining the potential semantic relationship between images and words, and obtaining the semantic embedding based on both internal graph deep walk and an external knowledge base. experimental results demonstrate that dhns yields better cross-media search performance on standard benchmarks.","['media semantic correlation learning based', 'deep hash network', 'social network cross', 'semantic expansion', 'media search', 'cross']"
"in this paper, we devise a saliency prediction model for stereoscopic videos that learns to explore saliency inspired by the component-based interactions including spatial, temporal, as well as depth cues. the model first takes advantage of specific structure of 3d residual network (3d-resnet) to model the saliency driven by spatio-temporal coherence from consecutive frames. subsequently, the saliency inferred by implicit-depth is automatically derived based on the displacement correlation between left and right views by leveraging a deep convolutional network (convnet). finally, a component-wise refinement network is devised to produce final saliency maps over time by aggregating saliency distributions obtained from multiple components. in order to further facilitate research towards stereoscopic video saliency, we create a new dataset including 175 stereoscopic video sequences with diverse content, as well as their dense eye fixation annotations. extensive experiments support that our proposed model can achieve superior performance compared to the state-of-the-art methods on all publicly available eye fixation datasets.","['stereoscopic videos via component', 'explore saliency', 'based interaction', 'learning']"
"the various defects that occur on asphalt pavement are a direct cause car accidents, and countermeasures are required because they cause significantly dangerous situations. in this paper, we propose fully convolutional neural networks (cnn)-based road surface damage detection with semi-supervised learning. first, the training db is collected through the camera installed in the vehicle while driving on the road. moreover, the cnn model is trained in the form of a semantic segmentation using the deep convolutional autoencoder. here, we augmented the training dataset depending on brightness, and finally generated a total of 40,536 training images. furthermore, the cnn model is updated by using the pseudo-labeled images from the semi-supervised learning methods for improving the performance of road surface damage detection technique. to demonstrate the effectiveness of the proposed method, 450 evaluation datasets were created to verify the performance of the proposed road surface damage detection, and four experts evaluated each image. as a result, it is confirmed that the proposed method can properly segment the road surface damages.","['road surface damage detection using fully convolutional neural networks', 'supervised learning', 'semi']"
"in the absence of accurate medical records, it is critical to correctly classify implant fixture systems using periapical radiographs to provide accurate diagnoses and treatments to patients or to respond to complications. the purpose of this study was to evaluate whether deep neural networks can identify four different types of implants on intraoral radiographs. in this study, images of 801 patients who underwent periapical radiographs between 2005 and 2019 at yonsei university dental hospital were used. images containing the following four types of implants were selected: brånemark mk tiunite, dentium implantium, straumann bone level, and straumann tissue level. squeezenet, googlenet, resnet-18, mobilenet-v2, and resnet-50 were tested to determine the optimal pre-trained network architecture. the accuracy, precision, recall, and f1 score were calculated for each network using a confusion matrix. all five models showed a test accuracy exceeding 90%. squeezenet and mobilenet-v2, which are small networks with less than four million parameters, showed an accuracy of approximately 96% and 97%, respectively. the results of this study confirmed that convolutional neural networks can classify the four implant fixtures with high accuracy even with a relatively small network and a small number of images. this may solve the inconveniences associated with unnecessary treatments and medical expenses caused by lack of knowledge about the exact type of implant.","['implant fixture system classification using periapical radiographs', 'transfer learning via deep neural networks']"
preterm birth imposes a high risk for developing neuromotor delay. earlier prediction of adverse outcome in preterm infants is crucial for referral to earlier intervention. this study aimed to predict abnormal motor outcome at 2 years from early brain diffusion magnetic resonance imaging (mri) acquired between 29 and 35 weeks postmenstrual age (pma) using a deep learning convolutional neural network (cnn) model.,"['early brain diffusion mri using', 'deep learning convolutional neural network', 'predicting motor outcome', 'preterm infants', 'cn']"
"this is a systematic review on the main algorithms using machine learning (ml) in retinal image processing for glaucoma diagnosis and detection. ml has proven to be a significant tool for the development of computer aided technology. furthermore, secondary research has been widely conducted over the years for ophthalmologists. such aspects indicate the importance of ml in the context of retinal image processing.","['retinal image processing', 'machine learning applied', 'glaucoma detection', 'review', 'perspective']"
"artificial intelligence is a hot topic in medical imaging. the development of deep learning methods and in particular the use of convolutional neural networks (cnns), have led to substantial performance gain over the classic machine learning techniques. multiple usages are currently being evaluated, especially for thoracic imaging, such as such as lung nodule evaluation, tuberculosis or pneumonia detection or quantification of diffuse lung diseases. chest radiography is a near perfect domain for the development of deep learning algorithms for automatic interpretation, requiring large annotated datasets, in view of the high number of procedures and increasing data availability. current algorithms are able to detect up to 14 common anomalies, when present as isolated findings. chest computed tomography is another major field of application for artificial intelligence, especially in the perspective of large scale lung cancer screening. it is important for radiologists to apprehend, contribute actively and lead this new era of radiology powered by artificial intelligence. such a perspective requires understanding new terms and concepts associated with machine learning. the objective of this paper is to provide useful definitions for understanding the methods used and their possibilities, and report current and future developments for thoracic imaging. prospective validation of ai tools will be required before reaching routine clinical implementation.","['artificial intelligence applications', 'thoracic imaging']"
"autism spectrum disorder (asd) includes different neurodevelopmental disorders characterized by deficits in social communication, and restricted, repetitive patterns of behavior, interests or activities. based on the importance of early diagnosis for effective therapeutic intervention, several strategies have been employed for detection of the disorder. the artificial neural network (ann) as a type of machine learning method is a common strategy. in the current study, we extracted genomic data for 487 asd patients and 455 healthy individuals. all individuals were genotyped in certain single-nucleotide polymorphisms within retinoic acid-related orphan receptor alpha (rora), gamma-aminobutyric acid type a receptor beta3 subunit (gabrb3), synaptosomal-associated protein 25 (snap25) and metabotropic glutamate receptor 7 (grm7) genes. subsequently, we used the ""keras"" package to create and train the ann model. for cross-validation, samples were divided into ten folds. in the training process, initially, the first fold was preserved for validation and the other folds were used to train the model. the validation fold was then used to evaluate model performance. the k-fold cross-validation method was used to ensure model generalizability and to prevent overfitting. local interpretable model-agnostic explanations (lime) were applied to explain model predictions at the data sample level. the output of loss function was evaluated in the training process for each fold in the k-fold cross-validation model. finally, the number of losses was reduced to less than 0.6 after 200 epochs (except in two cases). the accuracy, sensitivity and specificity of our model were 73.67%, 82.75% and 63.95%, respectively. the area under the curve (auc) was 80.59. consequently, in the current study, we propose an ann-based method for differentiating asd status from healthy status with adequate power.","['autism spectrum disorders', 'artificial neural networks', 'preliminary study', 'nucleotide polymorphisms', 'single', 'diagnosis', 'application']"
"the seventh annual deep brain stimulation (dbs) think tank held on september 8th of 2019 addressed the most current: (1) use and utility of complex neurophysiological signals for development of adaptive neurostimulation to improve clinical outcomes; (2) advancements in recent neuromodulation techniques to treat neuropsychiatric disorders; (3) new developments in optogenetics and dbs; (4) the use of augmented virtual reality (vr) and neuromodulation; (5) commercially available technologies; and (6) ethical issues arising in and from research and use of dbs. these advances serve as both ""markers of progress"" and challenges and opportunities for ongoing address, engagement, and deliberation as we move to improve the functional capabilities and translational value of dbs. it is in this light that these proceedings are presented to inform the field and initiate ongoing discourse. as consistent with the intent, and spirit of this, and prior dbs think tanks, the overarching goal is to continue to develop multidisciplinary collaborations to rapidly advance the field and ultimately improve patient outcomes.","['seventh annual deep brain stimulation think tank', 'virtual reality', 'adaptive dbs', 'technology', 'proceedings', 'neurophysiology', 'neuroethics', 'advances']"
"the automatic segmentation of kidneys in medical images is not a trivial task when the subjects undergoing the medical examination are affected by autosomal dominant polycystic kidney disease (adpkd). several works dealing with the segmentation of computed tomography images from pathological subjects were proposed, showing high invasiveness of the examination or requiring interaction by the user for performing the segmentation of the images. in this work, we propose a fully-automated approach for the segmentation of magnetic resonance images, both reducing the invasiveness of the acquisition device and not requiring any interaction by the users for the segmentation of the images.","['autosomal dominant polycystic kidney disease segmentation based', 'two semantic deep learning frameworks', 'magnetic resonance images', 'comparison']"
"sparse-data computed tomography (ct) frequently occurs, such as breast tomosynthesis, c-arm ct, on-board four-dimensional cone-beam ct (4d cbct), and industrial ct. however, sparse-data image reconstruction remains challenging due to highly undersampled data. this work develops a data-driven image reconstruction method for sparse-data ct using deep neural networks (dnn).","['deep neural network regularization', 'iterative reconstruction', 'fused analytical', 'data ct', 'sparse', 'airnet']"
"detecting the electrocardiogram pattern in internet of things-based healthcare system and notifying this to the user is a challenging task. using advance computing methods for classification of electrocardiogram signal is a notable research topic. in this research work, an intelligent electrocardiogram signal classification, employing deep learning algorithm, developed and tested in internet of things-based smart healthcare system was proposed. for classification of acquired electrocardiogram signal, a partitioned deep convolutional neural network was proposed. the electrocardiogram feature continuously in the internet of things-based monitoring system was learnt. to make use of learned features in the continuous time series data, it forms a higher order space in the server. we have made quantifiable comparative analysis with other classification algorithm with the same time series data collected from different atrial fibrillation samples in the internet of things-based e-health system. our proposed algorithm learned features were tested in atrial fibrillation classified signal with other conventional classifiers with various performance indices. we obtained an accuracy of 96.3\u2009percent with 93.5-percent sensitivity and 97.5-percent precision. from the obtained result, processing with proposed deep convolutional neural network provides reliable timely assist and accurate classification of electrocardiogram signal in internet of things-based smart healthcare system.","['atrial fibrillation classification using deep learning algorithm', 'based smart healthcare system', 'things', 'internet']"
"cryo-em single particle analysis workflows require tens of thousands of high-quality particle projections to unveil the three-dimensional structure of macromolecules. conventional methods for automatic particle picking tend to suffer from high false-positive rates, hampering the reconstruction process. one common cause of this problem is the presence of carbon and different types of high-contrast contaminations. in order to overcome this limitation, we have developed micrographcleaner, a deep learning package designed to discriminate, in an automated fashion, between regions of micrographs which are suitable for particle picking, and those which are not. micrographcleaner implements a u-net-like deep learning model trained on a manually curated dataset compiled from over five hundred micrographs. the benchmarking, carried out on approximately one hundred independent micrographs, shows that micrographcleaner is a very efficient approach for micrograph preprocessing. micrographcleaner (micrograph_cleaner_em) package is available at pypi and anaconda cloud and also as a scipion/xmipp protocol. source code is available at https://github.com/rsanchezgarc/micrograph_cleaner_em.","['em micrograph cleaning using deep learning', 'python package', 'micrographcleaner', 'cryo']"
"3d transesophageal echocardiography is an excellent tool for evaluating the mitral valve and is also well suited for guiding cardiac interventions. we introduce a fully automatic method for mitral annulus segmentation in 3d transesophageal echocardiography, which requires no manual input. one hundred eleven multi-frame 3d transesophageal echocardiography recordings were split into training, validation, and test sets. each 3d recording was decomposed into a set of 2d planes, exploiting the symmetry around the centerline of the left ventricle. a deep 2d convolutional neural network was trained to predict the mitral annulus coordinates, and the predictions from neighboring planes were regularized by enforcing continuity around the annulus. applying the final model and post-processing to the test set data gave a mean error of 2.0\xa0mm - with a standard deviation of 1.9\xa0mm. fully automatic segmentation of the mitral annulus can alleviate the need for manual interaction in the quantification of an array of mitral annular parameters and has the potential to eliminate inter-observer variability.","['mitral annulus segmentation using deep learning', 'transesophageal echocardiography', '3']"
"the infection of a novel coronavirus found in wuhan of china (sars-cov-2) is rapidly spreading, and the incidence rate is increasing worldwide. due to the lack of effective treatment options for sars-cov-2, various strategies are being tested in china, including drug repurposing. in this study, we used our pre-trained deep learning-based drug-target interaction model called molecule transformer-drug target interaction (mt-dti) to identify commercially available drugs that could act on viral proteins of sars-cov-2. the result showed that atazanavir, an antiretroviral medication used to treat and prevent the human immunodeficiency virus (hiv), is the best chemical compound, showing an inhibitory potency with kd of 94.94\xa0nm against the sars-cov-2 3c-like proteinase, followed by remdesivir (113.13\xa0nm), efavirenz (199.17\xa0nm), ritonavir (204.05\xa0nm), and dolutegravir (336.91\xa0nm). interestingly, lopinavir, ritonavir, and darunavir are all designed to target viral proteinases. however, in our prediction, they may also bind to the replication complex components of sars-cov-2 with an inhibitory potency with kd \xa0<\xa01000\xa0nm. in addition, we also found that several antiviral agents, such as kaletra (lopinavir/ritonavir), could be used for the treatment of sars-cov-2. overall, we suggest that the list of antiviral drugs identified by the mt-dti model should be considered, when establishing effective treatment strategies for sars-cov-2.","['predicting commercially available antiviral drugs', 'novel coronavirus', 'may act', 'sars', 'cov']"
"the medial forebrain bundle (mfb) is involved in the integration of pleasure and reward. previous studies have used various stimulation parameters for operant conditioning, though the effectiveness of these parameters has not been systematically studied.","['medial forebrain bundle stimulation parameters', 'operant conditioning', 'rats', 'optimization']"
"objective. the purpose of this study was to perform quantitative and qualitative evaluation of a deep learning image reconstruction (dlir) algorithm in contrast-enhanced oncologic ct of the abdomen. materials and methods. retrospective review (april-may 2019) of the cases of adults undergoing oncologic staging with portal venous phase abdominal ct was conducted for evaluation of standard 30% adaptive statistical iterative reconstruction v (30% asir-v) reconstruction compared with dlir at low, medium, and high strengths. attenuation and noise measurements were performed. two radiologists, blinded to examination details, scored six categories while comparing reconstructions for overall image quality, lesion diagnostic confidence, artifacts, image noise and texture, lesion conspicuity, and resolution. results. dlir had a better contrast-to-noise ratio than 30% asir-v did; high-strength dlir performed the best. high-strength dlir was associated with 47% reduction in noise, resulting in a 92-94% increase in contrast-to-noise ratio compared with that of 30% asir-v. for overall image quality and image noise and texture, dlir scored significantly higher than 30% asir-v with significantly higher scores as dlir strength increased. a total of 193 lesions were identified. the lesion diagnostic confidence, conspicuity, and artifact scores were significantly higher for all dlir levels than for 30% asir-v. there was no significant difference in perceived resolution between the reconstruction methods. conclusion. compared with 30% asir-v, dlir improved ct evaluation of the abdomen in the portal venous phase. dlir strength should be chosen to balance the degree of desired denoising for a clinical task relative to mild blurring, which increases with progressively higher dlir strengths.","['new deep learning image reconstruction', 'image quality assessment', 'initial experience', 'abdominal ct', 'use']"
"lung cancer has a high mortality rate, but an early diagnosis can contribute to a favorable prognosis. a liquid biopsy that captures and detects tumor-related biomarkers in body fluids has great potential for early-stage diagnosis. exosomes, nanosized extracellular vesicles found in blood, have been proposed as promising biomarkers for liquid biopsy. here, we demonstrate an accurate diagnosis of early-stage lung cancer, using deep learning-based surface-enhanced raman spectroscopy (sers) of the exosomes. our approach was to explore the features of cell exosomes through deep learning and figure out the similarity in human plasma exosomes, without learning insufficient human data. the deep learning model was trained with sers signals of exosomes derived from normal and lung cancer cell lines and could classify them with an accuracy of 95%. in 43 patients, including stage i and ii cancer patients, the deep learning model predicted that plasma exosomes of 90.7% patients had higher similarity to lung cancer cell exosomes than the average of the healthy controls. such similarity was proportional to the progression of cancer. notably, the model predicted lung cancer with an area under the curve (auc) of 0.912 for the whole cohort and stage i patients with an auc of 0.910. these results suggest the great potential of the combination of exosome analysis and deep learning as a method for early-stage liquid biopsy of lung cancer.","['stage lung cancer diagnosis', 'based spectroscopic analysis', 'deep learning', 'circulating exosomes', 'early']"
"studying the biology of sleep requires the accurate assessment of the state of experimental subjects, and manual analysis of relevant data is a major bottleneck. recently, deep learning applied to electroencephalogram and electromyogram data has shown great promise as a sleep scoring method, approaching the limits of inter-rater reliability. as with any machine learning algorithm, the inputs to a sleep scoring classifier are typically standardized in order to remove distributional shift caused by variability in the signal collection process. however, in scientific data, experimental manipulations introduce variability that should not be removed. for example, in sleep scoring, the fraction of time spent in each arousal state can vary between control and experimental subjects. we introduce a standardization method, mixture z-scoring, that preserves this crucial form of distributional shift. using both a simulated experiment and mouse in vivo data, we demonstrate that a common standardization method used by state-of-the-art sleep scoring algorithms introduces systematic bias, but that mixture z-scoring does not. we present a free, open-source user interface that uses a compact neural network and mixture z-scoring to allow for rapid sleep scoring with accuracy that compares well to contemporary methods. this work provides a set of computational tools for the robust automation of sleep scoring.","['distributional shift correction', 'compact neural network', 'automated sleep scoring', 'robust']"
"knee osteoarthritis (oa) is a common musculoskeletal disorder in the united states. when diagnosed at early stages, lifestyle interventions such as exercise and weight loss can slow oa progression, but at later stages, only an invasive option is available: total knee replacement (tkr). though a generally successful procedure, only 2/3 of patients who undergo the procedure report their knees feeling ""normal"" post-operation, and complications can arise that require revision. this necessitates a model to identify a population at higher risk of tkr, particularly at less advanced stages of oa, such that appropriate treatments can be implemented that slow oa progression and delay tkr. here, we present a deep learning pipeline that leverages mri images and clinical and demographic information to predict tkr with auc 0.834 ± 0.036 (p\u2009<\u20090.05). most notably, the pipeline predicts tkr with auc 0.943 ± 0.057 (p\u2009<\u20090.05) for patients without oa. furthermore, we develop occlusion maps for case-control pairs in test data and compare regions used by the model in both, thereby identifying tkr imaging biomarkers. as such, this work takes strides towards a pipeline with clinical utility, and the biomarkers identified further our understanding of oa progression and eventual tkr onset.","['deep learning predicts total knee replacement', 'magnetic resonance images']"
"quality of single optical coherence tomography angiography (octa) images of myopic choroidal neovascularisation (mcnv) is poorer than in averaged images, although obtaining averaged images takes much time. this study evaluated the clinical usefulness of novel denoising process for depicting mcnv. this study included 20 eyes of 20 patients with mcnv. ten en face images taken in a 3\u2009×\u20093\u2009mm macular cube were obtained from outer-retina-to-choriocapillaris layer. three image types were prepared for analysis; single images before and after the denoising process accomplished deep learning (single and denoising groups, respectively) and up to 10 images were averaged (averaging group). pairwise comparisons showed vessel density, vessel length density, and fractal dimension (fd) were higher; whereas, vessel density index (vdi) was lower in single group than in denoising and averaging groups. detectable cnv indices, contrast-to-nose ratio, and cnv diagnostic scores were higher in denoising and averaging groups than in single group. no significant differences were detected in vdi, fd, or cnv diagnostic scores between denoising and averaging groups. the denoising process can utilise single octa images to provide results comparable to averaged octa images, which is clinically useful for shortening examination times with quality similar to averaging.","['single optical coherence tomography angiography image', 'depict myopic choroidal neovascularisation using', 'denoising process', 'usefulness']"
"in order to train the neural network for plant phenotyping, a sufficient amount of training data must be prepared, which requires time-consuming manual data annotation process that often becomes the limiting step. here, we show that an instance segmentation neural network aimed to phenotype the barley seed morphology of various cultivars, can be sufficiently trained purely by a synthetically generated dataset. our attempt is based on the concept of domain randomization, where a large amount of image is generated by randomly orienting the seed object to a virtual canvas. the trained model showed 96% recall and 95% average precision against the real-world test dataset. we show that our approach is effective also for various crops including rice, lettuce, oat, and wheat. constructing and utilizing such synthetic data can be a powerful method to alleviate human labor costs for deploying deep learning-based analysis in the agricultural domain.","['training instance segmentation neural network', 'crop seed phenotyping', 'synthetic datasets']"
"the reappearance of human visual perception is a challenging topic in the field of brain decoding. due to the complexity of visual stimuli and the constraints of fmri data collection, the present decoding methods can only reconstruct the basic outline or provide similar figures/features of the perceived natural stimuli. to achieve a high-quality and high-resolution reconstruction of natural images from brain activity, this paper presents an end-to-end perception reconstruction model called the similarity-conditions generative adversarial network (sc-gan), where visually perceptible images are reconstructed based on human visual cortex responses. the sc-gan extracts the high-level semantic features of natural images and corresponding visual cortical responses and then introduces the semantic features as conditions of generative adversarial networks (gans) to realize the perceptual reconstruction of visual images. the experimental results show that the semantic features extracted from sc-gan play a key role in the reconstruction of natural images. the similarity between the presented and reconstructed images obtained by the sc-gan is significantly higher than that obtained by a condition generative adversarial network (c-gan). the model we proposed offers a potential perspective for decoding the brain activity of complex natural stimuli.","['reconstructing natural images', 'brain activity', 'visual perception', 'perception', 'image']"
"the medical imaging literature has witnessed remarkable progress in high-performing segmentation models based on convolutional neural networks. despite the new performance highs, the recent advanced segmentation models still require large, representative, and high quality annotated datasets. however, rarely do we have a perfect training dataset, particularly in the field of medical imaging, where data and annotations are both expensive to acquire. recently, a large body of research has studied the problem of medical image segmentation with imperfect datasets, tackling two major dataset limitations: scarce annotations where only limited annotated data is available for training, and weak annotations where the training data has only sparse annotations, noisy annotations, or image-level annotations. in this article, we provide a detailed review of the solutions above, summarizing both the technical novelties and empirical results. we further compare the benefits and requirements of the surveyed methodologies and provide our recommended solutions. we hope this survey article increases the community awareness of the techniques that are available to handle imperfect medical image segmentation datasets.","['medical image segmentation', 'embracing imperfect datasets', 'deep learning solutions', 'review']"
"detecting early gastric cancer is difficult, and it may even be overlooked by experienced endoscopists. recently, artificial intelligence based on deep learning through convolutional neural networks (cnns) has enabled significant advancements in the field of gastroenterology. however, it remains unclear whether a cnn can outperform endoscopists. in this study, we evaluated whether the performance of a cnn in detecting early gastric cancer is better than that of endoscopists.","['detecting early gastric cancer', 'convolutional neural networks', 'diagnostic ability', 'endoscopists', 'comparison']"
phenological annotation models computed on large-scale herbarium data sets were developed and tested in this study.,"['deep phenological stage annotation', 'herbarium specimens', 'equatorial floras', 'case studies', 'tropical', 'toward', 'temperate', 'scale', 'large']"
the purpose of this study is to develop an image-based deep learning (dl) model to predict the 5-year risk of breast cancer on the basis of a single breast mr image from a screening examination.,"['breast mr image alone', 'deep learning model', 'assess cancer risk', 'basis']"
"many medical and biological protocols for analyzing individual biological cells involve morphological evaluation based on cell staining, designed to enhance imaging contrast and enable clinicians and biologists to differentiate between various cell organelles. however, cell staining is not always allowed in certain medical procedures. in other cases, staining may be time-consuming or expensive to implement. staining protocols may be operator-sensitive, and hence may lead to varying analytical results, as well as cause artificial imaging artifacts or false heterogeneity. we present a deep-learning approach, called holostain, which converts images of isolated biological cells acquired without staining by holographic microscopy to their virtually stained images. we demonstrate this approach for human sperm cells, as there is a well-established protocol and global standardization for characterizing the morphology of stained human sperm cells for fertility evaluation, but, on the other hand, staining might be cytotoxic and thus is not allowed during human in vitro fertilization (ivf). after a training process, the deep neural network can take images of unseen sperm cells retrieved from holograms acquired without staining and convert them to their stainlike images. we obtained a fivefold recall improvement in the analysis results, demonstrating the advantage of using virtual staining for sperm cell analysis. with the introduction of simple holographic imaging methods in clinical settings, the proposed method has a great potential to become a common practice in human ivf procedures, as well as to significantly simplify and radically change other cell analyses and techniques such as imaging flow cytometry.","['individual biological cells', 'holographic virtual staining']"
"colon cancer generally begins as a neoplastic growth of tissue, called polyps, originating from the inner lining of the colon wall. most colon polyps are considered harmless but over time, they can evolve into colon cancer, which when diagnosed in later stages is often fatal. hence, time is of the essence in the early detection of polyps and the prevention of colon cancer.","['deep learning based computer aided methods', 'machine learning', 'ct colonography', 'survey', 'polyps', 'detection']"
"still under debate is the question of whether machine learning is capable of going beyond black-box modeling for complex physical systems. we investigate the generalizing and interpretability properties of learning algorithms. to this end, we use supervised and unsupervised learning to infer the phase boundaries of the active ising model, starting from an ensemble of configurations of the system. we illustrate that unsupervised learning techniques are powerful at identifying the phase boundaries in the control parameter space, even in situations of phase coexistence. it is demonstrated that supervised learning with neural networks is capable of learning the characteristics of the phase diagram, such that the knowledge obtained at a limited set of control variables can be used to determine the phase boundaries across the phase diagram. in this way, we show that properly designed supervised learning provides predictive power to regions in the phase diagram that are not included in the training phase of the algorithm. we stress the importance of introducing interpretability methods in order to perform a physically relevant classification of the phases with deep learning.","['interpretable machine learning', 'phase boundaries', 'nonequilibrium system', 'inferring']"
"both genetic and environmental factors influence the etiology of age-related macular degeneration (amd), a leading cause of blindness. amd severity is primarily measured by fundus images and recently developed machine learning methods can successfully predict amd progression using image data. however, none of these methods have utilized both genetic and image data for predicting amd progression. here we jointly used genotypes and fundus images to predict an eye as having progressed to late amd with a modified deep convolutional neural network (cnn). in total, we used 31,262 fundus images and 52 amd-associated genetic variants from 1,351 subjects from the age-related eye disease study (areds) with disease severity phenotypes and fundus images available at baseline and follow-up visits over a period of 12 years. our results showed that fundus images coupled with genotypes could predict late amd progression with an averaged area under the curve (auc) value of 0.85 (95%ci: 0.83-0.86). the results using fundus images alone showed an averaged auc of 0.81 (95%ci: 0.80-0.83). we implemented our model in a cloud-based application for individual risk assessment.","['related macular degeneration progression', 'late age', 'based prediction', 'learning', 'deep']"
"accurate grading of non-muscle invasive urothelial cell carcinoma (ucc) is of major importance, however high inter-observer variability exists. a fully-automated detection and grading network based on deep learning is proposed to enhance reproducibility. a total of 328 transurethral resection specimens from 232 patients were included. a consensus reading by three specialized pathologists was utilized. the slides were digitized and the urothelium was annotated by expert observers. the u-net based segmentation network was trained to automatically detect urothelium in the sections. this detection was used as input for the classification network. the classification network aimed to grade the tumors according to the who'04 grading system. the automated grading was compared with the consensus and individual grading. the segmentation network resulted in an accurate detection of urothelium. false positive urothelium detection was mostly found in regions with extensive color loss or inflammation and occurred in 13% of the sections. the automated grading shows moderate agreement (κ=0.48 ± 0.14 se) with the consensus reading. the agreement among pathologists ranges between fair (κ=0.35 ± 0.13 se & κ=0.38 ± 0.11 se) and moderate (κ=0.52 ± 0.13 se). the automated classification correctly grades 76% of the low-grade and 71% of the high-grade cancers according to the consensus reading. these results indicate that deep learning can be used for the fully-automated detection and grading of ucc.","['muscle invasive urothelial cell carcinoma', 'automated detection', 'non', 'grading', 'bladder']"
chronic obstructive pulmonary disease (copd) is a progressive lung disease that is classified into stages based on disease severity. we aimed to characterize the time to progression prior to death in patients with copd and to generate a temporal visualization that describes signs and symptoms during different stages of copd progression.,"['chronic obstructive pulmonary disease progression using deep learning', 'unstructured clinical notes', 'temporal visualization']"
"accurately predicting distant metastasis in head & neck cancer has the potential to improve patient survival by allowing early treatment intensification with systemic therapy for high-risk patients. by extracting large amounts of quantitative features and mining them, radiomics has achieved success in predicting treatment outcomes for various diseases. however, there are several challenges associated with conventional radiomic approaches, including: 1) how to optimally combine information extracted from multiple modalities; 2) how to construct models emphasizing different objectives for different clinical applications; and 3) how to utilize and fuse output obtained by multiple classifiers. to overcome these challenges, we propose a unified model termed as multifaceted radiomics (m-radiomics). in m-radiomics, a deep learning with stacked sparse autoencoder is first utilized to fuse features extracted from different modalities into one representation feature set. a multi-objective optimization model is then introduced into m-radiomics where probability- based objective functions are designed to maximize the similarity between the probability output and the true label vector. finally, m-radiomics employs multiple base classifiers to get a diverse pareto-optimal model set and then fuses the output probabilities of all the pareto-optimal models through an evidential reasoning rule fusion (errf) strategy in the testing stage to obtain the final output probability. experimental results show that m-radiomics with the stacked autoencoder outperforms the model without the autoencoder. m-radiomics obtained more accurate results with a better balance between sensitivity and specificity than other single-objective or single-classifier-based models.","['distant metastasis prediction', 'neck cancer', 'multifaceted radiomics', 'head']"
to quantify morphologic photoreceptor integrity during anti-vascular endothelial growth factor (anti-vegf) therapy of neovascular age-related macular degeneration and correlate these findings with disease morphology and function.,"['related macular degeneration', 'photoreceptor loss correlated', 'topographic analysis', 'neovascular age', 'disease morphology']"
"quantitative susceptibility mapping (qsm) is based on magnetic resonance imaging (mri) phase measurements and has gained broad interest because it yields relevant information on biological tissue properties, predominantly myelin, iron and calcium in vivo. thereby, qsm can also reveal pathological changes of these key components in widespread diseases such as parkinson's disease, multiple sclerosis, or hepatic iron overload. while the ill-posed field-to-source-inversion problem underlying qsm is conventionally assessed by the means of regularization techniques, we trained a fully convolutional deep neural network - deepqsm - to directly invert the magnetic dipole kernel convolution. deepqsm learned the physical forward problem using purely synthetic data and is capable of solving the ill-posed field-to-source inversion on in vivo mri phase data. the magnetic susceptibility maps reconstructed by deepqsm enable identification of deep brain substructures and provide information on their respective magnetic tissue properties. in summary, deepqsm can invert the magnetic dipole kernel convolution and delivers robust solutions to this ill-posed problem.","['using deep learning', 'quantitative susceptibility mapping', 'dipole inversion', 'solve', 'deepqsm']"
"person re-identification (re-id) favors discriminative representations over unseen shots to recognize identities in disjoint camera views. effective methods are developed via pair-wise similarity learning to detect a fixed set of region features, which can be mapped to compute the similarity value. however, relevant parts of each image are detected independently without referring to the correlation on the other image. also, region-based methods spatially position local features for their aligned similarities. in this article, we introduce the deep coattention-based comparator (dcc) to fuse codependent representations of paired images so as to correlate the best relevant parts and produce their relative representations accordingly. the proposed approach mimics the human foveation to detect the distinct regions concurrently across images and alternatively attends to fuse them into the similarity learning. our comparator is capable of learning representations relative to a test shot and well-suited to reidentifying pedestrians in surveillance. we perform extensive experiments to provide the insights and demonstrate the state of the arts achieved by our method in benchmark data sets: 1.2 and 2.5 points gain in mean average precision (map) on dukemtmc-reid and market-1501, respectively.","['relative representation learning', 'deep coattention', 'based comparator', 'person', 'identification']"
"background enhancing lesions on mri scans obtained after contrast material administration are commonly thought to represent disease activity in multiple sclerosis (ms); it is desirable to develop methods that can predict enhancing lesions without the use of contrast material. purpose to evaluate whether deep learning can predict enhancing lesions on mri scans obtained without the use of contrast material. materials and methods this study involved prospective analysis of existing mri data. a convolutional neural network was used for classification of enhancing lesions on unenhanced mri scans. this classification was performed for each slice, and the slice scores were combined by using a fully connected network to produce participant-wise predictions. the network input consisted of 1970 multiparametric mri scans from 1008 patients recruited from 2005 to 2009. enhanced lesions on postcontrast t1-weighted images served as the ground truth. the network performance was assessed by using fivefold cross-validation. statistical analysis of the network performance included calculation of lesion detection rates and areas under the receiver operating characteristic curve (aucs). results mri scans from 1008 participants (mean age, 37.7 years ± 9.7; 730 women) were analyzed. at least one enhancing lesion was observed in 519 participants. the sensitivity and specificity averaged across the five test sets were 78% ± 4.3 and 73% ± 2.7, respectively, for slice-wise prediction. the corresponding participant-wise values were 72% ± 9.0 and 70% ± 6.3. the diagnostic performances (aucs) were 0.82 ± 0.02 and 0.75 ± 0.03 for slice-wise and participant-wise enhancement prediction, respectively. conclusion deep learning used with conventional mri identified enhanced lesions in multiple sclerosis from images from unenhanced multiparametric mri with moderate to high accuracy.","['predicting enhancing lesions', 'noncontrast mri', 'multiple sclerosis', 'deep learning']"
"deep learning is a class of machine learning algorithms that are popular for building risk prediction models. when observations are censored, the outcomes are only partially observed and standard deep learning algorithms cannot be directly applied. we develop a new class of deep learning algorithms for outcomes that are potentially censored. to account for censoring, the unobservable loss function used in the absence of censoring is replaced by a censoring unbiased transformation. the resulting class of algorithms can be used to estimate both survival probabilities and restricted mean survival. we show how the deep learning algorithms can be implemented by adapting software for uncensored data by using a form of response transformation. we provide comparisons of the proposed deep learning algorithms to existing risk prediction algorithms for predicting survival probabilities and restricted mean survival through both simulated datasets and analysis of data from breast cancer patients.","['survival outcomes', 'deep learning']"
"in the cultural heritage (ch) context, art galleries and museums employ technology devices to enhance and personalise the museum visit experience. however, the most challenging aspect is to determine what the visitor is interested in. in this work, a novel visual attentive model (vam) has been proposed that is learned from eye tracking data. in particular, eye-tracking data of adults and children observing five paintings with similar characteristics have been collected. the images are selected by ch experts and are-the three ""ideal cities"" (urbino, baltimore and berlin), the inlaid chest in the national gallery of marche and wooden panel in the ""studiolo del duca"" with marche view. these pictures have been recognized by experts as having analogous features thus providing coherent visual stimuli. our proposed method combines a new coordinates representation from eye sequences by using geometric algebra with a deep learning model for automated recognition (to identify, differentiate, or authenticate individuals) of people by the attention focus of distinctive eye movement patterns. the experiments were conducted by comparing five deep convolutional neural networks (dcnns), yield high accuracy (more than 80 %), demonstrating the effectiveness and suitability of the proposed approach in identifying adults and children as museums\' visitors.","['visual attentive model', 'tracking data', 'discovering patterns', 'cultural heritage', 'proposal', 'eye']"
"the development of digital pathology and progression of state-of-the-art algorithms for computer vision have led to increasing interest in the use of artificial intelligence (ai), especially deep learning (dl)-based ai, in tumor pathology. the dl-based algorithms have been developed to conduct all kinds of work involved in tumor pathology, including tumor diagnosis, subtyping, grading, staging, and prognostic prediction, as well as the identification of pathological features, biomarkers and genetic changes. the applications of ai in pathology not only contribute to improve diagnostic accuracy and objectivity but also reduce the workload of pathologists and subsequently enable them to spend additional time on high-level decision-making tasks. in addition, ai is useful for pathologists to meet the requirements of precision oncology. however, there are still some challenges relating to the implementation of ai, including the issues of algorithm validation and interpretability, computing systems, the unbelieving attitude of pathologists, clinicians and patients, as well as regulators and reimbursements. herein, we present an overview on how ai-based approaches could be integrated into the workflow of pathologists and discuss the challenges and perspectives of the implementation of ai in tumor pathology.","['based artificial intelligence', 'tumor pathology', 'emerging role', 'deep learning']"
"traffic crash detection is a major component of intelligent transportation systems. it can explore inner relationships between traffic conditions and crash risk, prevent potential crashes, and improve road safety. however, there exist some limitations in current studies on crash detection: (1) the commonly used machine learning methods cannot simulate the evolving transitions of traffic conditions before crash occurrences; (2) current models collected traffic data of only one temporal resolution, which cannot fully represent traffic trends in different time intervals. therefore, this study proposes a long short-term memory (lstm) based framework considering traffic data of different temporal resolutions (lstmdtr) for crash detection. lstm is an effective deep learning method to capture the long-term dependency and dynamic transitions of pre-crash conditions. three lstm networks considering traffic data of different temporal resolutions are constructed, which can comprehensively indicate traffic variations in different time intervals. a fully-connected layer is used to combine the outputs of three lstm networks, and a dropout layer is used to reduce overfitting and improve prediction performance. the lstmdtr model is implemented on datasets of i880-n and i805-n in california, america. the results indicate that the lstmdtr model can obtain satisfactory performance on crash detection, with the highest crash accuracy of 70.43 %. lstmdtr models constructed on one freeway can be transferred to other similar freeways, with 65.12 % of crash accuracy on transferability. compared with machine learning methods and lstm models with one or two temporal resolutions, the lstmdtr model has been validated to perform better on crash detection and transferability. a proper number of neurons in the lstmdtr model should be determined in real applications considering acceptable detection performance and computation time. the dropout technique can reduce overfitting and improve the generalization ability of the lstmdtr model, increasing crash accuracy from 64.49 % to 70.43 %.","['different temporal resolutions', 'traffic data', 'term memory', 'long short', 'crash detection', 'based framework', 'freeways']"
"as a promising method in artificial intelligence, deep learning has been proven successful in several domains ranging from acoustics and images to natural language processing. with medical imaging becoming an important part of disease screening and diagnosis, deep learning-based approaches have emerged as powerful techniques in medical image areas. in this process, feature representations are learned directly and automatically from data, leading to remarkable breakthroughs in the medical field. deep learning has been widely applied in medical imaging for improved image analysis. this paper reviews the major deep learning techniques in this time of rapid evolution and summarizes some of its key contributions and state-of-the-art outcomes. the topics include classification, detection, and segmentation tasks on medical image analysis with respect to pulmonary medical images, datasets, and benchmarks. a comprehensive overview of these methods implemented on various lung diseases consisting of pulmonary nodule diseases, pulmonary embolism, pneumonia, and interstitial lung disease is also provided. lastly, the application of deep learning techniques to the medical image and an analysis of their future challenges and potential directions are discussed.","['pulmonary medical imaging', 'deep learning', 'survey']"
"accurate identification of bone surface modifications (bsm) is crucial for the taphonomic understanding of archaeological and paleontological sites. critical interpretations of when humans started eating meat and animal fat or when they started using stone tools, or when they occupied new continents or interacted with predatory guilds impinge on accurate identifications of bsm. until now, interpretations of plio-pleistocene bsm have been contentious because of the high uncertainty in discriminating among taphonomic agents. recently, the use of machine learning algorithms has yielded high accuracy in the identification of bsm. a branch of machine learning methods based on imaging, computer vision (cv), has opened the door to a more objective and accurate method of bsm identification. the present work has selected two extremely similar types of bsm (cut marks made on fleshed an defleshed bones) to test the immense potential of artificial intelligence methods. this cv approach not only produced the highest accuracy in the classification of these types of bsm until present (95% on complete images of bsm and 88.89% of images of only internal mark features), but it also has enabled a method for determining which inconspicuous microscopic features determine successful bsm discrimination. the potential of this method in other areas of taphonomy and paleobiology is enormous.","['defleshed bones using convolutional neural networks', 'cut marks made', 'high accuracy', 'deep learning', 'taphonomy', 'fleshed', 'classification']"
"the unparalleled performance of deep learning approaches in generic image processing has motivated its extension to neuroimaging data. these approaches learn abstract neuroanatomical and functional brain alterations that could enable exceptional performance in classification of brain disorders, predicting disease progression, and localizing brain abnormalities.","['deep residual learning', 'predict progression', 'neuroimaging', 'disease', 'application', 'alzheimer']"
"high-throughput quantification of oligodendrocyte myelination is a challenge that, if addressed, would facilitate the development of therapeutics to promote myelin protection and repair. here, we established a high-throughput method to assess oligodendrocyte ensheathment in-vitro, combining nanofiber culture devices and automated imaging with a heuristic approach that informed the development of a deep learning analytic algorithm. the heuristic approach was developed by modeling general characteristics of oligodendrocyte ensheathments, while the deep learning neural network employed a unet architecture and a single-cell training method to associate ensheathed segments with individual oligodendrocytes. reliable extraction of multiple morphological parameters from individual cells, without heuristic approximations, allowed the unet to match the accuracy of expert-human measurements. the capacity of this technology to perform multi-parametric analyses at the level of individual cells, while reducing manual labor and eliminating human variability, permits the detection of nuanced cellular differences to accelerate the discovery of new insights into oligodendrocyte physiology.","['throughput quantification', 'oligodendrocyte ensheathment', 'deep learning', 'cell resolution', 'single', 'high']"
"currently, most real-world time series datasets are multivariate and are rich in dynamical information of the underlying system. such datasets are attracting much attention; therefore, the need for accurate modelling of such high-dimensional datasets is increasing. recently, the deep architecture of the recurrent neural network (rnn) and its variant long short-term memory (lstm) have been proven to be more accurate than traditional statistical methods in modelling time series data. despite the reported advantages of the deep lstm model, its performance in modelling multivariate time series (mts) data has not been satisfactory, particularly when attempting to process highly non-linear and long-interval mts datasets. the reason is that the supervised learning approach initializes the neurons randomly in such recurrent networks, disabling the neurons that ultimately must properly learn the latent features of the correlated variables included in the mts dataset. in this paper, we propose a pre-trained lstm-based stacked autoencoder (lstm-sae) approach in an unsupervised learning fashion to replace the random weight initialization strategy adopted in deep lstm recurrent networks. for evaluation purposes, two different case studies that include real-world datasets are investigated, where the performance of the proposed approach compares favourably with the deep lstm approach. in addition, the proposed approach outperforms several reference models investigating the same case studies. overall, the experimental results clearly show that the unsupervised pre-training approach improves the performance of deep lstm and leads to better and faster convergence than other models.","['multivariate time series forecasting problems', 'based stacked autoencoder', 'unsupervised pre', 'deep lstm', 'training']"
"multi-species microbial communities are widespread in natural ecosystems. when employed for biomanufacturing, engineered synthetic communities have shown increased productivity in comparison with monocultures and allow for the reduction of metabolic load by compartmentalising bioprocesses between multiple sub-populations. despite these benefits, co-cultures are rarely used in practice because control over the constituent species of an assembled community has proven challenging. here we demonstrate, in silico, the efficacy of an approach from artificial intelligence-reinforcement learning-for the control of co-cultures within continuous bioreactors. we confirm that feedback via a trained reinforcement learning agent can be used to maintain populations at target levels, and that model-free performance with bang-bang control can outperform a traditional proportional integral controller with continuous control, when faced with infrequent sampling. further, we demonstrate that a satisfactory control policy can be learned in one twenty-four hour experiment by running five bioreactors in parallel. finally, we show that reinforcement learning can directly optimise the output of a co-culture bioprocess. overall, reinforcement learning is a promising technique for the control of microbial communities.","['deep reinforcement learning', 'microbial co', 'cultures', 'control', 'bioreactors']"
"existing deep learning methods for action recognition in videos require a large number of labeled videos for training, which is labor-intensive and time-consuming. for the same action, the knowledge learned from different media types, e.g., videos and images, may be related and complementary. however, due to the domain shifts and heterogeneous feature representations between videos and images, the performance of classifiers trained on images may be dramatically degraded when directly deployed to videos. in this paper, we propose a novel method, named deep image-to-video adaptation and fusion networks (divafn), to enhance action recognition in videos by transferring knowledge from images using video keyframes as a bridge. the divafn is a unified deep learning model, which integrates domain-invariant representations learning and cross-modal feature fusion into a unified optimization framework. specifically, we design an efficient cross-modal similarities metric to reduce the modality shift among images, keyframes and videos. then, we adopt an autoencoder architecture, whose hidden layer is constrained to be the semantic representations of the action class names. in this way, when the autoencoder is adopted to project the learned features from different domains to the same space, more compact, informative and discriminative representations can be obtained. finally, the concatenation of the learned semantic feature representations from these three autoencoders are used to train the classifier for action recognition in videos. comprehensive experiments on four real-world datasets show that our method outperforms some state-of-the-art domain adaptation and action recognition methods.","['video adaptation', 'fusion networks', 'deep image', 'action recognition']"
"artificial intelligence and machine learning are rapidly expanding fields with increasing relevance in anesthesia and, in particular, airway management. the ability of artificial intelligence and machine learning algorithms to recognize patterns from large volumes of complex data makes them attractive for use in pediatric anesthesia airway management. the purpose of this review is to introduce artificial intelligence, machine learning, and deep learning to the pediatric anesthesiologist. current evidence and developments in artificial intelligence, machine learning, and deep learning relevant to pediatric airway management are presented. we critically assess the current evidence on the use of artificial intelligence and machine learning in the assessment, diagnosis, monitoring, procedure assistance, and predicting outcomes during pediatric airway management. further, we discuss the limitations of these technologies and offer areas for focused research that may bring pediatric airway management anesthesiology into the era of artificial intelligence and machine learning.","['pediatric airway', 'machine learning', 'artificial intelligence']"
"the cerebellum plays a key role in the regulation of motor learning, coordination and timing, and has been implicated in sensory and cognitive processes as well. however, our current knowledge of its electrophysiological mechanisms comes primarily from direct recordings in animals, as investigations into cerebellar function in humans have instead predominantly relied on lesion, haemodynamic and metabolic imaging studies. while the latter provide fundamental insights into the contribution of the cerebellum to various cerebellar-cortical pathways mediating behaviour, they remain limited in terms of temporal and spectral resolution. in principle, this shortcoming could be overcome by monitoring the cerebellum's electrophysiological signals. non-invasive assessment of cerebellar electrophysiology in humans, however, is hampered by the limited spatial resolution of electroencephalography (eeg) and magnetoencephalography (meg) in subcortical structures, i.e., deep sources. furthermore, it has been argued that the anatomical configuration of the cerebellum leads to signal cancellation in meg and eeg. yet, claims that meg and eeg are unable to detect cerebellar activity have been challenged by an increasing number of studies over the last decade. here we address this controversy and survey reports in which electrophysiological signals were successfully recorded from the human cerebellum. we argue that the detection of cerebellum activity non-invasively with meg and eeg is indeed possible and can be enhanced with appropriate methods, in particular using connectivity analysis in source space. we provide illustrative examples of cerebellar activity detected with meg and eeg. furthermore, we propose practical guidelines to optimize the detection of cerebellar activity with meg and eeg. finally, we discuss meg and eeg signal contamination that may lead to localizing spurious sources in the cerebellum and suggest ways of handling such artefacts. this review is to be read as a perspective review that highlights that it is indeed possible to measure cerebellum with meg and eeg and encourages meg and eeg researchers to do so. its added value beyond highlighting and encouraging is that it offers useful advice for researchers aspiring to investigate the cerebellum with meg and eeg.","['meg detect signals', 'human cerebellum', 'eeg']"
"electroencephalograph (eeg) classification is an important technology that can establish a mapping relationship between eeg features and cognitive tasks. emerging matrix classifiers have been successfully applied to motor imagery (mi) eeg classification, but they belong to shallow classifiers, making powerful stacked generalization principle not exploited for automatically learning deep eeg features. to learn\xa0the high-level\xa0representation and\xa0abstraction, we proposed a novel deep stacked support matrix machine (dssmm) to improve the performance of existing shallow matrix classifiers in eeg classification.","['deep stacked support matrix machine based representation learning', 'motor imagery eeg classification']"
"in developing countries like pakistan, cleft surgery is expensive for families, and the child also experiences much pain. in this article, we propose a machine learning-based solution to avoid cleft in the mother's womb. the possibility of cleft lip and palate in embryos can be predicted before birth by using the proposed solution. we collected 1000 pregnant female samples from three different hospitals in lahore, punjab. a questionnaire has been designed to obtain a variety of data, such as gender, parenting, family history of cleft, the order of birth, the number of children, midwives counseling, miscarriage history, parent smoking, and physician visits. different cleaning, scaling, and feature selection methods have been applied to the data collected. after selecting the best features from the cleft data, various machine learning algorithms were used, including random forest, k-nearest neighbor, decision tree, support vector machine, and multilayer perceptron. in our implementation, multilayer perceptron is a deep neural network, which yields excellent results for the cleft dataset compared to the other methods. we achieved 92.6% accuracy on test data based on the multilayer perceptron model. our promising results of predictions would help to fight future clefts for children who would have cleft.","['birth using deep neural network', 'cleft prediction']"
"multiview representation learning (mvrl) leverages information from multiple views to obtain a common representation summarizing the consistency and complementarity in multiview data. most previous matrix factorization-based mvrl methods are shallow models that neglect the complex hierarchical information. the recently proposed deep multiview factorization models cannot explicitly capture consistency and complementarity in multiview data. we present the deep multiview concept learning (dmcl) method, which hierarchically factorizes the multiview data, and tries to explicitly model consistent and complementary information and capture semantic structures at the highest abstraction level. we explore two variants of the dmcl framework, dmcl-l and dmcl-n, with respectively linear/nonlinear transformations between adjacent layers. we propose two block coordinate descent-based optimization methods for dmcl-l and dmcl-n. we verify the effectiveness of dmcl on three real-world data sets for both clustering and classification tasks.",['multiview concept learning via deep matrix factorization']
"the 21st century marks the emergence of ""big data"" with a rapid increase in the availability of data sets with multiple measurements. in neuroscience, brain-imaging datasets are more commonly accompanied by dozens or even hundreds of phenotypic subject descriptors on the behavioral, neural, and genomic level. the complexity of such ""big data"" repositories offer new opportunities and pose new challenges for systems neuroscience. canonical correlation analysis (cca) is a prototypical family of methods that is useful in identifying the links between variable sets from different modalities. importantly, cca is well suited to describing relationships across multiple sets of data and so is well suited to the analysis of big neuroscience datasets. our primer discusses the rationale, promises, and pitfalls of cca.","['canonical correlation analysis', 'dimensional haystack', 'neuroscientists', 'needle', 'high', 'finding']"
"transcriptomics data are relevant to address a number of challenges in toxicogenomics (tgx). after careful planning of exposure conditions and data preprocessing, the tgx data can be used in predictive toxicology, where more advanced modelling techniques are applied. the large volume of molecular profiles produced by omics-based technologies allows the development and application of artificial intelligence (ai) methods in tgx. indeed, the publicly available omics datasets are constantly increasing together with a plethora of different methods that are made available to facilitate their analysis, interpretation and the generation of accurate and stable predictive models. in this review, we present the state-of-the-art of data modelling applied to transcriptomics data in tgx. we show how the benchmark dose (bmd) analysis can be applied to tgx data. we review read across and adverse outcome pathways (aop) modelling methodologies. we discuss how network-based approaches can be successfully employed to clarify the mechanism of action (moa) or specific biomarkers of exposure. we also describe the main ai methodologies applied to tgx data to create predictive classification and regression models and we address current challenges. finally, we present a short description of deep learning (dl) and data integration methodologies applied in these contexts. modelling of tgx data represents a valuable tool for more accurate chemical safety assessment. this review is the third part of a three-article series on transcriptomics in toxicogenomics.","['risk assessment', 'part iii', 'data modelling', 'transcriptomics', 'toxicogenomics']"
"protein structure determination has long been one of the most challenging problems in molecular biology for the past 60\u2009years. here we present an ab initio protein tertiary-structure prediction method assisted by predicted contact maps from spot-contact and predicted dihedral angles from spider 3. these predicted properties were then fed to the crystallography and nmr system (cns) for restrained structure modeling. the resulted structures are first evaluated by the potential energy calculated by cns, followed by ddfire energy function for model selections. the method called spot-fold has been tested on 241 casp targets between 67 and 670 amino acid residues, 60 randomly selected globular proteins under 100 amino acids. the method has a comparable accuracy to other contact-map-based modeling techniques.","['free protein structure prediction guided', 'predicted backbone structure', 'contact map', 'spot', 'fragment', 'fold']"
"brain age prediction based on imaging data and machine learning (ml) methods has great potential to provide insights into the development of cognition and mental disorders. though different ml models have been proposed, a systematic comparison of ml models in combination with imaging features derived from different modalities is still needed. in this study, we evaluate the prediction performance of 36 combinations of imaging features and ml models including deep learning. we utilize single and multimodal brain imaging data including mri, dti, and rs-fmri from a large data set with 839 subjects. our study is a follow-up to the initial work (liang et al., 2019. human brain mapping) to investigate different analytic strategies to combine data from mri, dti, and rs-fmri with the goal to improve brain age prediction accuracy. additionally, the traditional approach to predicting the brain age gap has been shown to have a systematic bias. the potential nonlinear relationship between the brain age gap and chronological age has not been thoroughly tested. here we propose a new method to correct the systematic bias of brain age gap by taking gender, chronological age, and their interactions into consideration. as the true brain age is unknown and may deviate from chronological age, we further examine whether various levels of behavioral performance across subjects predict their brain age estimated from neuroimaging data. this is an important step to quantify the practical implication of brain age prediction. our findings are helpful to advance the practice of optimizing different analytic methodologies in brain age prediction.","['brain age using multimodal neuroimaging data', 'improved prediction']"
"backgroundaccurate segmentation of brain tumor depicting on magnetic resonance imaging (mri) is an important step for doctors to determine optimal treatment plan of gliomas, which are the common malignant brain tumors that seriously damage patients' health and life.objectthis study aims to improve accuracy and efficiency of brain tumor segmentation on mri using the advanced deep learning model.methodin this study, an improved model based on the u-net for accurate segmentation of brain tumor mri images, called deeper resu-net, is proposed. first, a deep deeper u-net is built, which has deeper network depth compared with u-net, uses squeeze operator to control network parameters and attempts to enhance the feature extraction ability. then, deeper resu-net is formed to eliminate degradation phenomenon of the deep network, in which residual unit is designed and integrated into the deeper u-net to keep the number of parameters unchanged.resultdeeper resu-net makes the deep network conduct stable training without degrading. evaluation result shows that the deeper resu-net has achieved competitive result with average dsc metrics of 0.9, 0.82, 0.88 for complete tumor region, core tumor region and enhanced tumor region, respectively.conclusionby extending the u-net model to a deeper layer and adding the residual structure to ensure effective and stable training of the model, the experiment results demonstrate that applying the improved deeper resu-net can effectively eliminate the degradation phenomenon of deep network and improve segmentation performance.","['improving brain tumor segmentation', 'residual units', 'mri based', 'deep u', 'net']"
"prostate cancer (pca) is a major health concern in aging males, and proper management of the disease depends on accurately interpreting pathology specimens. however, reading prostatectomy histopathology slides, which is basically for staging, is usually time consuming and differs from reading small biopsy specimens, which is mainly used for diagnosis. generally, each prostatectomy specimen generates tens of large tissue sections and for each section, the malignant region needs to be delineated to assess the amount of tumor and its burden. with the aim of reducing the workload of pathologists, in this study, we focus on developing a computer-aided diagnosis (cad) system based on a densely connected convolutional neural network (densenet) for whole-slide histopathology images to outline the malignant regions.","['slide prostate histopathology image using spatial statistics', 'aided diagnosis system', 'multidimensional densenet', 'malignant regions', 'whole', 'differentiation', 'delineation', 'computer']"
"learning a powerful representation for a class with few labeled samples is a challenging problem. although some state-of-the-art few-shot learning algorithms perform well based on meta-learning, they only focus on novel network architecture and fail to take advantage of the knowledge of every classification task. in this paper, to accomplish this goal, it proposes to combine the channel attention and spatial attention module (c-sam), the c-sam can mine deeply more effective information using samples of different classes that exist in different tasks. the residual network is used to alleviate the loss of the underlying semantic information when the network is deeper. finally, a relation network including a c-sam is applied to act as a classifier, which avoids learning more redundant information and compares the relation between difference samples. the experiment was carried out using the proposed method on six datasets, such as miniimagenet, omniglot, caltech-ucsd birds, describable textures dataset, stanford dogs and stanford cars. the experimental results show that the c-sam outperforms many state-of-the-art few-shot classification methods.","['spatial attention network', 'fewshot classification', 'channel']"
"to train deep learning models to differentiate benign and malignant breast tumors in ultrasound images, we need to collect many training samples with clear labels. in general, biopsy results can be used as benign/malignant labels. however, most clinical samples generally do not have biopsy results. previous works have proposed generating benign/malignant labels according to breast imaging, reporting and data system (bi-rads) ratings. however, this approach will cause noisy labels, which means that the benign/malignant labels produced from bi-rads diagnoses may be inconsistent with the ground truths. consequently, deep models will overfit the noisy labels and hence obtain poor generalization performance. in this work, we mainly focus on how to reduce the negative effect of noisy labels when they are used to train breast tumor classification models.","['noisy labeled ultrasound images', 'breast tumor classification', 'learning']"
"recent advances in artificial intelligence along with the development of large data sets of energies calculated using quantum mechanical (qm)/density functional theory (dft) methods have enabled prediction of accurate molecular energies at reasonably low computational cost. however, machine learning models that have been reported so far require the atomic positions obtained from geometry optimizations using high-level qm/dft methods as input in order to predict the energies and do not allow for geometry optimization. in this study, a transferable and molecule size-independent machine learning model bonds (b), angles (a), nonbonded (n) interactions, and dihedrals (d) neural network (band nn) based on a chemically intuitive representation inspired by molecular mechanics force fields is presented. the model predicts the atomization energies of equilibrium and nonequilibrium structures as sum of energy contributions from bonds (b), angles (a), nonbonds (n), and dihedrals (d) at remarkable accuracy. the robustness of the proposed model is further validated by calculations that span over the conformational, configurational, and reaction space. the transferability of this model on systems larger than the ones in the data set is demonstrated by performing calculations on selected large molecules. importantly, employing the band nn model, it is possible to perform geometry optimizations starting from nonequilibrium structures along with predicting their energies.","['organic small molecules', 'deep learning framework', 'geometry optimization', 'energy prediction', 'band nn']"
"to improve image quality and ct number accuracy of fast-scan low-dose cone-beam computed tomography (cbct) through a deep-learning convolutional neural network (cnn) methodology for head-and-neck (hn) radiotherapy. fifty-five paired cbct and ct images from hn patients were retrospectively analysed. among them, 15 patients underwent adaptive replanning during treatment, thus had same-day ct/cbct pairs. the remaining 40 patients (post-operative) had paired planning ct and 1st fraction cbct images with minimal anatomic changes. a 2d u-net architecture with 27-layers in 5 depths was built for the cnn. cnn training was performed using data from 40 post-operative hn patients with 2080 paired ct/cbct slices. validation and test datasets include 5 same-day datasets with 260 slice pairs and 10 same-day datasets with 520 slice pairs, respectively. to examine the impact of differences in training dataset selection and network performance as a function of training data size, additional networks were trained using 30, 40 and 50 datasets. image quality of enhanced cbct images were quantitatively compared against the ct image using mean absolute error (mae) of hounsfield units (hu), signal-to-noise ratio (snr) and structural similarity (ssim). enhanced cbct images reduced artifact distortion and improved soft tissue contrast. networks trained with 40 datasets had imaging performance comparable to those trained with 50 datasets and outperformed those trained with 30 datasets. comparison of cbct and enhanced cbct images demonstrated improvement in average mae from 172.73 to 49.28 hu, snr from 8.27 to 14.25 db, and ssim from 0.42 to 0.85. the image processing time is 2\u2009s per patient using a nvidia geforce gtx 1080 ti gpu. the proposed deep-leaning methodology was fast and effective for image quality enhancement of fast-scan low-dose cbct. this method has potential to support fast online-adaptive re-planning for hn cancer patients.","['convolutional neural network enhancement', 'beam ct images', 'scan low', 'neck radiotherapy', 'dose cone', 'head', 'fast']"
"deconvolution is the most commonly used image processing method in optical imaging systems to remove the blur caused by the point-spread function (psf). while this method has been successful in deblurring, it suffers from several disadvantages, such as slow processing time due to multiple iterations required to deblur and suboptimal in cases where the experimental operator chosen to represent psf is not optimal. in this paper, we present a deep-learning-based deblurring method that is fast and applicable to optical microscopic imaging systems. we tested the robustness of proposed deblurring method on the publicly available data, simulated data and experimental data (including 2d optical microscopic data and 3d photoacoustic microscopic data), which all showed much improved deblurred results compared to deconvolution. we compared our results against several existing deconvolution methods. our results are better than conventional techniques and do not require multiple iterations or pre-determined experimental operator. our method has several advantages including simple operation, short time to compute, good deblur results and wide application in all types of optical microscopic imaging systems. the deep learning approach opens up a new path for deblurring and can be applied in various biomedical imaging fields.","['new deep learning method', 'optical microscopic systems', 'image deblurring']"
"our previous study has constructed a deep learning model for predicting gastrointestinal infection morbidity based on environmental pollutant indicators in some regions in central china. this article aims to adapt the prediction model for three purposes: 1) predicting the morbidity of a different disease in the same region; 2) predicting the morbidity of the same disease in a different region; and 3) predicting the morbidity of a different disease in a different region. we propose a tridirectional transfer learning approach, which achieves the abovementioned three purposes by: 1) developing a combined univariate regression and multivariate gaussian model for establishing the relationship between the morbidity of the target disease and that of the source disease together with the high-level pollutant features in the current source region; 2) using mapping-based deep transfer learning to extend the current model to predict the morbidity of the source disease in both source and target regions; and 3) applying the pattern of the combined model in the source region to the extended model to derive a new combined model for predicting the morbidity of the target disease in the target region. we select gastric cancer as the target disease and use the proposed transfer learning approach to predict its morbidity in the source region and three target regions. the results show that, given only a limited number of labeled samples, our approach achieves an average prediction accuracy of over 80% in the source region and up to 78% in the target regions, which can contribute considerably to improving medical preparedness and response.","['predicting gastric cancer morbidity', 'tridirectional transfer learning']"
"video inpainting aims to fill in spatio-temporal holes in videos with plausible content. despite tremendous progress on deep learning-based inpainting of a single image, it is still challenging to extend these methods to video domain due to the additional time dimension. in this paper, we propose a recurrent temporal aggregation framework for fast deep video inpainting. in particular, we construct an encoder-decoder model, where the encoder takes multiple reference frames which can provide visible pixels revealed from the scene dynamics. these hints are aggregated and fed into the decoder. we apply a recurrent feedback in an auto-regressive manner to enforce temporal consistency in the video results. we propose two architectural designs based on this framework. our first model is a blind video decaptioning network (bvdnet) that is designed to automatically remove and inpaint text overlays in videos without any mask information. our bvdnet wins the first place in the eccv chalearn 2018 lap inpainting competition track 2: video decaptioning. second, we propose a network for more general video inpainting (vinet) to deal with more arbitrary and larger holes. video results demonstrate the advantage of our framework compared to state-of-the-art methods both qualitatively and quantitatively. the codes are available at https://github.com/mcahny/deep-video-inpainting, and https://github.com/shwoo93/video_decaptioning.","['recurrent temporal aggregation framework', 'deep video inpainting']"
the purpose of this study is to evaluate the performance of a novel deep learning (dl) tool for fully automated measurements of the sagittal spinopelvic balance from x-ray images of the spine in comparison with manual measurements.,"['sagittal spinopelvic balance', 'fully automated measurements', 'deep learning tool', 'ray images', 'performance evaluation', 'x']"
"we propose a deep learning-based image interpretation system for skeleton segmentation and extraction of hot spots of bone metastatic lesion from a whole-body bone scintigram followed by automated measurement of a bone scan index (bsi), which will be clinically useful.","['bone scan index', 'body bone scintigram', 'automated measurement', 'whole']"
"ki-67 is one of the most important biomarkers of breast cancer traditionally measured invasively via immunohistochemistry. in this study, deep learning based radiomics models were established for preoperative prediction of ki-67 status using multiparametric magnetic resonance imaging (mp-mri).","['multiparametric mri using transfer learning', 'preoperative prediction', 'breast cancer', '67 status', 'ki']"
"the global healthcare landscape is continuously changing throughout the world as technology advances, leading to a gradual change in lifestyle. several diseases such as asthma and cardiovascular conditions are becoming more diffuse, due to a rise in pollution exposure and a more sedentary lifestyle. healthcare providers deal with increasing new challenges, and thanks to fast-developing big data technologies, they can be faced with systems that provide direct support to citizens. in this context, within the eu-funded participatory urban living for sustainable environments (pulse) project, we are implementing a data analytic platform designed to provide public health decision makers with advanced approaches, to jointly analyze maps and geospatial information with healthcare and air pollution data. in this paper we describe a component of such platforms, which couples deep learning analysis of urban geospatial images with healthcare indexes collected by the 500 cities project. by applying a pre-learned deep neural network architecture, satellite images of new york city are analyzed and latent feature variables are extracted. these features are used to derive clusters, which are correlated with healthcare indicators by means of a multivariate classification model. thanks to this pipeline, it is possible to show that, in new york city, health care indexes are significantly correlated to the urban landscape. this pipeline can serve as a basis to ease urban planning, since the same interventions can be organized on similar areas, even if geographically distant.","['urban landscape', 'unveil correlations', 'population health', 'deep learning']"
"infertility and subfertility affect a significant proportion of humanity. assisted reproductive technology has been proven capable of alleviating infertility issues. in vitro fertilisation is one such option whose success is highly dependent on the selection of a high-quality embryo for transfer. this is typically done manually by analysing embryos under a microscope. however, evidence has shown that the success rate of manual selection remains low. the use of new incubators with integrated time-lapse imaging system is providing new possibilities for embryo assessment. as such, we address this problem by proposing an approach based on deep learning for automated embryo quality evaluation through the analysis of time-lapse images. automatic embryo detection is complicated by the topological changes of a tracked object. moreover, the algorithm should process a large number of image files of different qualities in a reasonable amount of time.","['stage human embryo development detection', 'towards', 'early', 'automation']"
an amendment to this paper has been published and can be accessed via a link at the top of the paper.,"['optical coherence tomography images using deep learning', 'automatic choroid layer segmentation', 'publisher correction']"
"we argue that natural language can be usefully described as quasi-compositional and we suggest that deep learning-based neural language models bear long-term promise to capture how language conveys meaning. we also note that a successful account of human language processing should explain both the outcome of the comprehension process and the continuous internal processes underlying this performance. these points motivate our discussion of a neural network model of sentence comprehension, the sentence gestalt model, which we have used to account for the n400 component of the event-related brain potential (erp), which tracks meaning processing as it happens in real time. the model, which shares features with recent deep learning-based language models, simulates n400 amplitude as the automatic update of a probabilistic representation of the situation or event described by the sentence, corresponding to a temporal difference learning signal at the level of meaning. we suggest that this process happens relatively automatically, and that sometimes a more-controlled attention-dependent process is necessary for successful comprehension, which may be reflected in the subsequent p600 erp component. we relate this account to current deep learning models as well as classic linguistic theory, and use it to illustrate a domain general perspective on some specific linguistic operations postulated based on compositional analyses of natural language. this article is part of the theme issue 'towards mechanistic models of meaning composition'.","['human language comprehension', 'capturing neural responses', 'neural network', 'compositional mapping', 'based approach', 'quasi', 'meaning', 'form']"
"stochastic gradient descent (sgd) is a popular and efficient method with wide applications in training deep neural nets and other nonconvex models. while the behavior of sgd is well understood in the convex learning setting, the existing theoretical results for sgd applied to nonconvex objective functions are far from mature. for example, existing results require to impose a nontrivial assumption on the uniform boundedness of gradients for all iterates encountered in the learning process, which is hard to verify in practical implementations. in this article, we establish a rigorous theoretical foundation for sgd in nonconvex learning by showing that this boundedness assumption can be removed without affecting convergence rates, and relaxing the standard smoothness assumption to hölder continuity of gradients. in particular, we establish sufficient conditions for almost sure convergence as well as optimal convergence rates for sgd applied to both general nonconvex and gradient-dominated objective functions. a linear convergence is further derived in the case with zero variances.","['nonconvex learning without bounded gradient assumptions', 'stochastic gradient descent']"
"images/videos captured from outdoor visual devices are usually degraded by turbid media, such as haze, smoke, fog, rain, and snow. haze is the most common one in outdoor scenes due to the atmosphere conditions. in this paper, a novel deep learning-based architecture (denoted by msrl-dehazenet) for single image haze removal relying on multi-scale residual learning (msrl) and image decomposition is proposed. instead of learning an end-to-end mapping between each pair of hazy image and its corresponding haze-free one adopted by most existing learningbased approaches, we reformulate the problem as restoration of the image base component. based on the decomposition of a hazy image into the base and the detail components, haze removal (or dehazing) can be achieved by both of our multi-scale deep residual learning and our simplified u-net learning only for mapping between hazy and haze-free base components, while the detail component is further enhanced via the other learned convolutional neural network (cnn). moreover, benefited by the basic building block of our deep residual cnn architecture and our simplified unet structure, the feature maps (produced by extracting structural and statistical features), and each previous layer can be fully preserved and fed into the next layer. therefore, possible color distortion in the recovered image would be avoided. as a result, the final haze-removed (or dehazed) image is obtained by integrating the haze-removed base and the enhanced detail image components. experimental results have demonstrated good effectiveness of the proposed framework, compared with state-ofthe-art approaches.","['based single image haze removal via image decomposition', 'scale deep residual learning', 'multi']"
"reliable detection of disseminated tumor cells and of the biodistribution of tumor-targeting therapeutic antibodies within the entire body has long been needed to better understand and treat cancer metastasis. here, we developed an integrated pipeline for automated quantification of cancer metastases and therapeutic antibody targeting, named deepmact. first, we enhanced the fluorescent signal of cancer cells more than 100-fold by applying the vdisco method to image metastasis in transparent mice. second, we developed deep learning algorithms for automated quantification of metastases with an accuracy matching human expert manual annotation. deep learning-based quantification in 5 different metastatic cancer models including breast, lung, and pancreatic cancer with distinct organotropisms allowed us to systematically analyze features such as size, shape, spatial distribution, and the degree to which metastases are targeted by a therapeutic monoclonal antibody in entire mice. deepmact can thus considerably improve the discovery of effective antibody-based therapeutics at the pre-clinical stage. video abstract.","['deep learning reveals cancer metastasis', 'therapeutic antibody targeting', 'entire body']"
to design a computational method for automatic brain glioma segmentation of multimodal mri scans with high efficiency and accuracy.,"['assembled deep learning segmentation', 'three', 'plane', 'gliomas']"
"mid-infrared laser absorption imaging of methane in flames is performed with a learning-based approach to the limited view-angle inversion problem. a deep neural network is trained with superimposed gaussian field distributions of spectral absorption coefficients, and the prediction capability is compared to linear tomography methods at a varying number of view angles for simulated fields representative of a flame pair. experimental 3d imaging is demonstrated on a methane-oxygen laminar flame doublet (${\\lt}\\text{cm}$<cm) backlit with tunable radiation from an interband cascade laser near 3.16 µm. spectrally resolved data at each pixel provide for species-specific projected absorbance. 2d images were collected at six projection angles on a high-speed infrared camera, yielding an aggregate of 27,648 unique lines of sight capturing the scene with a pixel resolution of $\\sim 70$∼70 µm. mole fraction measurements are inferred from the predicted absorption coefficient images using an estimated temperature field, showing consistency with expected values from reactant flow rates. to the authors' knowledge, this work represents the first 3d imaging of methane in a reacting flow.","['deep neural network inversion', '3d laser absorption imaging', 'reacting flows', 'methane']"
"automatic fruit detection is a very important benefit of harvesting robots. however, complicated environment conditions, such as illumination variation, branch, and leaf occlusion as well as tomato overlap, have made fruit detection very challenging. in this study, an improved tomato detection model called yolo-tomato is proposed for dealing with these problems, based on yolov3. a dense architecture is incorporated into yolov3 to facilitate the reuse of features and help to learn a more compact and accurate model. moreover, the model replaces the traditional rectangular bounding box (r-bbox) with a circular bounding box (c-bbox) for tomato localization. the new bounding boxes can then match the tomatoes more precisely, and thus improve the intersection-over-union (iou) calculation for the non-maximum suppression (nms). they also reduce prediction coordinates. an ablation study demonstrated the efficacy of these modifications. the yolo-tomato was compared to several state-of-the-art detection methods and it had the best detection performance.","['tomato detection based', 'robust algorithm', 'tomato', 'yolov3', 'yolo']"
"we present a case study for implementing a machine learning algorithm with an incremental value framework in the domain of lung cancer research. machine learning methods have often been shown to be competitive with prediction models in some domains; however, implementation of these methods is in early development. often these methods are only directly compared to existing methods; here we present a framework for assessing the value of a machine learning model by assessing the incremental value. we developed a machine learning model to identify and classify lung nodules and assessed the incremental value added to existing risk prediction models. multiple external datasets were used for validation. we found that our image model, trained on a dataset from the cancer imaging archive (tcia), improves upon existing models that are restricted to patient characteristics, but it was inconclusive about whether it improves on models that consider nodule features. another interesting finding is the variable performance on different datasets, suggesting population generalization with machine learning models may be more challenging than is often considered.","['lung nodule detection', 'incremental value', 'deep learning', 'quantifying', 'application']"
nonophthalmologist physicians do not confidently perform direct ophthalmoscopy. the use of artificial intelligence to detect papilledema and other optic-disk abnormalities from fundus photographs has not been well studied.,"['ocular fundus photographs', 'detect papilledema', 'artificial intelligence']"
"ultrasound molecular imaging (umi) is enabled by targeted microbubbles (mbs), which are highly reflective ultrasound contrast agents that bind to specific biomarkers. distinguishing between adherent mbs and background signals can be challenging in vivo. the preferred preclinical technique is differential targeted enhancement (dte), wherein a strong acoustic pulse is used to destroy mbs to verify their locations. however, dte intrinsically cannot be used for real-time imaging and may cause undesirable bioeffects. in this work, we propose a simple 4-layer convolutional neural network to nondestructively detect adherent mb signatures. we investigated several types of input data to the network: ""anatomy-mode"" (fundamental frequency)"", contrast-mode"" (pulse-inversion harmonic frequency), or both, i.e."", dual-mode"", using iq channel signals, the channel sum, or the channel sum magnitude. training and evaluation were performed on in vivo mouse tumor data and microvessel phantoms. the dual-mode channel signals yielded optimal performance, achieving a soft dice coefficient of 0.45 and auc of 0.91 in two test images. in a volumetric acquisition, the network best detected a breast cancer tumor, resulting in a generalized contrast-to-noise ratio (gcnr) of 0.93 and kolmogorov-smirnov statistic (kss) of 0.86, outperforming both regular contrast mode imaging (gcnr=0.76, kss=0.53) and dte imaging (gcnr=0.81, kss=0.62). further development of the methodology is necessary to distinguish free from adherent mbs. these results demonstrate that neural networks can be trained to detect targeted mbs with dte-like quality using nondestructive dual-mode data, and can be used to facilitate the safe and real-time translation of umi to clinical applications.","['time ultrasound molecular imaging', 'targeted microbubbles using dual', 'nondestructive detection', 'mode data', 'deep learning', 'real']"
"crash detection is essential in providing timely information to traffic management centers and the public to reduce its adverse effects. prediction of crash risk is vital for avoiding secondary crashes and safeguarding highway traffic. for many years, researchers have explored several techniques for early and precise detection of crashes to aid in traffic incident management. with recent advancements in data collection techniques, abundant real-time traffic data is available for use. big data infrastructure and machine learning algorithms can utilize this data to provide suitable solutions for the highway traffic safety system. this paper explores the feasibility of using deep learning models to detect crash occurrence and predict crash risk. volume, speed and sensor occupancy data collected from roadside radar sensors along interstate 235 in des moines, ia is used for this study. this real-world traffic data is used to design feature set for the deep learning models for crash detection and crash risk prediction. the results show that a deep model has better crash detection performance and similar crash prediction performance than state of the art shallow models. additionally, a sensitivity analysis was conducted for crash risk prediction using data 1-minute, 5-minutes and 10-minutes prior to crash occurrence. it was observed that is hard to predict the crash risk of a traffic condition, 10\u202fmin prior to a crash.","['risk estimation using deep learning', 'highway crash detection']"
"originally inspired by neurobiology, deep neural network models have become a powerful tool of machine learning and artificial intelligence. they can approximate functions and dynamics by learning from examples. here we give a brief introduction to neural network models and deep learning for biologists. we introduce feedforward and recurrent networks and explain the expressive power of this modeling framework and the backpropagation algorithm for setting the parameters. finally, we consider how deep neural network models might help us understand brain computation.","['neural network models', 'deep learning']"
"determining biomarkers for autism spectrum disorder (asd) is crucial to understanding its mechanisms. recently deep learning methods have achieved success in the classification task of asd using fmri data. however, due to the black-box nature of most deep learning models, it's hard to perform biomarker selection and interpret model decisions. the recently proposed invertible networks can accurately reconstruct the input from its output, and have the potential to unravel the black-box representation. therefore, we propose a novel method to classify asd and identify biomarkers for asd using the connectivity matrix calculated from fmri as the input. specifically, with invertible networks, we explicitly determine the decision boundary and the projection of data points onto the boundary. like linear classifiers, the difference between a point and its projection onto the decision boundary can be viewed as the explanation. we then define the importance as the explanation weighted by the gradient of prediction w.r.t the input, and identify biomarkers based on this importance measure. we perform a regression task to further validate our biomarker selection: compared to using all edges in the connectivity matrix, using the top 10% important edges we generate a lower regression error on 6 different severity scores. our experiments show that the invertible network is both effective at asd classification and interpretable, allowing for discovery of reliable biomarkers.","['invertible network', 'biomarker selection', 'classification', 'asd']"
"automated oscillometric blood pressure monitors are commonly used to measure blood pressure for many patients at home, office, and medical centers, and they have been actively studied recently. these devices usually provide a single blood pressure point and they are not able to indicate the uncertainty of the measured quantity. we propose a new technique using an ensemble-based recursive methodology to measure uncertainty for oscillometric blood pressure measurements. there are three stages we consider: the first stage is pre-learning to initialize good parameters using the bagging technique. in the second stage, we fine-tune the parameters using the ensemble-based recursive methodology that is used to accurately estimate blood pressure and then measure the uncertainty for the systolic blood pressure and diastolic blood pressure in the third stage.","['blood pressure measurement estimated using ensemble', 'based recursive methodology', 'uncertainty']"
"accurate identification of ligand-binding pockets in a protein is important for structure-based drug design. in recent years, several deep learning models were developed to learn important physical-chemical and spatial information to predict ligand-binding pockets in a protein. however, ranking the native ligand binding pockets from a pool of predicted pockets is still a hard task for computational molecular biologists using a single web-based tool. hence, we believe, by using closer to real application data set as training and by providing ligand information, an enhanced model to identify accurate pockets can be obtained. in this article, we propose a new deep learning method called deepbindpoc for identifying and ranking ligand-binding pockets in proteins. the model is built by using information about the binding pocket and associated ligand. we take advantage of the mol2vec tool to represent both the given ligand and pocket as vectors to construct a densely fully connected layer model. during the training, important features for pocket-ligand binding are automatically extracted and high-level information is preserved appropriately. deepbindpoc demonstrated a strong complementary advantage for the detection of native-like pockets when combined with traditional popular methods, such as fpocket and p2rank. the proposed method is extensively tested and validated with standard procedures on multiple datasets, including a dataset with g-protein coupled receptors. the systematic testing and validation of our method suggest that deepbindpoc is a valuable tool to rank near-native pockets for theoretically modeled protein with unknown experimental active site but have known ligand. the deepbindpoc model described in this article is available at github (https://github.com/haiping1010/deepbindpoc) and the webserver is available at (http://cbblab.siat.ac.cn/deepbindpoc/index.php).","['rank ligand binding pockets using molecular vector representation', 'deep learning method', 'deepbindpoc']"
"annotation of protein functions plays an important role in understanding life at the molecular level. high-throughput sequencing produces massive numbers of raw proteins sequences and only about 1% of them have been manually annotated with functions. experimental annotations of functions are expensive, time-consuming and do not keep up with the rapid growth of the sequence numbers. this motivates the development of computational approaches that predict protein functions. a novel deep learning framework, deepfunc, is proposed which accurately predicts protein functions from protein sequence- and network-derived information. more precisely, deepfunc uses a long and sparse binary vector to encode information concerning domains, families, and motifs collected from the interpro tool that is associated with the input protein sequence. this vector is processed with two neural layers to obtain a low-dimensional vector which is combined with topological information extracted from protein-protein interactions (ppis) and functional linkages. the combined information is processed by a deep neural network that predicts protein functions. deepfunc is empirically and comparatively tested on a benchmark testing dataset and the critical assessment of protein function annotation algorithms (cafa) 3 dataset. the experimental results demonstrate that deepfunc outperforms current methods on the testing dataset and that it secures the highest fmax \xa0=\xa00.54 and auc\xa0=\xa00.94 on the cafa3 dataset.","['deep learning framework', 'protein sequences', 'protein functions', 'accurate prediction', 'interactions', 'deepfunc']"
"gliomas are the most common primary tumor of the brain and are classified into grades i-iv of the world health organization (who), based on their invasively histological appearance. gliomas grading plays an important role to determine the treatment plan and prognosis prediction. in this study we propose two novel methods for automatic, non-invasively distinguishing low-grade (grades ii and iii) glioma (lgg) and high-grade (grade iv) glioma (hgg) on conventional mri images by using deep convolutional neural networks (cnns).","['conventional mri images using deep convolutional neural networks', 'automated glioma grading']"
"deep learning has recently gained popularity in digital pathology due to its high prediction quality. however, the medical domain requires explanation and insight for a better understanding beyond standard quantitative performance evaluation. recently, many explanation methods have emerged. this work shows how heatmaps generated by these explanation methods allow to resolve common challenges encountered in deep learning-based digital histopathology analyses. we elaborate on biases which are typically inherent in histopathological image data. in the binary classification task of tumour tissue discrimination in publicly available haematoxylin-eosin-stained images of various tumour entities, we investigate three types of biases: (1) biases which affect the entire dataset, (2) biases which are by chance correlated with class labels and (3) sampling biases. while standard analyses focus on patch-level evaluation, we advocate pixel-wise heatmaps, which offer a more precise and versatile diagnostic instrument. this insight is shown to not only be helpful to detect but also to remove the effects of common hidden biases, which improves generalisation within and across datasets. for example, we could see a trend of improved area under the receiver operating characteristic (roc) curve by 5% when reducing a labelling bias. explanation techniques are thus demonstrated to be a helpful and highly relevant tool for the development and the deployment phases within the life cycle of real-world applications in digital pathology.","['histopathological images using explanation methods', 'resolving challenges', 'deep learning', 'based analyses']"
"in this study, we propose a novel anomaly detection model targeting subtle brain lesions in multiparametric mri. to compensate for the lack of annotated data adequately sampling the heterogeneity of such pathologies, we cast this problem as an outlier detection problem and introduce a novel configuration of unsupervised deep siamese networks to learn normal brain representations using a series of non-pathological brain scans. the proposed siamese network, composed of stacked convolutional autoencoders as subnetworks is designed to map patches extracted from healthy control scans only and centered at the same spatial localization to 'close' representations with respect to the chosen metric in a latent space. it is based on a novel loss function combining a similarity term and a regularization term compensating for the lack of dissimilar pairs. these latent representations are then fed into oc-svm models at voxel-level to produce anomaly score maps. we evaluate the performance of our brain anomaly detection model to detect subtle epilepsy lesions in multiparametric (t1-weighted, flair) mri exams considered as normal (mri-negative). our detection model trained on 75 healthy subjects and validated on 21 epilepsy patients (with 18 mri-negatives) achieves a maximum sensitivity of 61% on the mri-negative lesions, identified among the 5 most suspicious detections on average. it is shown to outperform detection models based on the same architecture but with stacked convolutional or wasserstein autoencoders as unsupervised feature extraction mechanisms.","['brain multiparametric magnetic resonance imaging', 'regularized siamese neural network', 'unsupervised outlier detection', 'epilepsy lesion screening', 'application']"
"despite the lack of invariance problem (the many-to-many mapping between acoustics and percepts), human listeners experience phonetic constancy and typically perceive what a speaker intends. most models of human speech recognition (hsr) have side-stepped this problem, working with abstract, idealized inputs and deferring the challenge of working with real speech. in contrast, carefully engineered deep learning networks allow robust, real-world automatic speech recognition (asr). however, the complexities of deep learning architectures and training regimens make it difficult to use them to provide direct insights into mechanisms that may support hsr. in this brief article, we report preliminary results from a two-layer network that borrows one element from asr, long short-term memory nodes, which provide dynamic memory for a range of temporal spans. this allows the model to learn to map real speech from multiple talkers to semantic targets with high accuracy, with human-like timecourse of lexical access and phonological competition. internal representations emerge that resemble phonetically organized responses in human superior temporal gyrus, suggesting that the model develops a distributed phonological code despite no explicit training on phonetic or phonemic targets. the ability to work with real speech is a major advance for cognitive models of hsr.","['minimal neural network model', 'incremental human speech recognition', 'earshot']"
"segmentation of prostate in medical imaging data (e.g., ct, mri, trus) is often considered as a critical yet challenging task for radiotherapy treatment. it is relatively easier to segment prostate from mr images than from ct images, due to better soft tissue contrast of the mr images. for segmenting prostate from ct images, most previous methods mainly used ct alone, and thus their performances are often limited by low tissue contrast in the ct images. in this paper, we explore the possibility of using indirect guidance from mr images for improving prostate segmentation in the ct images. in particular, we propose a novel deep transfer learning approach, i.e., mr-guided ct network training (namely mics-net), which can employ mr images to help better learning of features in ct images for prostate segmentation. in mics-net, the guidance from mri consists of two steps: (1) learning informative and transferable features from mri and then transferring them to ct images in a cascade manner, and (2) adaptively transferring the prostate likelihood of mri model (i.e., well-trained convnet by purely using mr images) with a view consistency constraint. to illustrate the effectiveness of our approach, we evaluate mics-net on a real ct prostate image set, with the manual delineations available as the ground truth for evaluation. our methods generate promising segmentation results which achieve (1) six percentages higher dice ratio than the ct model purely using ct images and (2) comparable performance with the mri model purely using mr images.","['guided ct network training', 'ct images', 'segmenting prostate', 'effective mr']"
"anatomical examinations have been designed to assess topographical and/or applied knowledge of anatomy with or without the inclusion of visual resources such as cadaveric specimens or images, radiological images and/or clinical photographs. multimedia learning theories have advanced the understanding of how words and images are processed during learning. however, the evidence of the impact of including anatomical and radiological images within written assessments is sparse. this study investigates the impact of including images within clinically oriented single-best-answer questions on students' scores in a tailored online tool. second-year medical students (n = 174) from six schools in the united kingdom participated voluntarily in the examination, and 55 students provided free-text comments which were thematically analyzed. all questions were categorized as to whether their stimulus format was purely textual or included an associated image. the type (anatomical and radiological image) and deep structure of images (question referring to a bone or soft tissue on the image) were taken into consideration. students scored significantly better on questions with images compared to questions without images (p < 0.001), and on questions referring to bones than to soft tissue (p < 0.001) but no difference was found in their performance on anatomical and radiological image questions. the coding highlighted areas of the 'test applicability' and 'challenges faced by the students'. in conclusion, images are critical in medical practice for investigating a patient's anatomy, and this study sets out a way to understand the effects of images on students' performance and their views in commonly employed written assessments.","['applied anatomy knowledge', 'online assessment', 'medical students', 'performance', 'images', 'effect']"
"in industrial processes, inferential sensors have been extensively applied for prediction of quality variables that are difficult to measure online directly by hard sensors. deep learning is a recently developed technique for feature representation of complex data, which has great potentials in soft sensor modeling. however, it often needs a large number of representative data to train and obtain a good deep network. moreover, layer-wise pretraining often causes information loss and generalization degradation of high hidden layers. this greatly limits the implementation and application of deep learning networks in industrial processes. in this article, a layer-wise data augmentation (lwda) strategy is proposed for the pretraining of deep learning networks and soft sensor modeling. in particular, the lwda-based stacked autoencoder (lwda-sae) is developed in detail. finally, the proposed lwda-sae model is applied to predict the 10% and 50% boiling points of the aviation kerosene in an industrial hydrocracking process. the results show that the lwda-sae-based soft sensor is superior to multilayer perceptron, traditional sae, and the sae with data augmentation only for its input layer (ida-sae). moreover, lwda-sae can converge at a faster speed with a lower learning error than the other methods.","['wise data augmentation strategy', 'soft sensor application', 'industrial hydrocracking process', 'deep learning networks', 'layer']"
"this letter is devoted to the application of machine learning, namely, convolutional neural networks to solve problems in the initial steps of the common pipeline for data analysis in metabolomics. these steps are the peak detection and the peak integration in raw liquid chromatography-mass spectrometry (lc-ms) data. widely used algorithms suffer from rather poor precision for these tasks, yielding many false positive signals. in the present work, we developed an algorithm named peakonly, which has high flexibility for the detection or exclusion of low-intensity noisy peaks, and shows excellent quality in the detection of true positive peaks, approaching the highest possible precision. the current approach was developed for the analysis of high-resolution lc-ms data for the purposes of metabolomics, but potentially it can be applied with several adaptations in other fields, which utilize high-resolution gc- or lc-ms techniques. peakonly is freely available on github ( https://github.com/arseha/peakonly ) under an mit license.","['precise peak detection', 'resolution lc', 'ms data', 'deep learning', 'high']"
"with the advancement of high throughput techniques, the discovery rate of enzyme sequences has increased significantly in the recent past. all of these raw sequences are required to be precisely mapped to their respective functional attributes, which helps in deciphering their biological role. in the recent past, various prediction models have been proposed to predict the enzyme functional class; however, all of these models were able to quantify at most six functional enzyme classes (ec1 to ec6) out of existing seven functional classes, making these approaches inappropriate for handling enzymes corresponding to the seventh functional class (ec7). in this study, a deep neural network-based approach, deepn, has been proposed, which can quantify enzymes corresponding to all seven functional classes with high precision and accuracy. the proposed model was compared with two recently developed tools, ecpred and svm-prot. the result demonstrated that deepn outperformed ecpred and svm-prot in terms of predictive quality. the deepn tool has been hosted as a web-based tool at https://bioserver.iiita.ac.in/deepn/.communicated by ramaswamy h. sarma.","['deep neural network based tool', 'enzyme functional annotation', 'deepn']"
"plasticity theory aims at describing the yield loci and work hardening of a material under general deformation states. most of its complexity arises from the nontrivial dependence of the yield loci on the complete strain history of a material and its microstructure. this motivated 3 ingenious simplifications that underpinned a century of developments in this field: 1) yield criteria describing yield loci location; 2) associative or nonassociative flow rules defining the direction of plastic flow; and 3) effective stress-strain laws consistent with the plastic work equivalence principle. however, 2 key complications arise from these simplifications. first, finding equations that describe these 3 assumptions for materials with complex microstructures is not trivial. second, yield surface evolution needs to be traced iteratively, i.e., through a return mapping algorithm. here, we show that these assumptions are not needed in the context of sequence learning when using recurrent neural networks, diverting the above-mentioned complications. this work offers an alternative to currently established plasticity formulations by providing the foundations for finding history- and microstructure-dependent constitutive models through deep learning.","['deep learning predicts path', 'dependent plasticity']"
"issuing of correct prescriptions is a foundation of patient safety. medication errors represent one of the most important problems in health care, with 'look-alike and sound-alike' (lasa) being the lead error. existing solutions to prevent lasa still have their limitations. deep learning techniques have revolutionized identification classifiers in many fields. in search of better image-based solutions for blister package identification problem, this study using a baseline deep learning drug identification (dldi) aims to understand how identification confusion of look-alike images by human occurs through the cognitive counterpart of deep learning solutions and thereof to suggest further solutions to approach them.","['drug identification model developed using deep learning technologies', 'medical center', 'taiwan', 'experience']"
to quantitatively measure hyperreflective foci (hrf) during the progression of geographic atrophy (ga) secondary to age-related macular degeneration (amd) using deep learning (dl) and investigate the association with local and global growth of ga.,"['deep learning quantified hyperreflective foci', 'geographic atrophy progression', 'role', 'prediction']"
"drug label, or packaging insert play a significant role in all the operations from production through drug distribution channels to the end consumer. image of the label also called display panel or label could be used to identify illegal, illicit, unapproved and potentially dangerous drugs. due to the time-consuming process and high labor cost of investigation, an artificial intelligence-based deep learning model is necessary for fast and accurate identification of the drugs.","['drug label identification', 'deep learning approach', 'text embedding', 'image', 'dli']"
"in the last decade, deep learning techniques have further improved human activity recognition (har) performance on several benchmark datasets. this paper presents a novel framework to classify and analyze human activities. a new convolutional neural network (cnn) strategy is applied to a single user movement recognition using a smartphone. three parallel cnns are used for local feature extraction, and latter they are fused in the classification task stage. the whole cnn scheme is based on a feature fusion of a fine-cnn, a medium-cnn, and a coarse-cnn. a tri-axial accelerometer and a tri-axial gyroscope sensor embedded in a smartphone are used to record the acceleration and angle signals. six human activities successfully classified are walking, walking-upstairs, walking-downstairs, sitting, standing and laying. performance evaluation is presented for the proposed cnn.","['human activity recognition', 'fine convolutional deep', 'learning strategy', 'coarse']"
"one-class classification (occ) poses as an essential component in many machine learning and computer vision applications, including novelty, anomaly, and outlier detection systems. with a known definition for a target or normal set of data, one-class classifiers can determine if any given new sample spans within the distribution of the target class. solving for this task in a general setting is particularly very challenging, due to the high diversity of samples from the target class and the absence of any supervising signal over the novelty (nontarget) concept, which makes designing end-to-end models unattainable. in this article, we propose an adversarial training approach to detect out-of-distribution samples in an end-to-end trainable deep model. to this end, we jointly train two deep neural networks, r and d. the latter plays as the discriminator while the former, during training, helps d characterize a probability distribution for the target class by creating adversarial examples and, during testing, collaborates with it to detect novelties. using our occ, we first test outlier detection on two image data sets, modified national institute of standards and technology (mnist) and caltech-256. then, several experiments for video anomaly detection are performed on university of minnesota (umn) and university of california, san diego (ucsd) data sets. our proposed method can successfully learn the target class underlying distribution and outperforms other approaches.","['end one', 'deep end', 'class classifier']"
"brain monitors tracking quantitative brain activities from electroencephalogram (eeg) to predict hypnotic levels have been proposed as a labor-saving alternative to behavioral assessments. expensive clinical trials are required to validate any newly developed processed eeg monitor for every drug and combinations of drugs due to drug-specific eeg patterns. there is a need for an alternative, efficient, and economical method.","['sleep brain rhythms using deep learning', 'predicting deep hypnotic state', 'repurposing approach', 'data']"
"despite the proliferation of diverse teaching methods, it is uncertain which teaching components have enhanced students' approach to learning and in what way these components have produced positive outcomes.","['sectional design', 'multisite cross', 'facilitate students', 'educators could', 'deep approach', 'use', 'learning']"
"orbital blow out fracture is a common disease in emergency department and a delay or failure in diagnosis can lead to permanent visual changes. this study aims to evaluate the ability of an automatic orbital blowout fractures detection system based on computed tomography (ct) data.orbital ct scans of adult orbital blowout fractures patients and normal cases were obtained from shanghai ninth people's hospital between january and march 2017. the region of fractures was annotated using 3d slicer. the inception v3 convolutional neural networks were constructed utilizing the python programming language with pytorch as the framework to extract high dimension features from each slice in a ct scan. these extracted features are processed through a xgboost model to make the final differentiation of fracture cases and nonfracture ones. accuracy, receiver operating characteristics, and area under the curve were evaluated.this study used 94 ct scans diagnosed with orbital blowout fractures and 94 healthy control cases. the automatic detection system showed accuracy of 92% in single-image classification and 87% in patient level detection. the area under the receiver operating characteristic curve was 0.9574.using a deep learning-based automatic detection system of orbital blowout fracture can accurately detect and classify orbital blowout fractures from ct scans. the convolutional neural networks model combined with an accurate annotation system could achieve good performance in a small dataset. further studies with large and multicenter data are required to refine this technology for possible clinical applications.","['deep convolutional neural networks', 'orbital blowout fractures', 'automatic detection']"
to develop and test a three-dimensional (3d) deep learning model for predicting 3d voxel-wise dose distributions for intensity-modulated radiotherapy (imrt).,"['using deep learning', 'dimensional dose distributions', 'rectal cancer', 'predict three', 'modulated radiotherapy', 'method', 'intensity']"
"small-animal imaging is an essential tool that provides noninvasive, longitudinal insight into novel cancer therapies. however, considerable variability in image analysis techniques can lead to inconsistent results. we have developed quantitative imaging for application in the preclinical arm of a coclinical trial by using a genetically engineered mouse model of soft tissue sarcoma. magnetic resonance imaging (mri) images were acquired 1 day before and 1 week after radiation therapy. after the second mri, the primary tumor was surgically removed by amputating the tumor-bearing hind limb, and mice were followed for up to 6\u2009months. an automatic analysis pipeline was used for multicontrast mri data using a convolutional neural network for tumor segmentation followed by radiomics analysis. we then calculated radiomics features for the tumor, the peritumoral area, and the 2 combined. the first radiomics analysis focused on features most indicative of radiation therapy effects; the second radiomics analysis looked for features that might predict primary tumor recurrence. the segmentation results indicated that dice scores were similar when using multicontrast versus single t2-weighted data (0.863 vs 0.861). one week post rt, larger tumor volumes were measured, and radiomics analysis showed greater heterogeneity. in the tumor and peritumoral area, radiomics features were predictive of primary tumor recurrence (auc: 0.79). we have created an image processing pipeline for high-throughput, reduced-bias segmentation of multiparametric tumor mri data and radiomics analysis, to better our understanding of preclinical imaging and the insights it provides when studying new cancer therapies.","['based deep learning segmentation', 'sarcoma', 'radiomics', 'mri', 'mice']"
"unmanned aerial vehicles (uavs) are being increasingly viewed as valuable tools to aid the management of farms. this kind of technology can be particularly useful in the context of extensive cattle farming, as production areas tend to be expansive and animals tend to be more loosely monitored. with the advent of deep learning, and convolutional neural networks (cnns) in particular, extracting relevant information from aerial images has become more effective. despite the technological advancements in drone, imaging and machine learning technologies, the application of uavs for cattle monitoring is far from being thoroughly studied, with many research gaps still remaining. in this context, the objectives of this study were threefold: (1) to determine the highest possible accuracy that could be achieved in the detection of animals of the canchim breed, which is visually similar to the nelore breed (bos taurus indicus); (2) to determine the ideal ground sample distance (gsd) for animal detection; (3) to determine the most accurate cnn architecture for this specific problem. the experiments involved 1853 images containing 8629 samples of animals, and 15 different cnn architectures were tested. a total of 900 models were trained (15 cnn architectures × 3 spacial resolutions × 2 datasets × 10-fold cross validation), allowing for a deep analysis of the several aspects that impact the detection of cattle using aerial images captured using uavs. results revealed that many cnn architectures are robust enough to reliably detect animals in aerial images even under far from ideal conditions, indicating the viability of using uavs for cattle monitoring.","['uav images using deep learning', 'study', 'detection', 'cattle']"
"in this paper, we describe our method for the isic 2019 skin lesion classification challenge. the challenge comes with two tasks. for task 1, skin lesions have to be classified based on dermoscopic images. for task 2, dermoscopic images and additional patient meta data are used. our deep learning-based method achieved first place for both tasks. the are several problems we address with our method. first, there is an unknown class in the test set which we cover with a data-driven approach. second, there is a severe class imbalance that we address with loss balancing. third, there are images with different resolutions which motivates two different cropping strategies and multi-crop evaluation. last, there is patient meta data available which we incorporate with a dense neural network branch. • we address skin lesion classification with an ensemble of deep learning models including efficientnets, senet, and resnext wsl, selected by a search strategy. • we rely on multiple model input resolutions and employ two cropping strategies for training. we counter severe class imbalance with a loss balancing approach. • we predict an additional, unknown class with a data-driven approach and we make use of patient meta data with an additional input branch.","['skin lesion classification using ensembles', 'resolution efficientnets', 'meta data', 'multi']"
"humans perceive physical properties such as motion and elastic force by observing objects in visual scenes. recent research has proven that computers are capable of inferring physical properties from camera images like humans. however, few studies perceive the physical properties in more complex environment, i.e. humans have difficulty estimating physical quantities directly from the visual observation, or encounter difficulty visualizing the physical process in mind according to their daily experiences. as an appropriate example, fractional flow reserve (ffr), which measures the blood pressure difference across the vessel stenosis, becomes an important physical quantitative value determining the likelihood of myocardial ischemia in clinical coronary intervention procedure. in this study, we propose a novel deep neural network solution (treeves-net) that allows machines to perceive ffr values directly from static coronary ct angiography images. our framework fully utilizes a tree-structured recurrent neural network (rnn) with a coronary representation encoder. the encoder captures coronary geometric information providing the blood fluid-related representation. the tree-structured rnn builds a long-distance spatial dependency of blood flow information inside the coronary tree. the experiments performed on 13000 synthetic coronary trees and 180 real coronary trees from clinical patients show that the values of the area under roc curve (auc) are 0.92 and 0.93 under two clinical criterions. these results can demonstrate the effectiveness of our framework and its superiority to seven ffr computation methods based on machine learning.","['static ct angiography imaging', 'perceiving blood flow dynamics', 'learning physical properties', 'complex visual scenes', 'intelligent machine']"
"superpixel segmentation is a fundamental computer vision technique that finds application in a multitude of high level computer vision tasks. most state-of-the-art superpixel segmentation methods are unsupervised in nature and thus cannot fully utilize frequently occurring texture patterns or incorporate multiscale context. in this paper, we show that superpixel segmentation can be improved by leveraging the superior modeling power of deep convolutional autoencoders in a fully unsupervised manner. we pose the superpixel segmentation problem as one of manifold learning where pixels that belong to similar texture patterns are assigned near identical embedding vectors. the proposed deep network is able to learn image-wide and dataset-wide feature patterns and the relationships between them. this knowledge is used to segment and group pixels in a way that is consistent with a more global definition of pattern coherence. experiments demonstrate that the superpixels obtained from the embeddings learned by the proposed method outperform the state-of-theart superpixel segmentation methods for boundary precision and recall values. additionally, we find that semantic edges obtained from the superpixel embeddings to be significantly better than the contemporary unsupervised approaches.",['superpixel embedding network']
to develop a deep learning-based bayesian estimation for mri reconstruction.,['mri reconstruction using deep bayesian estimation']
"background most risk prediction models for breast cancer are based on questionnaires and mammographic density assessments. by training a deep neural network, further information in the mammographic images can be considered. purpose to develop a risk score that is associated with future breast cancer and compare it with density-based models. materials and methods in this retrospective study, all women aged 40-74 years within the karolinska university hospital uptake area in whom breast cancer was diagnosed in 2013-2014 were included along with healthy control subjects. network development was based on cases diagnosed from 2008 to 2012. the deep learning (dl) risk score, dense area, and percentage density were calculated for the earliest available digital mammographic examination for each woman. logistic regression models were fitted to determine the association with subsequent breast cancer. false-negative rates were obtained for the dl risk score, age-adjusted dense area, and age-adjusted percentage density. results a total of 2283 women, 278 of whom were later diagnosed with breast cancer, were evaluated. the age at mammography (mean, 55.7 years vs 54.6 years; p < .001), the dense area (mean, 38.2 cm2 vs 34.2 cm2; p < .001), and the percentage density (mean, 25.6% vs 24.0%; p < .001) were higher among women diagnosed with breast cancer than in those without a breast cancer diagnosis. the odds ratios and areas under the receiver operating characteristic curve (aucs) were higher for age-adjusted dl risk score than for dense area and percentage density: 1.56 (95% confidence interval [c","['auc', '64', '6', '48', '1', '0']"
"in the present study, a new methodology is proposed for recognition of emotional state mediated by affective video film clips. principal component analysis (pca) is applied to full-band specific phase space trajectory matrix extracted from short emotional eeg segment of 6 s, then the first principal component is used as emotional feature in terms of neuro-cortical complexity levels in discriminating nine discrete emotions (fear, anger, happiness, sadness, amusement, surprise, excitement, calmness, disgust) from baseline through convolutional neural networks (cnns). in tests, the performance of cnns is compared to another deep learning application called long-short term memory networks and support vector machine classifiers with different kernels as well as naive bayes classifier. in applications, two concepts (gender classification and emotion classification) have been considered with respect to both instants (single feature extracted from single epoch) and subjects (large number of features extracted from single subject in an emotional state). the resulting performance of the proposed method has also been examined for longer segment statement of 12 s. experimental data was downloaded from an internationally publicly available dataset called dreamer. the results show that healthy young females differ from males in amusement such that the difference becomes higher when subject classification is performed. regarding the combined features extracted from females and males, the other emotional states are clearly discriminated from baseline with considerably high accuracy levels by using cnns in both instant and subject classification manners. the results reveal that emotion formation is mostly influenced by individual experiences rather than gender. in detail, local neuronal complexity is mostly sensitive to the affective valance rating. pca can be proposed as secondary process on phase domain eeg space in order to obtain useful emotional features. cnn provides high performance for emotion recognition.","['emotional phase domain complexity levels induced', 'affective video film clips', 'deep learning classification', 'neuro']"
"white matter hyperintensities (wmhs) of presumed vascular origin are frequently observed in magnetic resonance images (mris) of the elderly. detection and quantification of wmhs is important to help doctors make diagnoses and evaluate prognosis of their elderly patients, and once quantified, these can act as biomarkers in clinical research studies. manual delineation of wmhs can be both time-consuming and inconsistent, hence, automatic segmentation methods are often preferred. however, fully automatic methods can be challenging to construct due to the variability in lesion load, placement of lesions, and voxel intensities. several state-of-the-art lesion segmentation methods based on supervised convolutional neural networks (cnns) have been proposed. these approaches require manually delineated lesions for training the parameters of the network. here we present a novel approach for wmh segmentation using a cnn trained in an unsupervised manner, by reconstructing multiple mri sequences as weighted sums of segmentations of wmhs and tissues present in the images. after training, our method can be used to segment new images that are not part of the training set to provide fast and robust segmentation of wmhs in a matter of seconds per subject. comparisons with state-of-the-art wmh segmentation methods evaluated on ground truth manual labels from two distinct data sets and six different scanners indicate that the proposed method works well at generating accurate wmh segmentations without the need for manual delineations.","['unsupervised white matter lesion segmentation', 'brain mris using', 'cnn autoencoder', 'segae']"
"electronic health records (ehrs) provide possibilities to improve patient care and facilitate clinical research. however, there are many challenges faced by the applications of ehrs, such as temporality, high dimensionality, sparseness, noise, random error and systematic bias. in particular, temporal information is difficult to effectively use by traditional machine learning methods while the sequential information of ehrs is very useful.","['clinical time series prediction tasks', 'electronic health records', 'representation learning']"
"the difficulty of obtaining annotations to build training databases still slows down the adoption of recent deep learning approaches for biomedical image analysis. in this paper, we show that we can train a deep net to perform 3d volumetric delineation given only 2d annotations in maximum intensity projections (mip) of the training volumes. this significantly reduces the annotation time: we conducted a user study that suggests that annotating 2d projections is on average twice as fast as annotating the original 3d volumes. our technical contribution is a loss function that evaluates a 3d prediction against annotations of 2d projections. it is inspired by space carving, a classical approach to reconstructing complex 3d shapes from arbitrarily-positioned cameras. it can be used to train any deep network with volumetric output, without the need to change the network's architecture. substituting the loss is all it takes to enable 2d annotations in an existing training setup. in extensive experiments on 3d light microscopy images of neurons and retinal blood vessels, and on magnetic resonance angiography (mra) brain scans, we show that, when trained on projection annotations, deep delineation networks perform as well as when they are trained using costlier 3d annotations.","['3d deep delineation', 'linear structures', 'annotation effort', 'tracing', 'reduce', '2d']"
"deep learning has shown remarkable results for image analysis and is expected to aid individual treatment decisions in health care. treatment recommendations are predictions with an inherently causal interpretation. to use deep learning for these applications in the setting of observational data, deep learning methods must be made compatible with the required causal assumptions. we present a scenario with real-world medical images (ct-scans of lung cancer) and simulated outcome data. through the data simulation scheme, the images contain two distinct factors of variation that are associated with survival, but represent a collider (tumor size) and a prognostic factor (tumor heterogeneity), respectively. when a deep network would use all the information available in the image to predict survival, it would condition on the collider and thereby introduce bias in the estimation of the treatment effect. we show that when this collider can be quantified, unbiased individual prognosis predictions are attainable with deep learning. this is achieved by (1) setting a dual task for the network to predict both the outcome and the collider and (2) enforcing a form of linear independence of the activation distributions of the last layer. our method provides an example of combining deep learning and structural causal models to achieve unbiased individual prognosis predictions. extensions of machine learning methods for applications to causal questions are required to attain the long-standing goal of personalized medicine supported by artificial intelligence.","['lung cancer images', 'eliminating biasing signals', 'prognosis predictions', 'deep learning']"
"zanthoxyli pericarpium (zp) are the dried ripe peel of zanthoxylum schinifolium sieb. et zucc (zc) or zanthoxylum bungeanum maxim (zb). it has wide range of uses both medicine and food, and favorable market value. the diverse specifications of components of zp is exceptional, and the common aims of adulteration for economic profit is conducted. in this work, a novel method for the identification different species of zp is proposed using convolutional neural networks (cnns). the data used for the experiment is 5 classes obtained from camera and mobile phones. firstly, the data considering 2 categories are trained to detect the labels by yolo. then, the multiple deep learning including vgg, resnet, inception v4, and densenet are introduced to identify the different species of zp (hzb, dzb, ozb, za and jzc). in order to assess the performance of cnns, compared with two traditional identification models including support vector machines (svm) and back propagation (bp). the experimental results demonstrate that the cnn model have a better performance to identify different species of zp and the highest identification accuracy is 99.35%. the present study is proved to be a useful strategy for the discrimination of different traditional chinese medicines (tcms).","['zanthoxyli pericarpium based', 'convolution neural network', 'different species', 'identification']"
"the aim of this study was to enhance multispecialty ct and mri protocol assignment quality and efficiency through development, testing, and proposed workflow design of a natural language processing (nlp)-based machine learning classifier.","['radiology protocols', 'machine learning', 'efficiency improvement', 'quality', 'automation']"
"heterogeneity in intratumoral cancers leads to discrepancies in drug responsiveness, due to diverse genomics profiles. thus, prediction of drug responsiveness is critical in precision medicine. so far, in drug responsiveness prediction, drugs\' molecular ""fingerprints"", along with mutation statuses, have not been considered. here, we constructed a 1-dimensional convolution neural network model, deepic50, to predict three drug responsiveness classes, based on 27,756 features including mutation statuses and various drug molecular fingerprints. as a result, deepic50 showed better cell viability ic50 prediction accuracy in pan-cancer cell lines over two independent cancer cell line datasets. gastric cancer (gc) is not only one of the lethal cancer types in east asia, but also a heterogeneous cancer type. currently approved targeted therapies in gc are only trastuzumab and ramucirumab. responsive gc patients for the drugs are limited, and more drugs should be developed in gc. due to the importance of gc, we applied deepic50 to a real gc patient dataset. drug responsiveness prediction in the patient dataset by deepic50, when compared to the other models, were comparable to responsiveness observed in gc cell lines. deepic50 could possibly accurately predict drug responsiveness, to new compounds, in diverse cancer cell lines, in the drug discovery process.","['cell growth inhibition ic50 prediction', 'gastric cancer patients', 'deep learning model', 'application']"
"calling genetic variations from sequence reads is an important problem in genomics. there are many existing methods for calling various types of variations. recently, google developed a method for calling single nucleotide polymorphisms (snps) based on deep learning. their method visualizes sequence reads in the forms of images. these images are then used to train a deep neural network model, which is used to call snps. this raises a research question: can deep learning be used to call more complex genetic variations such as structural variations (svs) from sequence data?","['throughput sequencing data using deep convolutional neural network', 'genomic deletions', 'accurate calling', 'high', 'deepsv']"
"to better control and manage harbor water quality is an important mission for coastal cities such as new york city (nyc). to achieve this, managers and governors need keep track of key quality indicators, such as temperature, ph, and dissolved oxygen. among these, the biochemical oxygen demand (bod) over five days is a critical indicator that requires much time and effort to detect, causing great inconvenience in both academia and industry. existing experimental and statistical methods cannot effectively solve the detection time problem or provide limited accuracy. also, due to various human-made mistakes or facility issues, the data used for bod detection and prediction contain many missing values, resulting in a sparse matrix. few studies have addressed the sparse matrix problem while developing statistical detection methods. to address these gaps, we propose a deep learning based model that combines deep matrix factorization (dmf) and deep neural network (dnn). the model was able to solve the sparse matrix problem more intelligently and predict the bod value more accurately. to test its effectiveness, we conducted a case study on the nyc harbor water, based on 32,323 water samples. the results showed that the proposed method achieved 11.54%-17.23% lower rmse than conventional matrix completion methods, and 19.20%-25.16% lower rmse than traditional machine learning algorithms.","['city harbor water using deep learning techniques', 'sparse matrix', 'soft detection', 'day bod', '5']"
"the debate about the ethical implications of artificial intelligence dates from the 1960s (samuel in science, 132(3429):741-742, 1960. https://doi.org/10.1126/science.132.3429.741; wiener in cybernetics: or control and communication in the animal and the machine, mit press, new york, 1961). however, in recent years symbolic ai has been complemented and sometimes replaced by (deep) neural networks and machine learning (ml) techniques. this has vastly increased its potential utility and impact on society, with the consequence that the ethical debate has gone mainstream. such a debate has primarily focused on principles-the 'what' of ai ethics (beneficence, non-maleficence, autonomy, justice and explicability)-rather than on practices, the 'how.' awareness of the potential issues is increasing at a fast rate, but the ai community's ability to take action to mitigate the associated risks is still at its infancy. our intention in presenting this research is to contribute to closing the gap between principles and practices by constructing a typology that may help practically-minded developers apply ethics at each stage of the machine learning development pipeline, and to signal to researchers where further work is needed. the focus is exclusively on machine learning, but it is hoped that the results of this research may be easily applicable to other branches of ai. the article outlines the research method for creating this typology, the initial findings, and provides a summary of future research needs.","['publicly available ai ethics tools', 'translate principles', 'initial review', 'research', 'practices', 'methods']"
"in robotic-assisted kidney surgery, computational methods make it possible to augment the surgical scene and potentially improve patient outcome. most often, soft-tissue registration is a prerequisite for the visualization of tumors and vascular structures hidden beneath the surface. state-of-the-art volume-to-surface registration methods, however, are computationally demanding and require a sufficiently large target surface. to overcome this limitation, the first step toward registration is the extraction of the outer edge of the kidney.","['laparoscopic image data', 'kidney edge detection', 'assisted surgery', 'computer']"
"object detection has been a challenging task in computer vision. although significant progress has been made in object detection with deep neural networks, the attention mechanism has yet to be fully developed. in this paper, we propose a hybrid attention mechanism for single-stage object detection. first, we present the modules of spatial attention, channel attention and aligned attention for single-stage object detection. in particular, dilated convolution layers with symmetrically fixed rates are stacked to learn spatial attention. a channel attention mechanism with the cross-level group normalization and squeeze-and-excitation operation is proposed. aligned attention is constructed with organized deformable filters. second, the three types of attention are unified to construct the hybrid attention mechanism. we then plug the hybrid attention into retina-net and propose the efficient single-stage har-net for object detection. the attention modules and the proposed har-net are evaluated on the coco detection dataset. the experiments demonstrate that hybrid attention can significantly improve the detection accuracy and that the har-net can achieve a state-of-the-art 45.8% map, thus outperforming existing single-stage object detectors.","['stage object detection', 'joint learning', 'hybrid attention', 'single', 'net', 'har']"
"x-ray computed tomography (ct) is widely used in clinical practice. the involved ionizingx-ray radiation, however, could increase cancer risk. hence, the reduction of the radiation dosehas been an important topic in recent years. few-view ct image reconstruction is one of the mainways to minimize radiation dose and potentially allow a stationary ct architecture. in this paper,we propose a deep encoder-decoder adversarial reconstruction (dear) network for 3d ct imagereconstruction from few-view data. since the artifacts caused by few-view reconstruction appear in3d instead of 2d geometry, a 3d deep network has a great potential for improving the image qualityin a data driven fashion. more specifically, our proposed dear-3d network aims at reconstructing3d volume directly from clinical 3d spiral cone-beam image data. dear is validated on a publiclyavailable abdominal ct dataset prepared and authorized by mayo clinic. compared with other2d deep learning methods, the proposed dear-3d network can utilize 3d information to producepromising reconstruction results.","['decoder adversarial reconstruction', 'deep encoder', 'dea']"
"the dentate nucleus (dn) is a gray matter structure deep in the cerebellum involved in motor coordination, sensory input integration, executive planning, language, and visuospatial function. the dn is an emerging biomarker of disease, informing studies that advance pathophysiologic understanding of neurodegenerative and related disorders. the main challenge in defining the dn radiologically is that, like many deep gray matter structures, it has poor contrast in t1-weighted magnetic resonance (mr) images and therefore requires specialized mr acquisitions for visualization. manual tracing of the dn across multiple acquisitions is resource-intensive and does not scale well to large datasets. we describe a technique that automatically segments the dn using deep learning (dl) on common imaging sequences, such as t1-weighted, t2-weighted, and diffusion mr imaging. we trained a dl algorithm that can automatically delineate the dn and provide an estimate of its volume. the automatic segmentation achieved higher agreement to the manual labels compared to template registration, which is the current common practice in dn segmentation or multiatlas segmentation of manual labels. across all sequences, the fa maps achieved the highest mean dice similarity coefficient (dsc) of 0.83 compared to t1 imaging ( dsc = 0.76 ), t2 imaging ( dsc = 0.79 ), or a multisequence approach ( dsc = 0.80 ). a single atlas registration approach using the spatially unbiased atlas template of the cerebellum and brainstem template achieved a dsc of 0.23, and multi-atlas segmentation achieved a dsc of 0.33. overall, we propose a method of delineating the dn on clinical imaging that can reproduce manual labels with higher accuracy than current atlas-based tools.","['using deep learning', 'dentate nucleus', 'based segmentation', 'based methods', 'diffusion', 'benefits', 'atlas']"
"cancer is an aggressive disease with a low median survival rate. ironically, the treatment process is long and very costly due to its high recurrence and mortality rates. accurate early diagnosis and prognosis prediction of cancer are essential to enhance the patient's survival rate. developments in statistics and computer engineering over the years have encouraged many scientists to apply computational methods such as multivariate statistical analysis to analyze the prognosis of the disease, and the accuracy of such analyses is significantly higher than that of empirical predictions. furthermore, as artificial intelligence (ai), especially machine learning and deep learning, has found popular applications in clinical cancer research in recent years, cancer prediction performance has reached new heights. this article reviews the literature on the application of ai to cancer diagnosis and prognosis, and summarizes its advantages. we explore how ai assists cancer diagnosis and prognosis, specifically with regard to its unprecedented accuracy, which is even higher than that of general statistical applications in oncology. we also demonstrate ways in which these methods are advancing the field. finally, opportunities and challenges in the clinical implementation of ai are discussed. hence, this article provides a new perspective on how ai technology can help improve cancer diagnosis and prognosis, and continue improving human health in the future.","['cancer diagnosis', 'artificial intelligence', 'prognosis', 'opportunities', 'challenges']"
artificial intelligence (ai) is being increasingly used in the field of radiology. the aim of this review is to illustrate the developments expected in the next 5 to 10 years as well as possible advantages and risks.,"['years ?]', 'artificial intelligence', 'radiology', 'next', 'expected']"
"powdery mildew is a common disease in plants, and it is also one of the main diseases in the middle and final stages of cucumber (cucumis sativus). powdery mildew on plant leaves affects the photosynthesis, which may reduce the plant yield. therefore, it is of great significance to automatically identify powdery mildew. currently, most image-based models commonly regard the powdery mildew identification problem as a dichotomy case, yielding a true or false classification assertion. however, quantitative assessment of disease resistance traits plays an important role in the screening of breeders for plant varieties. therefore, there is an urgent need to exploit the extent to which leaves are infected which can be obtained by the area of diseases regions. in order to tackle these challenges, we propose a semantic segmentation model based on convolutional neural networks (cnn) to segment the powdery mildew on cucumber leaf images at pixel level, achieving an average pixel accuracy of 96.08%, intersection over union of 72.11% and dice accuracy of 83.45% on twenty test samples. this outperforms the existing segmentation methods, k-means, random forest, and gbdt methods. in conclusion, the proposed model is capable of segmenting the powdery mildew on cucumber leaves at pixel level, which makes a valuable tool for cucumber breeders to assess the severity of powdery mildew.","['cucumber powdery mildew using convolutional neural network', 'deep learning', 'based segmentation', 'quantification']"
"laryngeal endoscopy is one of the primary diagnostic tools for laryngeal disorders. the main techniques are videostroboscopy and lately high-speed video endoscopy. unfortunately, due to the restricting anatomy of the larynx and technical limitations of the recording equipment, many videos suffer from insufficient illumination, which complicates clinical examination and analysis. this work presents an approach to enhance low-light images from high-speed video endoscopy using a convolutional neural network. we introduce a new technique to generate realistically darkened training samples using perlin noise. extensive data augmentation is employed to cope with the limited training data allowing training with just 55 videos. the approach is compared against four state-of-the-art low-light enhancement methods and statistically significantly outperforms each on a no-reference (niqe) and two full-reference (psnr, ssim) image quality metrics. the presented approach can be run on consumer-grade hardware and is thereby directly applicable in a clinical context. it is likely transferable to similar techniques such as videostroboscopy. graphical abstract the basic setup for training and employing an improved fully convolutional u-net neural network to predict a brightness map used to enhance the lighting of ill-lit endoscopic high-speed videos - artificially darkened training data are created using perlin noise to allow region-specific darkening.","['speed endoscopic videos using', 'light image enhancement', 'convolutional neural network', 'low', 'high']"
"cell or nucleus quantification has recently achieved state-of-the-art performance by using convolutional neural networks (cnns). in general, training cnns requires a large amount of annotated microscopy image data, which is prohibitively expensive or even impossible to obtain in some applications. additionally, when applying a deep supervised model to new datasets, it is common to annotate individual cells in those target datasets for model re-training or fine-tuning, leading to low-throughput image analysis. in this papersss, we propose a novel adversarial domain adaptation method for cell/nucleus quantification across multimodality microscopy image data. specifically, we learn a fully convolutional network detector with task-specific cycle-consistent adversarial learning, which conducts pixel-level adaptation between source and target domains and completes a cell/nucleus detection task. then we generate pseudo-labels on target training data using the detector trained with adapted source images and further fine-tune the detector towards the target domain to boost the performance. we evaluate the proposed method on multiple cross-modality microscopy image datasets and obtain a significant improvement in cell/nucleus detection compared to the reference baselines and a recent state-of-the-art deep domain adaptation approach. in addition, our method is very competitive with the fully supervised models trained with all real target training labels.","['modality microscopy image quantification', 'adversarial domain adaptation', 'pseudo', 'labeling', 'cross']"
"to evaluate the diagnostic performance of a deep learning algorithm for automated detection of small 18f-fdg-avid pulmonary nodules in pet scans, and to assess whether novel block sequential regularized expectation maximization (bsrem) reconstruction affects detection accuracy as compared to ordered subset expectation maximization (osem) reconstruction.","['positive lung nodules', 'detecting small fdg', 'image reconstructions', 'digital pet', 'diagnostic performance', 'artificial intelligence', 'impact', 'ct']"
"to correct wavefront aberrations, commonly employing proportional-integral control in adaptive optics (ao) systems, the control process depends strictly on the response matrix of the deformable mirror. the alignment error between the hartmann-shack wavefront sensor and the deformable mirror is caused by various factors in ao systems. in the conventional control method, the response matrix can be recalibrated to reduce the impact of alignment error, but the impact cannot be eliminated. this paper proposes a control method based on a deep learning control model (dlcm) to compensate for wavefront aberrations, eliminating the dependence on the deformable mirror response matrix. based on the wavefront slope data, the cost functions of the model network and the actor network are defined, and the gradient optimization algorithm improves the efficiency of the network training. the model network guarantees the stability and convergence speed, while the actor network improves the control accuracy, realizing an online identification and self-adaptive control of the system. a parameter-sharing mechanism is adopted between the model network and the actor network to control the system gain. simulation results show that the dlcm has good adaptability and stability. through self-learning, it improves the convergence accuracy and iterations, as well as the adjustment tolerance of the system.","['deep learning control model', 'adaptive optics systems']"
"modern digital cameras rely on the sequential execution of separate image processing steps to produce realistic images. the first two steps are usually related to denoising and demosaicking where the former aims to reduce noise from the sensor and the latter converts a series of light intensity readings to color images. modern approaches try to jointly solve these problems, i.e. joint denoising-demosaicking which is an inherently ill-posed problem given that two-thirds of the intensity information is missing and the rest are perturbed by noise. while there are several machine learning systems that have been recently introduced to solve this problem, the majority of them relies on generic network architectures which do not explicitly take into account the physical image model. in this work we propose a novel algorithm which is inspired by powerful classical image regularization methods, large-scale optimization, and deep learning techniques. consequently, our derived iterative optimization algorithm, which involves a trainable denoising network, has a transparent and clear interpretation compared to other black-box data driven approaches. our extensive experimentation line demonstrates that our proposed method outperforms any previous approaches for both noisy and noise-free data across many different datasets. this improvement in reconstruction quality is attributed to the rigorous derivation of an iterative solution and the principled way we design our denoising network architecture, which as a result requires fewer trainable parameters than the current state-of-the-art solution and furthermore can be efficiently trained by using a significantly smaller number of training data than existing deep demosaicking networks.","['iterative joint image demosaicking', 'residual denoising network', 'denoising using']"
"this paper introduces a convolutional neural network (cnn) semantic re-ranking system to enhance the performance of sketch-based image retrieval (sbir). distinguished from the existing approaches, the proposed system can leverage category information brought by cnns to support effective similarity measurement between the images. to achieve effective classification of query sketches and high-quality initial retrieval results, one cnn model is trained for classification of sketches, another for that of natural images. through training dual cnn models, the semantic information of both the sketches and natural images is captured by deep learning. in order to measure the category similarity between images, a category similarity measurement method is proposed. category information is then used for re-ranking. re-ranking operation first infers the retrieval category of the query sketch and then uses the category similarity measurement to measure the category similarity between the query sketch and each initial retrieval result. finally, the initial retrieval results are re-ranked. the experiments on different types of sbir datasets demonstrate the effectiveness of the proposed re-ranking method. comparisons with other re-ranking algorithms are also given to show the proposed method's superiority. further, compared to the baseline systems, the proposed re-ranking approach achieves significantly higher precision in the top ten different sbir methods and datasets.","['based image retrieval', 'enhancing sketch', 'cnn semantic', 'ranking']"
"protein model quality assessment (qa) is a crucial and yet open problem in structural bioinformatics. the current best methods for single-model qa typically combine results from different approaches, each based on different input features constructed by experts in the field. then, the prediction model is trained using a machine-learning algorithm. recently, with the development of convolutional neural networks (cnn), the training paradigm has changed. in computer vision, the expert-developed features have been significantly overpassed by automatically trained convolutional filters. this motivated us to apply a three-dimensional (3d) cnn to the problem of protein model qa.",['protein model quality assessment using 3d oriented convolutional neural networks']
the calcaneus is the most fracture-prone tarsal bone and injuries to the surrounding tissue are some of the most difficult to treat. currently there is a lack of consensus on treatment or interpretation of computed tomography (ct) images for calcaneus fractures. this study proposes a novel computer-assisted method for automated classification and detection of fracture locations in calcaneus ct images using a deep learning algorithm.,"['deep learning', 'ct images', 'calcaneus fractures', 'automated classification', 'surf', 'detection']"
"we present an efficient deep learning approach for the challenging task of tumor segmentation in multisequence mr images. in recent years, convolutional neural networks (cnn) have achieved state-of-the-art performances in a large variety of recognition tasks in medical imaging. because of the considerable computational cost of cnns, large volumes such as mri are typically processed by subvolumes, for instance slices (axial, coronal, sagittal) or small 3d patches. in this paper we introduce a cnn-based model which efficiently combines the advantages of the short-range 3d context and the long-range 2d context. furthermore, we propose a network architecture with modality-specific subnetworks in order to be more robust to the problem of missing mr sequences during the training phase. to overcome the limitations of specific choices of neural network architectures, we describe a hierarchical decision process to combine outputs of several segmentation models. finally, a simple and efficient algorithm for training large cnn models is introduced. we evaluate our method on the public benchmark of the brats 2017 challenge on the task of multiclass segmentation of malignant brain tumors. our method achieves good performances and produces accurate segmentations with median dice scores of 0.918 (whole tumor), 0.883 (tumor core) and 0.854 (enhancing core).","['tumor segmentation using long', '3d convolutional neural networks', 'range 2d context']"
"the widespread adoption of whole slide imaging has increased the demand for effective and efficient gigapixel image analysis. deep learning is at the forefront of computer vision, showcasing significant improvements over previous methodologies on visual understanding. however, whole slide images have billions of pixels and suffer from high morphological heterogeneity as well as from different types of artifacts. collectively, these impede the conventional use of deep learning. for the clinical translation of deep learning solutions to become a reality, these challenges need to be addressed. in this paper, we review work on the interdisciplinary attempt of training deep neural networks using whole slide images, and highlight the different ideas underlying these methodologies.","['whole slide image analysis', 'deep learning', 'overview']"
"deep brain stimulation in the ventral tegmental area (vta-dbs) has provided remarkable therapeutic benefits in decreasing headache frequency and severity in patients with medically refractory chronic cluster headache (ch). however, to date the effects of vta-dbs on cognition, mood and quality of life have not been examined in detail.","['ventral tegmental area deep brain stimulation', 'pain report behaviour', 'chronic cluster headache', 'quality', 'mood', 'life', 'effects', 'cognition']"
"deep artificial neural networks are powerful tools with many possible applications in nanophotonics. here, we demonstrate how a deep neural network can be used as a fast, general purpose predictor of the full near-field and far-field response of plasmonic and dielectric nanostructures. a trained neural network is shown to infer the internal fields of arbitrary three-dimensional nanostructures many orders of magnitude faster compared to conventional numerical simulations. secondary physical quantities are derived from the deep learning predictions and faithfully reproduce a wide variety of physical effects without requiring specific training. we discuss the strengths and limitations of the neural network approach using a number of model studies of single particles and their near-field interactions. our approach paves the way for fast, yet universal, methods for design and analysis of nanophotonic systems.","['deep learning meets nanophotonics', 'generalized accurate predictor', 'arbitrary 3d nanostructures', 'near fields', 'far fields']"
"while neuroscience has elucidated the mechanisms underpinning learning and memory, accurate dissemination of this knowledge to teachers and educators has been limited. this review focuses on teacher professional development in neuroscience that harnessed the power of active-learning strategies and best educational practices resulting in increased teacher and student understanding of cognition and brain function. for teachers, the experience of learning a novel subject in an active manner enabled them to subsequently teach using similar strategies. most important, participants viewed neuroscience as a frame for understanding why active-learning pedagogies work to engage and motivate students. teachers themselves made connections applying neuroscience concepts to understand why learner-centered pedagogies are effective in promoting higher order thinking and deep learning in their students. teachers planned and embraced pedagogies involving modeling, experimentation, discussion, analysis, and synthesis, increasing classroom cognitive engagement. comprehending that everyone is in charge of changing their own brains is a tremendously powerful idea that may motivate science and non-science teachers to provide students opportunities to actively engage with content. neuroscience courses for preservice and in-service teachers, provided as collaborations between scientists and teacher educators, can result in improved science education, pedagogy, and understanding of neuroscience.","['neuroscience knowledge', 'teachers', 'practice', 'contributions']"
"deep learning refers to a set of computer models that have recently been used to make unprecedented progress in the way computers extract information from images. these algorithms have been applied to tasks in numerous medical specialties, most extensively radiology and pathology, and in some cases have attained performance comparable to human experts. furthermore, it is possible that deep learning could be used to extract data from medical images that would not be apparent by human analysis and could be used to inform on molecular status, prognosis, or treatment sensitivity. in this review, we outline the current developments and state-of-the-art in applying deep learning for cancer diagnosis, and discuss the challenges in adapting the technology for widespread clinical deployment.","['deep learning', 'cancer diagnosis', 'rise', 'machines', 'advances']"
"the drug development is generally arduous, costly, and success rates are low. thus, the identification of drug-target interactions (dtis) has become a crucial step in early stages of drug discovery. consequently, developing computational approaches capable of identifying potential dtis with minimum error rate are increasingly being pursued. these computational approaches aim to narrow down the search space for novel dtis and shed light on drug functioning context. most methods developed to date use binary classification to predict if the interaction between a drug and its target exists or not. however, it is more informative but also more challenging to predict the strength of the binding between a drug and its target. if that strength is not sufficiently strong, such dti may not be useful. therefore, the methods developed to predict drug-target binding affinities (dtba) are of great value. in this study, we provide a comprehensive overview of the existing methods that predict dtba. we focus on the methods developed using artificial intelligence (ai), machine learning (ml), and deep learning (dl) approaches, as well as related benchmark datasets and databases. furthermore, guidance and recommendations are provided that cover the gaps and directions of the upcoming work in this research area. to the best of our knowledge, this is the first comprehensive comparison analysis of tools focused on dtba with reference to ai/ml/dl.","['target binding affinities', 'computational prediction tools', 'comparison study', 'drug']"
"cultivar recognition is a basic work in flower production, research, and commercial application. chinese large-flowered chrysanthemum (chrysanthemum\u2009×\u2009morifolium ramat.) is miraculous because of its high ornamental value and rich cultural deposits. however, the complicated capitulum structure, various floret types and numerous cultivars hinder chrysanthemum cultivar recognition. here, we explore how deep learning method can be applied to chrysanthemum cultivar recognition.","['flowered chrysanthemum cultivar recognition', 'deep learning', 'based large', 'image']"
"decadal time-series derived from satellite observations are useful for discriminating crops and identifying crop succession at national and regional scales. however, use of these data for crop modeling is challenged by the presence of mixed pixels due to the coarse spatial resolution of these data, which influences model accuracy, and the scarcity of field data over the decadal period necessary to calibrate and validate the model. for this data article, cloud-free satellite ""vegetation indices 16-day global 250\xa0m"" terra (mod13q1) and aqua (myd13q1) products derived from the moderate resolution imaging spectroradiometer (modis), as well as the land parcel information system (lpis) vector field data, were collected throughout france for the 12-year period from 2006 to the end of 2017. a gis workflow was developed using r software to combine the mod13q1 and myd13q1 products, and then to select ""pure"" modis pixels located within single-crop parcels over the entire period. as a result, a dataset for 21,129 reference plots (corresponding to ""pure"" pixels) was generated that contained a spectral time-series (red band, near-infrared band, normalized difference vegetation index (ndvi), and enhanced vegetation index (evi)) and the associated annual crop type with an 8-day time step over the period. this dataset can be used to develop new classification methods based on time-series analysis using deep learning, and to monitor and predict crop succession.","['series spectral dataset', 'time', 'france', 'croplands', '201', '2006']"
"the aim of this work is to generate synthetic computed tomography (sct) images from multi-sequence magnetic resonance (mr) images using an adversarial network and to assess the feasibility of sct-based treatment planning for brain radiotherapy. datasets for 15 patients with glioblastoma were selected and 580 pairs of ct and mr images were used. t1-weighted, t2-weighted and fluid-attenuated inversion recovery mr sequences were combined to create a three-channel image as input data. a conditional generative adversarial network (cgan) was trained using image patches. the image quality was evaluated using voxel-wise mean absolute errors (maes) of the ct number. for the dosimetric evaluation, 3d conformal radiotherapy (3d-crt) and volumetric modulated arc therapy (vmat) plans were generated using the original ct set and recalculated using the sct images. the isocenter dose and dose-volume parameters were compared for 3d-crt and vmat plans, respectively. the equivalent path length was also compared. the mean maes for the whole body, soft tissue and bone region were 108.1\xa0±\xa024.0, 38.9\xa0±\xa010.7 and 366.2\xa0±\xa062.0 hounsfield unit, respectively. the dosimetric evaluation revealed no significant difference in the isocenter dose for 3d-crt plans. the differences in the dose received by 2% of the volume (d2%), d50% and d98% relative to the prescribed dose were\xa0<1.0%. the overall equivalent path length was shorter than that for real ct by 0.6\xa0±\xa01.9\xa0mm. a treatment planning study using generated sct detected only small, clinically negligible differences. these findings demonstrated the feasibility of generating sct images for mr-only radiotherapy from multi-sequence mr images using cgan.","['synthetic computed tomography generated', 'sequence magnetic resonance', 'based brain radiotherapy', 'adversarial network', 'multi', 'feasibility']"
"sensory neuroscience aims to build models that predict neural responses and perceptual behaviors, and that provide insight into the principles that give rise to them. for decades, artificial neural networks trained to perform perceptual tasks have attracted interest as potential models of neural computation. only recently, however, have such systems begun to perform at human levels on some real-world tasks. the recent engineering successes of deep learning have led to renewed interest in artificial neural networks as models of the brain. here we review applications of deep learning to sensory neuroscience, discussing potential limitations and future directions. we highlight the potential uses of deep neural networks to reveal how task performance may constrain neural systems and behavior. in particular, we consider how task-optimized networks can generate hypotheses about neural representations and functional organization in ways that are analogous to traditional ideal observer models.","['deep neural network models', 'windows onto', 'task constraints', 'sensory systems', 'role']"
to assess reliability and validity of revised biggs two-factor study process questionnaire to measure learning approaches among medical students.,"['measure learning approaches among undergraduate medical students', 'factor study process questionnaire', 'revised biggs two', 'assessing reliability', 'validity', 'pakistan', 'lahore']"
"deep reinforcement learning (drl) is applied to control a nonlinear, chaotic system governed by the one-dimensional kuramoto-sivashinsky (ks) equation. drl uses reinforcement learning principles for the determination of optimal control solutions and deep neural networks for approximating the value function and the control policy. recent applications have shown that drl may achieve superhuman performance in complex cognitive tasks. in this work, we show that using restricted localized actuation, partial knowledge of the state based on limited sensor measurements and model-free drl controllers, it is possible to stabilize the dynamics of the ks system around its unstable fixed solutions, here considered as target states. the robustness of the controllers is tested by considering several trajectories in the phase space emanating from different initial conditions; we show that drl is always capable of driving and stabilizing the dynamics around target states. the possibility of controlling the ks system in the chaotic regime by using a drl strategy solely relying on local measurements suggests the extension of the application of rl methods to the control of more complex systems such as drag reduction in bluff-body wakes or the enhancement/diminution of turbulent mixing.","['deep reinforcement learning', 'chaotic systems', 'control']"
"it is a challenge to automatically and accurately segment the liver and tumors in computed tomography (ct) images, as the problem of over-segmentation or under-segmentation often appears when the hounsfield unit (hu) of liver and tumors is close to the hu of other tissues or background. in this paper, we propose the spatial channel-wise convolution, a convolutional operation along the direction of the channel of feature maps, to extract mapping relationship of spatial information between pixels, which facilitates learning the mapping relationship between pixels in the feature maps and distinguishing the tumors from the liver tissue. in addition, we put forward an iterative extending learning strategy, which optimizes the mapping relationship of spatial information between pixels at different scales and enables spatial channel-wise convolution to map the spatial information between pixels in high-level feature maps. finally, we propose an end-to-end convolutional neural network called channel-unet, which takes unet as the main structure of the network and adds spatial channel-wise convolution in each up-sampling and down-sampling module. the network can converge the optimized mapping relationship of spatial information between pixels extracted by spatial channel-wise convolution and information extracted by feature maps and realizes multi-scale information fusion. the proposed channelunet is validated by the segmentation task on the 3dircadb dataset. the dice values of liver and tumors segmentation were 0.984 and 0.940, which is slightly superior to current best performance. besides, compared with the current best method, the number of parameters of our method reduces by 25.7%, and the training time of our method reduces by 33.3%. the experimental results demonstrate the efficiency and high accuracy of channel-unet in liver and tumors segmentation in ct images.","['wise convolutional neural network', 'tumors segmentation', 'spatial channel', 'channel', 'unet', 'liver']"
"with the recent growth of smart tv technology, the demand for unique and beneficial applications motivates the study of a unique gesture-based system for a smart tv-like environment. combining movie recommendation, social media platform, call a friend application, weather updates, chatting app, and tourism platform into a single system regulated by natural-like gesture controller is proposed to allow the ease of use and natural interaction. gesture recognition problem solving was designed through 24 gestures of 13 static and 11 dynamic gestures that suit to the environment. dataset of a sequence of rgb and depth images were collected, preprocessed, and trained in the proposed deep learning architecture. combination of three-dimensional convolutional neural network (3dcnn) followed by long short-term memory (lstm) model was used to extract the spatio-temporal features. at the end of the classification, finite state machine (fsm) communicates the model to control the class decision results based on application context. the result suggested the combination data of depth and rgb to hold 97.8% of accuracy rate on eight selected gestures, while the fsm has improved the recognition rate from 89% to 91% in a real-time performance.","['dynamic hand gesture recognition using 3dcnn', 'fsm context', 'aware model', 'lstm']"
"the interactions between rnas and rna binding proteins (rbps) are crucial for understanding post-transcriptional regulation mechanisms. a lot of computational tools have been developed to automatically predict the binding relationship between rnas and rbps. however, most of the methods can only predict the presence or absence of binding sites for a sequence fragment, without providing specific information on the position or length of the binding sites. besides, the existing tools focus on the interaction between rbps and linear rnas, while the binding sites on circular rnas (circrnas) have been rarely studied. in this study, we model the prediction of binding sites on rnas as a sequence labeling problem, and propose a new model called circslnn to identify the specific location of rbp-binding sites on circrnas. circslnn is driven by pretrained rna embedding vectors and a composite labeling model. on our constructed circrna datasets, our model has an average f 1 score of 0.790. we assess the performance on full-length rna sequences, the proposed model outperforms previous classification-based models by a large margin.","['circrnas via sequence labeling neural networks', 'identifying rbp', 'binding sites', 'circslnn']"
"considerable number of indoor navigation systems has been proposed to augment people with visual impairments (vi) about their surroundings. these systems leverage several technologies, such as computer-vision, bluetooth low energy (ble), and other techniques to estimate the position of a user in indoor areas. computer-vision based systems use several techniques including matching pictures, classifying captured images, recognizing visual objects or visual markers. ble based system utilizes ble beacons attached in the indoor areas as the source of the radio frequency signal to localize the position of the user.","['ble technology based indoor navigation systems', 'visual impairments', 'comparative analysis', 'vision', 'people', 'computer']"
"plate fixation using traditional lateral l-shape approach for intra-articular calcaneal fractures is complicated by 30% of wound complications, and the lateral small incision techniques with a tarsal sinus approach cannot sufficiently address all the fragments. a modified tarsal sinus approach with combined advantages of traditional lateral l-shape and tarsal sinus approaches for the treatment of intra-articular calcaneal fractures was developed.","['modified tarsal sinus approach', 'articular calcaneal fractures', 'intra']"
we aimed to use deep learning with convolutional neural network (cnn) to discriminate between benign and malignant breast mass images from ultrasound.,"['breast ultrasound using deep learning method', 'malignant breast masses', 'convolutional neural network', 'distinction', 'benign']"
"convolutional neural network (cnn) based methods have outperformed conventional machine learning methods in predicting the binding preference of dna-protein binding. although studies in the past have shown that more convolutional kernels help to achieve better performance, visualization of the model can be obscured by the use of many kernels, resulting in overfitting and reduced interpretation because the number of motifs in true models is limited. therefore, we aim to arrive at high performance, but with limited kernel numbers, in cnn-based models for motif inference. we herein present deepprune, a novel deep learning framework, which prunes the weights in the dense layer and fine-tunes iteratively. these two steps enable the training of cnn-based models with limited kernel numbers, allowing easy interpretation of the learned model. we demonstrate that deepprune significantly improves motif inference performance for the simulated datasets. furthermore, we show that deepprune outperforms the baseline with limited kernel numbers when inferring dna-binding sites from chip-seq data.","['interpretable convolutional networks', 'weight pruning', 'protein binding', 'predicting dna', 'learning efficient', 'deepprune']"
"as a biomimetic model of visual information processing, predictive coding (pc) has become increasingly popular for explaining a range of neural responses and many aspects of brain organization. while the development of pc model is encouraging in the neurobiology community, its practical applications in machine learning (e.g., image classification) have not been fully explored yet. in this paper, a novel image processing model called fast inference pc (fipc) is presented for image representation and classification. compared with the basic pc model, a regression procedure and a classification layer have been added to the proposed fipc model. the regression procedure is used to learn regression mappings that achieve fast inference at test time, while the classification layer can instruct the model to extract more discriminative features. in addition, effective learning and fine-tuning algorithms are developed for the proposed model. experimental results obtained on four image benchmark data sets show that our model is able to directly and fast infer representations and, simultaneously, produce lower error rates on image classification tasks.","['fast inference predictive coding', 'constructing deep neural networks', 'novel model']"
"it has demonstrated that glycogen synthase kinase 3β (gsk3β) is related to alzheimer's disease (ad). on the basis of the world largest traditional chinese medicine (tcm) database, a network-pharmacology-based approach was utilized to investigate tcm candidates that can dock well with multiple targets. support vector machine (svm) and multiple linear regression (mlr) methods were utilized to obtain predicted models. in particular, the deep learning method and the random forest (rf) algorithm were adopted. we achieved r2 values of 0.927 on the training set and 0.862 on the test set with deep learning and 0.869 on the training set and 0.890 on the test set with rf. besides, comparative molecular similarity indices analysis (comsia) was performed to get a predicted model. all of the training models achieved good results on the test set. the stability of gsk3β protein-ligand complexes was evaluated using 100 ns of md simulation. methyl 3- o-feruloylquinate and cynanogenin a induced both more compactness to the gsk3β complex and stable conditions at all simulation times, and the gsk3β complex also had no substantial fluctuations after a simulation time of 5 ns. for tcm molecules, we used the trained models to calculate predicted bioactivity values, and the optimum tcm candidates were obtained by ranking the predicted values. the results showed that methyl 3- o-feruloylquinate contained in phellodendron amurense and cynanogenin a contained in cynanchum atratum are capable of forming stable interactions with gsk3β.","['optimal traditional chinese medicine formula', 'random forest approach', 'deep learning', 'treatment', 'finding', 'disease', 'alzheimer']"
"the movement of ions across the cell membrane is an essential for many biological processes. this study is focused on ion channels and ion transporters (pumps) as types of border guards control the incessant traffic of ions across cell membranes. ion channels and ion transporters function to regulate membrane potential and electrical signaling and play important roles in cell proliferation, migration, apoptosis, and differentiation. in their behaviors, it is found that ion channels differ significantly from ion transporters. therefore, a method for automatically classifying ion transporters and ion channels from membrane proteins is proposed by training deep neural networks and using the position-specific scoring matrix profile as an input. the key of novelty is the three-stage approach, in which five techniques for data normalization are used; next three imbalanced data techniques are applied to the minority classes and then, six classifiers are compared with the proposed method.","['deep learning approach', 'classifying ion transporters', 'ion channels', 'membrane proteins', 'deepion']"
"there has been burgeoning interest in applying machine learning methods for predicting radiotherapy outcomes. however, the imbalanced ratio of a large number of variables to a limited sample size in radiation oncology constitutes a major challenge. therefore, dimensionality reduction methods can be a key to success. the study investigates and contrasts the application of traditional machine learning methods and deep learning approaches for outcome modeling in radiotherapy. in particular, new joint architectures based on variational autoencoder (vae) for dimensionality reduction are presented and their application is demonstrated for the prediction of lung radiation pneumonitis (rp) from a large-scale heterogeneous dataset.","['induced lung damage', 'combining handcrafted features', 'machine learning', 'latent variables', 'radiation', 'prediction']"
"genomic selection uses single-nucleotide polymorphisms (snps) to predict quantitative phenotypes for enhancing traits in breeding populations and has been widely used to increase breeding efficiency for plants and animals. existing statistical methods rely on a prior distribution assumption of imputed genotype effects, which may not fit experimental datasets. emerging deep learning technology could serve as a powerful machine learning tool to predict quantitative phenotypes without imputation and also to discover potential associated genotype markers efficiently. we propose a deep-learning framework using convolutional neural networks (cnns) to predict the quantitative traits from snps and also to investigate genotype contributions to the trait using saliency maps. the missing values of snps are treated as a new genotype for the input of the deep learning model. we tested our framework on both simulation data and experimental datasets of soybean. the results show that the deep learning model can bypass the imputation of missing values and achieve more accurate results for predicting quantitative phenotypes than currently available other well-known statistical methods. it can also effectively and efficiently identify significant markers of snps and snp combinations associated in genome-wide association study.","['wide association study using deep convolutional neural network', 'phenotype prediction', 'soybean', 'genome']"
"chronic infection with hepatitis b virus (hbv) is a major risk factor for the development of advanced liver disease including fibrosis, cirrhosis, and hepatocellular carcinoma (hcc). the relative contribution of virological factors to disease progression has not been fully defined and tools aiding the deconvolution of complex patient virus profiles is an unmet clinical need. variable viral mutant signatures develop within individual patients due to the low-fidelity replication of the viral polymerase creating 'quasispecies' populations. here we present the first comprehensive survey of the diversity of hbv quasispecies through ultra-deep sequencing of the complete hbv genome across two distinct european and asian patient populations. seroconversion to the hbv e antigen (hbeag) represents a critical clinical waymark in infected individuals. using a machine learning approach, a model was developed to determine the viral variants that accurately classify hbeag status. serial surveys of patient quasispecies populations and advanced analytics will facilitate clinical decision support for chronic hbv infection and direct therapeutic strategies through improved patient stratification.","['learning based patient classification using hepatitis b virus full', 'length genome quasispecies', 'european cohorts', 'machine', 'asian']"
"it is known that many driver nodes are required to control complex biological networks. previous studies imply that o(n) driver nodes are required in both linear complex network and boolean network models with n nodes if an arbitrary state is specified as the target. in order to cope with this intrinsic difficulty, we consider a special case of the control problem in which the targets are restricted to attractors. for this special case, we mathematically prove under the uniform distribution of states in basins that the expected number of driver nodes is only o(log2n+log2m) for controlling boolean networks, where m is the number of attractors. since it is expected that m is not very large in many practical networks, the new model requires a much smaller number of driver nodes. this result is based on discovery of novel relationships between control problems on boolean networks and the coupon collector's problem, a well-known concept in combinatorics. we also provide lower bounds of the number of driver nodes as well as simulation results using artificial and realistic network data, which support our theoretical findings.","['driver nodes', 'boolean network', 'targets', 'restricted', 'number', 'controlling', 'attractors']"
"the overwhelming amount, production speed, multidimensionality, and potential value of data currently available-often simplified and referred to as big data -exceed the limits of understanding of the human brain. at the same time, developments in data analytics and computational power provide the opportunity to obtain new insights and transfer data-provided added value to clinical practice in real time. what is the role of the health care professional in collaboration with the data scientist in the changing landscape of modern care? we discuss how health care professionals should provide expert knowledge in each of the stages of clinical decision support design: data level, algorithm level, and decision support level. including various ethical considerations, we advocate for health care professionals to responsibly initiate and guide interprofessional teams, including patients, and embrace novel analytic technologies to translate big data into patient benefit driven by human(e) values.",['human']
"the combination of big data and deep learning is a world-shattering technology that can make a great impact on any industry if used in a proper way. with the availability of large volume of health care datasets and progressions in deep learning techniques, systems are now well equipped in diagnosing many health problems. utilizing the intensity of substantial historical information in electronic health record (ehr), we built up, a conventional predictive temporal model utilizing recurrent neural systems (rnn) like lstm and connected to longitudinal time stepped ehr. experience records were contribution to rnn to anticipate the analysis and prescription classes for a resulting visit during heart disappointment (e.g. diagnosis codes, drug codes or method codes). in this paper, we also investigated whether use of deep learning to model temporal relations among events in electronic health records (ehrs) would enhance the model performance in predicting initial diagnosis of heart failure (hf) compared to some of the traditional methods that disregard temporality. by examining these time stamped ehrs, we could recognize the associations between various diagnosis occasions and finally predicate when a patient is being analyzed for a disease. in any case, it is hard to access the current ehr data straightforwardly, since almost all data are sparse and not standardized. along these lines, we proposed a robust model for prediction of heart failure. the fundamental commitment of this paper is to predict the failure of heart by means of a neural network model based on patient's electronic medicinal information. in order to, demonstrate the diagnosis events and prediction of heart failure, we used the medical concept vectors and the essential standards of a long short-term memory (lstm) deep network model. the proposed lstm model uses silu and tanh as activation function in the hidden layers and softmax in output layer in the network. bridgeout is used as a regularization technique for weight optimization throughout the network. assessments subject to the real-time data exhibit the favorable effectiveness and feasibility of recommended model in the risk of heart failure prediction. the results showed improved accuracy in heart failure detection and the model performance is compared using the existing deep learning models. enhanced prior detection could expose novel chances for deferring or anticipating movement to analysis of heart failure and diminish cost.","['lstm model', 'heart failure', 'big data', 'prediction']"
"an important field in robotics is the optimization of controllers. currently, robots are often treated as a black box in this optimization process, which is the reason why derivative-free optimization methods such as evolutionary algorithms or reinforcement learning are omnipresent. when gradient-based methods are used, models are kept small or rely on finite difference approximations for the jacobian. this method quickly grows expensive with increasing numbers of parameters, such as found in deep learning. we propose the implementation of a modern physics engine, which can differentiate control parameters. this engine is implemented for both cpu and gpu. firstly, this paper shows how such an engine speeds up the optimization process, even for small problems. furthermore, it explains why this is an alternative approach to deep q-learning, for using deep learning in robotics. finally, we argue that this is a big step for deep learning in robotics, as it opens up new possibilities to optimize robots, both in hardware and software.","['differentiable physics engine', 'deep learning', 'robotics']"
"over the past few years, spiking neural networks (snns) have become popular as a possible pathway to enable low-power event-driven neuromorphic hardware. however, their application in machine learning have largely been limited to very shallow neural network architectures for simple problems. in this paper, we propose a novel algorithmic technique for generating an snn with a deep architecture, and demonstrate its effectiveness on complex visual recognition problems such as cifar-10 and imagenet. our technique applies to both vgg and residual network architectures, with significantly better accuracy than the state-of-the-art. finally, we present analysis of the sparse event-driven computations to demonstrate reduced hardware overhead when operating in the spiking domain.","['spiking neural networks', 'residual architectures', 'going deeper', 'vgg']"
"mesothelioma patients rely on the information their clinical team obtains from medical imaging. whether x-ray-based computed tomography (ct) or magnetic resonance imaging (mri) based on local magnetic fields within a patient's tissues, different modalities generate images with uniquely different appearances and information content due to the physical differences of the image-acquisition process. researchers are developing sophisticated ways to extract a greater amount of the information contained within these images. this paper summarizes the imaging-based research presented orally at the 2018 international conference of the international mesothelioma interest group (imig) in ottawa, ontario, canada, held may 2-5, 2018. presented topics included advances in the imaging of preclinical mesothelioma models to inform clinical therapeutic strategies, optimization of the time delay between contrast administration and image acquisition for maximized enhancement of mesothelioma tumor on ct, an investigation of image-based criteria for clinical tumor and nodal staging of mesothelioma by contrast-enhanced ct, an investigation of methods for the extraction of mesothelioma tumor volume from mri and the association of volume with patient survival, the use of deep learning for mesothelioma tumor segmentation in ct, and an evaluation of ct-based radiomics for the prognosis of mesothelioma patient survival.","['international mesothelioma interest group', '14th international conference', 'pleural mesothelioma', 'review', 'imaging']"
"the goal of this data challenge was to create a structured dynamic with the following objectives: (1)\xa0teach radiologists the new rules of general data protection regulation (gdpr), while building a large multicentric prospective database of ultrasound, computed tomography (ct) and mri patient images; (2)\xa0build a network including radiologists, researchers, start-ups, large companies, and students from engineering schools, and; (3)\xa0provide all french stakeholders working together during 5 data challenges with a secured framework, offering a realistic picture of the benefits and concerns in october 2018.","['five simultaneous artificial intelligence data challenges', 'ultrasound', 'mri', 'ct']"
"despite the effective application of deep learning (dl) in brain-computer interface (bci) systems, the successful execution of this technique, especially for inter-subject classification, in cognitive bci has not been accomplished yet. in this paper, we propose a framework based on the deep convolutional neural network (cnn) to detect the attentive mental state from single-channel raw electroencephalography (eeg) data.","['end deep convolutional neural network', 'subject transfer learning', 'based bci', 'end', 'inter', 'eeg']"
"knowing the future condition of a patient would enable a physician to customize current therapeutic options to prevent disease worsening, but predicting that future condition requires sophisticated modeling and information. if artificial intelligence models were capable of forecasting future patient outcomes, they could be used to aid practitioners and patients in prognosticating outcomes or simulating potential outcomes under different treatment scenarios.","['electronic health record data', 'deep learning model based', 'forecast clinical outcomes', 'rheumatoid arthritis', 'patients', 'assessment']"
recent advances in deep neural networks (dnns) have unlocked opportunities for their application for automatic image segmentation. we have evaluated a dnn-based algorithm for automatic segmentation of the prostate gland on a large cohort of patient images.,"['ct images using deep neural networks', 'automatic segmentation', 'prostate', 'dn']"
"the aim of this study was to provide automated identification of postural point-features required to estimate the location and orientation of the head, multi-segmented trunk and arms from videos of the clinical test 'segmental assessment of trunk control' (satco). three expert operators manually annotated 13 point-features in every fourth image of 177 short (5-10 s) videos (25 hz) of 12 children with cerebral palsy (aged: 4.52 ± 2.4 years), participating in satco testing. linear interpolation for the remaining images resulted in 30 825 annotated images. convolutional neural networks were trained with cross-validation, giving held-out test results for all children. the point-features were estimated with error 4.4 ± 3.8 pixels at approximately 100 images per second. truncal segment angles (head, neck and six thoraco-lumbar-pelvic segments) were estimated with error 6.4 ± 2.8°, allowing accurate classification (f 1 > 80%) of deviation from a reference posture at thresholds up to 3°, 3° and 2°, respectively. contact between arm point-features (elbow and wrist) and supporting surface was classified at f 1 = 80.5%. this study demonstrates, for the first time, technical feasibility to automate the identification of (i) a sitting segmental posture including individual trunk segments, (ii) changes away from that posture, and (iii) support from the upper limb, required for the clinical satco.","['cerebral palsy using deep learning', 'fully automated image', 'postural point', 'based estimation', 'features', 'children']"
"the microbiome-wide association studies are to figure out the relationship between microorganisms and humans, with the goal of discovering relevant biomarkers to guide disease diagnosis. however, the microbiome data is complex, with high noise and dimensions. traditional machine learning methods are limited by the models' representation ability and cannot learn complex patterns from the data. recently, deep learning has been widely applied to fields ranging from text processing to image recognition due to its efficient flexibility and high capacity. but the deep learning models must be trained with enough data in order to achieve good performance, which is impractical in reality. in addition, deep learning is considered as black box and hard to interpret. these factors make deep learning not widely used in microbiome-wide association studies. in this work, we construct a sparse microbial interaction network and embed this graph into deep model to alleviate the risk of overfitting and improve the performance. further, we explore a graph embedding deep feedforward network (gedfn) to conduct feature selection and guide meaningful microbial markers' identification. based on the experimental results, we verify the feasibility of combining the microbial graph model with the deep learning model, and demonstrate the feasibility of applying deep learning and feature selection on microbial data. our main contributions are: firstly, we utilize different methods to construct a variety of microbial interaction networks and combine the network via graph embedding deep learning. secondly, we introduce a feature selection method based on graph embedding and validate the biological meaning of microbial markers. the code is available at https://github.com/microava/gedfn.git.","['graph embedding deep learning guides microbial biomarkers', 'identification']"
"the deep cerebellar nuclei (dcn) have been suggested to play a critical role in sensorimotor learning and some forms of long-term synaptic plasticity observed in vitro have been proposed as a possible substrate. however, till now it was not clear whether and how dcn neuron responses manifest long-lasting changes in vivo. here, we have characterized dcn unit responses to tactile stimulation of the facial area in anesthetized mice and evaluated the changes induced by theta-sensory stimulation (tss), a 4 hz stimulation pattern that is known to induce plasticity in the cerebellar cortex in vivo. dcn units responded to tactile stimulation generating bursts and pauses, which reflected combinations of excitatory inputs most likely relayed by mossy fiber collaterals, inhibitory inputs relayed by purkinje cells, and intrinsic rebound firing. interestingly, initial bursts and pauses were often followed by stimulus-induced oscillations in the peri-stimulus time histograms (psth). tss induced long-lasting changes in dcn unit responses. spike-related potentiation and suppression (sr-p and sr-s), either in units initiating the response with bursts or pauses, were correlated with stimulus-induced oscillations. fitting with resonant functions suggested the existence of peaks in the theta-band (burst sr-p at 9 hz, pause sr-s at 5 hz). optogenetic stimulation of the cerebellar cortex altered stimulus-induced oscillations suggesting that purkinje cells play a critical role in the circuits controlling dcn oscillations and plasticity. this observation complements those reported before on the granular and molecular layers supporting the generation of multiple distributed plasticities in the cerebellum following naturally patterned sensory entrainment. the unique dependency of dcn plasticity on circuit oscillations discloses a potential relationship between cerebellar learning and activity patterns generated in the cerebellar network.","['lasting response changes', 'deep cerebellar nuclei', 'vivo correlate', 'frequency oscillations', 'low', 'long']"
to develop a deep learning-based computer-aided diagnosis (cad) system for use in the ct diagnosis of cervical lymph node metastasis (lnm) in patients with thyroid cancer.,"['cervical lymph node metastasis', 'thyroid cancer', 'deep learning', 'diagnosis', 'ct', 'application']"
"deep artificial neural network learning is an emerging tool in image analysis. we demonstrate its potential in the field of digital holographic microscopy by addressing the challenging problem of determining the in-focus reconstruction depth of madin-darby canine kidney cell clusters encoded in digital holograms. a deep convolutional neural network learns the in-focus depths from half a million hologram amplitude images. the trained network correctly determines the in-focus depth of new holograms with high probability, without performing numerical propagation. this paper reports on extensions to preliminary work published earlier as one of the first applications of deep learning in the field of digital holographic microscopy.","['digital holographic microscopy using deep convolutional neural networks', 'focus prediction']"
"isocitrate dehydrogenase (idh) mutation status is an important marker in glioma diagnosis and therapy. we propose an automated pipeline for noninvasively predicting idh status using deep learning and t2-weighted (t2w) magnetic resonance (mr) images with minimal preprocessing (n4 bias correction and normalization to zero mean and unit variance). t2w mr images and genomic data were obtained from the cancer imaging archive dataset for 260 subjects (120 high-grade and 140 low-grade gliomas). a fully automated two-dimensional densely connected model was trained to classify idh mutation status on 208 subjects and tested on another held-out set of 52 subjects using fivefold cross validation. data leakage was avoided by ensuring subject separation during the slice-wise randomization. mean classification accuracy of 90.5% was achieved for each axial slice in predicting the three classes of no tumor, idh mutated, and idh wild type. test accuracy of 83.8% was achieved in predicting idh mutation status for individual subjects on the test dataset of 52 subjects. we demonstrate a deep learning method to predict idh mutation status using t2w mri alone. radiologic imaging studies using deep learning methods must address data leakage (subject duplication) in the randomization process to avoid upward bias in the reported classification accuracy.","['brain tumor isocitrate dehydrogenase status using mri', 'deep learning', 'classification']"
"land cover classification and investigation of temporal changes are considered to be common applications of remote sensing. water/non-water region estimation is one of the most fundamental classification tasks, analyzing the occurrence of water on the earth's surface. however, common remote sensing practices such as thresholding, spectral analysis, and statistical approaches are not sufficient to produce a globally adaptable water classification. the aim of this study is to develop a formula with automatically derived tuning parameters using perceptron neural networks for water/non-water region estimation, which we call the perceptron-derived water formula (pdwf), using landsat-8 images. water/non-water region estimates derived from pdwf were compared with three different approaches-modified normalized difference water index (mndwi), automatic water extraction index (awei), and deep convolutional neural network-using various case studies. our proposed method outperforms all three approaches, showing a significant improvement in water/non-water region estimation. pdwf performance is consistently better even in cases of challenging conditions such as low reflectance due to hill shadows, building-shadows, and dark soils. moreover, our study implemented a sunglint correction to adapt water/non-water region estimation over sunglint-affected pixels.","['water region estimation using large', 'scale multispectral images', 'perceptron learning', 'investigation']"
"early identification of dementia at the stage of mild cognitive impairment (mci) is crucial for timely diagnosis and intervention of alzheimer's disease (ad). although several pioneering studies have been devoted to automated ad diagnosis based on resting-state functional magnetic resonance imaging (rs-fmri), their performance is somewhat limited due to non-effective mining of spatial-temporal dependency. besides, few of these existing approaches consider the explicit detection and modeling of discriminative brain regions (i.e., network hubs) that are sensitive to ad progression. in this paper, we propose a unique spatial-temporal convolutional-recurrent neural network (stnet) for automated prediction of ad progression and network hub detection from rs-fmri time series. our stnet incorporates the spatial-temporal information mining and ad-related hub detection into an end-to-end deep learning model. specifically, we first partition rs-fmri time series into a sequence of overlapping sliding windows. a sequence of convolutional components are then designed to capture the local-to-global spatially-dependent patterns within each sliding window, based on which we are able to identify discriminative hubs and characterize their unique contributions to disease diagnosis. a recurrent component with long short-term memory (lstm) units is further employed to model the whole-brain temporal dependency from the spatially-dependent pattern sequences, thus capturing the temporal dynamics along time. we evaluate our method on 174 subjects with 563 rs-fmri scans, with results suggesting the effectiveness of our method in disease prediction and hub detection.","['functional mri analysis via convolutional', 'temporal dependency modeling', 'network hub detection', 'recurrent network', 'spatial']"
"image intensity correction is crucial to enable cone beam computed tomography (cbct) based radiotherapy dose calculations. this study evaluated three different deep learning based correction methods using a u-shaped convolutional neural network architecture (unet) in terms of their photon and proton dose calculation accuracy. ct and cbct imaging data of 42 prostate cancer patients were included. for target ground truth data generation, a cbct correction method based on ct to cbct deformable image registration (dir) was used. the method yields a deformed ct called (i) virtual ct (vct) which is used to generate (ii) corrected cbct projections allowing the reconstruction of (iii) a final corrected cbct image. the single unet architecture was trained using these three different datasets: (unet1) raw and corrected cbct projections, (unet2) raw cbct and vct image slices and (unet3) raw and reference corrected cbct image slices. volumetric arc therapy (vmat) and proton pencil beam scanning (pbs) single field uniform dose (sfud) plans were optimized on the reference corrected image and recalculated on the obtained unet-corrected cbct images. the mean error (me) and mean absolute error (mae) for unet1/2/3 were [formula: see tex","['unsfield units', 'h']"
"given the recent advent in machine learning and artificial intelligence on medical data analysis, we hypothesized that the deep learning algorithm can classify resting needle electromyography (n-emg) discharges.","['resting needle electromyography signals', 'waveform identification', 'deep learning']"
"practical motor imagery electroencephalogram (eeg) data-based applications are limited by the waste of unlabeled samples in supervised learning and excessive time consumption in the pretraining period. a semisupervised deep stacking network with an adaptive learning rate strategy (sadsn) is proposed to solve the sample loss caused by supervised learning of eeg data and the extraction of manual features. the sadsn adopts the idea of an adaptive learning rate into a contrastive divergence (cd) algorithm to accelerate its convergence. prior knowledge is introduced into the intermediary layer of the deep stacking network, and a restricted boltzmann machine is trained by a semisupervised method in which the adjusting scope of the coefficient in learning rate is determined by performance analysis. several eeg data sets are carried out to evaluate the performance of the proposed method. the results show that the recognition accuracy of sadsn is advanced with a more significant convergence rate and successfully classifies motor imagery.","['semisupervised deep stacking network', 'motor imagery eeg recognition', 'adaptive learning rate strategy']"
"data science is likely to lead to major changes in cardiovascular imaging. problems with timing, efficiency, and missed diagnoses occur at all stages of the imaging chain. the application of artificial intelligence (ai) is dependent on robust data; the application of appropriate computational approaches and tools; and validation of its clinical application to image segmentation, automated measurements, and eventually, automated diagnosis. ai may reduce cost and improve value at the stages of image acquisition, interpretation, and decision-making. moreover, the precision now possible with cardiovascular imaging, combined with ""big data"" from the electronic health record and pathology, is likely to better characterize disease and personalize therapy. this review summarizes recent promising applications of ai in cardiology and cardiac imaging, which potentially add value to patient care.","['jacc state', 'cardiovascular imaging', 'artificial intelligence', 'art review']"
"we combine a generative adversarial network (gan) with light microscopy to achieve deep learning super-resolution under a large field of view (fov). by appropriately adopting prior microscopy data in an adversarial training, the neural network can recover a high-resolution, accurate image of new specimen from its single low-resolution measurement. its capacity has been broadly demonstrated via imaging various types of samples, such as usaf resolution target, human pathological slides, fluorescence-labelled fibroblast cells, and deep tissues in transgenic mouse brain, by both wide-field and light-sheet microscopes. the gigapixel, multi-color reconstruction of these samples verifies a successful gan-based single image super-resolution procedure. we also propose an image degrading model to generate low resolution images for training, making our approach free from the complex image registration during training data set preparation. after a well-trained network has been created, this deep learning-based imaging approach is capable of recovering a large fov (~95 mm2) enhanced resolution of ~1.7 μm at high speed (within 1 second), while not necessarily introducing any changes to the setup of existing microscopes.","['resolution deep learning microscopy based', 'free generative adversarial network', 'throughput', 'registration', 'high']"
"this paper presents an algorithm for non-invasive sleep stage identification using respiratory, heart rate and movement signals. the algorithm is part of a system suitable for long-term monitoring in a home environment, which should support experts analysing sleep.","['automatic sleep stages classification using respiratory', 'movement signals', 'heart rate']"
this work aims to develop a new framework of image quality assessment using deep learning-based model observer (dl-mo) and to validate it in a low-contrast lesion detection task that involves ct images with patient anatomical background.,"['partial least square regression', 'contrast lesion detection task', 'based model observer', 'deep learning', 'low', 'ct']"
"this study classifies sleep stages from a single lead electrocardiogram (ecg) using beat detection, cardiorespiratory coupling in the time-frequency domain and a deep convolutional neural network (cnn).","['time frequency domain', 'sleep staging', 'lead electrocardiogram', 'deep learning', 'single', 'cross']"
"synthesis planning is the process of recursively decomposing target molecules into available precursors. computer-aided retrosynthesis can potentially assist chemists in designing synthetic routes; however, at present, it is cumbersome and cannot provide satisfactory results. in this study, we have developed a template-free self-corrected retrosynthesis predictor (scrop) to predict retrosynthesis using transformer neural networks. in the method, the retrosynthesis planning was converted to a machine translation problem from the products to molecular linear notations of the reactants. by coupling with a neural network-based syntax corrector, our method achieved an accuracy of 59.0% on a standard benchmark data set, which outperformed other deep learning methods by >21% and template-based methods by >6%. more importantly, our method was 1.7 times more accurate than other state-of-the-art methods for compounds not appearing in the training set.","['predicting retrosynthetic reactions using self', 'corrected transformer neural networks']"
"minimally invasive surgery is often built upon a time-consuming preoperative step consisting of segmentation and trajectory planning. at the temporal bone, a complete automation of these two tasks might lead to faster interventions and more reproducible results, benefiting clinical workflow and patient health.","['guided temporal bone surgery', 'automatic preoperative pipeline', 'toward', 'image']"
"a major challenge in cancer treatment is predicting clinical response to anti-cancer drugs on a personalized basis. using a pharmacogenomics database of 1,001 cancer cell lines, we trained deep neural networks for prediction of drug response and assessed their performance on multiple clinical cohorts. we demonstrate that deep neural networks outperform the current state in machine learning frameworks. we provide a proof of concept for the use of deep neural network-based frameworks to aid precision oncology strategies.","['deep learning framework', 'predicting response', 'therapy', 'cancer']"
"recent advances in large-scale single-cell rna-seq enable fine-grained characterization of phenotypically distinct cellular states in heterogeneous tissues. we present scscope, a scalable deep-learning-based approach that can accurately and rapidly identify cell-type composition from millions of noisy single-cell gene-expression profiles.","['cell transcriptomics using deep recurrent learning', 'type composition', 'scalable analysis', 'cell', 'single']"
to analyze the implementation of deep learning software for the detection and worklist prioritization of acute intracranial hemorrhage on non-contrast head ct (ncct) in various clinical settings\xa0at an academic medical center.,"['head ct scans flagged', 'deep learning software', 'acute intracranial hemorrhage', 'analysis']"
"in this paper, we propose bag of adversarial features (bafs) for identifying mild traumatic brain injury (mtbi) patients from their diffusion magnetic resonance images (mris) (obtained within one month of injury) by incorporating unsupervised feature learning techniques. mtbi is a growing public health problem with an estimated incidence of over 1.7 million people annually in usa. diagnosis is based on clinical history and symptoms, and accurate, concrete measures of injury are lacking. unlike most of the previous works, which use hand-crafted features extracted from different parts of brain for mtbi classification, we employ feature learning algorithms to learn more discriminative representation for this task. a major challenge in this field thus far is the relatively small number of subjects available for training. this makes it difficult to use an end-to-end convolutional neural network to directly classify a subject from mris. to overcome this challenge, we first apply an adversarial auto-encoder (with convolutional structure) to learn patch-level features, from overlapping image patches extracted from different brain regions. we then aggregate these features through a bag-of-words approach. we perform an extensive experimental study on a dataset of 227 subjects (including 109 mtbi patients, and 118 age and sex-matched healthy controls) and compare the bag-of-deep-features with several previous approaches. our experimental results show that the baf significantly outperforms earlier works relying on the mean values of mr metrics in selected brain regions.","['diffusion mr images using bag', 'adversarial visual features', 'mtbi identification']"
"deep learning has been recently applied to a multitude of computer vision and medical image analysis problems. although recent research efforts have improved the state of the art, most of the methods cannot be easily accessed, compared or used by other researchers or clinicians. even if developers publish their code and pre-trained models on the internet, integration in stand-alone applications and existing workflows is often not straightforward, especially for clinical research partners. in this paper, we propose an open-source framework to provide ai-enabled medical image analysis through the network.","['resolution medical image analysis', 'cloud deployment', 'tomaat', 'high']"
"this paper outlines typical terminology for modeling and highlights key historical and forthcoming aspects of mathematical modeling. mathematical models (mm) are mental conceptualizations, enclosed in a virtual domain, whose purpose is to translate real-life situations into mathematical formulations to describe existing patterns or forecast future behaviors in real-life situations. the appropriateness of the virtual representation of real-life situations through mm depends on the modeler's ability to synthesize essential concepts and associate their interrelationships with measured data. the development of mm paralleled the evolution of digital computing. the scientific community has only slightly accepted and used mm, in part because scientists are trained in experimental research and not systems thinking. the scientific advancements in ruminant production have been tangible but incipient because we are still learning how to connect experimental research data and concepts through mm, a process that is still obscure to many scientists. our inability to ask the right questions and to define the boundaries of our problem when developing models might have limited the breadth and depth of mm in agriculture. artificial intelligence (ai) has been developed in tandem with the need to analyze big data using high-performance computing. however, the emergence of ai, a computational technology that is data-intensive and requires less systems thinking of how things are interrelated, may further reduce the interest in mechanistic, conceptual mm. artificial intelligence might provide, however, a paradigm shift in mm, including nutrition modeling, by creating novel opportunities to understand the underlying mechanisms when integrating large amounts of quantifiable data. associating ai with mechanistic models may eventually lead to the development of hybrid mechanistic machine-learning modeling. modelers must learn how to integrate powerful data-driven tools and knowledge-driven approaches into functional models that are sustainable and resilient. the successful future of mm might rely on the development of redesigned models that can integrate existing technological advancements in data analytics to take advantage of accumulated scientific knowledge. however, the next evolution may require the creation of novel technologies for data gathering and analyses and the rethinking of innovative mm concepts rather than spending resources in collecting futile data or amending old technologies.","['upcoming predictive analytics1', 'mathematical modeling', 'extant models', 'data analytics', 'asas symposium', 'ruminant nutrition', 'nutrition', 'thoughts', 'paradigms', 'future', 'asn', 'approaches', '2']"
"learning 3d global features by aggregating multiple views is important. pooling is widely used to aggregate views in deep learning models. however, pooling disregards a lot of content information within views and the spatial relationship among the views, which limits the discriminability of learned features. to resolve this issue, 3d to sequential views (3d2seqviews) is proposed to more effectively aggregate the sequential views using convolutional neural networks with a novel hierarchical attention aggregation. specifically, the content information within each view is first encoded. then, the encoded view content information and the sequential spatiality among the views are simultaneously aggregated by the hierarchical attention aggregation, where view-level attention and class-level attention are proposed to hierarchically weight sequential views and shape classes. view-level attention is learned to indicate how much attention is paid to each view by each shape class, which subsequently weights sequential views through a novel recursive view integration. recursive view integration learns the semantic meaning of view sequence, which is robust to the first view position. furthermore, class-level attention is introduced to describe how much attention is paid to each shape class, which innovatively employs the discriminative ability of the fine-tuned network. 3d2seqviews learns more discriminative features than the state-of-the-art, which leads to the outperforming results in shape classification and retrieval under three large-scale benchmarks.","['3d global feature learning', 'hierarchical attention aggregation', 'aggregating sequential views', 'cnn', '3d2seqviews']"
"computer aided diagnosis using artificial intelligent techniques made tremendous improvement in medical applications especially for easy detection of tumor area, tumor type and grades. this paper presents automatic glioma tumor grade identification from magnetic resonant images using wndchrm tool based classifier (weighted neighbour distance using compound heirarchy of algorithms representing morphology) and vgg-19 deep convolutional neural network (dnn). for experimentation, dicom images are collected from reputed government hospital and the proposed intelligent system categorized the tumor into four grades such as low grade glioma, oligodendroglioma, anaplastic glioma and glioblastoma multiform. after preprocessing, features are extracted, optimized and then classified using windchrm tool where the most significant features are selected on the basis of fisher score. in the case of dnn classifier, data augmentation is also performed before applying the images into the deep learning network. the performance of the classifiers are analysed with various measures such as accuracy, precision, sensitivity, specificity and f1-score. the results showed reasonably good performance with a maximum classification accuracy of 92.86% for the wndchrm classifier and 98.25% for vgg-19 dnn classifier. the results are also compared with similar recent works and the proposed system is found to have better performance.",['glioma tumor grade identification using artificial intelligent techniques']
"electrocorticography (ecog) based studies generally analyze features from specific frequency bands selected by manual evaluation of spectral power. however, the definition of these features can vary across subjects, cortical areas, tasks and across time for a given subject. we propose an autoencoder based approach for summarizing ecog data with 'template spectrograms', i.e. informative time-frequency (t-f) patterns, and demonstrate their efficacy in two contexts: brain-computer interfaces (bcis) and functional brain mapping.","['learning template spectrograms', 'electrocorticographic signals', 'autoencoders']"
"breast cancer is the most common female malignancy among women. sentinel lymph node (sln) status is a crucial prognostic factor for breast cancer. in this paper, we propose an integrated scheme of deep learning and bag-of-features (bof) model for preoperative prediction of sln metastasis. specifically, convolution neural networks (cnns) are used to extract deep features from the three 2d representative orthogonal views of a segmented 3d volume of interest. then, we use a bof model to furtherly encode the all deep features, which makes features more compact and products high-dimension sparse representation. in particular, a kernel fusion method that assembles all features is proposed to build a discriminative support vector machine (svm) classifier. the bag of deep feature model is evaluated using the diffusion-weighted magnetic resonance imaging (dwi) database of 172 patients, including 74 sln and 98 non-sln. the results show that the proposed method achieves area under the curve (auc) as high as 0.852 (95% confidence interval (ci): 0.716-0.988) at test set. the results demonstrate that the proposed model can potentially provide a noninvasive approach for automatically predicting prediction of sln metastasis in patients with breast cancer.","['sentinel lymph node metastasis', 'preoperative prediction', 'deep features', 'breast cancer', 'bag']"
"virus diseases are of high concern in the cultivation of seed potatoes. once found in the field, virus diseased plants lead to declassification or even rejection of the seed lots resulting in a financial loss. farmers put in a lot of effort to detect diseased plants and remove virus-diseased plants from the field. nevertheless, dependent on the cultivar, virus diseased plants can be missed during visual observations in particular in an early stage of cultivation. therefore, there is a need for fast and objective disease detection. early detection of diseased plants with modern vision techniques can significantly reduce costs. laboratory experiments in previous years showed that hyperspectral imaging clearly could distinguish healthy from virus infected potato plants. this paper reports on our first real field experiment. a new imaging setup was designed, consisting of a hyperspectral line-scan camera. hyperspectral images were taken in the field with a line interval of 5 mm. a fully convolutional neural network was adapted for hyperspectral images and trained on two experimental rows in the field. the trained network was validated on two other rows, with different potato cultivars. for three of the four row/date combinations the precision and recall compared to conventional disease assessment exceeded 0.78 and 0.88, respectively. this proves the suitability of this method for real world disease detection.","['seed potatoes using deep learning', 'potato virus', 'hyperspectral images', 'detection']"
"background and purpose- the prediction of long-term outcomes in ischemic stroke patients may be useful in treatment decisions. machine learning techniques are being increasingly adapted for use in the medical field because of their high accuracy. this study investigated the applicability of machine learning techniques to predict long-term outcomes in ischemic stroke patients. methods- this was a retrospective study using a prospective cohort that enrolled patients with acute ischemic stroke. favorable outcome was defined as modified rankin scale score 0, 1, or 2 at 3 months. we developed 3 machine learning models (deep neural network, random forest, and logistic regression) and compared their predictability. to evaluate the accuracy of the machine learning models, we also compared them to the acute stroke registry and analysis of lausanne (astral) score. results- a total of 2604 patients were included in this study, and 2043 (78%) of them had favorable outcomes. the area under the curve for the deep neural network model was significantly higher than that of the astral score (0.888 versus 0.839; p<0.001), while the areas under the curves of the random forest (0.857; p=0.136) and logistic regression (0.849; p=0.413) models were not significantly higher than that of the astral score. using only the 6 variables that are used for the astral score, the performance of the machine learning models did not significantly differ from that of the astral score. conclusions- machine learning algorithms, particularly the deep neural network, can improve the prediction of long-term outcomes in ischemic stroke patients.","['machine learning', 'based model', 'acute stroke', 'prediction', 'outcomes']"
"accurate segmentation of prostate and surrounding organs at risk is important for prostate cancer radiotherapy treatment planning. we present a fully automated workflow for male pelvic ct image segmentation using deep learning. the architecture consists of a 2d organ volume localization network followed by a 3d segmentation network for volumetric segmentation of prostate, bladder, rectum, and femoral heads. we used a multi-channel 2d u-net followed by a 3d u-net with encoding arm modified with aggregated residual networks, known as resnext. the models were trained and tested on a pelvic ct image dataset comprising 136 patients. test results show that 3d u-net based segmentation achieves mean (±sd) dice coefficient values of 90 (±2.0)%, 96 (±3.0)%, 95 (±1.3)%, 95 (±1.5)%, and 84 (±3.7)% for prostate, left femoral head, right femoral head, bladder, and rectum, respectively, using the proposed fully automated segmentation method.","['male pelvic ct images', 'fully automated organ segmentation']"
"the ability to predict which pairs of amino acid residues in a protein are in contact with each other offers many advantages for various areas of research that focus on proteins. for example, contact prediction can be used to reduce the computational complexity of predicting the structure of proteins and even to help identify functionally important regions of proteins. these predictions are becoming especially important given the relatively low number of experimentally determined protein structures compared to the amount of available protein sequence data.","['residue contacts using random forests', 'predicting protein residue', 'deep networks']"
"hashing plays a pivotal role in nearest-neighbor searching for large-scale image retrieval. recently, deep learning-based hashing methods have achieved promising performance. however, most of these deep methods involve discriminative models, which require large-scale, labeled training datasets, thus hindering their real-world applications. in this paper, we propose a novel strategy to exploit the semantic similarity of the training data and design an efficient generative adversarial framework to learn binary hash codes in an unsupervised manner. specifically, our model consists of three different neural networks: an encoder network to learn hash codes from images, a generative network to generate images from hash codes, and a discriminative network to distinguish between pairs of hash codes and images. by adversarially training these networks, we successfully learn mutually coherent encoder and generative networks, and can output efficient hash codes from the encoder network. we also propose a novel strategy, which utilizes both feature and neighbor similarities, to construct a semantic similarity matrix, then use this matrix to guide the hash code learning process. integrating the supervision of this semantic similarity matrix into the adversarial learning framework can efficiently preserve the semantic information of training data in hamming space. the experimental results on three widely used benchmarks show that our method not only significantly outperforms several state-of-the-art unsupervised hashing methods, but also achieves comparable performance with popular supervised hashing methods.","['preserving adversarial hashing', 'unsupervised semantic', 'image search']"
"we present a deep neural network to reduce coherent noise in three-dimensional quantitative phase imaging. inspired by the cycle generative adversarial network, the denoising network was trained to learn a transform between two image domains: clean and noisy refractive index tomograms. the unique feature of this network, distinct from previous machine learning approaches employed in the optical imaging problem, is that it uses unpaired images. the learned network quantitatively demonstrated its performance and generalization capability through denoising experiments of various samples. we concluded by applying our technique to reduce the temporally changing noise emerging from focal drift in time-lapse imaging of biological cells. this reduction cannot be performed using other optical methods for denoising.","['consistent deep learning approach', 'optical diffraction tomography', 'coherent noise reduction', 'cycle']"
"we propose an attention-based method that aggregates local image features to a subject-level representation for predicting disease severity. in contrast to classical deep learning that requires a fixed dimensional input, our method operates on a set of image patches; hence it can accommodate variable length input image without image resizing. the model learns a clinically interpretable subject-level representation that is reflective of the disease severity. our model consists of three mutually dependent modules which regulate each other: (1) a discriminative network that learns a fixed-length representation from local features and maps them to disease severity; (2) an attention mechanism that provides interpretability by focusing on the areas of the anatomy that contribute the most to the prediction task; and (3) a generative network that encourages the diversity of the local latent features. the generative term ensures that the attention weights are non-degenerate while maintaining the relevance of the local regions to the disease severity. we train our model end-to-end in the context of a large-scale lung ct study of chronic obstructive pulmonary disease (copd). our model gives state-of-the art performance in predicting clinical measures of severity for copd.the distribution of the attention provides the regional relevance of lung tissue to the clinical measurements.","['image patches', 'discriminative approach', 'vector', 'subject2vec', 'set', 'generative']"
"machine learning, especially deep learning, has the predictive power to predict adverse drug reactions, repurpose drugs and perform precision medicine. we provide a background of machine learning and propose a potential high-performance deep learning framework for its successful applications in these practices.","['adverse drug reactions', 'machine learning', 'pharmacovigilance']"
"computational intelligence re-meets medical image processing a comparison of some nature-inspired optimization metaheuristics applied in biomedical image registration background: \u2003diffuse lung diseases (dlds) are a diverse group of pulmonary disorders, characterized by inflammation of lung tissue, which may lead to permanent loss of the ability to breathe and death. distinguishing among these diseases is challenging to physicians due their wide variety and unknown causes. computer-aided diagnosis (cad) is a useful approach to improve diagnostic accuracy, by combining information provided by experts with machine learning (ml) methods.","['machine learning algorithms', 'diffuse lung diseases', 'diagnosis', 'analysis']"
"the term ""socratic method"" is so pervasive in education across the disciplines that it has largely lost its meaning, and it has lost its roots in its originator-the historical socrates. in this article we draw from the original source, plato\'s ancient dialogues, to understand the theory and principles behind the questioning used in socratic method. a deep understanding of socratic method is particularly timely now as nursing leaders call for increased use of theory-based debriefing across the nursing curriculum. socratic questioning is ideally suited as a method for debriefing in nursing classrooms because of its ability to enhance critical thinking and self-reflection of the learner and because of its basis in care for the learner through a learner-centred design. we present an analysis of the socratic method in plato\'s works and provide an overview of the key socratic principles and techniques. we illustrate these principles and techniques with examples of how socratic teaching can be applied in the nursing classroom, and we address the challenges and rewards for nursing faculty implementing socratic method. learning about socratic method directly from plato\'s dialogues can provide a richer and more robust understanding of this key pedagogical technique and help nurse educators practice more intentional and informed socratic questioning and debriefing.","['putting socrates back', 'socratic method', 'nursing classroom', 'based debriefing', 'theory']"
"compressive sensing (cs) offers compression of data below the nyquist rate, making it an attractive solution in the field of medical imaging, and has been extensively used for ultrasound (us) compression and sparse recovery. in practice, cs offers a reduction in data sensing, transmission, and storage. compressive sensing relies on the sparsity of data; i.e., data should be sparse in original or in some transformed domain. a look at the literature reveals that rich variety of algorithms have been suggested to recover data using compressive sensing from far fewer samples accurately, but with tradeoffs for efficiency. this paper reviews a number of significant cs algorithms used to recover us images from the undersampled data along with the discussion of cs in 3d us images. in this paper, sparse recovery algorithms applied to us are classified in five groups. algorithms in each group are discussed and summarized based on their unique technique, compression ratio, sparsifying transform, 3d ultrasound, and deep learning. research gaps and future directions are also discussed in the conclusion of this paper. this study is aimed to be beneficial for young researchers intending to work in the area of cs and its applications, specifically to us.","['ultrasound images', 'compressive sensing', 'review', 'application']"
"in recent years, an increasing number of distribution maps of invasive alien plant species (iaps) have been published using different machine learning algorithms (mlas). however, for designing spatially explicit management strategies, distribution maps should include information on the local cover/abundance of the iaps. this study compares the performances of five mlas: gradient boosting machine in two different implementations, random forest, support vector machine and deep learning neural network, one ensemble model and a generalized linear model; thereby identifying the best-performing ones in mapping the fractional cover/abundance and distribution of ipas, in this case called prosopis juliflora (sw. dc.). field level prosopis cover and spatial datasets of seventeen biophysical and anthropogenic variables were collected, processed, and used to train and validate the algorithms so as to generate fractional cover maps of prosopis in the dryland ecosystem of the afar region, ethiopia. out of the seven tested algorithms, random forest performed the best with an accuracy of 92% and sensitivity and specificity >0.89. the next best-performing algorithms were the ensemble model and gradient boosting machine with an accuracy of 89% and 88%, respectively. the other tested algorithms achieved comparably low performances. the strong explanatory variables for prosopis distributions in all models were ndvi, elevation, distance to villages and distance to rivers; rainfall, temperature, near-infrared and red reflectance, whereas topographic variables, except for elevation, did not contribute much to the current distribution of prosopis. according to the random forest model, a total of 1.173\xa0million ha (12.33% of the study region) was found to be invaded by prosopis to varying degrees of cover. our findings demonstrate that mlas can be successfully used to develop fractional cover maps of plant species, particularly iaps so as to design targeted and spatially explicit management strategies.","['mapping fractional cover', 'machine learning algorithms', 'invasive plant species', 'dryland ecosystem', 'performances']"
"understanding of the neuroscientific sleep mechanisms is associated with mental/cognitive and physical well-being and pathological conditions. a prerequisite for further analysis is the identification of the sleep macroarchitecture through manual sleep staging. several computer-based approaches have been proposed to extract time and/or frequency-domain features with accuracy ranging from 80% to 95% compared with the golden standard of manual staging. however, their acceptability by the medical community is still suboptimal. recently, utilizing deep learning methodologies increased the research interest in computer-assisted recognition of sleep stages. aiming to enhance the arsenal of automatic sleep staging, we propose a novel classification framework based on convolutional neural networks. these receive as input synchronizations features derived from cortical interactions within various electroencephalographic rhythms (delta, theta, alpha, and beta) for specific cortical regions which are critical for the sleep deepening. these functional connectivity metrics are then processed as multidimensional images. we also propose to augment the small portion of sleep onset (n1 stage) through the synthetic minority oversampling technique in order to deal with the great difference in its duration when compared with the remaining sleep stages. our results (99.85%) indicate the flexibility of deep learning techniques to learn sleep-related neurophysiological patterns.","['automatic sleep staging employing convolutional neural networks', 'cortical connectivity images']"
"case-based reasoning (cbr) is a form of analogical reasoning in which the solution for a (new) query case is determined using a database of previous known cases with their solutions. cases similar to the query are retrieved from the database, and then their solutions are adapted to the query. in medicine, a case usually corresponds to a patient and the problem consists of classifying the patient in a class of diagnostic or therapy. compared to ""black box"" algorithms such as deep learning, the responses of cbr systems can be justified easily using the similar cases as examples. however, this possibility is often under-exploited and the explanations provided by most cbr systems are limited to the display of the similar cases. in this paper, we propose a cbr method that can be both executed automatically as an algorithm and presented visually in a user interface for providing visual explanations or for visual reasoning. after retrieving similar cases, a visual interface displays quantitative and qualitative similarities between the query and the similar cases, so as one can easily classify the query through visual reasoning, in a fully explainable manner. it combines a quantitative approach (visualized by a scatter plot based on multidimensional scaling in polar coordinates, preserving distances involving the query) and a qualitative approach (set visualization using rainbow boxes). we applied this method to breast cancer management. we showed on three public datasets that our qualitative method has a classification accuracy comparable to k-nearest neighbors algorithms, but is better explainable. we also tested the proposed interface during a small user study. finally, we apply the proposed approach to a real dataset in breast cancer. medical experts found the visual approach interesting as it explains why cases are similar through the visualization of shared patient characteristics.","['explainable artificial intelligence', 'based reasoning approach', 'visual case', 'breast cancer']"
"this article reviews current limitations and future opportunities for the application of computer-aided detection (cad) systems and artificial intelligence in breast imaging. traditional cad systems in mammography screening have followed a rules-based approach, incorporating domain knowledge into hand-crafted features before using classical machine learning techniques as a classifier. the first commercial cad system, imagechecker m1000, relies on computer vision techniques for pattern recognition. unfortunately, cad systems have been shown to adversely affect some radiologists' performance and increase recall rates. the digital mammography dream challenge was a multidisciplinary collaboration that provided 640,000 mammography images for teams to help decrease false-positive rates in breast cancer screening. winning solutions leveraged deep learning's (dl) automatic hierarchical feature learning capabilities and used convolutional neural networks. start-ups therapixel and kheiron medical technologies are using dl for breast cancer screening. with increasing use of digital breast tomosynthesis, specific artificial intelligence (ai)-cad systems are emerging to include icad's powerlook tomo detection and screenpoint medical's transpara. other ai-cad systems are focusing on breast diagnostic techniques such as ultrasound and magnetic resonance imaging (mri). there is a gap in the market for contrast-enhanced spectral mammography ai-cad tools. clinical implementation of ai-cad tools requires testing in scenarios mimicking real life to prove its usefulness in the clinical environment. this requires a large and representative dataset for testing and assessment of the reader's interaction with the tools. a cost-effectiveness assessment should be undertaken, with a large feasibility study carried out to ensure there are no unintended consequences. ai-cad systems should incorporate explainable ai in accordance with the european union general data protection regulation (gdpr).","['breast imaging', 'artificial intelligence']"
"while predicting the secondary structure of rna is vital for researching its function, determining rna secondary structure is challenging, especially for that with pseudoknots. typically, several excellent computational methods can be utilized to predict the secondary structure (with or without pseudoknots), but they have their own merits and demerits. these methods can be classified into two categories: the multi-sequence method and the single-sequence method. the main advantage of the multi-sequence method lies in its use of the auxiliary sequences to assist in predicting the secondary structure, but it can only successfully predict in the presence of multiple highly homologous sequences. the single-sequence method is associated with the major merit of easy operation (only need the target sequence to predict secondary structure), but its folding parameters are the common features of diversity rna, which cannot describe the unique characteristics of rna, thus potentially resulting in the low prediction accuracy in some rna. in this paper, ""dmfold,"" a method based on the deep learning and improved base pair maximization principle, is proposed to predict the secondary structure with pseudoknots, which fully absorbs the advantages and avoids some disadvantages of those two methods. notably, dmfold could predict the secondary structure of rna by learning similar rna in the known structures, which uses the similar rna sequences instead of the highly homogeneous sequences in the multi-sequence method, thereby reducing the requirement for auxiliary sequences. in dmfold, it only needs to input the target sequence to predict the secondary structure. its folding parameters are fully extracted automatically by deep learning, which could avoid the lack of folding parameters in the single-sequence method. experiments show that our method is not only simple to operate, but also improves the prediction accuracy compared to multiple excellent prediction methods. a repository containing our code can be found at https://github.com/linyuwangphd/rna-secondary-structure-database.","['improved base pair maximization principle', 'predict rna secondary structure', 'pseudoknots based', 'novel method', 'deep learning', 'dmfold']"
"recent advances in deep learning methods have redefined the state-of-the-art for many medical imaging applications, surpassing previous approaches and sometimes even competing with human judgment in several tasks. those models, however, when trained to reduce the empirical risk on a single domain, fail to generalize when applied to other domains, a very common scenario in medical imaging due to the variability of images and anatomical structures, even across the same imaging modality. in this work, we extend the method of unsupervised domain adaptation using self-ensembling for the semantic segmentation task and explore multiple facets of the method on a small and realistic publicly-available magnetic resonance (mri) dataset. through an extensive evaluation, we show that self-ensembling can indeed improve the generalization of the models even when using a small amount of unlabeled data.","['unsupervised domain adaptation', 'medical imaging segmentation', 'self', 'ensembling']"
current approaches to identifying individuals at high risk for opioid overdose target many patients who are not truly at high risk.,"['predicting opioid overdose risk among medicare beneficiaries', 'opioid prescriptions', 'learning algorithms', 'machine', 'evaluation']"
grading of meningiomas is important in the choice of the most effective treatment for each patient.,"['preliminary study', 'mr images', 'histopathological grading', 'deep learning', 'meningiomas', 'differentiate', 'accuracy']"
"urban areas feature complex and heterogeneous land covers which create challenging issues for tree species classification. the increased availability of high spatial resolution multispectral satellite imagery and lidar datasets combined with the recent evolution of deep learning within remote sensing for object detection and scene classification, provide promising opportunities to map individual tree species with greater accuracy and resolution. however, there are knowledge gaps that are related to the contribution of worldview-3 swir bands, very high resolution pan band and lidar data in detailed tree species mapping. additionally, contemporary deep learning methods are hampered by lack of training samples and difficulties of preparing training data. the objective of this study was to examine the potential of a novel deep learning method, dense convolutional network (densenet), to identify dominant individual tree species in a complex urban environment within a fused image of worldview-2 vnir, worldview-3 swir and lidar datasets. densenet results were compared against two popular machine classifiers in remote sensing image analysis, random forest (rf) and support vector machine (svm). our results demonstrated that: (1) utilizing a data fusion approach beginning with vnir and adding swir, lidar, and panchromatic (pan) bands increased the overall accuracy of the densenet classifier from 75.9% to 76.8%, 81.1% and 82.6%, respectively. (2) densenet significantly outperformed rf and svm for the classification of eight dominant tree species with an overall accuracy of 82.6%, compared to 51.8% and 52% for svm and rf classifiers, respectively. (3) densenet maintained superior performance over rf and svm classifiers under restricted training sample quantities which is a major limiting factor for deep learning techniques. overall, the study reveals that densenet is more effective for urban tree species classification as it outperforms the popular rf and svm techniques when working with highly complex image scenes regardless of training sample size.","['urban tree species classification using', 'lidar data fusion approach', 'deep learning', 'worldview', '3', '2']"
this study suggests a lifelong learning-based convolutional neural network (ll-cnn) algorithm as a superior alternative to single-task learning approaches for automatic segmentation of head and neck (oars) organs at risk.,"['risk using deep lifelong learning', 'convolutional neural network algorithm', 'neck organs', 'automatic segmentation', 'head']"
"learning approaches have been proposed to affect the experience of psychological stress among tertiary students in recent years. this relationship becomes important in stressful environments such as medical schools. however, the relationship between stress and learning approaches is not well understood, and often studies done cannot be generalized due to different sociocultural differences. in particular, no study in malaysia has looked at learning approaches among medical students.","['perceived stress among medical students', 'sectional examination', 'relationship', 'malaysia', 'learning', 'cross', 'approaches']"
"antimicrobial resistance extracts high morbidity, mortality and economic costs yearly by rendering bacteria immune to antibiotics. identifying and understanding antimicrobial resistance are imperative for clinical practice to treat resistant infections and for public health efforts to limit the spread of resistance. technologies such as next-generation sequencing are expanding our abilities to detect and study antimicrobial resistance. this review provides a detailed overview of antimicrobial resistance identification and characterization methods, from traditional antimicrobial susceptibility testing to recent deep-learning methods. we focus on sequencing-based resistance discovery and discuss tools and databases used in antimicrobial resistance studies.","['study antimicrobial resistance', 'based methods', 'sequencing', 'resources']"
"the automatic classification of breast cancer histopathological images has great significance in computer-aided diagnosis. recently, deep learning via neural networks has enabled pattern detection and prediction using large, labeled datasets; whereas, collecting and annotating sufficient histological data using professional pathologists is time consuming, tedious, and extremely expensive. in the proposed paper, a deep active learning framework is designed and implemented for classification of breast cancer histopathological images, with the goal of maximizing the learning accuracy from very limited labeling. this method involves manual annotation of the most valuable unlabeled samples, which are then integrated into the training set. the model is then iteratively updated with an increasing training set. here, two selection strategies are discussed for the proposed deep active learning framework: an entropy-based strategy and a confidence-boosting strategy. the proposed method has been validated using a publicly available breast cancer histopathological image dataset, wherein each image patch is binarily classified as benign or malignant. the experimental results demonstrate that, compared with a random selection, our proposed framework can reduce annotation costs up to 66.67%, with higher accuracy and less expensive annotation than standard query strategy.","['efficient breast cancer histopathological image classification', 'label']"
"the convolutional neural network (cnn), one of the deep learning models, has demonstrated outstanding performance in a variety of computer vision tasks. however, as the network architectures become deeper and more complex, designing cnn architectures requires more expert knowledge and trial and error. in this article, we attempt to automatically construct high-performing cnn architectures for a given task. our method uses cartesian genetic programming (cgp) to encode the cnn architectures, adopting highly functional modules such as a convolutional block and tensor concatenation, as the node functions in cgp. the cnn structure and connectivity, represented by the cgp, are optimized to maximize accuracy using the evolutionary algorithm. we also introduce simple techniques to accelerate the architecture search: rich initialization and early network training termination. we evaluated our method on the cifar-10 and cifar-100 datasets, achieving competitive performance with state-of-the-art models. remarkably, our method can find competitive architectures with a reasonable computational cost compared to other automatic design methods that require considerably more computational time and machine resources.","['deep convolutional neural networks using cartesian genetic programming', 'evolution']"
"deep learning has become the new state-of-the-art for many problems in image analysis. however, large datasets are often required for such deep networks to learn effectively. this poses a difficult challenge for many medical image analysis problems in which only a small number of subjects are available, e.g., patients undergoing a new treatment. in this work, we propose a number of approaches for learning generalizable recurrent neural networks from smaller task-fmri datasets: 1) a resampling method for roi-based fmri analysis to create augmented data; 2) inclusion of a small number of non-imaging variables to provide subject-specific initialization of the recurrent neural network; and 3) selection of the most generalizable model from multiple reinitialized training runs using criteria based on only training loss. using cross-validation to assess model performance, we demonstrate the effectiveness of the proposed methods to train recurrent neural networks from small datasets to predict treatment outcome for children with autism spectrum disorder (n = 21) and classify autistic vs. typical control subjects (n = 40) from task-fmri scans.","['learning generalizable recurrent neural networks', 'small task', 'fmri datasets']"
"current harvesting robots are limited by low detection rates due to the unstructured and dynamic nature of both the objects and the environment. state-of-the-art algorithms include color- and texture-based detection, which are highly sensitive to the illumination conditions. deep learning algorithms promise robustness at the cost of significant computational resources and the requirement for intensive databases. in this paper we present a flash-no-flash (fnf) controlled illumination acquisition protocol that frees the system from most ambient illumination effects and facilitates robust target detection while using only modest computational resources and no supervised training. the approach relies on the simultaneous acquisition of two images-with/without strong artificial lighting (""flash""/""no-flash""). the difference between these images represents the appearance of the target scene as if only the artificial light was present, allowing a tight control over ambient light for color-based detection. a performance evaluation database was acquired in greenhouse conditions using an eye-in-hand rgb camera mounted on a robotic manipulator. the database includes 156 scenes with 468 images containing a total of 344 yellow sweet peppers. performance of both color blob and deep-learning detection algorithms are compared on flash-only and fnf images. the collected database is made public.","['sweet pepper robotic harvesting', 'independent target detection', 'time cost', 'efficient applications', 'controlled lighting', 'case study', 'real', 'illumination']"
"brain vessel status is a promising biomarker for better prevention and treatment in cerebrovascular disease. however, classic rule-based vessel segmentation algorithms need to be hand-crafted and are insufficiently validated. a specialized deep learning method-the u-net-is a promising alternative. using labeled data from 66 patients with cerebrovascular disease, the u-net framework was optimized and evaluated with three metrics: dice coefficient, 95% hausdorff distance (95hd) and average hausdorff distance (avd). the model performance was compared with the traditional segmentation method of graph-cuts. training and reconstruction was performed using 2d patches. a full and a reduced architecture with less parameters were trained. we performed both quantitative and qualitative analyses. the u-net models yielded high performance for both the full and the reduced architecture: a dice value of ~0.88, a 95hd of ~47 voxels and an avd of ~0.4 voxels. the visual analysis revealed excellent performance in large vessels and sufficient performance in small vessels. pathologies like cortical laminar necrosis and a rete mirabile led to limited segmentation performance in few patients. the u-net outperfomed the traditional graph-cuts method (dice ~0.76, 95hd ~59, avd ~1.97). our work highly encourages the development of clinically applicable segmentation tools based on deep learning. future works should focus on improved segmentation of small vessels and methodologies to deal with specific pathologies.","['net deep learning framework', 'high performance vessel segmentation', 'cerebrovascular disease', 'u', 'patients']"
"the general uncertainty of epilepsy and its unpredictable seizures often affect badly the quality of life of people exposed to this disease. there are patients who can be considered fortunate in terms of prediction of any seizures. these are patients with epileptic auras. in this study, it was aimed to evaluate pre-seizure warning symptoms of the electroencephalography (eeg) signals by a convolutional neural network (cnn) inspired by the epileptic auras defined in the medical field. in this context, one-dimensional eeg signals were transformed into a spectrogram display form in the frequency-time domain by applying a short-time fourier transform (stft). systemic changes in pre-epileptic seizure have been described by applying the cnn approach to the eeg signals represented in the image form, and the subjective eeg-aura process has been tried to be determined for each patient. considering all patients included in the evaluation, it was determined that the 1-min interval covering the time from the second minute to the third minute before the seizure had the highest mean and the lowest variance to determine the systematic changes before the seizure. thus, the highest performing process is described as eeg-aura. the average success for the eeg-aura process was 90.38\u2009±\u20096.28%, 89.78\u2009±\u20098.34% and 90.47\u2009±\u20095.95% for accuracy, specificity and sensitivity, respectively. through the proposed model, epilepsy patients who do not respond to medical treatment methods are expected to maintain their lives in a more comfortable and integrated way.","['eeg signals using deep convolutional neural networks', 'potential auras', 'generalized epilepsy', 'frequency representation', 'time', 'evaluation']"
"the analysis of neuroimaging data is frequently used to assist the diagnosis of neurodegenerative disorders such as alzheimer's disease (ad) or parkinson's disease (pd) and has become a routine procedure in the clinical practice. during the past decade, the pattern recognition community has proposed a number of machine learning-based systems that automatically analyse neuroimaging data in order to improve the diagnosis. however, the high dimensionality of the data is still a challenge and there is room for improvement. the development of novel classification frameworks as tensorflow, recently released as open source by google inc., represents an opportunity to continue evolving these systems. in this work, we demonstrate several computer-aided diagnosis (cad) systems based on deep neural networks that improve the diagnosis for ad and pd and outperform those based on classical classifiers. in order to address the small sample size problem we evaluate two dimensionality reduction algorithms based on principal component analysis and non-negative matrix factorization (nnmf), respectively. the performance of developed cad systems is assessed using 4 datasets with neuroimaging data of different modalities.","['using deep neural networks along', 'dimensionality reduction techniques', 'neurodegenerative disorders', 'diagnosis', 'assist']"
to describe and evaluate a segmentation method using joint adversarial and segmentation convolutional neural network to achieve accurate segmentation using unannotated mr image datasets.,"['segment unannotated image structure using adversarial network', 'susan']"
"visual object tracking has played a crucial role in computer vision with many applications. being intensively studied in recent decades, visual tracking has witnessed great advances in either speed (e.g., with correlation filters) or accuracy (e.g., with deep features). real-time and high accuracy tracking algorithms, nevertheless, remain scarce. in this paper we study the problem from a new perspective and present a novel parallel tracking and verifying (ptav) framework, by taking advantage of the ubiquity of multi-thread techniques and borrowing ideas from the success of parallel tracking and mapping in visual slam. the proposed ptav framework typically consists of two components, a (base) tracker t and a verifier v, working in parallel on two separate threads. the tracker t aims at providing a super real-time tracking inference and is expected to perform well most of the time; by contrast, the verifier v validates the tracking results and corrects t when needed. the key innovation is that, v does not work on every frame but only upon the requests from t; on the other end, t may adjust the tracking according to the feedback from v. with such collaboration, ptav enjoys both high efficiency provided by t and strong discriminative power by v. meanwhile, in order to adapt v to object appearance changes, we maintain a dynamic target template pool for adaptive verification, resulting in further improvement. in our extensive experiments on otb2015, tc128, uav20l and vot2016, ptav achieves top tracking accuracy among all real-time trackers, and in fact even outperforms many deep learning based algorithms. moreover, as a general framework, ptav is very flexible with great potentials for future improvement and generalization.","['parallel tracking', 'verifying']"
"chemical named entity recognition (ner) has traditionally been dominated by conditional random fields (crf)-based approaches but given the success of the artificial neural network techniques known as ""deep learning"" we decided to examine them as an alternative to crfs. we present here several chemical named entity recognition systems. the first system translates the traditional crf-based idioms into a deep learning framework, using rich per-token features and neural word embeddings, and producing a sequence of tags using bidirectional long short term memory (lstm) networks-a type of recurrent neural net. the second system eschews the rich feature set-and even tokenisation-in favour of character labelling using neural character embeddings and multiple lstm layers. the third system is an ensemble that combines the results of the first two systems. our original biocreative v.5 competition entry was placed in the top group with the highest f scores, and subsequent using transfer learning have achieved a final f score of 90.33% on the test data (precision 91.47%, recall 89.21%).","['chemical named entity recognition using recurrent neural networks', 'chemlistem']"
"conventional cell handling and sorting methods require manual labor, which decreases both cell quality and quantity. to purify adherent cultured cells, cell purification technologies that are high throughput without dissociation and can be utilized in an on-demand manner are expected. here, we developed a laser-induced, light-responsive-polymer-activated, cell killing (lilack) system that enables high-speed and on-demand adherent cell sectioning and purification. this system employs a visible laser beam, which does not kill cells directly, but induces local heat production through the trans-cis-trans photo-isomerization of azobenzene moieties. using this system in each passage for sectioning, human induced pluripotent stem cells (hipscs) maintained their pluripotency and self-renewal during long-term culture. furthermore, combined with deep machine-learning analysis on fluorescent and phase contrast images, a label-free and automatic cell processing system has been developed by eliminating unwanted spontaneously differentiated cells in undifferentiated hipsc culture conditions.","['automated adherent cell elimination', 'speed laser mediated', 'responsive polymer', 'light', 'high']"
"for patients undergoing surgical cancer resection of squamous cell carcinoma (scca), cancer-free surgical margins are essential for good prognosis. we developed a method to use hyperspectral imaging (hsi), a noncontact optical imaging modality, and convolutional neural networks (cnns) to perform an optical biopsy of ex-vivo, surgical gross-tissue specimens, collected from 21 patients undergoing surgical cancer resection. using a cross-validation paradigm with data from different patients, the cnn can distinguish scca from normal aerodigestive tract tissues with an area under the receiver operator curve (auc) of 0.82. additionally, normal tissue from the upper aerodigestive tract can be subclassified into squamous epithelium, muscle, and gland with an average auc of 0.94. after separately training on thyroid tissue, the cnn can differentiate between thyroid carcinoma and normal thyroid with an auc of 0.95, 92% accuracy, 92% sensitivity, and 92% specificity. moreover, the cnn can discriminate medullary thyroid carcinoma from benign multinodular goiter (mng) with an auc of 0.93. classical-type papillary thyroid carcinoma is differentiated from mng with an auc of 0.91. our preliminary results demonstrate that an hsi-based optical biopsy method using cnns can provide multicategory diagnostic information for normal and cancerous head-and-neck tissue, and more patient data are needed to fully investigate the potential and reliability of the proposed technique.","['neck cancer using hyperspectral imaging', 'convolutional neural networks', 'optical biopsy', 'head']"
"asthma is a syndrome composed of heterogeneous disease entities. although it is agreed that proper asthma endo-typing and appropriate type-specific interventions are crucial in the management of asthma, little data are available regarding pediatric asthma.","['korean childhood asthma study', 'ka']"
"accurate predictive modeling in clinical research enables effective early intervention that patients are most likely to benefit from. however, due to the complex biological nature of disease progression, capturing the highly non-linear information from low-level input features is quite challenging. this requires predictive models with high-capacity. in practice, clinical datasets are often of limited size, bringing danger of overfitting for high-capacity models. to address these two challenges, we propose a deep multi-task neural network for predictive modeling.","['task neural network', 'leveraging auxiliary measures', 'predictive modeling', 'deep multi', 'clinical research']"
"as a fundamental and challenging problem in computer vision, hand pose estimation aims to estimate the hand joint locations from depth images. typically, the problems are modeled as learning a mapping function from images to hand joint coordinates in a data-driven manner. in this paper, we propose a context-aware deep spatiotemporal network, a novel method to jointly model the spatiotemporal properties for hand pose estimation. our proposed network is able to learn the representations of the spatial information and the temporal structure from the image sequences. moreover, by adopting the adaptive fusion method, the model is capable of dynamically weighting different predictions to lay emphasis on sufficient context. our method is examined on two common benchmarks, the experimental results demonstrate that our proposed approach achieves the best or the second-best performance with the state-of-the-art methods and runs in 60 fps.","['aware deep spatiotemporal network', 'hand pose estimation', 'depth images', 'context']"
"we introduce the cdrp (concatenated diagnostic-relapse prognostic) architecture for multi-task deep learning that incorporates a clinical algorithm, e.g., a risk stratification schema to improve prognostic profiling. we present the first application to survival prediction in high-risk (hr) neuroblastoma from transcriptomics data, a task that studies from the maqc consortium have shown to remain the hardest among multiple diagnostic and prognostic endpoints predictable from the same dataset. to obtain a more accurate risk stratification needed for appropriate treatment strategies, cdrp combines a first component (cdrp-a) synthesizing a diagnostic task and a second component (cdrp-n) dedicated to one or more prognostic tasks. the approach leverages the advent of semi-supervised deep learning structures that can flexibly integrate multimodal data or internally create multiple processing paths. cdrp-a is an autoencoder trained on gene expression on the hr/non-hr risk stratification by the children's oncology group, obtaining a 64-node representation in the bottleneck layer. cdrp-n is a multi-task classifier for two prognostic endpoints, i.e., event-free survival (efs) and overall survival (os). cdrp-a provides the hr embedding input to the cdrp-n shared layer, from which two branches depart to model efs and os, respectively. to control for selection bias, cdrp is trained and evaluated using a data analysis protocol (dap) developed within the maqc initiative. cdrp was applied on illumina rna-seq of 498 neuroblastoma patients (hr: 176) from the seqc study (12,464 entrez genes) and on affymetrix human exon array expression profiles (17,450 genes) of 247 primary diagnostic neuroblastoma of the target nbl cohort. on the seqc hr patients, cdrp achieves matthews correlation coefficient (mcc) 0.38 for efs and mcc = 0.19 for os in external validation, improving over published seqc models. we show that a cdrp-n embedding is indeed parametrically associated to increasing severity and the embedding can be used to better stratify patients' survival.","['clinical algorithm improves prognosis', 'task deep learning', 'risk neuroblastoma', 'multi', 'high', 'distillation']"
"thermal imaging (infrared-imaging-iri) is a promising new technique for psychophysiological research and application. unlike traditional physiological measures (like skin conductance and heart rate), it is uniquely contact-free, substantially enhancing its ecological validity. investigating facial regions and subsequent reliable signal extraction from iri data is challenging due to head motion artefacts. exploiting its potential thus depends on advances in analytical methods. here, we developed a novel semi-automated thermal signal extraction method employing deep learning algorithms for facial landmark identification. we applied this method to physiological responses elicited by a sudden auditory stimulus, to determine if facial temperature changes induced by a stimulus of a loud sound can be detected. we compared thermal responses with psycho-physiological sensor-based tools of galvanic skin response (gsr) and electrocardiography (ecg). we found that the temperatures of selected facial regions, particularly the nose tip, significantly decreased after the auditory stimulus. additionally, this response was quite rapid at around 4-5\u2009seconds, starting less than 2\u2009seconds following the gsr changes. these results demonstrate that our methodology offers a sensitive and robust tool to capture facial physiological changes with minimal manual intervention and manual pre-processing of signals. newer methodological developments for reliable temperature extraction promise to boost iri use as an ecologically-valid technique in social and affective neuroscience.","['sudden auditory stimulus based', 'facial temperature induced', 'assisted face tracking', 'detecting changes', 'deep learning']"
"cardiovascular calcification is a health disorder with increasing prevalence and high morbidity and mortality. the only available therapeutic options for calcific vascular and valvular heart disease are invasive transcatheter procedures or surgeries that do not fully address the wide spectrum of these conditions; therefore, an urgent need exists for medical options. cardiovascular calcification is an active process, which provides a potential opportunity for effective therapeutic targeting. numerous biological processes are involved in calcific disease, including matrix remodelling, transcriptional regulation, mitochondrial dysfunction, oxidative stress, calcium and phosphate signalling, endoplasmic reticulum stress, lipid and mineral metabolism, autophagy, inflammation, apoptosis, loss of mineralization inhibition, impaired mineral resorption, cellular senescence and extracellular vesicles that act as precursors of microcalcification. advances in molecular imaging and big data technology, including in multiomics and network medicine, and the integration of these approaches are helping to provide a more comprehensive map of human disease. in this review, we discuss ectopic calcification processes in the cardiovascular system, with an emphasis on emerging mechanistic knowledge obtained through patient data and advances in imaging methods, experimental models and multiomics-generated big data. we also highlight the potential and challenges of artificial intelligence, machine learning and deep learning to integrate imaging and mechanistic data for drug discovery.","['big data accelerate mechanistic discovery', 'cardiovascular calcification', 'artificial intelligence']"
"accurate prognosis of patients with cancer is important for the stratification of patients, the optimization of treatment strategies, and the design of clinical trials. both clinical features and molecular data can be used for this purpose, for instance, to predict the survival of patients censored at specific time points. multi-omics data, including genome-wide gene expression, methylation, protein expression, copy number alteration, and somatic mutation data, are becoming increasingly common in cancer studies. to harness the rich information in multi-omics data, we developed gdp (group lass regularized deep learning for cancer prognosis), a computational tool for survival prediction using both clinical and multi-omics data. gdp integrated a deep learning framework and cox proportional hazard model (cph) together, and applied group lasso regularization to incorporate gene-level group prior knowledge into the model training process. we evaluated its performance in both simulated and real data from the cancer genome atlas (tcga) project. in simulated data, our results supported the importance of group prior information in the regularization of the model. compared to the standard lasso regularization, we showed that group lasso achieved higher prediction accuracy when the group prior knowledge was provided. we also found that gdp performed better than cph for complex survival data. furthermore, analysis on real data demonstrated that gdp performed favorably against other methods in several cancers with large-scale omics data sets, such as glioblastoma multiforme, kidney renal clear cell carcinoma, and bladder urothelial carcinoma. in summary, we demonstrated that gdp is a powerful tool for prognosis of patients with cancer, especially when large-scale molecular features are available.","['group lasso regularized deep learning', 'clinical features', 'cancer prognosis', 'omics', 'multi']"
"neuromelanin sensitive magnetic resonance imaging (nms-mri) has been crucial in identifying abnormalities in the substantia nigra pars compacta (snc) in parkinson's disease (pd) as pd is characterized by loss of dopaminergic neurons in the snc. current techniques employ estimation of contrast ratios of the snc, visualized on nms-mri, to discern pd patients from the healthy controls. however, the extraction of these features is time-consuming and laborious and moreover provides lower prediction accuracies. furthermore, these do not account for patterns of subtle changes in pd in the snc. to mitigate this, our work establishes a computer-based analysis technique that uses convolutional neural networks (cnns) to create prognostic and diagnostic biomarkers of pd from nms-mri. our technique not only performs with a superior testing accuracy (80%) as compared to contrast ratio-based classification (56.5% testing accuracy) and radiomics classifier (60.3% testing accuracy), but also supports discriminating pd from atypical parkinsonian syndromes (85.7% test accuracy). moreover, it has the capability to locate the most discriminative regions on the neuromelanin contrast images. these discriminative activations demonstrate that the left snc plays a key role in the classification in comparison to the right snc, and are in agreement with the concept of asymmetry in pd. overall, the proposed technique has the potential to support radiological diagnosis of pd while facilitating deeper understanding into the abnormalities in snc.","['disease using deep neural nets', 'neuromelanin sensitive mri', 'predictive markers', 'parkinson']"
"deep neural networks (dnns) have been extensively used in multiple disciplines due to their superior performance. however, in most cases, dnns are considered as black-boxes and the interpretation of their internal working mechanism is usually challenging. given that model trust is often built on the understanding of how a model works, the interpretation of dnns becomes more important, especially in safety-critical applications (e.g., medical diagnosis, autonomous driving). in this paper, we propose deepvid, a deep learning approach to visually interpret and diagnose dnn models, especially image classifiers. in detail, we train a small locally-faithful model to mimic the behavior of an original cumbersome dnn around a particular data instance of interest, and the local model is sufficiently simple such that it can be visually interpreted (e.g., a linear model). knowledge distillation is used to transfer the knowledge from the cumbersome dnn to the small model, and a deep generative model (i.e., variational auto-encoder) is used to generate neighbors around the instance of interest. those neighbors, which come with small feature variances and semantic meanings, can effectively probe the dnn's behaviors around the interested instance and help the small model to learn those behaviors. through comprehensive evaluations, as well as case studies conducted together with deep learning experts, we validate the effectiveness of deepvid.","['image classifiers via knowledge distillation', 'deep visual interpretation', 'diagnosis', 'deepvid']"
"neurodegenerative disease is the umbrella term which refers to a range of clinical conditions causing degeneration of neurons within the central nervous system leading to loss of brain function and eventual death. the most prevalent of these is alzheimer's disease (ad), which affects approximately 50 million people worldwide and is predicted to reach 75 million by 2030. neurodegenerative diseases can only be fully diagnosed at post mortem by neuropathological assessment of the type and distribution of protein deposits which characterise each different condition, but there is a clear role for imaging technologies in aiding patient diagnoses in life. magnetic resonance imaging (mri) and spectroscopy (mrs) techniques have been applied to study these conditions for many years. in this review, we consider the range of mr-based measurements and describe the findings in ad, but also contrast these with the second most common dementia, dementia with lewy bodies (dlb). the most definitive observation is the major structural brain changes seen in ad using conventional t1-weighted (t1w) mri, where medial temporal lobe structures are notably atrophied in most symptomatic patients with ad, but often preserved in dlb. indeed these findings are sufficiently robust to have been incorporated into clinical diagnostic criteria. diffusion tensor imaging (dti) reveals widespread changes in tissue microstructure, with increased mean diffusivity and decreased fractional anisotropy reflecting the degeneration of the white matter structures. there are suggestions that there are subtle differences between ad and dlb populations. at the metabolic level, atrophy-corrected mrs demonstrates reduced density of healthy neurons in brain areas with altered perfusion and in regions known to show higher deposits of pathogenic proteins. as studies have moved from patients with advanced disease and clear dysfunction to patients with earlier presentation such as with mild cognitive impairment (mci), which in some represents the first signs of their ensuing dementia, the ability of mri to detect differences has been weaker and further work is still required, ideally in much larger cohorts than previously studied. the vast majority of imaging research in dementia populations has been univariate with respect to the mr-derived parameters considered. to date, none of these measurements has uniquely replicated the patterns of tissue involvement seen by neuropathology, and the ability of mr techniques to deliver a non-invasive diagnosis eludes us. future opportunities may lie in combining mr and nuclear medicine approaches (position emission tomography, pet) to provide a more complete view of structural and metabolic changes. such developments will require multi-variate analyses, possibly combined with artificial intelligence or deep learning algorithms, to enhance our ability to combine the array of image-derived information, genetic, gender and lifestyle factors.","['neurodegenerative disorders', 'mr approaches']"
"artificial intelligence and automation are topics dominating global discussions on the future of professional employment, societal change, and economic performance. in this paper, we describe fundamental concepts underlying ai and big data and their significance to public health. we highlight issues involved and describe the potential impacts and challenges to medical professionals and diagnosticians. the possible benefits of advanced data analytics and machine learning are described in the context of recently reported research. problems are identified and discussed with respect to ethical issues and the future roles of professionals and specialists in the age of artificial intelligence.","['public health', 'big data', 'artificial intelligence']"
"we present a system for automatic determination of the intradermal volume of hydrogels based on optical coherence tomography (oct) and deep learning. volumetric image data was acquired using a custom-built oct prototype that employs an akinetic swept laser at ~1310 nm with a bandwidth of 87 nm, providing an axial resolution of ~6.5 μm in tissue. three-dimensional data sets of a 10 mm × 10 mm skin patch comprising the intradermal filler and the surrounding tissue were acquired. a convolutional neural network using a u-net-like architecture was trained from slices of 100 oct volume data sets where the dermal filler volume was manually annotated. using six-fold cross-validation, a mean accuracy of 0.9938 and a jaccard similarity coefficient of 0.879 were achieved.","['mice using convolutional neural networks', 'oct images', 'dermal fillers', 'automated segmentation']"
"during recent years, the digital revolution has changed the face of societies including industrial production, economies and peoples\' social lives. from these changes we may extrapolate the developments that digitization of health care will bring to medicine in general and laboratory medicine in particular. disruptive technologies will fundamentally change the way laboratory tests are going to be ordered, carried out and interpreted in the future, and test results from various sources need to be curated to be of added value for the patient\'s condition. wearables and implantables will quantify the concentrations for an unknown number of laboratory parameters, and the data will be stored in cloud services at the fingertips of the patient as the sovereign of his/her health care data. a 24/7 online availability of health services will strengthen predictive medicine and may enable a vastly improved preventive health care that is supported by deep-learning algorithms for clinical decision-making not only on behalf of the physician, but also the empowered patient (e.g. health bots). this will likely shift the current role of laboratory medicine as a central provider of diagnostic information from a ""hidden champion"" towards a higher visibility redefining the patient-physician-laboratory relationship. for example, accessing digital health data will allow laboratory medicine to more efficiently contribute to the medical dialog than is often the case today. from this perspective, this will require major readjustments in the way we execute our profession, and it will also need new concepts of education and continuous professional development.","['medical laboratory', 'digital health', 'diagnostics 4', '0']"
"owning to the rapid development of computer technologies, an increasing number of relational data have been emerging in modern biomedical research. many network-based learning methods have been proposed to perform analysis on such data, which provide people a deep understanding of topology and knowledge behind the biomedical networks and benefit a lot of applications for human healthcare. however, most network-based methods suffer from high computational and space cost. there remain challenges on handling high dimensionality and sparsity of the biomedical networks. the latest advances in network embedding technologies provide new effective paradigms to solve the network analysis problem. it converts network into a low-dimensional space while maximally preserves structural properties. in this way, downstream tasks such as link prediction and node classification can be done by traditional machine learning methods. in this survey, we conduct a comprehensive review of the literature on applying network embedding to advance the biomedical domain. we first briefly introduce the widely used network embedding models. after that, we carefully discuss how the network embedding approaches were performed on biomedical networks as well as how they accelerated the downstream tasks in biomedical science. finally, we discuss challenges the existing network embedding applications in biomedical domains are faced with and suggest several promising future directions for a better improvement in human healthcare.","['biomedical data science', 'network embedding']"
"de novo design seeks to generate molecules with required property profiles by virtual design-make-test cycles. with the emergence of deep learning and neural generative models in many application areas, models for molecular design based on neural networks appeared recently and show promising results. however, the new models have not been profiled on consistent tasks, and comparative studies to well-established algorithms have only seldom been performed. to standardize the assessment of both classical and neural models for de novo molecular design, we propose an evaluation framework, guacamol, based on a suite of standardized benchmarks. the benchmark tasks encompass measuring the fidelity of the models to reproduce the property distribution of the training sets, the ability to generate novel molecules, the exploration and exploitation of chemical space, and a variety of single and multiobjective optimization tasks. the benchmarking open-source python code and a leaderboard can be found on https://benevolent.ai/guacamol .","['de novo molecular design', 'benchmarking models', 'guacamol']"
"for sparse sampling that accelerates magnetic resonance (mr) image acquisition, non-linear reconstruction algorithms have been developed, which incorporated patient specific a prior information. more generic a prior information could be acquired via deep learning and utilized for image reconstruction. in this study, we developed a volumetric hierarchical deep residual convolutional neural network, referred to as t-net, to provide a data-driven end-to-end mapping from sparsely sampled mr images to fully sampled mr images, where cartilage mr images were acquired using an ultra-short te sequence and retrospectively undersampled using pseudo-random cartesian and radial acquisition schemes. the network had a hierarchical architecture that promoted the sparsity of feature maps and increased the receptive field, which were valuable for signal synthesis and artifact suppression. relatively dense local connections and global shortcuts were established to facilitate residual learning and compensate for details lost in hierarchical processing. additionally, volumetric processing was adopted to fully exploit spatial continuity in three-dimensional space. data consistency was further enforced. the network was trained with 336 three-dimensional images (each consisting of 32 slices) and tested by 24 images. the incorporation of a priori information acquired via deep learning facilitated high acceleration factors (as high as 8) while maintaining high image fidelity (quantitatively evaluated using the structural similarity index measurement). the proposed t-net had an improved performance as compared to several state-of-the-art networks.","['incorporating prior knowledge via volumetric deep residual network', 'sparsely sampled mri', 'reconstruction', 'optimize']"
"with their working mechanisms based on ion migration, the switching dynamics and electrical behaviour of memristive devices resemble those of synapses and neurons, making these devices promising candidates for brain-inspired computing. built into large-scale crossbar arrays to form neural networks, they perform efficient in-memory computing with massive parallelism by directly using physical laws. the dynamical interactions between artificial synapses and neurons equip the networks with both supervised and unsupervised learning capabilities. moreover, their ability to interface with analogue signals from sensors without analogue/digital conversions reduces the processing time and energy overhead. although numerous simulations have indicated the potential of these networks for brain-inspired computing, experimental implementation of large-scale memristive arrays is still in its infancy. this review looks at the progress, challenges and possible solutions for efficient brain-inspired computation with memristive implementations, both as accelerators for deep learning and as building blocks for spiking neural networks.","['memristive crossbar arrays', 'inspired computing', 'brain']"
"distress is a complex condition, which affects a significant percentage of cancer patients and may lead to depression, anxiety, sadness, suicide and other forms of psychological morbidity. compelling evidence supports screening for distress as a means of facilitating early intervention and subsequent improvements in psychological well-being and overall quality of life. nevertheless, despite the existence of evidence-based and easily administered screening tools, for example, the distress thermometer, routine screening for distress is yet to achieve widespread implementation. efforts are intensifying to utilise innovative, cost-effective methods now available through emerging technologies in the informatics and computational arenas.","['automated screening', 'perspective', 'future', 'distress']"
"human driving behaviors are personalized and unique, and the automobile fingerprint of drivers could be helpful to automatically identify different driving behaviors and further be applied in fields such as auto-theft systems. current research suggests that in-vehicle controller area network-bus (can-bus) data can be used as an effective representation of driving behavior for recognizing different drivers. however, it is difficult to capture complex temporal features of driving behaviors in traditional methods. this paper proposes an end-to-end deep learning framework by fusing convolutional neural networks and recurrent neural networks with an attention mechanism, which is more suitable for time series can-bus sensor data. the proposed method can automatically learn features of driving behaviors and model temporal features without professional knowledge in features modeling. moreover, the method can capture salient structure features of high-dimensional sensor data and explore the correlations among multi-sensor data for rich feature representations of driving behaviors. experimental results show that the proposed framework performs well in the real world driving behavior identification task, outperforming the state-of-the-art methods.","['driving behavior identification', 'deep learning framework', 'bus sensor data', 'vehicle']"
"sleep apnea is one of the most common sleep disorders and the consequences of undiagnosed sleep apnea can be very severe, ranging from increased blood pressure to heart failure. however, many people are often unaware of their condition. the gold standard for diagnosing sleep apnea is an overnight polysomnography in a dedicated sleep laboratory. yet, these tests are expensive and beds are limited as trained staff needs to analyze the entire recording. an automated detection method would allow a faster diagnosis and more patients to be analyzed. most algorithms for automated sleep apnea detection use a set of human-engineered features, potentially missing important sleep apnea markers. in this paper, we present an algorithm based on state-of-the-art deep learning models for automatically extracting features and detecting sleep apnea events in respiratory signals. the algorithm is evaluated on the sleep-heart-health-study-1 dataset and provides per-epoch sensitivity and specificity scores comparable to the state of the art. furthermore, when these predictions are mapped to the apnea-hypopnea index, a considerable improvement in per-patient scoring is achieved over conventional methods. this paper presents a powerful aid for trained staff to quickly diagnose sleep apnea.","['raw respiratory signals using long short', 'term memory neural networks', 'automated sleep apnea detection']"
"the human microbiome plays a number of critical roles, impacting almost every aspect of human health and well-being. conditions in the microbiome have been linked to a number of significant diseases. additionally, revolutions in sequencing technology have led to a rapid increase in publicly-available sequencing data. consequently, there have been growing efforts to predict disease status from metagenomic sequencing data, with a proliferation of new approaches in the last few years. some of these efforts have explored utilizing a powerful form of machine learning called deep learning, which has been applied successfully in several biological domains. here, we review some of these methods and the algorithms that they are based on, with a particular focus on deep learning methods. we also perform a deeper analysis of type 2 diabetes and obesity datasets that have eluded improved results, using a variety of machine learning and feature extraction methods. we conclude by offering perspectives on study design considerations that may impact results and future directions the field can take to improve results and offer more valuable conclusions. the scripts and extracted features for the analyses conducted in this paper are available via github:https://github.com/nlapier2/metapheno.","['based disease prediction', 'machine learning', 'deep learning', 'critical evaluation', 'metapheno', 'metagenome']"
"existing deep-learning-based pulmonary nodule classification models usually use images and benign-malignant labels as inputs for training. image attributes of the nodules, as human-nameable high-level semantic labels, are rarely used to build a convolutional neural network (cnn). in this paper, a new method is proposed to combine the advantages of two classifications, which are pulmonary nodule benign-malignant classification and pulmonary nodule image attributes classification, into a deep learning network to improve the accuracy of pulmonary nodule classification. for this purpose, a unique 3d cnn is built to learn image attribute and benign-malignant classification simultaneously. a novel loss function is designed to balance the influence of two different kinds of classifications. the cnn is trained by a publicly available lung image database consortium (lidc) dataset and is tested by a cross-validation method to predict the risk of a pulmonary nodule being malignant. this proposed method generates the accuracy of 91.47%, which is better than many existing models. experimental findings show that if the cnn is built properly, the nodule attributes classification and benign-malignant classification can benefit from each other. by using nodule attribute learning as a control factor in a deep learning scheme, the accuracy of pulmonary nodule classification can be significantly improved by using a deep learning scheme.","['incorporating automatically learned pulmonary nodule attributes', 'malignant nodule classification', 'convolutional neural network', 'improve accuracy', 'benign']"
"deep learning has become an extremely effective tool for image classification and image restoration problems. here, we apply deep learning to microscopy and demonstrate how neural networks can exploit the chromatic dependence of the point-spread function to classify the colors of single emitters imaged on a grayscale camera. while existing localization microscopy methods for spectral classification require additional optical elements in the emission path, e.g., spectral filters, prisms, or phase masks, our neural net correctly identifies static and mobile emitters with high efficiency using a standard, unmodified single-channel configuration. furthermore, we show how deep learning can be used to design new phase-modulating elements that, when implemented into the imaging path, result in further improved color differentiation between species, including simultaneously differentiating four species in a single image.","['multicolor localization microscopy', 'function engineering', 'deep learning', 'spread', 'point']"
"flair (fluid attenuated inversion recovery) imaging via synthetic mri methods leads to artifacts in the brain, which can cause diagnostic limitations. the main sources of the artifacts are attributed to the partial volume effect and flow, which are difficult to correct by analytical modeling. in this study, a deep learning (dl)-based synthetic flair method was developed, which does not require analytical modeling of the signal.","['driven synthetic mri flair artifact correction via deep neural network', 'data']"
"when a satellite performs complex tasks such as discarding a payload or capturing a non-cooperative target, it will encounter sudden changes in the attitude and mass parameters, causing unstable flying and rolling of the satellite. in such circumstances, the change of the movement and mass characteristics are unpredictable. thus, the traditional attitude control methods are unable to stabilize the satellite since they are dependent on the mass parameters of the controlled object. in this paper, we proposed a reinforcement learning method to re-stabilize the attitude of a satellite under such circumstances. specifically, we discretize the continuous control torque, and build a neural network model that can output the discretized control torque to control the satellite. a dynamics simulation environment of the satellite is built, and the deep q network algorithm is then performed to train the neural network in this simulation environment. the reward of the training is the stabilization of the satellite. simulation experiments illustrate that, with the iteration of training progresses, the neural network model gradually learned to re-stabilize the attitude of a satellite after unknown disturbance. as a contrast, the traditional pd (proportion differential) controller was unable to re-stabilize the satellite due to its dependence on the mass parameters. the proposed method adopts self-learning to control satellite attitudes, shows considerable intelligence and certain universality, and has a strong application potential for future intelligent control of satellites performing complex space tasks.","['based satellite attitude stabilization method', 'cooperative target capturing', 'reinforcement learning', 'non']"
"self-interacting proteins (sips), whose more than two identities can interact with each other, play significant roles in the understanding of cellular process and cell functions. although a number of experimental methods have been designed to detect the sips, they remain to be extremely time-consuming, expensive, and challenging even nowadays. therefore, there is an urgent need to develop the computational methods for predicting sips. in this study, we propose a deep forest based predictor for accurate prediction of sips using protein sequence information. more specifically, a novel feature representation method, which integrate position-specific scoring matrix (pssm) with wavelet transform, is introduced. to evaluate the performance of the proposed method, cross-validation tests are performed on two widely used benchmark datasets. the experimental results show that the proposed model achieved high accuracies of 95.43 and 93.65% on human and yeast datasets, respectively. the auc value for evaluating the performance of the proposed method was also reported. the auc value for yeast and human datasets are 0.9203 and 0.9586, respectively. to further show the advantage of the proposed method, it is compared with several existing methods. the results demonstrate that the proposed model is better than other sips prediction methods. this work can offer an effective architecture to biologists in detecting new sips.","['protein sequence using wavelet transformation', 'improved deep forest model', 'predicting self', 'interacting proteins']"
"background studies on the effects of sociodemographic factors on health in aging now include the use of statistical models and machine learning. the aim of this study was to evaluate the determinants of health in aging using machine learning methods and to compare the accuracy with traditional methods. material and methods the health status of 6,209 adults, age <65 years (n=1,585), 65-79 years (n=3,267), and >80 years (n=1,357) were measured using an established health metric (0-100) that incorporated physical function and activities of daily living (adl). data from the english longitudinal study of ageing (elsa) included socio-economic and sociodemographic characteristics and history of falls. health-trend and personal-fitted variables were generated as predictors of health metrics using three machine learning methods, random forest (rf), deep learning (dl) and the linear model (lm), with calculation of the percentage increase in mean square error (%incmse) as a measure of the importance of a given predictive variable, when the variable was removed from the model. results health-trend, physical activity, and personal-fitted variables were the main predictors of health, with the%incmse of 85.76%, 63.40%, and 46.71%, respectively. age, employment status, alcohol consumption, and household income had the%incmse of 20.40%, 20.10%, 16.94%, and 13.61%, respectively. performance of the rf method was similar to the traditional lm (p=0.7), but rf significantly outperformed dl (p=0.006). conclusions machine learning methods can be used to evaluate multidimensional longitudinal health data and may provide accurate results with fewer requirements when compared with traditional statistical modeling.","['machine learning approach', 'health status using', 'english longitudinal study', 'sociodemographic indicators', 'els', 'data', 'aging']"
"in recent years, artificial intelligence (ai) and its subarea of deep learning have drawn the attention of many researchers. at the same time, advances in technologies enable the generation or collection of large amounts of valuable data (e.g., sensor data) from various sources in different applications, such as those for the internet of things (iot), which in turn aims towards the development of smart cities. with the availability of sensor data from various sources, sensor information fusion is in demand for effective integration of big data. in this article, we present an ai-based sensor-information fusion system for supporting deep supervised learning of transportation data generated and collected from various types of sensors, including remote sensed imagery for the geographic information system (gis), accelerometers, as well as sensors for the global navigation satellite system (gnss) and global positioning system (gps). the discovered knowledge and information returned from our system provides analysts with a clearer understanding of trajectories or mobility of citizens, which in turn helps to develop better transportation models to achieve the ultimate goal of smarter cities. evaluation results show the effectiveness and practicality of our ai-based sensor information fusion system for supporting deep supervised learning of big transportation data.","['supporting deep supervised learning', 'based sensor information fusion', 'ai']"
"automatic event detection in cell videos is essential for monitoring cell populations in biomedicine. deep learning methods have advantages over traditional approaches for cell event detection due to their ability to capture more discriminative features of cellular processes. supervised deep learning methods, however, are inherently limited due to the scarcity of annotated data. unsupervised deep learning methods have shown promise in general (non-cell) videos because they can learn the visual appearance and motion of regularly occurring events. cell videos, however, can have rapid, irregular changes in cell appearance and motion, such as during cell division and death, which are often the events of most interest. we propose a novel unsupervised two-path input neural network architecture to capture these irregular events with three key elements: 1) a visual encoding path to capture regular spatiotemporal patterns of observed objects with convolutional long short-term memory units; 2) an event detection path to extract information related to irregular events with max-pooling layers; and 3) integration of the hidden states of the two paths to provide a comprehensive representation of the video that is used to simultaneously locate and classify cell events. we evaluated our network in detecting cell division in densely packed stem cells in phase-contrast microscopy videos. our unsupervised method achieved higher or comparable accuracy to standard and state-of-the-art supervised methods.","['classification using spatiotemporal patterns', 'path neural network', 'cell event detection', 'unsupervised two']"
"brain-computer interfaces (bcis), which control external equipment using cerebral activity, have received considerable attention recently. translating brain activities measured by electroencephalography (eeg) into correct control commands is a critical problem in this field. most existing eeg decoding methods separate feature extraction from classification and thus are not robust across different bci users. in this paper, we propose to learn subject-specific features jointly with the classification rule. we develop a deep convolutional network (convnet) to decode eeg signals end-to-end by stacking time-frequency transformation, spatial filtering, and classification together. our proposed convnet implements a joint space-time-frequency feature extraction scheme for eeg decoding. morlet wavelet-like kernels used in our network significantly reduce the number of parameters compared with classical convolutional kernels and endow the features learned at the corresponding layer with a clear interpretation, i.e. spectral amplitude. we further utilize subject-to-subject weight transfer, which uses parameters of the networks trained for existing subjects to initialize the network for a new subject, to solve the dilemma between a large number of demanded data for training deep convnets and small labeled data collected in bcis. the proposed approach is evaluated on three public data sets, obtaining superior classification performance compared with the state-of-the-art methods.","['small labeled data', 'learning joint space', 'frequency features', 'eeg decoding', 'time']"
"automatic segmentation of the hippocampus from 3d magnetic resonance imaging mostly relied on multi-atlas registration methods. in this work, we exploit recent advances in deep learning to design and implement a fully automatic segmentation method, offering both superior accuracy and fast result. the proposed method is based on deep convolutional neural networks (cnns) and incorporates distinct segmentation and error correction steps. segmentation masks are produced by an ensemble of three independent models, operating with orthogonal slices of the input volume, while erroneous labels are subsequently corrected by a combination of replace and refine networks. we explore different training approaches and demonstrate how, in cnn-based segmentation, multiple datasets can be effectively combined through transfer learning techniques, allowing for improved segmentation quality. the proposed method was evaluated using two different public datasets and compared favorably to existing methodologies. in the eadc-adni harp dataset, the correspondence between the method's output and the available ground truth manual tracings yielded a mean dice value of 0.9015, while the required segmentation time for an entire mri volume was 14.8 seconds. in the miccai dataset, the mean dice value increased to 0.8835 through transfer learning from the larger eadc-adni harp dataset.","['deep convolutional neural network ensembles', 'precise hippocampus segmentation', 'transfer learning', 'fast']"
"interpretation of chest radiographs is a challenging task prone to errors, requiring expert readers. an automated system that can accurately classify chest radiographs may help streamline the clinical workflow.","['based automated detection algorithm', 'major thoracic diseases', 'deep learning', 'chest radiographs', 'validation', 'development']"
"deep learning is a significant step forward for developing autonomous tasks. one of its branches, computer vision, allows image recognition with high accuracy thanks to the use of convolutional neural networks (cnns). our goal was to train a cnn with transmitted light microscopy images to distinguish pluripotent stem cells from early differentiating cells. we induced differentiation of mouse embryonic stem cells to epiblast-like cells and took images at several time points from the initial stimulus. we found that the networks can be trained to recognize undifferentiated cells from differentiating cells with an accuracy higher than 99%. successful prediction started just 20\xa0min after the onset of differentiation. furthermore, cnns displayed great performance in several similar pluripotent stem cell (psc) settings, including mesoderm differentiation in human induced pscs. accurate cellular morphology recognition in a simple microscopic set up may have a significant impact on how cell assays are performed in the near future.","['deep learning neural networks highly predict', 'pluripotent stem cell differentiation', 'early onset']"
"multi-modal functional magnetic resonance imaging has been widely used for brain research. conventional data-fusion methods cannot capture complex relationship (e.g., nonlinear predictive relationship) between multiple data. this paper aims to develop a neural network framework to extract phenotype related cross-data relationships and use it to study the brain development.","['multimodal brain development', 'deep collaborative learning', 'study', 'application']"
"physiological networks (pn) model couplings between organs in a high-dimensional parameter space. machine learning methods, in particular artifical neural networks (anns), are powerful on high-dimensional classification tasks. however, lack of interpretability of the resulting models has been a drawback in research. we assess relevant pn topology changes in obstructive sleep apnea (osa) by novel ann interpretation techniques.","['obstructive sleep apnea', 'physiological networks', 'feature relevance', 'classification']"
"many plant diseases have distinct visual symptoms, which can be used to identify and classify them correctly. this article presents a potato disease classification algorithm that leverages these distinct appearances and advances in computer vision made possible by deep learning. the algorithm uses a deep convolutional neural network, training it to classify the tubers into five classes: namely, four disease classes and a healthy potato class. the database of images used in this study, containing potato tubers of different cultivars, sizes, and diseases, was acquired, classified, and labeled manually by experts. the models were trained over different train-test splits to better understand the amount of image data needed to apply deep learning for such classification tasks. the models were tested over a data set of images taken using standard low-cost rgb (red, green, and blue) sensors and were tagged by experts, demonstrating high classification accuracy. this is the first article to report the successful implementation of deep convolutional networks, popular in object identification, to the task of disease identification in potato tubers, showing the potential of deep learning techniques in agricultural tasks.","['based potato tuber disease detection', 'using deep learning', 'image']"
"the purpose of this study was to explore the effects of ct slice thickness, reconstruction algorithm, and radiation dose on quantification of ct features to characterize lung nodules using a chest phantom. spherical lung nodule phantoms of known densities (-630 and\u2009+\u2009100 hu) were inserted into an anthropomorphic thorax phantom. ct scan was performed ten times with relocations. ct data were reconstructed using 12 different imaging settings; three different slice thicknesses of 1.25, 2.5, and 5.0\u2009mm, two reconstruction kernels of sharp and standard, and two radiation dose of 30\u2009mas and 12\u2009mas. lesions were segmented using a semiautomated method. twenty representative ct quantitative features representing ct density and texture were compared using multiple regression analysis. in 100 hu nodule phantoms, 18 and 19 among 20 computer features showed significant difference between different mas and reconstruction algorithms, respectively (p ≤ 0.05). 20, 19, and 19 computer features showed difference between slice thickness of 5.0 vs 1.25, 5.0 vs 2.5, and 2.5 vs 1.25\u2009mm, respectively (p ≤ 0.05). in -630 hu nodule phantoms, 18 and 19 showed significant difference between different mas and reconstruction algorithms, respectively (p ≤ 0.05). 18, 11, and 17 computer features showed difference between slice thickness of 5.0 vs 1.25, 5.0 vs 2.5, and 2.5 vs 1.25\u2009mm, respectively (p ≤ 0.05). when comparing the absolute value of regression coefficient, the effect of slice thickness in 100 hu nodule and reconstruction algorithm in -630 hu nodule was greater than the effect of remaining scan parameters. the slice thickness, mas, and reconstruction algorithm had a significant impact on the quantitative image features. in clinical studies involving deep learning or radiomics, it should be noted that differences in values can occur when using computer features obtained from different ct scan parameters in combination. therefore, when interpreting the statistical analysis results, it is necessary to reflect the difference in the computer features depending on the scan parameters.","['lung nodule phantom study', 'ct scan parameters', 'ct radiomic features', 'measurement', 'effect']"
"dementia is a chronic and degenerative condition affecting millions globally. the care of patients with dementia presents an ever-continuing challenge to healthcare systems in the 21st century. medical and health sciences have generated unprecedented volumes of data related to health and wellbeing for patients with dementia due to advances in information technology, such as genetics, neuroimaging, cognitive assessment, free texts, routine electronic health records, etc. making the best use of these diverse and strategic resources will lead to high-quality care of patients with dementia. as such, machine learning becomes a crucial factor in achieving this objective. the aim of this paper is to provide a state-of-the-art review of machine learning methods applied to health informatics for dementia care. we collate and review the existing scientific methodologies and identify the relevant issues and challenges when faced with big health data. machine learning has demonstrated promising applications to neuroimaging data analysis for dementia care, while relatively less effort has been made to make use of integrated heterogeneous data via advanced machine learning approaches. we further indicate future potential and research directions in applying advanced machine learning, such as deep learning, to dementia informatics.","['dementia informatics research', 'machine learning', 'power', 'opportunities', 'issues', 'harnessing', 'challenges']"
"automatic tumor segmentation from medical images is an important step for computer-aided cancer diagnosis and treatment. recently, deep learning has been successfully applied to this task, leading to state-of-the-art performance. however, most of existing deep learning segmentation methods only work for a single imaging modality. pet/ct scanner is nowadays widely used in the clinic, and is able to provide both metabolic information and anatomical information through integrating pet and ct into the same utility. in this study, we proposed a novel multi-modality segmentation method based on a 3d fully convolutional neural network (fcn), which is capable of taking account of both pet and ct information simultaneously for tumor segmentation. the network started with a multi-task training module, in which two parallel sub-segmentation architectures constructed using deep convolutional neural networks (cnns) were designed to automatically extract feature maps from pet and ct respectively. a feature fusion module was subsequently designed based on cascaded convolutional blocks, which re-extracted features from pet/ct feature maps using a weighted cross entropy minimization strategy. the tumor mask was obtained as the output at the end of the network using a softmax function. the effectiveness of the proposed method was validated on a clinic pet/ct dataset of 84 patients with lung cancer. the results demonstrated that the proposed network was effective, fast and robust and achieved significantly performance gain over cnn-based methods and traditional methods using pet or ct only, two v-net based co-segmentation methods, two variational co-segmentation methods based on fuzzy set theory and a deep learning co-segmentation method using w-net.","['modality fully convolutional neural network', 'ct using multi', 'tumor co', 'segmentation', 'pet']"
"deep inspiration breath hold (dibh) with surface supervising is a common technique for cardiac dose reduction in left breast cancer radiotherapy. surface supervision accuracy relies on the characteristics of surface region. in this study, a convolutional neural network (cnn) based automatic region-of-interest (roi) selection method was proposed to select an optimal surface roi for dibh surface monitoring. the curvature entropy and the normal of each vertex on the breast cancer patient surface were calculated and formed as representative maps for roi selection learning. 900 rois were randomly extracted from each patient's surface representative map, and the corresponding rigid roi registration errors (res) were calculated. the vgg-16 (a 16-layer network structure developed by visual geometry group(vgg) from university of oxford) pre-trained on a large natural image database imagenet were fine-tuned using 27 thousand extracted rois and the corresponding res from thirty patients. the re prediction accuracy of the trained model was validated on additional ten patients. satisfactory re predictive accuracies were achieved with the root mean square error (rmse)/mean absolute error (mae) smaller than 1\u2009mm/0.7\u2009mm in translations and 0.45°/0.35° in rotations, respectively. the res of the model selected rois on ten testing cases is close to the minimal predicted re with mean re differences\u2009\u2009<1\u2009mm and\u2009\u2009<0.5° for translation and rotation, respectively. the proposed re predictive model can be utilized for selecting a quasi-optimal roi in left breast cancer dibh radiotherapy (dibh-rt).","['learning based surface region selection', 'deep inspiration breath hold', 'deep', 'dib']"
"to investigate the effect of a deep learning-based denoising algorithm, pixelshine (ps), on the quality of 70 kvp pelvic arterial phase ct images.","['v reconstruction pelvic arterial phase ct images', 'pixelshine deep learning algorithm', 'potential value', 'increasing quality', '70 kvp', 'asir']"
"recently, a novel machine learning model has emerged in the field of reinforcement learning known as deep q-learning. this model is capable of finding the best possible solution in systems consisting of millions of choices, without ever experiencing it before, and has been used to beat the best human minds at complex games such as, go and chess, which both have a huge number of possible decisions and outcomes for each move. with a human-level intelligence, it has solved the problems that no other machine learning model has done before. here, we show the steps needed for implementing this model to an optical problem. we investigate the colour generation by dielectric nanostructures and show that this model can find geometrical properties that can generate much purer red, green and blue colours compared to previously reported results. the model found these results in 9000 steps from a possible 34.5 million solutions. this technique can easily be extended to predict and optimise the design parameters for other optical structures.","['dielectric nanostructures using reinforcement learning', 'colour generation', 'optimisation']"
the objective of this article was to compare the performances of health care-associated infection (hai) detection between deep learning and conventional machine learning (ml) methods in french medical reports.,"['deep learning versus conventional machine learning', 'french clinical narratives', 'associated infections', 'healthcare', 'detection']"
"estimating the number of people in highly clustered crowd scenes is an extremely challenging task on account of serious occlusion and non-uniformity distribution in one crowd image. traditional works on crowd counting take advantage of different cnn like networks to regress crowd density map, and further predict the count. in contrast, we investigate a simple but valid deep learning model that concentrates on accurately predicting the density map and simultaneously training a density level classifier to relax parameters of the network to prevent dangerous stampede with a smart camera. first, a combination of atrous and fractional stride convolutional neural network (cafn) is proposed to deliver larger receptive fields and reduce the loss of details during down-sampling by using dilated kernels. second, the expanded architecture is offered to not only precisely regress the density map, but also classify the density level of the crowd in the meantime (mtcafn, multiple tasks cafn for both regression and classification). third, experimental results demonstrated on four datasets (shanghai tech a (mae = 88.1) and b (mae = 18.8), worldexpo'10(average mae = 8.2), ns ucf_cc_50(mae = 303.2) prove our proposed method can deliver effective performance.",['smart camera aware crowd counting via multiple task fractional stride deep learning']
"cerebrovascular diseases, in particular ischemic stroke, are one of the leading global causes of death in developed countries. perfusion ct and/or mri are ideal imaging modalities for characterizing affected ischemic tissue in the hyper-acute phase. if infarct growth over time could be predicted accurately from functional acute imaging protocols together with advanced machine-learning based image analysis, the expected benefits of treatment options could be better weighted against potential risks. the quality of the outcome prediction by convolutional neural networks (cnns) is so far limited, which indicates that even highly complex deep learning algorithms are not fully capable of directly learning physiological principles of tissue salvation through weak supervision due to a lack of data (e.g., follow-up segmentation). in this work, we address these current shortcomings by explicitly taking into account clinical expert knowledge in the form of segmentations of the core and its surrounding penumbra in acute ct perfusion images (ctp), that are trained to be represented in a low-dimensional non-linear shape space. employing a multi-scale cnn (u-net) together with a convolutional auto-encoder, we predict lesion tissue probabilities for new patients. the predictions are physiologically constrained to a shape embedding that encodes a continuous progression between the core and penumbra extents. the comparison to a simple interpolation in the original voxel space and an unconstrained cnn shows that the use of such a shape space can be advantageous to predict time-dependent growth of stroke lesions on acute perfusion data, yielding a dice score overlap of 0.46 for predictions from expert segmentations of core and penumbra. our interpolation method models monotone infarct growth robustly on a linear time scale to automatically predict clinically plausible tissue outcomes that may serve as a basis for more clinical measures such as the expected lesion volume increase and can support the decision making on treatment options and triage.","['predict ischemic stroke growth', 'acute ct perfusion data', 'dimensional shape representations', 'interpolating low', 'learning']"
"isoforms are mrnas produced from the same gene locus by alternative splicing and may have different functions. although gene functions have been studied extensively, little is known about the specific functions of isoforms. recently, some computational approaches based on multiple instance learning have been proposed to predict isoform functions from annotated gene functions and expression data, but their performance is far from being desirable primarily due to the lack of labeled training data. to improve the performance on this problem, we propose a novel deep learning method, deepisofun, that combines multiple instance learning with domain adaptation. the latter technique helps to transfer the knowledge of gene functions to the prediction of isoform functions and provides additional labeled training data. our model is trained on a deep neural network architecture so that it can adapt to different expression distributions associated with different gene ontology terms.","['deep domain adaptation approach', 'predict isoform functions', 'deepisofun']"
"for the purpose of improving the accuracy of underwater acoustic target recognition with only a small number of labeled data, we proposed a novel recognition method, including 4 steps: pre-processing, pre-training, fine-tuning and recognition. the 4 steps can be explained as follows: (1) pre-processing with resonance-based sparsity signal decomposition (rssd): rssd was firstly utilized to extract high-resonance components from ship-radiated noise. the high-resonance components contain the major information for target recognition. (2) pre-training with unsupervised feature-extraction: we proposed a one-dimensional convolution autoencoder-decoder model and then we pre-trained the model to extract features from the high-resonance components. (3) fine-tuning with supervised feature-separation: a supervised feature-separation algorithm was proposed to fine-tune the model and separate the extracted features. (4) recognition: classifiers were trained to recognize the separated features and complete the recognition mission. the unsupervised pre-training autoencoder-decoder can make good use of a large number of unlabeled data, so that only a small number of labeled data are required in the following supervised fine-tuning and recognition, which is quite effective when it is difficult to collect enough labeled data. the recognition experiments were all conducted on ship-radiated noise data recorded using a sensory hydrophone. by combining the 4 steps above, the proposed recognition method can achieve recognition accuracy of 93.28%, which sufficiently surpasses other traditional state-of-art feature-extraction methods.","['underwater acoustic target recognition based', 'supervised feature', 'separation algorithm']"
we sought to investigate the diagnostic performance of coronary ct angiography (ccta)-derived plaque markers combined with deep machine learning-based fractional flow reserve (ct-ffr) to identify lesion-specific ischemia using invasive ffr as the reference standard.,"['artificial intelligence ct fractional flow reserve', 'coronary ct angiography', 'derived plaque quantification', 'specific ischemia', 'lesion', 'identification']"
"advancements in technology and digitization have ushered in novel ways of enhancing tissue-based research via digital microscopy and image analysis. whole slide imaging scanners enable digitization of histology slides to be stored in virtual slide repositories and to be viewed via computers instead of microscopes. easier and faster sharing of histologic images for teaching and consultation, improved storage and preservation of quality of stained slides, and annotation of features of interest in the digital slides are just a few of the advantages of this technology. combined with the development of software for digital image analysis, digital slides further pave the way for the development of tools that extract quantitative data from tissue-based studies. this review introduces digital microscopy and pathology, and addresses technical and scientific considerations in slide scanning, quantitative image analysis, and slide repositories. it also highlights the current state of the technology and factors that need to be taken into account to insure optimal utility, including preanalytical considerations and the importance of involving a pathologist in all major steps along the digital microscopy and pathology workflow.","['virtual slide repository', 'image analysis', 'digital microscopy']"
"cross-modal retrieval has drawn wide interest for retrieval across different modalities (such as text, image, video, audio, and 3-d model). however, existing methods based on a deep neural network often face the challenge of insufficient cross-modal training data, which limits the training effectiveness and easily leads to overfitting. transfer learning is usually adopted for relieving the problem of insufficient training data, but it mainly focuses on knowledge transfer only from large-scale datasets as a single-modal source domain (such as imagenet) to a single-modal target domain. in fact, such large-scale single-modal datasets also contain rich modal-independent semantic knowledge that can be shared across different modalities. besides, large-scale cross-modal datasets are very labor-consuming to collect and label, so it is significant to fully exploit the knowledge in single-modal datasets for boosting cross-modal retrieval. to achieve the above goal, this paper proposes a modal-adversarial hybrid transfer network (mhtn), which aims to realize knowledge transfer from a single-modal source domain to a cross-modal target domain and learn cross-modal common representation. it is an end-to-end architecture with two subnetworks. first, a modal-sharing knowledge transfer subnetwork is proposed to jointly transfer knowledge from a single modality in the source domain to all modalities in the target domain with a star network structure, which distills modal-independent supplementary knowledge for promoting cross-modal common representation learning. second, a modal-adversarial semantic learning subnetwork is proposed to construct an adversarial training mechanism between the common representation generator and modality discriminator, making the common representation discriminative for semantics but indiscriminative for modalities to enhance cross-modal semantic consistency during the transfer process. comprehensive experiments on four widely used datasets show the effectiveness of mhtn.","['adversarial hybrid transfer network', 'modal retrieval', 'modal', 'mhtn', 'cross']"
"detection of abnormalities in wireless capsule endoscopy (wce) images is a challenging task. typically, these images suffer from low contrast, complex background, variations in lesion shape and color, which affect the accuracy of their segmentation and subsequent classification. this research proposes an automated system for detection and classification of ulcers in wce images, based on state-of-the-art deep learning networks. deep learning techniques, and in particular, convolutional neural networks (cnns), have recently become popular in the analysis and recognition of medical images. the medical image datasets used in this study were obtained from wce video frames. in this work, two milestone cnn architectures, namely the alexnet and the googlenet are extensively evaluated in object classification into ulcer or non-ulcer. furthermore, we examine and analyze the images identified as containing ulcer objects to evaluate the efficiency of the utilized cnns. extensive experiments show that cnns deliver superior performance, surpassing traditional machine learning methods by large margins, which supports their effectiveness as automated diagnosis tools.","['wireless capsule endoscopy images', 'convolutional neural networks', 'automated ulcer detection', 'application']"
"an importance measure of 3d objects inspired by human perception has a range of applications since people want computers to behave like humans in many tasks. this paper revisits a well-defined measure, distinction of 3d surface mesh, which indicates how important a region of a mesh is with respect to classification. we develop a method to compute it based on a classification network and a markov random field (mrf). the classification network learns view-based distinction by handling multiple views of a 3d object. using a classification network has an advantage of avoiding the training data problem which has become a major obstacle of applying deep learning to 3d object understanding tasks. the mrf estimates the parameters of a linear model for combining the view-based distinction maps. the experiments using several publicly accessible datasets show that the distinctive regions detected by our method are not just significantly different from those detected by methods based on handcrafted features, but more consistent with human perception. we also compare it with other perceptual measures and quantitatively evaluate its performance in the context of two applications. furthermore, due to the view-based nature of our method, we are able to easily extend mesh distinction to 3d scenes containing multiple objects.","['scenes via classification network', 'markov random field', '3d objects', 'distinction']"
"parkinson's disease (pd) is a neurodegenerative disorder that remains incurable. the available treatments for the disorder include pharmacologic therapies and deep brain stimulation (dbs). these approaches may cause distinct side effects and motor responses. this work presents the application of t-distributed stochastic neighbor embedding (t-sne), which is a machine learning algorithm for nonlinear dimensionality reduction and data visualization, for the problem of discriminating neurologically healthy individuals from those suffering from pd (treated with levodopa and dbs). furthermore, the assessment of classification methods is presented. inertial and electromyographic data were collected while the subjects executed a sequence of four motor tasks. the results were focused on the comparison of the classification performance of a support vector machine (svm) while discriminating two-dimensional feature sets estimated from principal component analysis (pca), sammon's mapping, and t-sne. the results showed visual and statistical differences for all three investigated groups. classification accuracy for pca, sammon's mapping, and t-sne was, respectively, 73.5%, 78.6%, and 96.9% for the training set and 67.8%, 74.1%, and 76.6% for the test set. the possibility of discriminating healthy individuals from those with pd treated with levodopa and dbs highlights the fact that each treatment method produces distinct motor behavior. the scatter plots resulting from t-sne could be used in the clinical practice as an objective tool for measuring the discrepancy between normal and abnormal motor behaviors, being thus useful for the adjustment of treatments and the follow-up of the disorder.","['distributed stochastic neighbor embedding', 'data visualization', 'use', 'parkinson', 'individuals', 'disease', 'classification']"
"a class-agnostic tracker typically consists of three key components, i.e., its motion model, its target appearance model, and its updating strategy. however, most recent topperforming trackers mainly focus on constructing complicated appearance models and updating strategies, while using comparatively simple and heuristic motion models that may result in an inefficient search and degrade the tracking performance. to address this issue, we propose a hierarchical tracker that learns to move and track based on the combination of data-driven search at the coarse level, and coarse-to-fine verification at the fine level. at the coarse level, a data-driven motion model learned from deep recurrent reinforcement learning provides our tracker with coarse localization of an object. by formulating motion search as an action-decision problem in reinforcement learning, our tracker utilizes a recurrent convolutional neural network based deep q-network to effectively learn data-driven searching policies. the learned motion model cannot only significantly reduce the search space, but also provide more reliable interested regions for further verifying. at the fine level, a kernelized correlation filter (kcf) based appearance model is adopted to densely yet efficiently verify a local region centered on the predicted location from the motion model. through using of circulant matrices and fast fourier transformation, a large number of candidate samples in the local region can be efficiently and effectively evaluated by the kcf based appearance model. finally, a simple yet robust estimator is designed to analyze possible tracking failure. the experiments on otb50 and otb100 illustrate that our tracker achieves better performance than the state-of-the-art trackers.","['reinforcement learning based searching', 'hierarchical tracking', 'fine verifying', 'coarse']"
"cell shape provides both geometry for, and a reflection of, cell function. numerous methods for describing and modeling cell shape have been described, but previous evaluation of these methods in terms of the accuracy of generative models has been limited.","['nuclear shape', 'generative modeling', 'methods', 'evaluation', 'cell']"
"deep convolutional networks (dcnns) are achieving previously unseen performance in object classification, raising questions about whether dcnns operate similarly to human vision. in biological vision, shape is arguably the most important cue for recognition. we tested the role of shape information in dcnns trained to recognize objects. in experiment 1, we presented a trained dcnn with object silhouettes that preserved overall shape but were filled with surface texture taken from other objects. shape cues appeared to play some role in the classification of artifacts, but little or none for animals. in experiments 2-4, dcnns showed no ability to classify glass figurines or outlines but correctly classified some silhouettes. aspects of these results led us to hypothesize that dcnns do not distinguish object's bounding contours from other edges, and that dcnns access some local shape features, but not global shape. in experiment 5, we tested this hypothesis with displays that preserved local features but disrupted global shape, and vice versa. with disrupted global shape, which reduced human accuracy to 28%, dcnns gave the same classification labels as with ordinary shapes. conversely, local contour changes eliminated accurate dcnn classification but caused no difficulty for human observers. these results provide evidence that dcnns have access to some local shape information in the form of local edge relations, but they have no access to global object shapes.","['global object shape', 'deep convolutional networks', 'classify based']"
"the sequence-based prediction of beta-residue contacts and beta-sheet structures contain key information for protein structure prediction. however, the determination of beta-sheet structures poses numerous challenges due to long-range beta-residue interactions and the huge number of possible beta-sheet structures. recently gaining attention has been the prediction of residue contacts based on deep learning models whose results have led to improvement in protein structure prediction. in addition, to reduce the computational complexity of determining beta-sheet structures, it has been suggested that this problem be transformed into graph-based solutions. consequently, the current work proposes betadl, a combination of a deep learning and a graph-based beta-sheet structure predictor. betadl adopts deep learning models to capture beta-residue contacts and improve beta-sheet structure predictions. in addition, a graph-based approach is presented to model the beta-sheets conformational space and a new score function is introduced to evaluate beta-sheets. furthermore, the present study demonstrates that the beta-sheet structure can be predicted within an acceptable computational time by the utilization of a heuristic maximum weight independent set solution. when compared to state-of-the-art methods, experimental results from betasheet916 and betasheet1452 datasets indicate that betadl improves the accuracy of beta-residue contact and beta-sheet structure prediction. using betadl, beta-sheet structures are predicted with a 4% and 6% improvement in the f1-score at the residue and strand levels, respectively. betadl's source code and data are available at http://kerg.um.ac.ir/index.php/datasets/#betadl.","['sheet predictor utilizing', 'independent set solution', 'deep learning model', 'protein beta', 'betadl']"
"the medical field is creating large amount of data that physicians are unable to decipher and use efficiently. moreover, rule-based expert systems are inefficient in solving complicated medical tasks or for creating insights using big data. deep learning has emerged as a more accurate and effective technology in a wide range of medical problems such as diagnosis, prediction, and intervention. deep learning is a representation learning method that consists of layers that transform data nonlinearly, thus, revealing hierarchical relationships and structures. in this review, we survey deep learning application papers that use structured data, and signal and imaging modalities from cardiology. we discuss the advantages and limitations of applying deep learning in cardiology that also apply in medicine in general, while proposing certain directions as the most viable for clinical use.","['deep learning', 'cardiology']"
"the purpose of this study is to determine whether a convolutional neural network (cnn) can predict the maximum standardized uptake value (suvmax) of lymph nodes in patients with cancer using the unenhanced ct images from a pet/ct examination, thus providing a proof of concept for potentially using deep learning to diagnose nodal involvement.","['lymph node maximum standardized uptake value', '3d convolutional neural network', 'concept study', 'cancer using', 'proof', 'prediction', 'patients']"
"to apply a deep-learning system for diagnosis of maxillary sinusitis on panoramic radiography, and to clarify its diagnostic performance.","['learning classification using convolutional neural network', 'panoramic radiography', 'maxillary sinusitis', 'evaluation', 'deep']"
"to investigate the use and efficiency of 3-d deep learning, fully convolutional networks (dfcn) for simultaneous tumor cosegmentation on dual-modality nonsmall cell lung cancer (nsclc) and positron emission tomography (pet)-computed tomography (ct) images.","['ct images using deep fully convolutional networks', 'simultaneous cosegmentation', 'tumors', 'pet']"
"sequence-based prediction of one dimensional structural properties of proteins has been a long-standing subproblem of protein structure prediction. recently, prediction accuracy has been significantly improved due to the rapid expansion of protein sequence and structure libraries and advances in deep learning techniques, such as residual convolutional networks (resnets) and long-short-term memory cells in bidirectional recurrent neural networks (lstm-brnns). here we leverage an ensemble of lstm-brnn and resnet models, together with predicted residue-residue contact maps, to continue the push towards the attainable limit of prediction for 3- and 8-state secondary structure, backbone angles (θ, τ, ϕ and ψ), half-sphere exposure, contact numbers and solvent accessible surface area (asa).","['residual convolutional neural networks', 'using predicted contact maps', 'protein secondary structure', 'contact numbers', 'solvent accessibility', 'improving prediction', 'backbone angles', 'recurrent', 'ensemble']"
"the doctor-patient relationship has been evolving from benevolent paternalism to a more patient-centered relationship in the modern era. although artificial intelligence (ai) has the potential to improve nearly every aspect of health care, many physicians are skeptical about integrating ai into their current medical practice. the purpose of this article is to explore what ai means for the doctor-patient relationship and for breast imaging radiologists.","['patient relationship', 'artificial intelligence', 'doctor']"
"the allen mouse brain atlas allows study of the brain's molecular anatomy at cellular scale, for thousands genes. to fully leverage this resource, one must register histological images of brain tissue - a task made challenging by the brain's structural complexity and heterogeneity, as well as inter-experiment variability.","['deep learning based method', 'situ hybridization experiments', 'mouse olfactory bulb', 'scale classification', 'registration', 'large', 'clustering']"
"we present a simple and efficient method based on deep learning to automatically decompose sketched objects into semantically valid parts. we train a deep neural network to transfer existing segmentations and labelings from three-dimensional (3-d) models to freehand sketches without requiring numerous well-annotated sketches as training data. the network takes the binary image of a sketched object as input and produces a corresponding segmentation map with per-pixel labelings as output. a subsequent postprocess procedure with multilabel graph cuts further refines the segmentation and labeling result. we validate our proposed method on two sketch datasets. experiments show that our method outperforms the state-of-the-art method in terms of segmentation and labeling accuracy and is significantly faster, enabling further integration in interactive drawing systems. we demonstrate the efficiency of our method in a sketch-based modeling application that automatically transforms input sketches into 3-d models by part assembly.","['fast sketch segmentation', 'deep learning', 'labeling']"
"automatic artery/vein (a/v) segmentation from fundus images is required to track blood vessel changes occurring with many pathologies including retinopathy and cardiovascular pathologies. one of the clinical measures that quantifies vessel changes is the arterio-venous ratio (avr) which represents the ratio between artery and vein diameters. this measure significantly depends on the accuracy of vessel segmentation and classification into arteries and veins. this paper proposes a fast, novel method for semantic a/v segmentation combining deep learning and graph propagation.","['retinal arteries', 'joint segmentation', 'fundus images', 'veins', 'classification']"
"passing the american board of anesthesiology (aba) basic examination is required to progress through anesthesiology training in usa. failing the test may be related to medical knowledge gaps, presence of negative psychosocial factors, and/or individual approaches to learning. this article describes the experience of development and implementation of a multifaceted remediation program (mrp) in residents who failed the aba basic test.","['anesthesiology basic examination', 'multifaceted remediation program', 'residency program', 'rescue residents', 'american board', 'failed', 'experience']"
"access to palliative care is a key quality metric which most healthcare organizations strive to improve. the primary challenges to increasing palliative care access are a combination of physicians over-estimating patient prognoses, and a shortage of palliative staff in general. this, in combination with treatment inertia can result in a mismatch between patient wishes, and their actual care towards the end of life.","['improving palliative care', 'deep learning']"
"deep learning is now widely used as an efficient tool for medical image classification and segmentation. however, conventional machine learning techniques are still more accurate than deep learning when only a small dataset is available. in this study, we present a general data augmentation strategy using perlin noise, applying it to pixel-by-pixel image classification and quantification of various kinds of image patterns of diffuse interstitial lung disease (dild). using retrospectively obtained high-resolution computed tomography (hrct) images from 106 patients, 100 regions-of-interest (rois) for each of six classes of image patterns (normal, ground-glass opacity, reticular opacity, honeycombing, emphysema, and consolidation) were selected for deep learning classification by experienced thoracic radiologists. for extra-validation, the deep learning quantification of the six classification patterns was evaluated for 92 hrct whole lung images for which hand-labeled segmentation masks created by two experienced radiologists were available. fusionnet, a convolutional neural network (cnn), was used for training, test, and extra-validation on classifications of dild image patterns. the accuracy of fusionnet with data augmentation using perlin noise (89.5%, 49.8%, and 55.0% for roi-based classification and whole lung quantifications by two radiologists, respectively) was significantly higher than that with conventional data augmentation (82.1%, 45.7%, and 49.9%, respectively). this data augmentation strategy using perlin noise could be widely applied to deep learning studies for image classification and segmentation, especially in cases with relatively small datasets.","['small data samples', 'based augmentation strategy', 'perlin noise', 'hrct images', 'deep learning']"
the study was conducted to evaluate the performance of a state-of-the-art commercial deep learning-based computer-aided diagnosis (dl-cad) system for detecting and characterizing pulmonary nodules.,"['deep learning', 'based computer', 'aided diagnosis', 'performance', 'evaluating', 'dl', 'ca']"
"due to diverse reasons, most drug candidates cannot eventually become marketed drugs. developing reliable computational methods for prediction of drug-likeness of candidate compounds is of vital importance to improve the success rate of drug discovery and development. in this study, we used a fully connected neural networks (fnn) to construct drug-likeness classification models with deep autoencoder to initialize model parameters. we collected datasets of drugs (represented by zinc world drug), bioactive molecules (represented by mddr and wdi), and common molecules (represented by zinc all purchasable and acd). compounds were encoded with mold2 two-dimensional structure descriptors. the classification accuracies of drug-like/non-drug-like model are 91.04% on wdi/acd databases, and 91.20% on mddr/zinc, respectively. the performance of the models outperforms previously reported models. in addition, we develop a drug/non-drug-like model (zinc world drug vs. zinc all purchasable), which distinguishes drugs and common compounds, with a classification accuracy of 96.99%. our work shows that by using high-latitude molecular descriptors, we can apply deep learning technology to establish state-of-the-art drug-likeness prediction models.","['likeness using deep autoencoder neural networks', 'prediction', 'drug']"
"the analysis of fecal-type components for clinical diagnosis is important. the main examination involves the counting of red blood cells (rbcs), white blood cells (wbcs), and molds under the microscopic. with the development of machine vision, some vision-based detection schemes have been proposed. however, these methods have a single target for detection, with low detection efficiency and low accuracy. we proposed an algorithm to identify the visible image of fecal composition based on intelligent deep learning. the algorithm mainly includes region proposal and candidate recognition. in the process of segmentation, we proposed a morphology extraction algorithm in a complex background. as for the candidate recognition, we proposed a new convolutional neural network (cnn) architecture based on inception-v3 and principal component analysis (pca). this method achieves high-average precision of 90.7%, which is better than the other mainstream cnn models. finally, the images within the rectangle marks were obtained. the total time for detection of an image was roughly 1200 ms. the algorithm proposed in the present paper can be integrated into an automatic fecal detection system.","['microscopic fecal images using convolutional neural networks', 'automatic classification', 'cells']"
"fall risk assessment is essential to predict and prevent falls in geriatric populations, especially patients with life-long conditions like neurological disorders. inertial sensor-based pervasive gait analysis systems have become viable means to facilitate continuous fall risk assessment in non-hospital settings. however, a gait analysis system is not sufficient to detect the characteristics leading to increased fall risk, and powerful inference models are required to detect the underlying factors specific to fall risk. machine learning models and especially the recently proposed deep learning methods offer the needed predictive power. deep neural networks have the potential to produce models that can operate directly on the raw data, thus alleviating the need for feature engineering. however, the domain knowledge inherent in the well-established spatio-temporal gait parameters are still valuable to help a model achieve high inference accuracies. in this study, we explore deep learning methods, specifically long short-term memory (lstm) neural networks, for the problem of fall risk assessment. we utilize sequences of spatio-temporal gait parameters extracted by an inertial sensor-based gait analysis system as input features. to quantify the performance of the proposed approach, we compare it with more traditional machine learning methods. the proposed lstm model, trained with a gait dataset collected from 60 neurological disorder patients, achieves a superior classification accuracy of 92.1% on a separate test dataset collected from 16 patients. this study serves as one of the first attempts to employ deep learning approaches in this domain and the results demonstrate their potential.","['utilizing domain knowledge', 'temporal gait parameters', 'fall risk assessment', 'inertial sensors', 'deep learning', 'spatio']"
"mr images of infants and fetuses allow non-invasive analysis of the brain. quantitative analysis of brain development requires automatic brain tissue segmentation that is typically preceded by segmentation of the intracranial volume (icv). fast changes in the size and morphology of the developing brain, motion artifacts, and large variation in the field of view make icv segmentation a challenging task. we propose an automatic method for segmentation of the icv in fetal and neonatal mri scans. the method was developed and tested with a diverse set of scans regarding image acquisition parameters (i.e. field strength, image acquisition plane, image resolution), infant age (23-45 weeks post menstrual age), and pathology (posthaemorrhagic ventricular dilatation, stroke, asphyxia, and down syndrome). the results demonstrate that the method achieves accurate segmentation with a dice coefficient (dc) ranging from 0.98 to 0.99 in neonatal and fetal scans regardless of image acquisition parameters or patient characteristics. hence, the algorithm provides a generic tool for segmentation of the icv that may be used as a preprocessing step for brain tissue segmentation in fetal and neonatal brain mr scans.","['neonatal mr scans using convolutional neural networks', 'intracranial volume', 'automatic extraction', 'fetal']"
"facial action units (aus) may be represented spatially, temporally, and in terms of their correlation. previous research focuses on one or another of these aspects or addresses them disjointly. we propose a hybrid network architecture that jointly models spatial and temporal representations and their correlation. in particular, we use a convolutional neural network (cnn) to learn spatial representations, and a long short-term memory (lstm) to model temporal dependencies among them. the outputs of cnns and lstms are aggregated into a fusion network to produce per-frame prediction of multiple aus. the hybrid network was compared to previous state-of-the-art approaches in two large facs-coded video databases, gft and bp4d, with over 400,000 au-coded frames of spontaneous facial behavior in varied social contexts. relative to standard multi-label cnn and feature-based state-of-the-art approaches, the hybrid system reduced person-specific biases and obtained increased accuracy for au detection. to address class imbalance within and between batches during training the network, we introduce multi-labeling sampling strategies that further increase accuracy when aus are relatively sparse. finally, we provide visualization of the learned au models, which, to the best of our best knowledge, reveal for the first time how machines see aus.","['learning facial action units', 'spatiotemporal cues', 'label sampling', 'multi']"
"it is meaningful to efficiently identify the health status of bearing and automatically learn the effective features from the original vibration signals. in this paper, a multi-step progressive method based on energy entropy (ee) theory and hybrid ensemble auto-encoder (heae), systematically blending the statistical analysis approach with the deep learning technology, is proposed for rolling element bearing (reb) fault diagnosis. firstly, a preliminary detection about the reb health status is performed by the statistical analysis technique integrated with the ee theory. secondly, if fault exists in reb, a new heae is constructed based on denoising auto-encoder and contractive auto-encoder to strengthen the feature learning ability and automatically extract the deep state features from the raw data. subsequently, a modified t-distributed stochastic neighbor embedding (m-tsne) algorithm is developed to achieve the features reduction to further improve the diagnosis efficiency. finally, the low-dimensional representations after features reduction are as the inputs of softmax classifier to recognize the fault conditions. the proposed method is applied to the fault diagnosis of reb. the results confirm the effectiveness and superiority of the proposed method, and it is more suitable for the actual engineering applications compared with other existing methods.","['step progressive fault diagnosis method', 'rolling element bearing based', 'hybrid ensemble auto', 'energy entropy theory', 'multi', 'encoder']"
"we present a method for the automated segmentation of knee bones and cartilage from magnetic resonance imaging\xa0(mri) that combines a priori knowledge of anatomical shape with convolutional neural networks (cnns). the proposed approach incorporates 3d statistical shape models (ssms) as well as 2d and 3d cnns to achieve a robust and accurate segmentation of even highly pathological knee structures. the shape models and neural networks employed are trained using data from the osteoarthritis initiative (oai) and the miccai grand challenge ""segmentation of knee images 2010"" (ski10), respectively. we evaluate our method on 40 validation and 50 submission datasets from the ski10 challenge. for the first time, an accuracy equivalent to the inter-observer variability of human readers is achieved in this challenge. moreover, the quality of the proposed method is thoroughly assessed using various measures for data from the oai, i.e. 507 manual segmentations of bone and cartilage, and 88 additional manual segmentations of cartilage. our method yields sub-voxel accuracy for both oai datasets. we make the 507 manual segmentations as well as our experimental setup publicly available to further aid research in the field of medical image segmentation. in conclusion, combining localized classification via cnns with statistical anatomical knowledge via ssms results in a state-of-the-art segmentation method for knee bones and cartilage from mri data.","['cartilage combining statistical shape knowledge', 'convolutional neural networks', 'osteoarthritis initiative', 'knee bone', 'automated segmentation', 'data']"
"artificial intelligence (ai) is beginning to transform imrt treatment planning for head and neck patients. however, the complexity and novelty of ai algorithms make them susceptible to misuse by researchers and clinicians. understanding nuances of new technologies could serve to mitigate potential clinical implementation pitfalls. this article is intended to facilitate integration of ai into the radiotherapy clinic by providing an overview of ai algorithms, including support vector machines (svms), random forests (rf), gradient boosting (gb), and several variations of deep learning. this document describes current ai algorithms that have been applied to head and neck imrt planning and identifies rapidly growing branches of ai in industry that have potential applications to head and neck cancer patients receiving imrt. ai algorithms have great clinical potential if used correctly but can also cause harm if misused, so it is important to raise the level of ai competence within radiation oncology so that the benefits can be realized in a controlled and safe manner.","['imrt planning process', 'neck cancer', 'artificial intelligence', 'head', 'application']"
"a key component of automated molecular design is the generation of compound ideas for subsequent filtering and assessment. recently deep learning approaches have been explored as alternatives to traditional de novo molecular design techniques. deep learning algorithms rely on learning from large pools of molecules represented as molecular graphs (generally smiles), and several approaches can be used to tailor the generated molecules to defined regions of chemical space. cheminformatics has developed alternative higher-level representations that capture the key properties of a set of molecules, and it would be of interest to understand whether such representations can be used to constrain the output of molecule generation algorithms. in this work we explore the use of one such representation, the reduced graph, as a definition of target chemical space for a deep learning molecule generator. the reduced graph replaces functional groups with superatoms representing the pharmacophoric features. assigning these superatoms to specific nonorganic element types allows the reduced graph to be represented as a valid smiles string. the mapping from standard smiles to reduced graph smiles is well-defined, however, the inverse is not true, and this presents a particular challenge. here we present the results of a novel seq-to-seq approach to molecule generation, where the one to many mapping of reduced graph to smiles is learned on a large training set. this training needs to be performed only once. in a subsequent step, this model can be used to generate arbitrary numbers of compounds that have the same reduced graph as any input molecule. through analysis of data sets in chembl we show that the approach generates valid molecules and can extrapolate to reduced graphs unseen in the training set. the method offers an alternative deep learning approach to molecule generation that does not rely on transfer learning, latent space generation, or adversarial networks and is applicable to scaffold hopping and other cheminformatics applications in drug discovery.","['de novo molecule design', 'reduced graphs', 'translating', 'smiles']"
"computer-aided diagnosis offers a promising solution to reduce variation in colonoscopy performance. pooled miss rates for polyps are as high as 22%, and associated interval colorectal cancers after colonoscopy are of concern. optical biopsy, whereby in-vivo classification of polyps based on enhanced imaging replaces histopathology, has not been incorporated into routine practice because it is limited by interobserver variability and generally only meets accepted standards in expert settings. real-time decision-support software has been developed to detect and characterise polyps, and also to offer feedback on the technical quality of inspection. some of the current algorithms, particularly with recent advances in artificial intelligence techniques, match human expert performance for optical biopsy. in this review, we summarise the evidence for clinical applications of computer-aided diagnosis and artificial intelligence in colonoscopy.","['future directions', 'current evidence', 'artificial intelligence', 'aided diagnosis', 'computer', 'colonoscopy']"
"artificial intelligence has advanced at an unprecedented pace, backing recent breakthroughs in natural language processing, speech recognition, and computer vision: domains where the data is euclidean in nature. more recently, considerable progress has been made in engineering deep-learning architectures that can accept non-euclidean data such as graphs and manifolds: geometric deep learning. this progress is of considerable interest to the drug discovery community, as molecules can naturally be represented as graphs, where atoms are nodes and bonds are edges. in this work, we explore the performance of geometric deep-learning methods in the context of drug discovery, comparing machine learned features against the domain expert engineered features that are mainstream in the pharmaceutical industry.","['geometric deep learning autonomously learns chemical features', 'domain experts', 'outperform', 'engineered']"
"mental workload assessment is essential for maintaining human health and preventing accidents. most research on this issue is limited to a single task. however, cross-task assessment is indispensable for extending a pre-trained model to new workload conditions. because brain dynamics are complex across different tasks, it is difficult to propose efficient human-designed features based on prior knowledge. therefore, this paper proposes a concatenated structure of deep recurrent and 3d convolutional neural networks (r3dcnns) to learn eeg features across different tasks without prior knowledge. first, this paper adds frequency and time dimensions to eeg topographic maps based on a morlet wavelet transformation. then, r3dcnn is proposed to simultaneously learn eeg features from the spatial, spectral, and temporal dimensions. the proposed model is validated based on the eeg signals collected from 20 subjects. this paper employs a binary classification of low and high mental workload across spatial n-back and arithmetic tasks. the results show that the r3dcnn achieves an average accuracy of 88.9%, which is a significant increase compared with that of the state-of-the-art methods. in addition, the visualization of the convolutional layers demonstrates that the deep neural network can extract detailed features. these results indicate that r3dcnn is capable of identifying the mental workload levels for cross-task conditions.","['recurrent 3d convolutional neural networks', 'task mental workload assessment', 'temporal eeg features', 'learning spatial', 'spectral', 'cross']"
"deep-learning framework has significantly impelled the development of modern machine learning technology by continuously pushing the limit of traditional recognition and processing of images, speech, and videos. in the meantime, it starts to penetrate other disciplines, such as biology, genetics, materials science, and physics. here, we report a deep-learning-based model, comprising two bidirectional neural networks assembled by a partial stacking strategy, to automatically design and optimize three-dimensional chiral metamaterials with strong chiroptical responses at predesignated wavelengths. the model can help to discover the intricate, nonintuitive relationship between a metamaterial structure and its optical responses from a number of training examples, which circumvents the time-consuming, case-by-case numerical simulations in conventional metamaterial designs. this approach not only realizes the forward prediction of optical performance much more accurately and efficiently but also enables one to inversely retrieve designs from given requirements. our results demonstrate that such a data-driven model can be applied as a very powerful tool in studying complicated light-matter interactions and accelerating the on-demand design of nanophotonic devices, systems, and architectures for real world applications.","['demand design', 'chiral metamaterials', 'learning', 'enabled', 'deep']"
"unlike wired endoscopy, capsule endoscopy requires additional time for a clinical specialist to review the operation and examine the lesions. to reduce the tedious review time and increase the accuracy of medical examinations, various approaches have been reported based on artificial intelligence for computer-aided diagnosis. recently, deep learning-based approaches have been applied to many possible areas, showing greatly improved performance, especially for image-based recognition and classification. by reviewing recent deep learning-based approaches for clinical applications, we present the current status and future direction of artificial intelligence for capsule endoscopy.","['capsule endoscopy', 'artificial intelligence', 'application']"
"compressive sensing (cs) is an effective technique for reconstructing image from a small amount of sampled data. it has been widely applied in medical imaging, remote sensing, image compression, etc. in this paper, we propose two versions of a novel deep learning architecture, dubbed as admm-csnet, by combining the traditional model-based cs method and data-driven deep learning method for image reconstruction from sparsely sampled measurements. we first consider a generalized cs model for image reconstruction with undetermined regularizations in undetermined transform domains, and then two efficient solvers using alternating direction method of multipliers (admm) algorithm for optimizing the model are proposed. we further unroll and generalize the admm algorithm to be two deep architectures, in which all parameters of the cs model and the admm algorithm are discriminatively learned by end-to-end training. for both applications of fast cs complex-valued mr imaging and cs imaging of real-valued natural images, the proposed admm-csnet achieved favorable reconstruction accuracy in fast computational speed compared with the traditional and the other deep learning methods.","['image compressive sensing', 'deep learning approach', 'csnet', 'admm']"
"given an existing trained neural network, it is often desirable to learn new capabilities without hindering performance of those already learned. existing approaches either learn sub-optimal solutions, require joint training, or incur a substantial increment in the number of parameters for each added domain, typically as many as the original network. we propose a method called deep adaptation modules (dam) that constrains newly learned filters to be linear combinations of existing ones. dams precisely preserve performance on the original domain, require a fraction (typically 13 percent, dependent on network architecture) of the number of parameters compared to standard fine-tuning procedures and converge in less cycles of training to a comparable or better level of performance. when coupled with standard network quantization techniques, we further reduce the parameter cost to around 3 percent of the original with negligible or no loss in accuracy. the learned architecture can be controlled to switch between various learned representations, enabling a single network to solve a task from multiple different domains. we conduct extensive experiments showing the effectiveness of our method on a range of image classification tasks and explore different aspects of its behavior.","['incremental learning', 'deep adaptation']"
we evaluated whether machine learning may be helpful for the detection of lung cancer in fdg-pet imaging in the setting of ultralow dose pet scans.,"['ultralow dose pet', 'deep neural networks', 'lung cancer', 'initial results', 'automated detection', 'ct']"
"strokes, surgeries, or degenerative diseases can impair motor abilities and balance. long-term rehabilitation is often the only way to recover, as completely as possible, these lost skills. to be effective, this type of rehabilitation should follow three main rules. first, rehabilitation exercises should be able to keep patient's motivation high. second, each exercise should be customizable depending on patient's needs. third, patient's performance should be evaluated objectively, i.e., by measuring patient's movements with respect to an optimal reference model. to meet the just reported requirements, in this paper, an interactive and low-cost full body rehabilitation framework for the generation of 3d immersive serious games is proposed. the framework combines two natural user interfaces (nuis), for hand and body modeling, respectively, and a head mounted display (hmd) to provide the patient with an interactive and highly defined virtual environment (ve) for playing with stimulating rehabilitation exercises. the paper presents the overall architecture of the framework, including the environment for the generation of the pilot serious games and the main features of the used hand and body models. the effectiveness of the proposed system is shown on a group of ninety-two patients. in a first stage, a pool of seven rehabilitation therapists has evaluated the results of the patients on the basis of three reference rehabilitation exercises, confirming a significant gradual recovery of the patients' skills. moreover, the feedbacks received by the therapists and patients, who have used the system, have pointed out remarkable results in terms of motivation, usability, and customization. in a second stage, by comparing the current state-of-the-art in rehabilitation area with the proposed system, we have observed that the latter can be considered a concrete contribution in terms of versatility, immersivity, and novelty. in a final stage, by training a gated recurrent unit recurrent neural network (gru-rnn) with healthy subjects (i.e., baseline), we have also provided a reference model to objectively evaluate the degree of the patients' performance. to estimate the effectiveness of this last aspect of the proposed approach, we have used the ntu rgb\u202f+\u202fd action recognition dataset obtaining comparable results with the current literature in action recognition.","['cost full body rehabilitation framework based', '3d immersive serious games', 'low', 'interactive']"
"the recent demonstration that addiction-relevant neuronal ensembles defined by known master transcription factors and their connectome is networked throughout mesocorticolimbic reward circuits and resonates harmonically at known frequencies implies that single-cell pan-omics techniques can improve our understanding of substance use disorders (sud's). application of machine learning algorithms to such data could find diagnostic utility as biomarkers both to define the presence of the disorder and to quantitate its severity and find myriad applications in a developmental pipeline towards therapeutics and cure. recent epigenomic studies have uncovered a wealth of clinically important data relating to synapse-nucleus signalling, memory storage, lineage-fate determination and cellular control and are contributing greatly to our understanding of all sud's. epigenetics interacts extensively with glycobiology. glycans decorate dna, rna and many circulating critical proteins particularly immunoglobulins. glycosylation is emerging as a major information-laden post-translational protein modification with documented application for biomarker development. the integration of these two emerging cutting-edge technologies provides a powerful and fertile algorithmic-bioinformatic space for the development both of sud biomarkers and novel cutting edge therapeutics.","['glycobiology towards novel biomarkers', 'radical cure', 'pathways', 'epigenomics', 'addiction']"
"many vision science studies employ machine learning, especially the version called ""deep learning."" neuroscientists use machine learning to decode neural responses. perception scientists try to understand how living organisms recognize objects. to them, deep neural networks offer benchmark accuracies for recognition of learned stimuli. originally machine learning was inspired by the brain. today, machine learning is used as a statistical tool to decode brain activity. tomorrow, deep neural networks might become our best model of brain function. this brief overview of the use of machine learning in biological vision touches on its strengths, weaknesses, milestones, controversies, and current directions. here, we hope to help vision scientists assess what role machine learning should play in their research.","['study biological vision', 'using machine learning', 'deep learning']"
to evaluate the diagnostic performance of a deep learning system for automated detection of atrial fibrillation (af) in photoplethysmographic (ppg) pulse waveforms.,"['detecting atrial fibrillation', 'deep learning system', 'pulse waveforms', 'diagnostic assessment']"
"to help clinicians to efficiently diagnose the severity of a person's depression, the affective computing community and the artificial intelligence field have shown a growing interest in designing automated systems. the speech features have useful information for the diagnosis of depression. however, manually designing and domain knowledge are still important for the selection of the feature, which makes the process labor consuming and subjective. in recent years, deep-learned features based on neural networks have shown superior performance to hand-crafted features in various areas. in this paper, to overcome the difficulties mentioned above, we propose a combination of hand-crafted and deep-learned features which can effectively measure the severity of depression from speech. in the proposed method, deep convolutional neural networks (dcnn) are firstly built to learn deep-learned features from spectrograms and raw speech waveforms. then we manually extract the state-of-the-art texture descriptors named median robust extended local binary patterns (mrelbp) from spectrograms. to capture the complementary information within the hand-crafted features and deep-learned features, we propose joint fine-tuning layers to combine the raw and spectrogram dcnn to boost the depression recognition performance. moreover, to address the problems with small samples, a data augmentation method was proposed. experiments conducted on avec2013 and avec2014 depression databases show that our approach is robust and effective for the diagnosis of depression when compared to state-of-the-art audio-based methods.","['automated depression analysis using convolutional neural networks', 'speech']"
"deep learning has been applied to clinical applications in not only radiology, but also all other areas of medicine. this review provides a technical and clinical overview of deep learning in radiology. to gain a more practical understanding of deep learning, deep learning techniques are divided into five categories: classification, object detection, semantic segmentation, image processing, and natural language processing. after a brief overview of technical network evolutions, clinical applications based on deep learning are introduced. the clinical applications are then summarized to reveal the features of deep learning, which are highly dependent on training and test datasets. the core technology in deep learning is developed by image classification tasks. in the medical field, radiologists are specialists in such tasks. using clinical applications based on deep learning would, therefore, be expected to contribute to substantial improvements in radiology. by gaining a better understanding of the features of deep learning, radiologists could be expected to lead medical development.","['deep learning', 'clinical overview', 'technical', 'radiology']"
"gene expression data represents a unique challenge in predictive model building, because of the small number of samples (n) compared with the huge amount of features (p). this 'n≪p' property has hampered application of deep learning techniques for disease outcome classification. sparse learning by incorporating external gene network information could be a potential solution to this issue. still, the problem is very challenging because (i) there are tens of thousands of features and only hundreds of training samples, (ii) the scale-free structure of the gene network is unfriendly to the setup of convolutional neural networks.","['feature selection using gene expression data', 'embedded deep feedforward network', 'disease outcome classification', 'graph']"
to evaluate if a deep learning algorithm can be trained to identify tumour-infiltrating lymphocytes (tils) in tissue samples of testicular germ cell tumours and to assess whether the til counts correlate with relapse status of the patient.,"['testicular germ cell tumours', 'infiltrating lymphocytes', 'detecting tumour', 'deep learning']"
"visual perception involves the rapid formation of a coarse image representation at the onset of visual processing, which is iteratively refined by late computational processes. these early versus late time windows approximately map onto feedforward and feedback processes, respectively. state-of-the-art convolutional neural networks, the main engine behind recent machine vision successes, are feedforward architectures. their successes and limitations provide critical information regarding which visual tasks can be solved by purely feedforward processes and which require feedback mechanisms. we provide an overview of recent work in cognitive neuroscience and machine vision that highlights the possible role of feedback processes for both visual recognition and beyond. we conclude by discussing important open questions for future research.","['visual cortex', 'feedforward sweep', 'feedback computations', 'beyond']"
"\u3000during the preclinical research period of drug development, animal testing is widely used to help screen out a drug\'s dangerous side effects. however, it remains difficult to predict side effects within the central nervous system. here, we introduce a machine learning-based in vitro system designed to detect seizure-inducing side effects before clinical trial. we recorded local field potentials from the ca1 alveus in acute mouse neocortico-hippocampal slices that were bath-perfused with each of 14 different drugs, and at 5 different concentrations of each drug. for each of these experimental conditions, we collected seizure-like neuronal activity and merged their waveforms as one graphic image, which was further converted into a feature vector using caffe, an open framework for deep learning. in the space of the first two principal components, the support vector machine completely separated the vectors (i.e., doses of individual drugs) that induced seizure-like events, and identified diphenhydramine, enoxacin, strychnine and theophylline as ""seizure-inducing"" drugs, which have indeed been reported to induce seizures in clinical situations. thus, this artificial intelligence-based classification may provide a new platform to pre-clinically detect seizure-inducing side effects of drugs.","['adverse drug effect ].', 'machine learning', 'inducing action', 'based prediction', 'seizure']"
"available super-resolution techniques for 3-d images are either computationally inefficient prior-knowledge-based iterative techniques or deep learning methods which require a large database of known low-resolution and high-resolution image pairs. a recently introduced tensor-factorization-based approach offers a fast solution without the use of known image pairs or strict prior assumptions. in this paper, this factorization framework is investigated for single image resolution enhancement with an offline estimate of the system point spread function. the technique is applied to 3-d cone beam computed tomography for dental image resolution enhancement. to demonstrate the efficiency of our method, it is compared to a recent state-of-the-art iterative technique using low-rank and total variation regularizations. in contrast to this comparative technique, the proposed reconstruction technique gives a 2-order-of-magnitude improvement in running time-2 min compared to 2 h for a dental volume of 282×266×392 voxels. furthermore, it also offers slightly improved quantitative results (peak signal-to-noise ratio and segmentation quality). another advantage of the presented technique is the low number of hyperparameters. as demonstrated in this paper, the framework is not sensitive to small changes in its parameters, proposing an ease of use.","['tensor factorization method', 'super resolution', 'dental ct', 'application', '3']"
[this corrects the article doi: 10.1155/2017/4216281,"['nonintrusive load monitoring based', 'novel signature "".', 'advanced deep learning', 'corrigendum']"
"in this work, we demonstrate how to leverage our recent iterative deep learning-all atom molecular dynamics (md) technique ""reweighted autoencoded variational bayes for enhanced sampling (rave)"" (ribeiro, bravo, wang, tiwary, j. chem. phys. 2018, 149, 072301) for investigating ligand-protein unbinding mechanisms and calculating absolute binding free energies, δ gb, when plagued with difficult to sample rare events. in order to do so, we introduce a simple but powerful extension to rave that allows learning a reaction coordinate expressed as a piecewise function that is linear over all intervals. such an approach allows us to retain the physical interpretation of a rave-derived reaction coordinate while making the method more applicable to a wider range of complex biophysical problems. as we will demonstrate, using as our test-case the slow dissociation of benzene from the l99a variant of lysozyme, the rave extension led to observing an unbinding event in 100% of the independent all-atom md simulations, all within 3-50 ns for a process that takes on an average close to few hundred milliseconds, which reflects a 7 orders of magnitude acceleration relative to straightforward md. furthermore, we will show that without the use of time-dependent biasing, clear back-and-forth movement between metastable intermediates was achieved during the various simulations, demonstrating the caliber of the rave-derived piecewise reaction coordinate and bias potential, which together drive efficient and accurate sampling of the ligand-protein dissociation event. last, we report the results for δ gb, which via very short md simulations, can form a strict lower-bound that is ∼2-3 kcal/mol off from experiments. we believe that rave, together with its multidimensional extension that we introduce here, will be a useful tool for simulating the slow unbinding process of practical ligand-protein complexes in an automated manner with minimal use of human intuition.","['toward achieving efficient', 'protein unbinding', 'molecular dynamics', 'deep learning', 'accurate ligand', 'rave']"
"motif discovery in large biopolymer sequence datasets can be computationally demanding, presenting significant challenges for discovery in omics research. meme, arguably one of the most popular motif discovery software, takes quadratic time with respect to dataset size, leading to excessively long runtimes for large datasets. therefore, there is a demand for fast programs that can generate results of the same quality as meme.","['based motif discovery using deep learning libraries', 'thousandfold speedup', 'yamda', 'gpu', 'em']"
"clinical named entity recognition (ner) is a critical natural language processing (nlp) task to extract important concepts (named entities) from clinical narratives. researchers have extensively investigated machine learning models for clinical ner. recently, there have been increasing efforts to apply deep learning models to improve the performance of current clinical ner systems. this study examined two popular deep learning architectures, the convolutional neural network (cnn) and the recurrent neural network (rnn), to extract concepts from clinical texts. we compared the two deep neural network architectures with three baseline conditional random fields (crfs) models and two state-of-the-art clinical ner systems using the i2b2 2010 clinical concept extraction corpus. the evaluation results showed that the rnn model trained with the word embeddings achieved a new state-of-the- art performance (a strict f1 score of 85.94%) for the defined clinical ner task, outperforming the best-reported system that used both manually defined and unsupervised learning features. this study demonstrates the advantage of using deep neural network architectures for clinical concept extraction, including distributed feature representation, automatic feature learning, and long-term dependencies capture. this is one of the first studies to compare the two widely used deep learning models and demonstrate the superior performance of the rnn model for clinical ner.",['clinical named entity recognition using deep learning models']
"salient object detection is usually used as a preprocessing step to facilitate a variety of subsequent applications which should take little time cost. with the quick development of deep learning recently, profound progresses have been made to achieve a new state-of-the-art performance. however, the learned features of the existing deep learning-based methods are not accurate enough thus leading to unsatisfactory detection in complex scenes, such as low contrast or very similar between salient object and background region and multiple (small) salient objects with diverse characteristics. in addition, some post-processing techniques are usually needed for refinement, which is time consuming. to address these issues, this paper presents an efficient fully convolutional salient object detection network. specifically, we first introduce a visual attention mechanism to guide feature learning in side output layers. in detail, attention weight is employed in a top-down manner which can bridge high level semantic information to help shallow layers better locate salient objects and also filter out noisy response in the background region. second, we propose a residual refinement network to fuse the learned multilevel features gradually. not to simply add or concatenate them step by step as previous works, we introduce a second-order term into element-wise addition to learn stage-wise residual features for refinement. such a second-order term not only benefits efficient gradient propagation but also increases network nonlinearity. extensive experiments on seven standard benchmarks demonstrate that the proposed approach achieves consistently superior performance and performs well on small salient object detection in comparison with the very recent state-of-the-arts, especially in the metric of structure-measure.","['accurate salient object detection', 'residual network', 'embedding attention']"
"to investigate medical students' study habits, their learning styles, and preferences, during general surgery rotation, for better understanding the art of pedagogy and improving the quality of teaching and learning.","['mixed method study', 'medical student', 'learning habits', 'general surgery', 'clinical rotation']"
"temporo-mandibular osteo arthritis (tmj oa) is characterized by progressive cartilage degradation and subchondral bone remodeling. the causes of this pathology remain unclear. current research efforts are concentrated in finding new biomarkers that will help us understand disease progression and ultimately improve the treatment of the disease. in this work, we present shape variation analyzer (sva), the goal is to develop a noninvasive technique to provide information about shape changes in tmj oa. sva uses neural networks to classify morphological variations of 3d models of the mandibular condyle. the shape features used for training include normal vectors, curvature and distances to average models of the condyles. the selected features are purely geometric and are shown to favor the classification task into 6 groups generated by consensus between two clinician experts. with this new approach, we were able to accurately classify 3d models of condyles. in this paper, we present the methods used and the results obtained with this new tool.","['shape variation analyzer', 'sva']"
"foreground detection, which extracts moving objects from videos, is an important and fundamental problem of video analysis. classic methods often build background models based on some hand-craft features. recent deep neural network (dnn) based methods can learn more effective image features by training, but most of them do not use temporal feature or use simple hand-craft temporal features. in this paper, we propose a new dual multi-scale 3d fully-convolutional neural network for foreground detection problems. it uses an encoder⁻decoder structure to establish a mapping from image sequences to pixel-wise classification results. we also propose a two-stage training procedure, which trains the encoder and decoder separately to improve the training results. with multi-scale architecture, the network can learning deep and hierarchical multi-scale features in both spatial and temporal domains, which is proved to have good invariance for both spatial and temporal scales. we used the cdnet dataset, which is currently the largest foreground detection dataset, to evaluate our method. the experiment results show that the proposed method achieves state-of-the-art results in most test scenes, comparing to current dnn based methods.","['deeply learned multi', 'temporal features', 'scale spatial', 'foreground detection']"
"purpose to develop and evaluate a fully automated algorithm for segmenting the abdomen from ct to quantify body composition. materials and methods for this retrospective study, a convolutional neural network based on the u-net architecture was trained to perform abdominal segmentation on a data set of 2430 two-dimensional ct examinations and was tested on 270 ct examinations. it was further tested on a separate data set of 2369 patients with hepatocellular carcinoma (hcc). ct examinations were performed between 1997 and 2015. the mean age of patients was 67 years; for male patients, it was 67 years (range, 29-94 years), and for female patients, it was 66 years (range, 31-97 years). differences in segmentation performance were assessed by using two-way analysis of variance with bonferroni correction. results compared with reference segmentation, the model for this study achieved dice scores (mean ± standard deviation) of 0.98 ± 0.03, 0.96 ± 0.02, and 0.97 ± 0.01 in the test set, and 0.94 ± 0.05, 0.92 ± 0.04, and 0.98 ± 0.02 in the hcc data set, for the subcutaneous, muscle, and visceral adipose tissue compartments, respectively. performance met or exceeded that of expert manual segmentation. conclusion model performance met or exceeded the accuracy of expert manual segmentation of ct examinations for both the test data set and the hepatocellular carcinoma data set. the model generalized well to multiple levels of the abdomen and may be capable of fully automated quantification of body composition metrics in three-dimensional ct examinations. © rsna, 2018 online supplemental material is available for this article. see also the editorial by chang in this issue.","['body composition analysis using deep learning', 'automated abdominal segmentation', 'ct scans']"
"video stabilization techniques are essential for most hand-held captured videos due to high-frequency shakes. several 2d, 2.5d and 3d-based stabilization techniques have been presented previously, but to our knowledge, no solutions based on deep neural networks had been proposed to date. the main reason for this omission is shortage in training data as well as the challenge of modeling the problem using neural networks. in this paper, we present a video stabilization technique using a convolutional neural network. previous works usually propose an offline algorithm that smoothes a holistic camera path based on feature matching. instead, we focus on low-latency, real-time camera path smoothing, that does not explicitly represent the camera path, and does not use future frames. our neural network model, called stabnet, learns a set of mesh-grid transformations progressively for each input frame from the previous set of stabalized camera frames, and creates stable corresponding latent camera paths implicitly. to train the network, we collect a dataset of synchronized steady and unsteady video pairs via a specially designed hand-held hardware. experimental results show that our proposed online method performs comparatively to traditional offline video stabilization methods without using future frames, while running about 10× faster. more importantly, our proposed stabnet is able to handle low-quality videos such as night-scene videos, watermarked videos, blurry videos and noisy videos, where existing methods fail in feature extraction or matching.","['grid warping transformation learning', 'deep online video stabilization', 'multi']"
"predicting drug-protein interactions (dpis) for target proteins involved in dopamine pathways is a very important goal in medicinal chemistry. we can tackle this problem using molecular docking or machine learning (ml) models for one specific protein. unfortunately, these models fail to account for large and complex big data sets of preclinical assays reported in public databases. this includes multiple conditions of assays, such as different experimental parameters, biological assays, target proteins, cell lines, organism of the target, or organism of assay. on the other hand, perturbation theory (pt) models allow us to predict the properties of a query compound or molecular system in experimental assays with multiple boundary conditions based on a previously known case of reference. in this work, we report the first ptml (pt + ml) study of a large chembl data set of preclinical assays of compounds targeting dopamine pathway proteins. the best ptml model found predicts 50000 cases with accuracy of 70-91% in training and external validation series. we also compared the linear ptml model with alternative ptml models trained with multiple nonlinear methods (artificial neural network (ann), random forest, deep learning, etc.). some of the nonlinear methods outperform the linear model but at the cost of a notable increment of the complexity of the model. we illustrated the practical use of the new model with a proof-of-concept theoretical-experimental study. we reported for the first time the organic synthesis, chemical characterization, and pharmacological assay of a new series of l-prolyl-l-leucyl-glycinamide (plg) peptidomimetic compounds. in addition, we performed a molecular docking study for some of these compounds with the software vina autodock. the work ends with a ptml model predictive study of the outcomes of the new compounds in a large number of assays. therefore, this study offers a new computational methodology for predicting the outcome for any compound in new assays. this ptml method focuses on the prediction with a simple linear model of multiple pharmacological parameters (ic50, ec50, ki, etc.) for compounds in assays involving different cell lines used, organisms of the protein target, or organism of assay for proteins in the dopamine pathway.","['machine learning model', 'perturbation theory', 'glycinamide peptidomimetics', 'dopamine targets', 'chembl data', 'new l', 'l', 'synthesis', 'prolyl', 'leucyl', 'docking', 'assay']"
"wireless capsule endoscopy (wce) is a highly promising technology for gastrointestinal (gi) tract abnormality diagnosis. however, low image resolution and low frame rates are challenging issues in wce. in addition, the relevant frames containing the features of interest for accurate diagnosis only constitute 1% of the complete video information. for these reasons, analyzing the wce videos is still a time consuming and laborious examination for the gastroenterologists, which reduces wce system usability. this leads to the emergent need to speed-up and automates the wce video process for gi tract examinations. consequently, the present work introduced the concept of wce technology, including the structure of wce systems, with a focus on the medical endoscopy video capturing process using image sensors. it discussed also the significant characteristics of the different gi tract for effective feature extraction. furthermore, video approaches for bleeding and lesion detection in the wce video were reported with computer-aided diagnosis systems in different applications to support the gastroenterologist in the wce video analysis. in image enhancement, wce video review time reduction is also discussed, while reporting the challenges and future perspectives, including the new trend to employ the deep learning models for feature learning, polyp recognition, and classification, as a new opportunity for researchers to develop future wce video analysis techniques.","['wireless capsule endoscopy', 'colored video analysis', 'survey', 'state', 'art']"
"an extremely simple bulk sheet made of a piezoresistive carbon nanotube (cnt)-ecoflex composite can act as a smart keypad that is portable, disposable, and flexible enough to be carried crushed inside the pocket of a pair of trousers. both a rigid-button-imbedded, rollable (or foldable) pad and a patterned flexible pad have been introduced for use as portable keyboards. herein, we suggest a bare, bulk, macroscale piezoresistive sheet as a replacement for these complex devices that are achievable only through high-cost fabrication processes such as patterning-based coating, printing, deposition, and mounting. a deep-learning technique based on deep neural networks (dnn) enables this extremely simple bulk sheet to play the role of a smart keypad without the use of complicated fabrication processes. to develop this keypad, instantaneous electrical resistance change was recorded at several locations on the edge of the sheet along with the exact information on the touch position and pressure for a huge number of random touches. the recorded data were used for training a dnn model that could eventually act as a brain for a simple sheet-type keypad. this simple sheet-type keypad worked perfectly and outperformed all of the existing portable keypads in terms of functionality, flexibility, disposability, and cost.","['crude piezoresistive carbon nanotube', 'extremely flexible keypad', 'ecoflex composite sheet', 'learning technique', 'smart', 'portable', 'disposable', 'deep', 'convert']"
"neuroblastoma is the most common extracranial solid tumor in children younger than 5 years old. optimal management of neuroblastic tumors depends on many factors including histopathological classification. the gold standard for classification of neuroblastoma histological images is visual microscopic assessment. in this study, we propose and evaluate a deep learning approach to classify high-resolution digital images of neuroblastoma histology into five different classes determined by the shimada classification.","['convolutional deep belief network', 'neuroblastoma histological images', 'feature encoding', 'classification']"
"gleason grading of histological images is important in risk assessment and treatment planning for prostate cancer patients. much research has been done in classifying small homogeneous cancer regions within histological images. however, semi-supervised methods published to date depend on pre-selected regions and cannot be easily extended to an image of heterogeneous tissue composition. in this paper, we propose a multi-scale u-net model to classify images at the pixel-level using 224 histological image tiles from radical prostatectomies of 20 patients. our model was evaluated by a patient-based 10-fold cross validation, and achieved a mean jaccard index of 65.8% across 4 classes (stroma, gleason 3, gleason 4 and benign glands), and 75.5% for 3 classes (stroma, benign glands, prostate cancer), outperforming other methods.","['semantic segmentation', 'scale u', 'radical prostatectomies', 'histological images', 'net', 'multi']"
"deep convolutional neural networks (dcnn) are currently ubiquitous in medical imaging. while their versatility and high-quality results for common image analysis tasks including segmentation, localisation and prediction is astonishing, the large representational power comes at the cost of highly demanding computational effort. this limits their practical applications for image-guided interventions and diagnostic (point-of-care) support using mobile devices without graphics processing units (gpu).","['faster deep model inference without gpus', 'medical 3d segmentation using sparse', 'binary convolutions', 'ternarynet']"
"\u2003the deep inferior epigastric perforator (diep) flap is the most common perforator flap for microsurgical breast reconstruction. contrary to the conventional open approach, robotic-assisted diep flap harvest intends to preserve ars integrity, thereby reducing the morbidity. we assessed the feasibility and compared performance outcomes of a robotic, cadaveric training model for diep flap harvest using two approaches: transabdominal preperitoneal (tapp) and totally extraperitoneal (tep).","['assisted diep flap harvest', 'comparative feasibility study', 'autologous breast reconstruction', 'cadaveric model', 'robotic']"
"diabetes occurs due to the excess of glucose in the blood that may affect many organs of the body. the increase in blood sugar in the body causes many problems. one of the most prominent of these problems is diabetic retinopathy (dr). dr occurs due to the mutilation of the blood vessels in a retina. the detection of dr is complicated and time-consuming due to its features for the ophthalmologists. therefore, automatic detection is required, recently different machine and deep learning techniques are being applied to detect and classify dr. in this paper, we conducted a study of the various techniques available in the literature for the identification/classification of dr, the datasets used, strengths and weaknesses of each method and provides the future directions. moreover, we also discussed the different steps for the detection that are segmentation of blood vessels in a retina, detecting lesions and other abnormalities of dr in binary and multiclass classification.","['diabetic retinopathy detection', 'deep learning techniques']"
"hashing has attracted increasing research attention in recent years due to its high efficiency of computation and storage in image retrieval. recent works have demonstrated the superiority of simultaneous feature representations and hash functions learning with deep neural networks. however, most existing deep hashing methods directly learn the hash functions by encoding the global semantic information, while ignoring the local spatial information of images. the loss of local spatial structure makes the performance bottleneck of hash functions, therefore limiting its application for accurate similarity retrieval. in this paper, we propose a novel deep ordinal hashing (doh) method, which learns ordinal representations to generate ranking-based hash codes by leveraging the ranking structure of feature space from both local and global views. in particular, to effectively build the ranking structure, we propose to learn the rank correlation space by exploiting the local spatial information from fully convolutional network and the global semantic information from the convolutional neural network simultaneously. more specifically, an effective spatial attention model is designed to capture the local spatial information by selectively learning well-specified locations closely related to target objects. in such hashing framework, the local spatial and global semantic nature of images is captured in an end-to-end ranking-to-hashing manner. experimental results conducted on three widely used datasets demonstrate that the proposed doh method significantly outperforms the state-of-the-art hashing methods.","['deep ordinal hashing', 'spatial attention']"
"over the past few years, several approaches have been proposed to assist in the early diagnosis of alzheimer's disease (ad) and its prodromal stage of mild cognitive impairment (mci). using multimodal biomarkers for this high-dimensional classification problem, the widely used algorithms include support vector machines (svm), sparse representation-based classification (src), deep belief networks (dbn) and random forest (rf). these widely used algorithms continue to yield unsatisfactory performance for delineating the mci participants from the cognitively normal control (cn) group. a novel gaussian discriminant analysis-based algorithm is thus introduced to achieve a more effective and accurate classification performance than the aforementioned state-of-the-art algorithms. this study makes use of magnetic resonance imaging (mri) data uniquely as input to two separate high-dimensional decision spaces that reflect the structural measures of the two brain hemispheres. the data used include 190 cn, 305 mci and 133 ad subjects as part of the ad big data dream challenge #1. using 80% data for a 10-fold cross-validation, the proposed algorithm achieved an average f1 score of 95.89% and an accuracy of 96.54% for discriminating ad from cn; and more importantly, an average f1 score of 92.08% and an accuracy of 90.26% for discriminating mci from cn. then, a true test was implemented on the remaining 20% held-out test data. for discriminating mci from cn, an accuracy of 80.61%, a sensitivity of 81.97% and a specificity of 78.38% were obtained. these results show significant improvement over existing algorithms for discriminating the subtle differences between mci participants and the cn group.","['mild cognitive impairment', 'gaussian discriminant analysis', 'optimal delineation', 'disease', 'alzheimer']"
"graph models of cerebral vasculature derived from two-photon microscopy have shown to be relevant to study brain microphysiology. automatic graphing of these microvessels remain problematic due to the vascular network complexity and two-photon sensitivity limitations with depth. in this paper, we propose a fully automatic processing pipeline to address this issue. the modeling scheme consists of a fully-convolution neural network to segment microvessels, a three-dimensional surface model generator, and a geometry contraction algorithm to produce graphical models with a single connected component. based on a quantitative assessment using netmets metrics, at a tolerance of 60 μm, false negative and false positive geometric error 19 rates are 3.8% and 4.2%, respectively, whereas false nega- 20 tive and false positive topological error rates are 6.1% and 4.5%, respectively. our qualitative evaluation confirms the efficiency of our scheme in generating useful and accurate graphical models.","['brain microvessels captured', 'photon microscopy', 'based modeling', 'automatic graph', 'two']"
"this paper presents a deep learning method for faster magnetic resonance imaging (mri) by reducing k-space data with sub-nyquist sampling strategies and provides a rationale for why the proposed approach works well. uniform subsampling is used in the time-consuming phase-encoding direction to capture high-resolution image information, while permitting the image-folding problem dictated by the poisson summation formula. to deal with the localization uncertainty due to image folding, a small number of low-frequency k-space data are added. training the deep learning net involves input and output images that are pairs of the fourier transforms of the subsampled and fully sampled k-space data. our experiments show the remarkable performance of the proposed method; only 29[formula: see tex","['undersampled mri reconstruction', 'standard mri reconstruction', 'fully sampled data', 'space data', 'high quality', 'generate images', 'deep learning', 'k', 'effectively', ""'],""]"
"more than 50% of cancer patients are treated with radiotherapy, either exclusively or in combination with other methods. the planning and delivery of radiotherapy treatment is a complex process, but can now be greatly facilitated by artificial intelligence technology. deep learning is the fastest-growing field in artificial intelligence and has been successfully used in recent years in many domains, including medicine. in this article, we first explain the concept of deep learning, addressing it in the broader context of machine learning. the most common network architectures are presented, with a more specific focus on convolutional neural networks. we then present a review of the published works on deep learning methods that can be applied to radiotherapy, which are classified into seven categories related to the patient workflow, and can provide some insights of potential future applications. we have attempted to make this paper accessible to both radiotherapy and deep learning communities, and hope that it will inspire new collaborations between these two communities to develop dedicated radiotherapy applications.","['deep learning', 'survey', 'radiotherapy']"
"computational methods for protein post-translational modification (ptm) site prediction provide a useful approach for studying protein functions. the prediction accuracy of the existing methods has significant room for improvement. a recent deep-learning architecture, capsule network (capsnet), which can characterize the internal hierarchical representation of input data, presents a great opportunity to solve this problem, especially using small training data.","['translational modification site prediction', 'protein post', 'capsule network']"
"coded aperture snapshot spectral imaging (cassi) system encodes the 3d hyperspectral image (hsi) within a single 2d compressive image and then reconstructs the underlying hsi by employing an inverse optimization algorithm, which equips with the distinct advantage of snapshot but usually results in low reconstruction accuracy. to improve the accuracy, existing methods attempt to design either alternative coded apertures or advanced reconstruction methods, but cannot connect these two aspects via a unified framework, which limits the accuracy improvement. in this paper, we propose a convolution neural network (cnn) based endto- end method to boost the accuracy by jointly optimizing the coded aperture and the reconstruction method. on the one hand, based on the nature of cassi forward model, we design a repeated pattern for the coded aperture, whose entities are learned by acting as the network weights. on the other hand, we conduct the reconstruction through simultaneously exploiting intrinsic properties within hsi - the extensive correlations across the spatial and the spectral dimensions. by leveraging the power of deep learning, the coded aperture design and the image reconstruction are connected and optimized via a unified framework. experimental results show that our method outperforms the state-of-the-art methods under both comprehensive quantitative metrics and perceptive quality.","['joint coded aperture optimization', 'compressive hyperspectral imaging', 'image reconstruction', 'hyperreconnet']"
"lung mass density is directly associated with lung pathology. computed tomography (ct) evaluates lung pathology using the hounsfield unit (hu) but not lung density directly. we have developed a lung ultrasound surface wave elastography (luswe) technique to measure the surface wave speed of superficial lung tissue. the objective of this study was to develop a method for analyzing lung mass density of superficial lung tissue using a deep neural network (dnn) and synthetic data of wave speed measurements with luswe. the synthetic training dataset of surface wave speed, excitation frequency, lung mass density, and viscoelasticity from luswe (788,000 in total) was used to train the dnn model. the dnn was composed of 3 hidden layers of 1024 neurons for each layer and trained for 10\u202fepochs with a batch size of 4096 and a learning rate of 0.001 with three types of optimizers. the test dataset (4000) of wave speeds at three excitation frequencies (100, 150, and 200\u202fhz) and shear elasticity of superficial lung tissue was used to predict the lung density and evaluate its accuracy compared with predefined lung mass densities. this technique was then validated on a sponge phantom experiment. the obtained results showed that predictions matched well with test dataset (validation accuracy is 0.992) and experimental data in the sponge phantom experiment. this method may be useful to analyze lung mass density by using the dnn model together with the surface wave speed and lung stiffness measurements.","['lung mass density analysis using deep neural network', 'lung ultrasound surface wave elastography']"
"this study investigates learning in aphasia as manifested through automatic priming effects. there is growing evidence that people with aphasia have impairments beyond language processing that could affect their response to treatment. therefore, better understanding these mechanisms would be beneficial for improving methods of rehabilitation. this study assesses semantic and repetition priming effects at varied interstimulus intervals, using stimuli that are both non-linguistic and linguistic in tasks that range from requiring nearly no linguistic processing to requiring both lexical and semantic processing. results indicate that people with aphasia maintain typical patterns of learning across both linguistic and non-linguistic tasks as long as the implicit prime-target relationship does not depend on deep levels of linguistic processing. as linguistic processing demands increase, those with agrammatic aphasia may require more time to take advantage of learning through implicit prime-target relationships, and people with both agrammatic and non-agrammatic aphasia are more susceptible to breakdown of the semantic networks as processing demands on that system increase.","['linguistic processing demands', 'time course', 'learning along', 'priming', 'exploration', 'continuum', 'aphasia']"
"the growing availability of rich clinical data such as patients' electronic health records provide great opportunities to address a broad range of real-world questions in medicine. at the same time, artificial intelligence and machine learning (ml)-based approaches have shown great premise on extracting insights from those data and helping with various clinical problems. the goal of this study is to conduct a systematic comparative study of different ml algorithms for several predictive modeling problems in urgent care.","['machine learning approaches', 'urgent care', 'predictive modeling', 'comparative study']"
"monitoring the future health status of patients from the historical electronic health record (ehr) is a core research topic in predictive healthcare. the most important challenges are to model the temporality of sequential ehr data and to interpret the prediction results. in order to reduce the future risk of diseases, we propose a multi-task framework that can monitor the multiple status ofdiagnoses. patients' historical records are directly fed into a recurrent neural network (rnn) which memorizes all the past visit information, and then a task-specific layer is trained to predict multiple diagnoses. moreover, three attention mechanisms for rnns are introduced to measure the relationships between past visits and current status. experimental results show that the proposed attention-based rnns can significantly improve the prediction accuracy compared to widely used approaches. with the attention mechanisms, the proposed framework is able to identify the visit information which is important to the final prediction.","['monitoring health conditions via attention', 'based recurrent neural networks', 'task framework', 'multi']"
"the hashing technique has been extensively used in large-scale image retrieval applications due to its low storage and fast computing speed. most existing deep hashing approaches cannot fully consider the global semantic similarity and category-level semantic information, which result in the insufficient utilization of the global semantic similarity for hash codes learning and the semantic information loss of hash codes. to tackle these issues, we propose a novel deep hashing approach with triplet labels, namely, deep category-level and regularized hashing (dcrh), to leverage the global semantic similarity of deep feature and category-level semantic information to enhance the semantic similarity of hash codes. there are four contributions in this article. first, we design a novel global semantic similarity constraint about the deep feature to make the anchor deep feature more similar to the positive deep feature than to the negative deep feature. second, we leverage label information to enhance category-level semantics of hash codes for hash codes learning. third, we develop a new triplet construction module to select good image triplets for effective hash functions learning. finally, we propose a new triplet regularized loss (reg-l) term, which can force binary-like codes to approximate binary codes and eventually minimize the information loss between binary-like codes and binary codes. extensive experimental results in three image retrieval benchmark datasets show that the proposed dcrh approach achieves superior performance over other state-of-the-art hashing approaches.","['global semantic similarity learning', 'regularized hashing', 'deep category', 'level']"
"continuing medical information courses have been criticized for not promoting behavior change among their participants. for behavior change to occur, participants often need to consciously reject previous ideas and transform their way of thinking. transformational learning is a process that cultivates deep emotional responses and can lead to cognitive and behavioral change in learners, potentially facilitating rich learning experiences and expediting knowledge translation. we explored participants' experiences at a 2-day conference designed to support transformative learning as they encounter new concepts within information mastery, which challenge their previous frameworks around the topic of medical decision making. using the lens of transformative learning theory, we asked: how does information mastery qualitatively promote perspective transformation and hence behavior change?","['continuing medical education', 'transformative learning', 'based medicine', 'decision making', 'making', 'evidence', 'course']"
perforator free flap-based reconstruction of the head and neck is a challenging surgical procedure and needs a steep learning curve. a reproducible mammal large animal model with similarities to human anatomy is relevant for perforator flap raising and microanastomosis. the aim of this study was to assess the feasibility of a swine model for perforator-based free flaps in reconstructive microsurgery.,"['porcine experimental model', 'perforator flap raising', 'reconstructive microsurgery']"
"pancreatic ductal adenocarcinoma (pdac) is the fourth leading cause of cancer related death in the world with a five-year survival rate of less than 5%. not all pdac are the same, because there exist intra-tumoral heterogeneity between pdac, which poses a great challenge to personalized treatments for pdac.","['1200 pancreatic ductal adenocarcinoma reveals novel subtypes', 'gene expression profiling']"
"segmentation of histological images is one of the most crucial tasks for many biomedical analyses involving quantification of certain tissue types, such as fibrosis via masson's trichrome staining. however, challenges are posed by the high variability and complexity of structural features in such images, in addition to imaging artifacts. further, the conventional approach of manual thresholding is labor-intensive, and highly sensitive to inter- and intra-image intensity variations. an accurate and robust automated segmentation method is of high interest. we propose and evaluate an elegant convolutional neural network (cnn) designed for segmentation of histological images, particularly those with masson's trichrome stain. the network comprises 11 successive convolutional - rectified linear unit - batch normalization layers. it outperformed state-of-the-art cnns on a dataset of cardiac histological images (labeling fibrosis, myocytes, and background) with a dice similarity coefficient of 0.947. with 100 times fewer (only 300,000) trainable parameters than the state-of-the-art, our cnn is less susceptible to overfitting, and is efficient. additionally, it retains image resolution from input to output, captures fine-grained details, and can be trained end-to-end smoothly. to the best of our knowledge, this is the first deep cnn tailored to the problem of concern, and may potentially be extended to solve similar segmentation tasks to facilitate investigations into pathology and clinical treatment.","['convolutional neural network', 'histological images', 'fibrosis identification', 'segmentation']"
atherosclerotic plaque deposition within the coronary vessel wall leads to arterial stenosis and severe catastrophic events over time. identification of these atherosclerotic plaque components is essential to pre-estimate the risk of cardiovascular disease (cvd) and stratify them as a high or low risk. the characterization and quantification of coronary plaque components are not only vital but also a challenging task which can be possible using high-resolution imaging techniques.,"['coronary atherosclerotic plaque tissue characterization', 'intravascular optical coherence tomography', 'survey']"
manual brain tumor segmentation is a challenging task that requires the use of machine learning techniques. one of the machine learning techniques that has been given much attention is the convolutional neural network (cnn). the performance of the cnn can be enhanced by combining other data analysis tools such as wavelet transform.,"['enhanced convolutional neural network', 'deep learning paradigm', 'new idea', 'wavelet']"
"hierarchical variants of so-called deep convolutional neural networks (dcnns) have facilitated breakthrough results for numerous pattern recognition tasks in recent years. we assess the potential of these novel whole-image classifiers for raman-microscopy-based cytopathology. conceptually, dcnns facilitate a flexible combination of spectral and spatial information for classifying cellular images as healthy or cancer-affected cells. as we demonstrate, this conceptual advantage translates into practice, where dcnns exceed the accuracy of both conventional classifiers based on pixel spectra as well as classifiers based on morphological features extracted from raman microscopic images. remarkably, accuracies exceeding those of all previously proposed classifiers are obtained while using only a small fraction of the spectral information provided by the dataset. overall, our results indicate a high potential for dcnns in medical applications of not just raman, but also infrared microscopy.","['hierarchical deep convolutional neural networks combine spectral', 'highly accurate raman', 'spatial information', 'based cytopathology', 'microscopy']"
"radiology reports are a rich resource for advancing deep learning applications in medicine by leveraging the large volume of data continuously being updated, integrated, and shared. however, there are significant challenges as well, largely due to the ambiguity and subtlety of natural language. we propose a hybrid strategy that combines semantic-dictionary mapping and word2vec modeling for creating dense vector embeddings of free-text radiology reports. our method leverages the benefits of both semantic-dictionary mapping as well as unsupervised learning. using the vector representation, we automatically classify the radiology reports into three classes denoting confidence in the diagnosis of intracranial hemorrhage by the interpreting radiologist. we performed experiments with varying hyperparameter settings of the word embeddings and a range of different classifiers. best performance achieved was a weighted precision of 88% and weighted recall of 90%. our work offers the potential to leverage unstructured electronic health record data by allowing direct analysis of narrative clinical notes.","['text radiology reports', 'intelligent word embeddings', 'free']"
"training in endoscopic retrograde cholangiopancreatography (ercp) requires the development of technical, cognitive, and integrative skills well beyond those needed for standard endoscopic procedures. so far, there are limited data regarding what constitutes competency in ercp, including achievement and maintenance. recent studies have highlighted overall procedural numbers are not enough to warrant competency, although more is better. we performed a comprehensive literature search until june 2017 using predetermined search terms to identify relevant articles and summarized their results as a narrative review. selective native papilla deep cannulation should be used as a benchmark for assessing successful cannulation. accurate and validated ercp performance measures are needed to develop a curriculum that allows transition from numbers-based competency. however, available guidelines fail to state what degree of hands-on involvement is required by the trainee for the case to be counted in their overall procedural numbers. qualitative assessment of competency should be done by trained raters using specially designed assessment tools. competence continues to increase with practice following formal training in a fairly steady manner. the learning curve for overall common bile duct cannulation success may be a readily available surrogate for individual trainee progression and may correspond to learning curves for therapeutic interventions.","['endoscopic retrograde cholangiopancreatography', '50 years later', 'quality', 'competence']"
"benefiting from multi-energy x-ray imaging technology, material decomposition facilitates the characterization of different materials in x-ray imaging. however, the performance of material decomposition is limited by the accuracy of the decomposition model. due to the presence of nonideal effects in x-ray imaging systems, it is difficult to explicitly build the imaging system models for material decomposition. as an alternative, this paper explores the feasibility of using machine learning approaches for material decomposition tasks.","['based material decomposition pipeline', 'ray imaging', 'energy x', 'multi', 'learning']"
"over the past decade, there has been a groundswell of research interest in computer-based methods for objectively quantifying fibrotic lung disease on high resolution ct of the chest. in the past 5 years, the arrival of deep learning-based image analysis has created exciting new opportunities for enhancing the understanding of, and the ability to interpret, fibrotic lung disease on ct. specific unsolved problems for which computer-based imaging analysis might provide solutions include the development of reliable methods for assisting with diagnosis, detecting early disease, and predicting disease behaviour using baseline imaging data. however, to harness this technology, technical and societal challenges must be overcome. large ct datasets will be needed to power the training of deep learning algorithms. open science research and collaboration between academia and industry must be encouraged. prospective clinical utility studies will be needed to test computer algorithm performance in real-world clinical settings and demonstrate patient benefit over current best practice. finally, ethical standards, which ensure patient confidentiality and mitigate against biases in training datasets, that can be encoded in machine-learning systems will be needed as well as bespoke data governance and accountability frameworks to encourage buy-in from health-care professionals, patients, and the public.","['fibrotic lung disease', 'applying deep learning', 'unsolved problems', 'imaging research']"
"we address the problem of prostate lesion detection, localization, and segmentation in t2w magnetic resonance (mr) images. we train a deep convolutional encoder-decoder architecture to simultaneously segment the prostate, its anatomical structure, and the malignant lesions. to incorporate the 3d contextual spatial information provided by the mri series, we propose a novel 3d sliding window approach, which preserves the 2d domain complexity while exploiting 3d information. experiments on data from 19 patients provided for the public by the initiative for collaborative computer vision benchmarking (i2cvb) show that our approach outperforms traditional pattern recognition and machine learning approaches by a significant margin. particularly, for the task of cancer detection and localization, the system achieves an average auc of 0.995, an accuracy of 0.894, and a recall of 0.928. the proposed mono-modal deep learning-based system performs comparably to other multi-modal mr-based systems. it could improve the performance of a radiologist in prostate cancer diagnosis and treatment planning.","['t2 magnetic resonance images', 'prostate cancer', 'deep learning', 'based approach', 'localization', 'detection']"
"despite recent success of deep learning models in numerous applications, their widespread use on mobile devices is seriously impeded by storage and computational requirements. in this paper, we propose a novel network compression method called adaptive dimension adjustment tucker decomposition (ada-tucker). with learnable core tensors and transformation matrices, ada-tucker performs tucker decomposition of arbitrary-order tensors. furthermore, we propose that weight tensors in networks with proper order and balanced dimension are easier to be compressed. therefore, the high flexibility in decomposition choice distinguishes ada-tucker from all previous low-rank models. to compress more, we further extend the model to shared core ada-tucker (scada-tucker) by defining a shared core tensor for all layers. our methods require no overhead of recording indices of non-zero elements. without loss of accuracy, our methods reduce the storage of lenet-5 and lenet-300 by ratios of 691× and 233 ×, respectively, significantly outperforming state of the art. the effectiveness of our methods is also evaluated on other three benchmarks (cifar-10, svhn, ilsvrc12) and modern newly deep networks (resnet, wide-resnet).","['compressing deep neural networks via adaptive dimension adjustment tucker decomposition', 'tucker', 'ada']"
"the physionet/computing in cardiology (cinc) challenge 2017 focused on differentiating af from noise, normal or other rhythms in short term (from 9-61 s) ecg recordings performed by patients. a total of 12,186 ecgs were used: 8,528 in the public training set and 3,658 in the private hidden test set. due to the high degree of inter-expert disagreement between a significant fraction of the expert labels we implemented a mid-competition bootstrap approach to expert relabeling of the data, levering the best performing challenge entrants' algorithms to identify contentious labels. a total of 75 independent teams entered the challenge using a variety of traditional and novel methods, ranging from random forests to a deep learning approach applied to the raw data in the spectral domain. four teams won the challenge with an equal high f1 score (averaged across all classes) of 0.83, although the top 11 algorithms scored within 2% of this. a combination of 45 algorithms identified using lasso achieved an f1 of 0.87, indicating that a voting approach can boost performance.","['short single lead ecg recording', 'cardiology challenge 2017', 'af classification', 'physionet', 'computing']"
"retinopathy of prematurity (rop), a vasoproliferative retinal disease affecting premature infants, is a leading cause of childhood blindness throughout the world. plus disease, defined as venous dilatation and arteriolar tortuosity within the posterior retinal vessels greater than or equal to that of a standard published photograph, is the most critical finding in identifying treatment-requiring rop. despite an internationally accepted definition of plus disease, there is significant variability in diagnostic process and outcome, producing variable levels of reported intra- and interexpert agreement. several potential explanations for poor agreement have been proposed, including attention to undefined vascular features such as venous tortuosity, focus on narrower or wider field of view, unfamiliarity with digital images, the magnification and apparent severity of the standard photograph, and cut-off point differences among experts as to the level of tortuosity and dilation sufficient for ""plus disease"" along a continuum. moreover, differences in diagnostic consistency among groups of experts separated both geographically and chronologically have been reported. these findings have implications for clinical care, research, and education, and highlight the need for a more precise definition of plus disease and objective diagnostic methods for rop.","['plus disease', 'retinopathy', 'prematurity', 'meets', 'icrop']"
"low back pain (lbp) remains one of the most prevalent musculoskeletal disorders, while algorithms that able to recognise lbp patients from healthy population using balance performance data are rarely seen. in this study, human balance and body sway performance during standing trials were utilised to recognise chronic lbp populations using deep neural networks. to be specific, 44 chronic lbp and healthy individuals performed static standing tasks, while their spine kinematics and centre of pressure were recorded. a deep learning network with long short-term memory units was used for training, prediction and implementation. the performance of the model was evaluated by: (a) overall accuracy, (b) precision, (c) recall, (d) f1 measure, (e) receiver-operating characteristic and (f) area under the curve. results indicated that deep neural networks could recognise lbp populations with precision up to 97.2% and recall up to 97.2%. meanwhile, the results showed that the model with the c7 sensor output performed the best. practitioner summary: low back pain (lbp) remains the most common musculoskeletal disorder. in this study, we investigated the feasibility of applying artificial intelligent deep neural network in detecting lbp population from healthy controls with their kinematics data. results showed a deep learning network can solve the above classification problem with both promising precision and recall performance.","['recognise low back pain', 'deep learning network', 'static standing', 'using']"
"long non-coding rnas (lncrnas) are important regulatory elements in biological processes. lncrnas share similar sequence characteristics with messenger rnas, but they play completely different roles, thus providing novel insights for biological studies. the development of next-generation sequencing has helped in the discovery of lncrna transcripts. however, the experimental verification of numerous transcriptomes is time consuming and costly. to alleviate these issues, a computational approach is needed to distinguish lncrnas from the transcriptomes.","['coding rna identification using deep learning', 'long non', 'lncrnanet']"
purpose to reduce radiotracer requirements for amyloid pet/mri without sacrificing diagnostic quality by using deep learning methods. materials and methods forty data sets from 39 patients (mean age ± standard deviation [s,['7 years ±']
"the importance of micrornas (mirnas) is widely recognized in the community nowadays because these short segments of rna can play several roles in almost all biological processes. the computational prediction of novel mirnas involves training a classifier for identifying sequences having the highest chance of being precursors of mirnas (pre-mirnas). the big issue with this task is that well-known pre-mirnas are usually few in comparison with the hundreds of thousands of candidate sequences in a genome, which results in high class imbalance. this imbalance has a strong influence on most standard classifiers, and if not properly addressed in the model and the experiments, not only performance reported can be completely unrealistic but also the classifier will not be able to work properly for pre-mirna prediction. besides, another important issue is that for most of the machine learning (ml) approaches already used (supervised methods), it is necessary to have both positive and negative examples. the selection of positive examples is straightforward (well-known pre-mirnas). however, it is difficult to build a representative set of negative examples because they should be sequences with hairpin structure that do not contain a pre-mirna.","['predicting novel microrna', 'machine learning approaches', 'comprehensive comparison']"
"positron emission tomography (pet) has been substantially used recently. to minimize the potential health risk caused by the tracer radiation inherent to pet scans, it is of great interest to synthesize the high-quality pet image from the low-dose one to reduce the radiation exposure. in this paper, we propose a 3d auto-context-based locality adaptive multi-modality generative adversarial networks model (la-gans) to synthesize the high-quality fdg pet image from the low-dose one with the accompanying mri images that provide anatomical information. our work has four contributions. first, different from the traditional methods that treat each image modality as an input channel and apply the same kernel to convolve the whole image, we argue that the contributions of different modalities could vary at different image locations, and therefore a unified kernel for a whole image is not optimal. to address this issue, we propose a locality adaptive strategy for multi-modality fusion. second, we utilize 1 ×1 ×1 kernel to learn this locality adaptive fusion so that the number of additional parameters incurred by our method is kept minimum. third, the proposed locality adaptive fusion mechanism is learned jointly with the pet image synthesis in a 3d conditional gans model, which generates high-quality pet images by employing large-sized image patches and hierarchical features. fourth, we apply the auto-context strategy to our scheme and propose an auto-context la-gans model to further refine the quality of synthesized images. experimental results show that our method outperforms the traditional multi-modality fusion methods used in deep networks, as well as the state-of-the-art pet estimation approaches.","['based locality adaptive multi', 'pet synthesis', 'modality gans', '3d auto', 'context']"
"for real-time markerless tumour tracking in stereotactic lung radiotherapy, we propose a different approach which uses patient-specific deep learning (dl) using a personalised data generation strategy, avoiding the need for collection of a large patient data set. we validated our strategy with digital phantom simulation and epoxy phantom studies.","['time markerless tumour tracking', 'specific deep learning using', 'personalised data generation strategy', 'phantom study', 'real', 'proof', 'patient', 'concept']"
"chemical named entity recognition (ner) is an active field of research in biomedical natural language processing. to facilitate the development of new and superior chemical ner systems, biocreative released the chemdner corpus, an extensive dataset of diverse manually annotated chemical entities. most of the systems trained on the corpus rely on complicated hand-crafted rules or curated databases for data preprocessing, feature extraction and output post-processing, though modern machine learning algorithms, such as deep neural networks, can automatically design the rules with little to none human intervention. here we explored this approach by experimenting with various deep learning architectures for targeted tokenisation and named entity recognition. our final model, based on a combination of convolutional and stateful recurrent neural networks with attention-like loops and hybrid word- and character-level embeddings, reaches near human-level performance on the testing dataset with no manually asserted rules. to make our model easily accessible for standalone use and integration in third-party software, we've developed a python package with a minimalistic user interface.","['chemical named entity recognition', 'efficient deep cnn', 'rnn architecture', 'putting hands', 'crafted rules', 'rest', 'hand']"
"the case reinforces the importance of stepping back and looking at every possibility along with multiple co-existing pathologies. it takes into account the thought process of multiple systems and a multidisciplinary team approach. learning points to take are that decompression illness can present atypically, but one must exclude other causes.","['hyperbaric oxygen', 'decompression illness', 'responding', 'case']"
"deep learning convolutional neural networks (cnn) may facilitate melanoma detection, but data comparing a cnn's diagnostic performance to larger groups of dermatologists are lacking.","['deep learning convolutional neural network', 'dermoscopic melanoma recognition', 'diagnostic performance', '58 dermatologists', 'man', 'machine', 'comparison']"
"nanopore sensing is a versatile technique for the analysis of molecules on the single-molecule level. however, extracting information from data with established algorithms usually requires time-consuming checks by an experienced researcher due to inherent variability of solid-state nanopores. here, we develop a convolutional neural network (cnn) for the fully automated extraction of information from the time-series signals obtained by nanopore sensors. in our demonstration, we use a previously published data set on multiplexed single-molecule protein sensing. the neural network learns to classify translocation events with greater accuracy than previously possible, while also increasing the number of analyzable events by a factor of 5. our results demonstrate that deep learning can achieve significant improvements in single molecule nanopore detection with potential applications in rapid diagnostics.","['molecule nanopore sensing', 'convolutional neural network', 'single', 'quipunet']"
"biomimetic photonics extract the good design of nature and mimic it with photonics. the weakly electric fish genus, eigenmannia, has a unique neural algorithm - jamming avoidance response, to facilitate their survival in the deep dark ocean, by automatically adjusts the local transmitter carrier frequency to move away from the jamming frequency when it is within the jamming spectral range. examining our own wireless microwave systems, the situation of inadvertent jamming is very similar as that in eigenmannia. in this article, a biomimetic photonic approach inspired by the jamming avoidance response in a weakly electric fish genus, eigenmannia, is naturally adopted to experimentally tackle signal jamming in wireless systems. mimicking the system with photonics enables the proposed scheme to work for frequencies from hundreds of mhz to tens of ghz.","['jamming avoidance system', 'biomimetic photonics', 'eigenmannia']"
"in this paper, we aim to investigate the effect of computer-aided triage system, which is implemented for the health checkup of lung lesions involving tens of thousands of chest x-rays (cxrs) that are required for diagnosis. therefore, high accuracy of diagnosis by an automated system can reduce the radiologist's workload on scrutinizing the medical images.","['convolutional sparse denoising autoencoder', 'automated chest screening based', 'transfer learning', 'hybrid model']"
to evaluate the accuracy of detecting glaucoma visual field defect severity using deep-learning (dl) classifier with an ultrawide-field scanning laser ophthalmoscope.,"['field scanning laser ophthalmoscope detects glaucoma visual field severity', 'learning classifier', 'ultrawide', 'deep']"
"perineuronal nets (pnns), composed mainly of chondroitin sulfate proteoglycans, are the extracellular matrix that surrounds cell bodies, proximal dendrites, and axon initial segments of adult cns neurons. pnns are known to regulate neuronal plasticity, although their physiological roles in cerebellar functions have yet to be elucidated. here, we investigated the contribution of pnns to gabaergic transmission from cerebellar purkinje cells (pcs) to large glutamatergic neurons in the deep cerebellar nuclei (dcn) in male mice by recording ipscs from cerebellar slices, in which pnns were depleted with chondroitinase abc (chabc). we found that pnn depletion increased the amplitude of evoked ipscs and enhanced the paired-pulse depression. chabc treatment also facilitated spontaneous ipscs and increased the miniature ipsc frequency without changing not only the amplitude but also the density of pc terminals, suggesting that pnn depletion enhances presynaptic gaba release. we also demonstrated that the enhanced gabaergic transmission facilitated rebound firing in large glutamatergic dcn neurons, which is expected to result in the efficient induction of synaptic plasticity at synapses onto dcn neurons. furthermore, we tested whether pnn depletion affects cerebellar motor learning. mice having received the enzyme into the interpositus nuclei, which are responsible for delay eyeblink conditioning, exhibited the conditioned response at a significantly higher rate than control mice. therefore, our results suggest that pnns of the dcn suppress gabaergic transmission between pcs and large glutamatergic dcn neurons and restrict synaptic plasticity associated with motor learning in the adult cerebellum.significance statement perineuronal nets (pnns) are one of the extracellular matrices of adult cns neurons and implicated in regulating various brain functions. here we found that enzymatic pnn depletion in the mouse deep cerebellar nuclei (dcn) reduced the paired-pulse ratio of ipscs and increased the miniature ipsc frequency without changing the amplitude, suggesting that pnn depletion enhances gaba release from the presynaptic purkinje cell (pc) terminals. mice having received the enzyme in the interpositus nuclei exhibited a higher conditioned response rate in delay eyeblink conditioning than control mice. these results suggest that pnns regulate presynaptic functions of pc terminals in the dcn and functional plasticity of synapses on dcn neurons, which influences the flexibility of adult cerebellar functions.","['deep cerebellar nuclei regulate gabaergic transmission', 'delay eyeblink conditioning', 'perineuronal nets']"
"early detection of high fall risk is an essential component of fall prevention in older adults. wearable sensors can provide valuable insight into daily-life activities; biomechanical features extracted from such inertial data have been shown to be of added value for the assessment of fall risk. body-worn sensors such as accelerometers can provide valuable insight into fall risk. currently, biomechanical features derived from accelerometer data are used for the assessment of fall risk. here, we studied whether deep learning methods from machine learning are suited to automatically derive features from raw accelerometer data that assess fall risk. we used an existing dataset of 296 older adults. we compared the performance of three deep learning model architectures (convolutional neural network (cnn), long short-term memory (lstm) and a combination of these two (convlstm)) to each other and to a baseline model with biomechanical features on the same dataset. the results show that the deep learning models in a single-task learning mode are strong in recognition of identity of the subject, but that these models only slightly outperform the baseline method on fall risk assessment. when using multi-task learning, with gender and age as auxiliary tasks, deep learning models perform better. we also found that preprocessing of the data resulted in the best performance (auc = 0.75). we conclude that deep learning models, and in particular multi-task learning, effectively assess fall risk on the basis of wearable sensor data.","['older adults based', 'life trunk accelerometry', 'predict falls', 'deep learning', 'daily']"
to assess the performance of a deep learning classifier for differentiation of glaucomatous optic neuropathy (gon) from compressive optic neuropathy (con) based on ganglion cell-inner plexiform layer (gcipl) and retinal nerve fibre layer (rnfl) spectral-domain optical coherence tomography (sd-oct).,"['domain optical coherence tomography', 'deep learning classifier', 'compressive optic neuropathy', 'discriminating glaucomatous', 'spectral']"
"successful diagnosis and management of neurological dysfunction relies on proper communication between the neurologist and the primary physician (or other specialists). because this communication is documented within medical records, the ability to automatically infer the clinical correlations for a patient from his or her medical records would provide an important step towards enabling health care systems to automatically identify patients requiring additional follow-up as well as flagging any unexpected clinical correlations for review. in this paper, we present a deep section recovery model (dsrm) which applies deep neural learning on a large body of eeg reports in order to infer the expected clinical correlations for a patient from the information in a given eeg report by (1) automatically extracting word- and report- level features from the report and (2) inferring the most likely clinical correlations and expressing those clinical correlations in natural language. we evaluated the performance of the dsrm by removing the clinical correlation sections from eeg reports and measuring how well the model could recover that information from the remainder of the report. the dsrm obtained a 17% improvement over the top-performing baseline, highlighting not only the power of the dsrm but also the promise of automatically recognizing unexpected clinical correlations in the future.","['inferring clinical correlations', 'deep neural learning', 'eeg reports']"
"background radiofrequency ultrasound data from the liver contain rich information about liver microstructure and composition. deep learning might exploit such information to assess nonalcoholic fatty liver disease (nafld). purpose to develop and evaluate deep learning algorithms that use radiofrequency data for nafld assessment, with mri-derived proton density fat fraction (pdff) as the reference. materials and methods a hipaa-compliant secondary analysis of a single-center prospective study was performed for adult participants with nafld and control participants without liver disease. participants in the parent study were recruited between february 2012 and march 2014 and underwent same-day us and mri of the liver. participants were randomly divided into an equal number of training and test groups. the training group was used to develop two algorithms via cross-validation: a classifier to diagnose nafld (mri pdff ≥ 5%) and a fat fraction estimator to predict mri pdff. both algorithms used one-dimensional convolutional neural networks. the test group was used to evaluate the classifier for sensitivity, specificity, positive predictive value, negative predictive value, and accuracy and to evaluate the estimator for correlation, bias, limits of agreements, and linearity between predicted fat fraction and mri pdff. results a total of 204 participants were analyzed, 140 had nafld (mean age, 52 years ± 14 [standard deviatio",['2 wome']
"we have cast the net into the ocean of knowledge to retrieve the latest scientific research on deep learning methods for physiological signals. we found 53 research papers on this topic, published from 01.01.2008 to 31.12.2017.","['healthcare applications based', 'physiological signals', 'deep learning', 'review']"
"while biomedical ontologies have traditionally been used to guide the identification of concepts or relations in biomedical data, recent advances in deep learning are able to capture high-quality knowledge from textual data and represent it in graphical structures. as opposed to the top-down methodology used in the generation of ontologies, which starts with the principled design of the upper ontology, the bottom-up methodology enabled by deep learning encodes the likelihood that concepts share certain relations, as evidenced by data. in this paper, we present a knowledge representation produced by deep learning methods, called medical knowledge embeddings (mke), that encode medical concepts related to the study of epilepsy and the relations between them. many of the epilepsy-relevant medical concepts from mke are not yet available in existing biomedical ontologies, but are mentioned in vast collections of epilepsy-related medical records which also imply their relationships. the evaluation of the mke indicates high accuracy of the medical concepts automatically identified from clinical text as well as promising results in terms of correctness and completeness of relations produced by deep learning.","['deep learning meets biomedical ontologies', 'knowledge embeddings', 'epilepsy']"
"understanding decisions of deep learning techniques is important. especially in the medical field, the reasons for a decision in a classification task are as crucial as the pure classification results. in this article, we propose a new approach to compute relevant parts of a medical image. knowing the relevant parts makes it easier to understand decisions.","['lung nodule classification', 'evolutionary image simplification', 'convolutional neural networks']"
"falls are generally classified into two groups in clinical settings in japan: falls from the same level and falls from one level to another. we verified whether clinical staff could distinguish between these two types of falls by comparing 3,078 free-text incident reports about falls using a natural language processing technique and a machine learning technique. common terms were used in reports for both types of falls, but the similarity score between the two types of reports was low, and the performance of identification based on the classification model constructed by support vector machine and deep learning was low. although it is possible that adjustment of hyper parameters during construction of the classification model was required, we believe that clinical staff cannot distinguish between the two types of falls and do not record the distinction in incident reports.","['experimental hypothesis verification using japanese incident reports', 'staff distinguish falls', 'natural language processing']"
"deep learning techniques have recently emerged as promising decision supporting approaches to automatically analyze medical images for different clinical diagnosing purposes. diagnosing of pulmonary nodules by using computer-assisted diagnosing has received considerable theoretical, computational, and empirical research work, and considerable methods have been developed for detection and classification of pulmonary nodules on different formats of images including chest radiographs, computed tomography (ct), and positron emission tomography in the past five decades. the recent remarkable and significant progress in deep learning for pulmonary nodules achieved in both academia and the industry has demonstrated that deep learning techniques seem to be promising alternative decision support schemes to effectively tackle the central issues in pulmonary nodules diagnosing, including feature extraction, nodule detection, false-positive reduction, and benign-malignant classification for the huge volume of chest scan data. the main goal of this investigation is to provide a comprehensive state-of-the-art review of the deep learning aided decision support for pulmonary nodules diagnosing. as far as the authors know, this is the first time that a review is devoted exclusively to deep learning techniques for pulmonary nodules diagnosing.","['deep learning aided decision support', 'pulmonary nodules diagnosing', 'review']"
"in the human genome, 98% of dna sequences are non-protein-coding regions that were previously disregarded as junk dna. in fact, non-coding regions host a variety of cis-regulatory regions which precisely control the expression of genes. thus, identifying active cis-regulatory regions in the human genome is critical for understanding gene regulation and assessing the impact of genetic variation on phenotype. the developments of high-throughput sequencing and machine learning technologies make it possible to predict cis-regulatory regions genome wide.","['regulatory regions using supervised deep learning methods', 'wide prediction', 'genome', 'cis']"
"the interactions between non-coding rnas (ncrnas) and proteins play an important role in many biological processes, and their biological functions are primarily achieved by binding with a variety of proteins. high-throughput biological techniques are used to identify protein molecules bound with specific ncrna, but they are usually expensive and time consuming. deep learning provides a powerful solution to computationally predict rna-protein interactions. in this work, we propose the rpi-san model by using the deep-learning stacked auto-encoder network to mine the hidden high-level features from rna and protein sequences and feed them into a random forest (rf) model to predict ncrna binding proteins. stacked assembling is further used to improve the accuracy of the proposed method. four benchmark datasets, including rpi2241, rpi488, rpi1807, and npinter v2.0, were employed for the unbiased evaluation of\xa0five established prediction tools: rpi-pred, ipminer, rpiseq-rf, lncpro, and rpi-san. the experimental results show that our rpi-san model achieves much better performance than other methods, with accuracies of 90.77%, 89.7%, 96.1%, and 99.33%, respectively. it is anticipated that rpi-san can be used as an effective computational tool for future biomedical researches and can accurately predict the potential ncrna-protein interacted pairs, which provides reliable guidance for biological research.","['protein interactions using evolutionary information', 'deep learning framework', 'accurate prediction', 'robust', 'ncrna']"
"identification of characteristic genes associated with specific biological processes of different cancers could provide insights into the underlying cancer genetics and cancer prognostic assessment. it is of critical importance to select such characteristic genes effectively. in this paper, a novel unsupervised characteristic gene selection method based on sample learning and sparse filtering, sample learning based on deep sparse filtering (sldsf), is proposed. with sample learning, the proposed sldsf can better represent the gene expression level by the transformed sample space. most unsupervised characteristic gene selection methods did not consider deep structures, while a multilayer structure may learn more meaningful representations than a single layer, therefore deep sparse filtering is investigated here to implement sample learning in the proposed sldsf. experimental studies on several microarray and rna-seq datasets demonstrate that the proposed sldsf is more effective than several representative characteristic gene selection methods (e.g., rgnmf, gnmf, rpca and pmd) for selecting cancer characteristic genes.","['cancer characteristic gene selection via sample learning based', 'deep sparse filtering']"
"opioid analgesics, as commonly prescribed medications used for relieving pain in patients, are especially prevalent in us these years. however, an increasing amount of opioid misuse and abuse have caused lots of consequences. researchers and clinicians have attempted to discover the factors leading to opioid long-term use, dependence, and abuse, but only limited incidents are understood from previous works. motivated by recent successes of deep learning and the abundant amount of electronic health records, we apply state-of-the-art deep and recurrent neural network models on a dataset of more than one hundred thousand opioid users. our models are shown to achieve robust and superior results on classifying opioid users, and are able to extract key factors for different opioid user groups. this work is also a good demonstration on adopting novel deep learning methods for real-world health care problems.","['deep learning solutions', 'opioid use', 'classifying patients']"
"one of the world\'s most common infectious disease, periodontitis (pd), derives from largely uncharacterized communities of oral bacteria growing as biofilms (a.k.a. plaque) on teeth and gum surfaces in periodontal pockets. bacteria associated with periodontal disease trigger inflammatory responses in immune cells, which in later stages of the disease cause loss of both soft and hard tissue structures supporting teeth. thus far, only a handful of bacteria have been characterized as infectious agents of pd. although deep sequencing technologies, such as whole community shotgun sequencing have the potential to capture a detailed picture of highly complex bacterial communities in any given environment, we still lack major reference genomes for the oral microbiome associated with pd and other diseases. in recent work, by using a combination of supervised machine learning and genome assembly, we identified a genome from a novel member of the bacteroidetes phylum in periodontal samples. here, by applying a comparative metagenomics read-classification approach, including 272 metagenomes from various human body sites, and our previously assembled draft genome of the uncultivated candidatus bacteroides periocalifornicus (cbp) bacterium, we show cbp\'s ubiquitous distribution in dental plaque, as well as its strong association with the well-known pathogenic ""red complex"" that resides in deep periodontal pockets.","['novel periodontal disease', 'associated bacterium', 'discovery']"
肺癌是一种常见的肺部恶性肿瘤，是全球发病率和死亡率最高的恶性肿瘤。对于发生了表皮生长因子受体（egfr）基因突变的晚期非小细胞型肺癌患者，可以使用靶向药物来进行针对性治疗。egfr 基因突变的检测方法很多，但是各有优缺点。本文拟通过探索非小细胞型肺癌苏木精-伊红（he）染色的全扫描组织病理图像形态学特征与患者 egfr 基因突变之间的关联，达到预测 egfr 基因突变风险的目的。实验结果表明，本文所提出的 egfr 基因突变风险预测模型的曲线下面积（auc）在测试集上可达 72.4%，准确率为 70.8%，提示非小细胞型肺癌全扫描组织病理图像中的组织形态学特征与 egfr 基因突变之间存在密切关联。本文从病理图像的尺度来分析基因分子表型，将病理组学和分子组学相融合，建立 egfr 基因突变风险预测模型，揭示全扫描组织病理图像和 egfr 基因突变风险的关联性，或可为该领域提供一个颇具前景的研究方向。.,"['lung cancer based', 'histomorphology analysis ].', 'gene mutation', 'deep learning', 'prediction']"
"achieving the upper limits of face identification accuracy in forensic applications can minimize errors that have profound social and personal consequences. although forensic examiners identify faces in these applications, systematic tests of their accuracy are rare. how can we achieve the most accurate face identification: using people and/or machines working alone or in collaboration? in a comprehensive comparison of face identification by humans and computers, we found that forensic facial examiners, facial reviewers, and superrecognizers were more accurate than fingerprint examiners and students on a challenging face identification test. individual performance on the test varied widely. on the same test, four deep convolutional neural networks (dcnns), developed between 2015 and 2017, identified faces within the range of human accuracy. accuracy of the algorithms increased steadily over time, with the most recent dcnn scoring above the median of the forensic facial examiners. using crowd-sourcing methods, we fused the judgments of multiple forensic facial examiners by averaging their rating-based identity judgments. accuracy was substantially better for fused judgments than for individuals working alone. fusion also served to stabilize performance, boosting the scores of lower-performing individuals and decreasing variability. single forensic facial examiners fused with the best algorithm were more accurate than the combination of two examiners. therefore, collaboration among humans and between humans and machines offers tangible benefits to face identification accuracy in important applications. these results offer an evidence-based roadmap for achieving the most accurate face identification possible.","['face recognition algorithms', 'face recognition accuracy', 'forensic examiners', 'superrecognizers']"
"in recent years, researchers of deep neural networks (dnns)-based facial expression recognition (fer) have reported results showing that these approaches overcome the limitations of conventional machine learning-based fer approaches. however, as dnn-based fer approaches require an excessive amount of memory and incur high processing costs, their application in various fields is very limited and depends on the hardware specifications. in this paper, we propose a fast fer algorithm for monitoring a driver's emotions that is capable of operating in low specification devices installed in vehicles. for this purpose, a hierarchical weighted random forest (wrf) classifier that is trained based on the similarity of sample data, in order to improve its accuracy, is employed. in the first step, facial landmarks are detected from input images and geometric features are extracted, considering the spatial position between landmarks. these feature vectors are then implemented in the proposed hierarchical wrf classifier to classify facial expressions. our method was evaluated experimentally using three databases, extended cohn-kanade database (ck+), mmi and the keimyung university facial expression of drivers (kmu-fed) database, and its performance was compared with that of state-of-the-art methods. the results show that our proposed method yields a performance similar to that of deep learning fer methods as 92.6% for ck+ and 76.7% for mmi, with a significantly reduced processing cost approximately 3731 times less than that of the dnn method. these results confirm that the proposed method is optimized for real-time embedded applications having limited computing resources.","['facial expression recognition', 'safe driving', 'time', 'real', 'driver']"
"dynamic causal modeling (dcm) is an advanced biophysical model which explicitly describes the entire process from experimental stimuli to functional magnetic resonance imaging (fmri) signals via neural activity and cerebral hemodynamics. to conduct a dcm study, one needs to represent the experimental stimuli as a compact vector-valued function of time, which is hard in complex tasks such as book reading and natural movie watching. deep learning provides the state-of-the-art signal representation solution, encoding complex signals into compact dense vectors while preserving the essence of the original signals. there is growing interest in using recurrent neural networks (rnns), a major family of deep learning techniques, in fmri modeling. however, the generic rnns used in existing studies work as black boxes, making the interpretation of results in a neuroscience context difficult and obscure. in this paper, we propose a new biophysically interpretable rnn built on dcm, dcm-rnn. we generalize the vanilla rnn and show that dcm can be cast faithfully as a special form of the generalized rnn. dcm-rnn uses back propagation for parameter estimation. we believe dcm-rnn is a promising tool for neuroscience. it can fit seamlessly into classical dcm studies. we demonstrate face validity of dcm-rnn in two principal applications of dcm: causal brain architecture hypotheses testing and effective connectivity estimation. we also demonstrate construct validity of dcm-rnn in an attention-visual experiment. moreover, dcm-rnn enables end-to-end training of dcm and representation learning deep neural networks, extending dcm studies to complex tasks.","['generalized recurrent neural network accommodating dynamic causal modeling', 'functional mri analysis']"
"the classification and recognition technology of underwater acoustic signal were always an important research content in the field of underwater acoustic signal processing. currently, wavelet transform, hilbert-huang transform, and mel frequency cepstral coefficients are used as a method of underwater acoustic signal feature extraction. in this paper, a method for feature extraction and identification of underwater noise data based on cnn and elm is proposed. an automatic feature extraction method of underwater acoustic signals is proposed using depth convolution network. an underwater target recognition classifier is based on extreme learning machine. although convolution neural networks can execute both feature extraction and classification, their function mainly relies on a full connection layer, which is trained by gradient descent-based; the generalization ability is limited and suboptimal, so an extreme learning machine (elm) was used in classification stage. firstly, cnn learns deep and robust features, followed by the removing of the fully connected layers. then elm fed with the cnn features is used as the classifier to conduct an excellent classification. experiments on the actual data set of civil ships obtained 93.04% recognition rate; compared to the traditional mel frequency cepstral coefficients and hilbert-huang feature, recognition rate greatly improved.","['underwater target feature extraction', 'deep learning methods', 'recognition']"
"automated seizure detection from clinical eeg data can reduce the diagnosis time and facilitate targeting treatment for epileptic patients. however, current detection approaches mainly rely on limited features manually designed by domain experts, which are inflexible for the detection of a variety of patterns in a large amount of patients' eeg data. moreover, conventional machine learning algorithms for seizure detection cannot accommodate multi-channel electroencephalogram (eeg) data effectively, which contains both temporal and spatial information. recently, deep learning technology has been widely applied to perform image processing tasks, which could learns useful features from data and process multi-channel data automatically. to provide an effective system for automatic seizure detection, we proposed a new three-dimensional (3d) convolutional neural network (cnn) structure, whose inputs are multi-channel eeg signals.","['automatic seizure detection using three', 'dimensional cnn based', 'channel eeg', 'multi']"
the aim of the present study was to determine the incidence and type of complications during and after hip arthroscopy as well as the effect of the surgeon's learning curve on the occurrence of complications. we expect that the currently reported prevalence especially of minor complications is likely to be underreported in most retrospective series based on chart analysis.,"['learning curve', 'hip arthroscopy', 'surgeon', 'outcome', 'effect', 'complications']"
"the objectives were to develop and validate a convolutional neural network (cnn) using local features for differentiating distal ureteral stones from pelvic phleboliths, compare the cnn method with a semi-quantitative method and with radiologists' assessments and to evaluate whether the assessment of a calcification and its local surroundings is sufficient for discriminating ureteral stones from pelvic phleboliths in non-contrast-enhanced ct (nect). we retrospectively included 341 consecutive patients with acute renal colic and a ureteral stone on nect showing either a distal ureteral stone, a phlebolith or both. a 2.5-dimensional cnn (2.5d-cnn) model was used, where perpendicular axial, coronal and sagittal images through each calcification were used as input data for the cnn. the cnn was trained on 384 calcifications, and evaluated on an unseen dataset of 50 stones and 50 phleboliths. the cnn was compared to the assessment by seven radiologists who reviewed a local 5\u2009×\u20095\u2009×\u20095 cm image stack surrounding each calcification, and to a semi-quantitative method using cut-off values based on the attenuation and volume of the calcifications. the cnn differentiated stones and phleboliths with a sensitivity, specificity and accuracy of 94%, 90% and 92% and an auc of 0.95. this was similar to a majority vote accuracy of 93% and significantly higher (p\u2009=\u20090.03) than the mean radiologist accuracy of 86%. the semi-quantitative method accuracy was 49%. in conclusion, the cnn differentiated ureteral stones from phleboliths with higher accuracy than the mean of seven radiologists' assessments using local features. however, more than local features are needed to reach optimal discrimination.","['pelvic phleboliths using', 'distal ureteral stones', 'convolutional neural network', 'differentiation']"
"lymphatic spread determines treatment decisions in prostate cancer (pca) patients. 68ga-psma-pet/ct can be performed, although cost remains high and availability is limited. therefore, computed tomography (ct) continues to be the most used modality for pca staging. we assessed if convolutional neural networks (cnns) can be trained to determine 68ga-psma-pet/ct-lymph node status from ct alone. in 549 patients with 68ga-psma pet/ct imaging, 2616 lymph nodes were segmented. using pet as a reference standard, three cnns were trained. training sets balanced for infiltration status, lymph node location and additionally, masked images, were used for training. cnns were evaluated using a separate test set and performance was compared to radiologists\' assessments and random forest classifiers. heatmaps maps were used to identify the performance determining image regions. the cnns performed with an area-under-the-curve of 0.95 (status balanced) and 0.86 (location balanced, masked), compared to\xa0an auc of 0.81 of experienced radiologists. interestingly, cnns used anatomical surroundings to increase their performance, ""learning"" the infiltration probabilities of anatomical locations. in conclusion, cnns have the potential to build a well performing ct-based biomarker for lymph node metastases in pca, with different types of class balancing strongly affecting cnn performance.","['prostate cancer nodal staging', 'using deep learning', 'ct imaging alone', 'predict 68ga', 'psma', 'positivity']"
"muscle synergies analysis can provide a deep understanding of motor impairment after stroke and of changes after rehabilitation. in this study, the neuro-mechanical analysis of leg cycling was used to longitudinally investigate the motor recovery process coupled with cycling training augmented by functional electrical stimulation (fes) in subacute stroke survivors.","['leg cycling muscle synergies', 'subacute stroke survivors', 'functional electrical stimulation', 'training augmented', 'pilot study', 'changes']"
"remote sensing image scene classification has a high application value in the agricultural, military, as well as other fields. a large amount of remote sensing data is obtained every day. after learning the new batch data, scene classification algorithms based on deep learning face the problem of catastrophic forgetting, that is, they cannot maintain the performance of the old batch data. therefore, it has become more and more important to ensure that the scene classification model has the ability of continual learning, that is, to learn new batch data without forgetting the performance of the old batch data. however, the existing remote sensing image scene classification datasets all use static benchmarks and lack the standard to divide the datasets into a number of sequential learning training batches, which largely limits the development of continual learning in remote sensing image scene classification. first, this study gives the criteria for training batches that have been partitioned into three continual learning scenarios, and proposes a large-scale remote sensing image scene classification database called the continual learning benchmark for remote sensing (clrs). the goal of clrs is to help develop state-of-the-art continual learning algorithms in the field of remote sensing image scene classification. in addition, in this paper, a new method of constructing a large-scale remote sensing image classification database based on the target detection pretrained model is proposed, which can effectively reduce manual annotations. finally, several mainstream continual learning methods are tested and analyzed under three continual learning scenarios, and the results can be used as a baseline for future work.","['remote sensing image scene classification', 'continual learning benchmark', 'clrs']"
"admission computed tomography (ct) is a widely used diagnostic tool for patients with pelvic fractures. in this pilot study, we hypothesized that pelvic hematoma volumes derived using a rapid automated deep learning-based quantitative visualization and measurement algorithm predict interventions and outcomes including (a) need for angioembolization (ae), pelvic packing (pp), or massive transfusion (mt), and (b) in-hospital mortality.","['extraperitoneal hematoma volumes', 'based quantitative visualization', 'potential role', 'personalized forecasting', 'pelvic fractures', 'deep learning', 'decision support', 'patients', 'measurement']"
"standardized and robust risk stratification systems for patients with hepatocellular carcinoma (hcc) are required to improve therapeutic strategies and investigate the benefits of adjuvant systemic therapies after curative resection/ablation. in this study, we used two deep-learning algorithms based on whole-slide digitized histological slides (wsi) to build models for predicting the survival of patients with hcc treated by surgical resection. two independent series were investigated: a discovery set (henri mondor hospital, n=194) used to develop our algorithms and an independent validation set (tcga, n=328). wsis were first divided into small squares (""tiles"") and features were extracted with a pretrained convolutional neural network (preprocessing step). the first deep-learning based algorithm (""schmowder"") uses an attention mechanism on tumoral areas annotated by a pathologist while the second (""chowder"") does not require human expertise. in the discovery set, c-indexes for survival prediction of schmowder and chowder reached 0.78 and 0.75, respectively. both models outperformed a composite score incorporating all baseline variables associated with survival. the prognostic value of the models was further validated in the tcga dataset, and, as observed in the discovery series, both models had a higher discriminatory power than a score combining all baseline variables associated with survival. pathological review showed that the tumoral areas most predictive of poor survival were characterized by vascular spaces, the macrotrabecular architectural pattern and a lack of immune infiltration. conclusion: this study shows that artificial intelligence can help refine the prediction of hcc prognosis. it highlights the importance of pathologist/machine interactions for the construction of deep-learning algorithms that benefit from expert knowledge and allow a biological understanding of their output.","['hepatocellular carcinoma resection using deep', 'predicting survival', 'histological slides', 'learning']"
"models have been developed to predict stroke outcomes (e.g., mortality) in attempt to provide better guidance for stroke treatment. however, there is little work in developing classification models for the problem of unknown time-since-stroke (tss), which determines a patient's treatment eligibility based on a clinical defined cutoff time point (i.e., <4.5hrs). in this paper, we construct and compare machine learning methods to classify tss<4.5hrs using magnetic resonance (mr) imaging features. we also propose a deep learning model to extract hidden representations from the mr perfusion-weighted images and demonstrate classification improvement by incorporating these additional imaging features. finally, we discuss a strategy to visualize the learned features from the proposed deep learning model. the cross-validation results show that our best classifier achieved an area under the curve of 0.68, which improves significantly over current clinical methods (0.58), demonstrating the potential benefit of using advanced machine learning methods in tss classification.",['classifying acute ischemic stroke onset time using deep imaging features']
"the goal of drug design is to discover molecular structures that have suitable pharmacological properties in vast chemical space. in recent years, the use of deep generative models (dgms) is getting a lot of attention as an effective method of generating new molecules with desired properties. however, most of the properties do not have three-dimensional (3d) information, such as shape and pharmacophore. in drug discovery, pharmacophores are valuable clues in finding active compounds. in this study, we propose a computational strategy based on deep reinforcement learning for generating molecular structures with a desired pharmacophore. in addition, to extract selective molecules against a target protein, chemical genomics-based virtual screening (cgbvs) is used as post-processing method of deep reinforcement learning. as an example study, we have employed this strategy to generate molecular structures of selective tie2 inhibitors. this strategy can be adopted into general use for generating selective molecules with a desired pharmacophore.","['desired pharmacophore using deep reinforcement learning', 'molecular structures', 'strategies', 'design']"
"inferring potential adverse drug reactions is an important and challenging task for the drug discovery and healthcare industry. many previous studies in computational pharmacology have proposed utilizing multi-source drug information to predict drug side effects have and achieved initial success. however, most of the prediction methods mainly rely on direct similarities inferred from drug information and cannot fully utilize the drug information about the impact of protein⁻protein interactions (ppi) on potential drug targets. moreover, most of the methods are designed for specific tasks. in this work, we propose a novel heterogeneous network embedding approach for learning drug representations called sdhine, which integrates ppi information into drug embeddings and is generic for different adverse drug reaction (adr) prediction tasks. to integrate heterogeneous drug information and learn drug representations, we first design different meta-path-based proximities to calculate drug similarities, especially target propagation meta-path-based proximity based on ppi network, and then construct a semi-supervised stacking deep neural network model that is jointly optimized by the defined meta-path proximities. extensive experiments with three state-of-the-art network embedding methods on three adr prediction tasks demonstrate the effectiveness of the sdhine model. furthermore, we compare the drug representations in terms of drug differentiation by mapping the representations into 2d space; the results show that the performance of our approach is superior to that of the comparison methods.",['adverse drug reaction predictions using stacking deep heterogeneous information network embedding approach']
"understanding visual perceptual learning (vpl) has become increasingly more challenging as new phenomena are discovered with novel stimuli and training paradigms. although existing models aid our knowledge of critical aspects of vpl, the connections shown by these models between behavioral learning and plasticity across different brain areas are typically superficial. most models explain vpl as readout from simple perceptual representations to decision areas and are not easily adaptable to explain new findings. here, we show that a well -known instance of deep neural network (dnn), whereas not designed specifically for vpl, provides a computational model of vpl with enough complexity to be studied at many levels of analyses. after learning a gabor orientation discrimination task, the dnn model reproduced key behavioral results, including increasing specificity with higher task precision, and also suggested that learning precise discriminations could transfer asymmetrically to coarse discriminations when the stimulus conditions varied. consistent with the behavioral findings, the distribution of plasticity moved toward lower layers when task precision increased and this distribution was also modulated by tasks with different stimulus types. furthermore, learning in the network units demonstrated close resemblance to extant electrophysiological recordings in monkey visual areas. altogether, the dnn fulfilled predictions of existing theories regarding specificity and plasticity and reproduced findings of tuning changes in neurons of the primate visual areas. although the comparisons were mostly qualitative, the dnn provides a new method of studying vpl, can serve as a test bed for theories, and assists in generating predictions for physiological investigations.significance statement visual perceptual learning (vpl) has been found to cause changes at multiple stages of the visual hierarchy. we found that training a deep neural network (dnn) on an orientation discrimination task produced behavioral and physiological patterns similar to those found in human and monkey experiments. unlike existing vpl models, the dnn was pre-trained on natural images to reach high performance in object recognition, but was not designed specifically for vpl; however, it fulfilled predictions of existing theories regarding specificity and plasticity and reproduced findings of tuning changes in neurons of the primate visual areas. when used with care, this unbiased and deep-hierarchical model can provide new ways of studying vpl from behavior to physiology.","['modeling visual perceptual learning', 'deep neural networks']"
"electronic medical records (emrs) are written in an unstructured way, often using natural language. information extraction (ie) may be used for acquiring knowledge from such texts, including the automatic recognition of meaningful entities, through models\xa0for named entity recognition (ner). however, while most work on the previous was made for english, this experience aimed at testing different methods in portuguese text, more precisely, on the domain of neurology, and take some conclusions. this paper comprised the comparison between conditional random fields (crf), bidirectional long short-term memory - conditional random fields (bilstm-crf) and a bilstm-crf with residual learning connections, using not only portuguese texts from medical journals but also texts from the coimbra hospital and universitary centre (chuc) neurology service. furthermore, the performances of bilstm-crf models using word embeddings (wes) trained with clinical text and wes trained with general language texts were compared. deep learning models achieved f1-scores of nearly 83% and 75%, respectively for relaxed and strict evaluation, on texts extracted from the medical journal. for texts collected from the hospital, the same achieved f1-scores of nearly 71% and 62%. this work concludes that deep learning models outperform the shallow learning models and that in-domain wes get better results than general language wes, even when the latter are trained with much more text than the former. furthermore, the results show that it is possible to extract information from hospital clinical texts with models trained with clinical cases extracted from medical journals, and thus openly available. nevertheless, such results still require a healthcare technician to check if the information is well extracted.","['portuguese neurology text', 'named entity recognition', 'comparing different methods']"
"deep neural networks are increasingly being used in both supervised learning for classification tasks and unsupervised learning to derive complex patterns from the input data. however, the successful implementation of deep neural networks using neuroimaging datasets requires adequate sample size for training and well-defined signal intensity based structural differentiation. there is a lack of effective automated diagnostic tools for the reliable detection of brain dysmaturation in the neonatal period, related to small sample size and complex undifferentiated brain structures, despite both translational research and clinical importance. volumetric information alone is insufficient for diagnosis. in this study, we developed a computational framework for the automated classification of brain dysmaturation from neonatal mri, by combining a specific deep neural network implementation with neonatal structural brain segmentation as a method for both clinical pattern recognition and data-driven inference into the underlying structural morphology. we implemented three-dimensional convolution neural networks (3d-cnns) to specifically classify dysplastic cerebelli, a subset of surface-based subcortical brain dysmaturation, in term infants born with congenital heart disease. we obtained a 0.985\u202f±\u202f0. 0241-classification accuracy of subtle cerebellar dysplasia in chd using 10-fold cross-validation. furthermore, the hidden layer activations and class activation maps depicted regional vulnerability of the superior surface of the cerebellum, (composed of mostly the posterior lobe and the midline vermis), in regards to differentiating the dysplastic process from normal tissue. the posterior lobe and the midline vermis provide regional differentiation that is relevant to not only to the clinical diagnosis of cerebellar dysplasia, but also genetic mechanisms and neurodevelopmental outcome correlates. these findings not only contribute to the detection and classification of a subset of neonatal brain dysmaturation, but also provide insight to the pathogenesis of cerebellar dysplasia in chd. in addition, this is one of the first examples of the application of deep learning to a neuroimaging dataset, in which the hidden layer activation revealed diagnostically and biologically relevant features about the clinical pathogenesis. the code developed for this project is open source, published under the bsd license, and designed to be generalizable to applications both within and beyond neonatal brain imaging.","['neonatal mri using 3d convolutional neural networks', 'subcortical brain dysmaturation', 'computational framework', 'detection']"
"computer-aided medical decision-making (camdm) is the method to utilize massive emr data as both empirical and evidence support for the decision procedure of healthcare activities. well-developed information infrastructure, such as hospital information systems and disease surveillance systems, provides abundant data for camdm. however, the complexity of emr data with abstract medical knowledge makes the conventional model incompetent for the analysis. thus a deep belief networks (dbn) based model is proposed to simulate the information analysis and decision-making procedure in medical practice. the purpose of this paper is to evaluate a deep learning architecture as an effective solution for camdm.","['traditional chinese medicine', 'deep generative learning', 'automated ehr diagnosis']"
"we present a robust deep learning framework for the automatic localisation of cone photoreceptor cells in adaptive optics scanning light ophthalmoscope (aoslo) split-detection images. monitoring cone photoreceptors with aoslo imaging grants an excellent view into retinal structure and health, provides new perspectives into well known pathologies, and allows clinicians to monitor the effectiveness of experimental treatments. the multidimensional recurrent neural network (mdrnn) approach developed in this paper is the first method capable of reliably and automatically identifying cones in both healthy retinas and retinas afflicted with stargardt disease. therefore, it represents a leap forward in the computational image processing of aoslo images, and can provide clinical support in on-going longitudinal studies of disease progression and therapy. we validate our method using images from healthy subjects and subjects with the inherited retinal pathology stargardt disease, which significantly alters image quality and cone density. we conduct a thorough comparison of our method with current state-of-the-art methods, and demonstrate that the proposed approach is both more accurate and appreciably faster in localizing cones. as further validation to the method's robustness, we demonstrate it can be successfully applied to images of retinas with pathologies not present in the training data: achromatopsia, and retinitis pigmentosa.","['stargardt afflicted retinas using deep learning', 'automatic cone photoreceptor localisation', 'healthy']"
"growing metropolitan areas bring rapid urbanization and air pollution problems. as diseases and mortality rates increase because of the air pollution problem, it becomes a necessity to estimate the air pollution density and inform the public to protect the health. air pollution problem displays contextual characteristics such as meteorological conditions, industrial and technological developments, traffic problem etc. that change from country to country and also from city to city. in this study, we determined pm[formula: see tex","['new deep learning based air quality forecasting model', 'deep flexible sequentia', 'target pollutant', 'namely dfs', 'designed']"
"the aims of this study were, first, to evaluate a deep learning-based, automatic glioblastoma (gb) tumor segmentation algorithm on clinical routine data from multiple centers and compare the results to a ground truth, manual expert segmentation, and second, to evaluate the quality of the segmentation results across heterogeneous acquisition protocols of routinely acquired clinical magnetic resonance imaging (mri) examinations from multiple centers.","['glioblastoma segmentation using heterogeneous magnetic resonance imaging data', 'multiparametric deep learning model', 'clinical routine', 'clinical evaluation']"
we are developing a computerized segmentation tool for the inner and outer bladder wall as a part of an image analysis pipeline for ct urography (ctu).,"['outer bladder wall segmentation', 'learning convolutional neural network', 'ct urography', 'inner', 'deep']"
"rheumatologists use classification criteria to separate patients with inflammatory rheumatic diseases (ird). they change over time, and the concepts of the diseases also change. the paradigm is currently moving as the goal of classification in the future will be more to select which patients may be relevant for a specific treatment rather than to describe their characteristics. therefore, the challenge will be to reclassify multifactorial diseases on the basis of their biological mechanisms rather than their clinical phenotype. currently, various projects are trying to reclassify diseases using bioinformatics approaches and in the near future the use of advanced machine learning algorithms with large omics datasets could lead to new classification models not only based on a clinical phenotype but also on complex biological profile and common sensitivity to targeted treatment. these models would highlight common biological pathways between patients classified in the same cluster and provide a deep understanding of the mechanisms involved in the patient's clinical phenotype. such approaches would ultimately lead to classification models that rely more on biological causes than on symptoms. this overview on current classification of subgroups of ird summarises the classification criteria that we use routinely, and how we will classify ird in the future using bioinformatics and artificial intelligence techniques.","['inflammatory rheumatic diseases', 'new methodological tools', 'devising criteria sets', 'new criteria']"
"developing an accurate and reliable injury predictor is central to the biomechanical studies of traumatic brain injury. state-of-the-art efforts continue to rely on empirical, scalar metrics based on kinematics or model-estimated tissue responses explicitly pre-defined in a specific brain region of interest. they could suffer from loss of information. a single training dataset has also been used to evaluate performance but without cross-validation. in this study, we developed a deep learning approach for concussion classification using implicit features of the entire voxel-wise white matter fiber strains. using reconstructed american national football league (nfl) injury cases, leave-one-out cross-validation was employed to objectively compare injury prediction performances against two baseline machine learning classifiers (support vector machine (svm) and random forest (rf)) and four scalar metrics via univariate logistic regression (brain injury criterion (bric), cumulative strain damage measure of the whole brain (csdm-wb) and the corpus callosum (csdm-cc), and peak fiber strain in the cc). feature-based machine learning classifiers including deep learning, svm, and rf consistently outperformed all scalar injury metrics across all performance categories (e.g., leave-one-out accuracy of 0.828-0.862 vs. 0.690-0.776, and .632+ error of 0.148-0.176 vs. 0.207-0.292). further, deep learning achieved the best cross-validation accuracy, sensitivity, auc, and .632+ error. these findings demonstrate the superior performances of deep learning in concussion prediction and suggest its promise for future applications in biomechanical investigations of traumatic brain injury.","['concussion classification via deep learning using whole', 'brain white matter fiber strains']"
"deformable image registration (dir) of 4d-ct images is important in multiple radiation therapy applications including motion tracking of soft tissue or fiducial markers, target definition, image fusion, dose accumulation and treatment response evaluations. it is very challenging to accurately and quickly register 4d-ct abdominal images due to its large appearance variances and bulky sizes. in this study, we proposed an accurate and fast multi-scale dir network (ms-dirnet) for abdominal 4d-ct registration. ms-dirnet consists of a global network (globalnet) and local network (localnet). globalnet was trained using down-sampled whole image volumes while localnet was trained using sampled image patches. ms-dirnet consists of a generator and a discriminator. the generator was trained to directly predict a deformation vector field (dvf) based on the moving and target images. the generator was implemented using convolutional neural networks with multiple attention gates. the discriminator was trained to differentiate the deformed images from the target images to provide additional dvf regularization. the loss function of ms-dirnet includes three parts which are image similarity loss, adversarial loss and dvf regularization loss. the ms-dirnet was trained in a completely unsupervised manner meaning that ground truth dvfs are not needed. different from traditional dirs that calculate dvf iteratively, ms-dirnet is able to calculate the final dvf in a single forward prediction which could significantly expedite the dir process. the ms-dirnet was trained and tested on 25 patients' 4d-ct datasets using five-fold cross validation. for registration accuracy evaluation, target registration errors (tres) of ms-dirnet were compared to clinically used software. our results showed that the ms-dirnet with an average tre of 1.2 ± 0.8 mm outperformed the commercial software with an average tre of 2.5 ± 0.8 mm in 4d-ct abdominal dir, demonstrating the superior performance of our method in fiducial marker tracking and overall soft tissue alignment.","['ct deformable image registration using multiscale unsupervised deep learning', '4d']"
"methodological advances in metagenome assembly are rapidly increasing in the number of published metagenome assemblies. however, identifying misassemblies is challenging due to a lack of closely related reference genomes that can act as pseudo ground truth. existing reference-free methods are no longer maintained, can make strong assumptions that may not hold across a diversity of research projects, and have not been validated on large scale metagenome assemblies.","['metagenomic assemblies', 'quality', 'evaluating', 'deepmased']"
"despite their importance in reward, motivation, and learning there is only sparse anatomical knowledge about the human medial forebrain bundle (mfb) and the connectivity of the ventral tegmental area (vta). a thorough anatomical and microstructural description of the reward related pfc/ofc regions and their connection to the vta - the superolateral branch of the mfb (slmfb) - is however mandatory to enable an interpretation of distinct therapeutic effects from different interventional treatment modalities in neuropsychiatric disorders (dbs, tms etc.). this work aims at a normative description of the human mfb (and more detailed the slmfb) anatomy with respect to distant prefrontal connections and microstructural features.","['ventral tegmental area connections', 'human medial forebrain bundle', 'frontal lobe regions', 'associated subcortical', 'reward', 'anatomy']"
"fish in schooling formations navigate complex flow fields replete with mechanical energy in the vortex wakes of their companions. their schooling behavior has been associated with evolutionary advantages including energy savings, yet the underlying physical mechanisms remain unknown. we show that fish can improve their sustained propulsive efficiency by placing themselves in appropriate locations in the wake of other swimmers and intercepting judiciously their shed vortices. this swimming strategy leads to collective energy savings and is revealed through a combination of high-fidelity flow simulations with a deep reinforcement learning (rl) algorithm. the rl algorithm relies on a policy defined by deep, recurrent neural nets, with long-short-term memory cells, that are essential for capturing the unsteadiness of the two-way interactions between the fish and the vortical flow field. surprisingly, we find that swimming in-line with a leader is not associated with energetic benefits for the follower. instead, ""smart swimmer(s)"" place themselves at off-center positions, with respect to the axis of the leader(s) and deform their body to synchronize with the momentum of the oncoming vortices, thus enhancing their swimming efficiency at no cost to the leader(s). the results confirm that fish may harvest energy deposited in vortices and support the conjecture that swimming in formation is energetically advantageous. moreover, this study demonstrates that deep rl can produce navigation algorithms for complex unsteady and vortical flow fields, with promising implications for energy savings in autonomous robotic swarms.","['efficient collective swimming', 'deep reinforcement learning', 'harnessing vortices']"
"in this paper, we propose a convolutional neural network (cnn)-based deep learning architecture for multiclass classification of obstructive sleep apnea and hypopnea (osah) using single-lead electrocardiogram (ecg) recordings. osah is the most common sleep-related breathing disorder. many subjects who suffer from osah remain undiagnosed; thus, early detection of osah is important.","['obstructive sleep apnea', 'convolutional neural network', 'multiclass classification', 'lead electrocardiogram', 'hypopnea based', 'single']"
随着医学诊断、治疗模式的改变，医学影像的质量直接影响着医生对病情的诊断和治疗。因此，通过计算机实现智能影像质控对放射科技师的拍片工作会有较大的辅助作用。本文拟就深度学习领域中的图像分割模型、图像分类模型结合传统图像处理算法应用于医学影像质量评价的研究方法及应用情况予以阐述。我们发现使用深度学习算法对医学影像大数据进行有效训练，提取出来的特征相比于单纯使用传统图像处理算法更加准确、高效，诠释了深度学习在医疗领域的广阔应用前景。本文开发出了一套辅助拍片智能质控系统，并成功应用到了华西医院和其他市、县级医院的放射科，有效验证了该质控系统的可行性与稳定性。.,"['orthotopic dr chest radiograph quality control system based', 'artificial intelligence ].', 'research', 'application']"
"in recent years, advanced neurocomputing and machine learning techniques have been used for electroencephalogram (eeg)-based diagnosis of various neurological disorders. in this paper, a novel computer model is presented for eeg-based screening of depression using a deep neural network machine learning approach, known as convolutional neural network (cnn). the proposed technique does not require a semi-manually-selected set of features to be fed into a classifier for classification. it learns automatically and adaptively from the input eeg signals to differentiate eegs obtained from depressive and normal subjects. the model was tested using eegs obtained from 15 normal and 15 depressed patients. the algorithm attained accuracies of 93.5% and 96.0% using eeg signals from the left and right hemisphere, respectively. it was discovered in this research that the eeg signals from the right hemisphere are more distinctive in depression than those from the left hemisphere. this discovery is consistent with recent research and revelation that the depression is associated with a hyperactive right hemisphere. an exciting extension of this research would be diagnosis of different stages and severity of depression and development of a depression severity index (dsi).","['depression using deep convolutional neural network', 'based screening', 'automated eeg']"
"while deep learning has driven recent improvements in audio speaker diarization, it often faces performance issues in challenging interaction scenarios and varied acoustic settings such as between a child and adult (caregiver/examiner). in this work, the role of contextual factors that affect diarization performance in such interactions is analyzed. factors that affect each type of diarization error are identified. furthermore, a dnn is trained on diarization outputs in conjunction with the factors to improve diarization performance. the results demonstrate the usefulness of incorporating context in improving diarization performance of child-adult interactions in clinical settings.","['adult conversational interactions using contextual information', 'improving speaker diarization', 'naturalistic child']"
"data augmentation is an essential part of training discriminative convolutional neural networks (cnns). a variety of augmentation strategies, including horizontal flips, random crops, and principal component analysis (pca), have been proposed and shown to capture important characteristics of natural images. however, while data augmentation has been commonly used for deep learning in medical imaging, little work has been done to determine which augmentation strategies best capture medical image statistics, leading to more discriminative models. this work compares augmentation strategies and shows that the extent to which an augmented training set retains properties of the original medical images determines model performance. specifically, augmentation strategies such as flips and gaussian filters lead to validation accuracies of 84% and 88%, respectively. on the other hand, a less effective strategy such as adding noise leads to a significantly worse validation accuracy of 66%. finally, we show that the augmentation affects mass generation.","['medical imaging classification tasks', 'differential data augmentation techniques']"
"laser welding is a key technology for many industrial applications. however, its online quality monitoring is an open issue due to the highly complex nature of the process. this work aims at enriching existing approaches in this field. we propose a method for real-time detection of process instabilities that can lead to defects. hard x-ray radiography is used for the ground truth observations of the sub-surface events that are critical for the quality. a\xa0deep artificial neural network is applied to reveal the unique signatures of those events in wavelet spectrograms from the laser back-reflection and acoustic emission signals. the autonomous classification of the revealed signatures is tested on real-life data, while the real-time performance is reached by means of parallel computing. the confidence of the quality classification ranges between 71% and 99%, with a temporal resolution down to 2\u2009ms and a computation time per classification task as low as 2\u2009ms. this approach is a new paradigm in the digitization of industrial processes and can be exploited to provide feedbacks in a closed-loop quality control system.","['time quality monitoring', 'supervised deep learning', 'ray radiographic guidance', 'laser welding', 'x', 'real']"
"the atlantic rainforest of brazil is one of the global terrestrial hotspots of biodiversity. despite having undergone large scale deforestation, forest cover has shown signs of increases in the last decades. here, to understand the degradation and regeneration history of atlantic rainforest remnants near são paulo, we combine a unique dataset of very high resolution images from worldview-2 and worldview-3 (0.5 and 0.3m spatial resolution, respectively), georeferenced aerial photographs from 1962 and use a deep learning method called u-net to map (i) the forest cover and changes and (ii) two pioneer tree species, cecropia hololeuca and tibouchina pulchra. for tibouchina pulchra, all the individuals were mapped in february, when the trees undergo mass-flowering with purple and pink blossoms. additionally, elevation data at 30m spatial resolution from nasa shuttle radar topography mission (srtm) and annual mean climate variables (terraclimate datasets at ∼ 4km of spatial resolution) were used to analyse the forest and species distributions. we found that natural forests are currently more frequently found on south-facing slopes, likely because of geomorphology and past land use, and that tibouchina is restricted to the wetter part of the region (southern part), which annually receives at least 1600 mm of precipitation. tibouchina pulchra was found to clearly indicate forest regeneration as almost all individuals were found within or adjacent to forests regrown after 1962. by contrast, cecropia hololeuca was found to indicate older disturbed forests, with all individuals almost exclusively found in forest fragments already present in 1962. at the regional scale, using the dominance maps of both species, we show that at least 4.3% of the current region's natural forests have regrown after 1962 (tibouchina dominated, ∼ 4757 ha) and that ∼ 9% of the old natural forests have experienced significant disturbance (cecropia dominated).","['indicator species using convolutional network', 'mapping atlantic rainforest degradation', 'regeneration history']"
this corrects the article doi: 10.1038/ncomms15405.,"['deep sleep maintains learning efficiency', 'human brain', 'author correction']"
"urban heat island (uhi), a phenomenon involving increased air temperature of a city compared to the surrounding rural area, results in increased energy use and escalated health problems. to understand the magnitude and characteristics of uhi in seoul and to accommodate for the high temporal variability and spatial heterogeneity of the uhi which make it inherently challenging to analyze using conventional statistical methods, we developed two deep learning models, a temporal uhi-model and a spatial uhi model, using a feed-forward deep neural network (dnn) architecture. data related to meteorological elements (e.g. air temperature) and urban texture (e.g. surface albedo) were used to train and test the temporal uhi-model and the spatial uhi-model respectively. also, we develop and propose a new metric, uhi-hours, that quantifies the total number of hours that uhi exists in a given area. our results show that uhi-hours is a better indicator of seasonal uhi than the commonly used index, uhi-intensity. consequently, uhi-hours is likely to provide a better measure of the cumulative effects of uhi over time than uhi-intensity. uhi-hours will help us to better quantify the effect of uhi on, for example, the overall daily productivity of outdoor workers or heat-related mortality rates.","['urban heat island', 'using deep', 'seoul korea', 'magnitude', 'learning', 'forecast', 'characteristics']"
"neuroendoscopic surgery using an ultrasonic aspirator represents a valid tool with which to perform the safe resection of deep-seated ventricular lesions, but the handling of neuroendoscopic instruments is technically challenging, requiring extensive training to achieve a steep learning curve. simulation-based methods are increasingly used to improve surgical skills, allowing neurosurgical trainees to practice in a risk-free, reproducible environment. the authors introduce a synthetic, patient-specific simulator that enables trainees to develop skills for endoscopic ventricular tumor removal, and they evaluate the model's validity as a training instrument with regard to realism, mechanical proprieties, procedural content, and handling.","['neuroendoscopic ventricular lesion removal', 'synthetic 3d', 'printed simulator', 'validation', 'training', 'development']"
"bipolar disorder (bd) is a common and disabling psychiatric condition with a severe socioeconomic impact. bd is treated with mood stabilizers, among which lithium represents the first-line treatment. lithium alone or in combination is effective in 60% of chronically treated patients, but response remains\xa0heterogenous and a large number of patients require a change in therapy after several weeks or months. many studies have so far tried to identify molecular and genetic markers that could help us to predict response to mood stabilizers\xa0or the risk for adverse drug reactions. pharmacogenetic studies in bd\xa0have been for the most part focused on lithium, but the complexity and variability of the response\xa0phenotype, together with the unclear mechanism of action of lithium, limited the power of these studies to identify robust biomarkers. recent pharmacogenomic studies on lithium response have provided promising findings, suggesting that the integration of genome-wide investigations with deep phenotyping, in silico analyses and machine learning could lead us closer to personalized treatments for bd. nevertheless, to date none of the genes suggested by pharmacogenetic studies on mood stabilizers have been included in any of the genetic tests approved by the food and drug administration (fda) for drug efficacy. on the other hand, genetic information has been included in drug labels to test for the safety of carbamazepine and valproate. in this review, we will outline available studies investigating the pharmacogenetics and pharmacogenomics of lithium and other mood stabilizers, with a specific focus on the limitations of these studies and potential strategies to overcome them. we will also discuss fda-approved pharmacogenetic tests for treatments commonly used in the management of bd.","['moving towards precision medicine', 'bipolar disorder', 'role', 'pharmacogenomics']"
"serial laboratory testing is common, especially in intensive care units (icu). such repeated testing is expensive and may even harm patients. however, identifying specific tests that can be omitted is challenging. the search space of different lab tests is large and the optimal reduction is hard to determine without modeling the time trajectory of decisions, which is a nontrivial optimization problem. in this paper, we propose a novel deep-learning method with a very concise architecture to jointly predict future lab test events to be omitted and the values of the omitted events based on observed testing values. using our method, we were able to omit 15% of lab tests with <5% prediction accuracy loss. although the application is specific to repeated lab tests, our proposed framework is highly generalizable and can be used to tackle a family of similar business decision making problems.","['reduce lab tests', 'integrated method', 'draw blood', 'predict']"
"convolutional neural networks (cnns) are a branch of deep learning which have been turned into one of the popular methods in different applications, especially medical imaging. one of the significant applications in this category is to help specialists make an early detection of skin cancer in dermoscopy and can reduce mortality rate. however, there are a lot of reasons that affect system diagnosis accuracy. in recent years, the utilization of computer-aided technology for this purpose has been turned into an interesting category for scientists. in this research, a meta-heuristic optimized cnn classifier is applied for pre-trained network models for visual datasets with the purpose of classifying skin cancer images. however there are different methods about optimizing the learning step of neural networks, and there are few studies about the deep learning based neural networks and their applications. in the present work, a new approach based on whale optimization algorithm is utilized for optimizing the weight and biases in the cnn models. the new method is then compared with 10 popular classifiers on two skin cancer datasets including dermis digital database dermquest database. experimental results show that the use of this optimized method performs with better accuracy than other classification methods.","['convolutional neural networks', 'skin cancer', 'automatic detection', 'optimization']"
中华预防医学会新型冠状病毒肺炎防控专家组对于如何推进我国疾病预防控制体系现代化建设进行了充分的讨论，深入分析了我国疾病预防控制体系的发展、现状和存在问题，以及其他国家和地区疾病预防控制体系值得借鉴的地方。专家组提出了全面加强和完善公共卫生领域相关法律法规建设，建立符合国情的体制机制，改革和完善公共卫生突发事件应急处置体系，明确疾控体系在健康中国建设中的主导地位和作用，加快建设现代化的信息系统和加快一流人才队伍和先进文化建设等建议。.,"['prevention ].', 'disease control', 'recommendation', 'modernization']"
"medical named entity recognition (ner) in chinese electronic medical records (cemrs) has drawn much research attention, and plays a vital prerequisite role for extracting high-value medical information. in 2018, china health information processing conference (chip2018) organized a medical ner academic competition aiming to extract three types of malignant tumor entity from cemrs. since the three types of entity are highly domain-specific and interdependency, extraction of them cannot be achieved with a single neural network model. based on comprehensive study of the three types of entity and the entity interdependencies, we propose a collaborative cooperation of multiple neural network models based approach, which consists of two bilstm-crf models and a cnn model. in order to tackle the problem that target scene dataset is small and entity distributions are sparse, we introduce non-target scene datasets and propose sentence-level neural network model transfer learning. based on 30,000 real-world cemrs, we pre-train medical domain-specific chinese character embeddings with word2vec, glove and elmo, and apply them to our approach respectively to validate effects of pre-trained language models in chinese medical ner. also, as control experiments, we apply gated recurrent unit to our approach. finally, our approach achieves an overall f1-score of 87.60%, which is the state-of-the-art performance to the best of our knowledge. in addition, our approach has won the champion of the medical ner academic competition organized by 2019 china conference on knowledge graph and semantic computing, which proves the outstanding generalization ability of our approach.","['chinese medical named entity recognition based', 'multiple neural network models', 'collaborative cooperation', 'research']"
"the electroencephalogram (eeg) is the most prominent means to study epilepsy and capture changes in electrical brain activity that could declare an imminent seizure. in this work, long short-term memory (lstm) networks are introduced in epileptic seizure prediction using eeg signals, expanding the use of deep learning algorithms with convolutional neural networks (cnn). a pre-analysis is initially performed to find the optimal architecture of the lstm network by testing several modules and layers of memory units. based on these results, a two-layer lstm network is selected to evaluate seizure prediction performance using four different lengths of preictal windows, ranging from 15\u202fmin to 2\u202fh. the lstm model exploits a wide range of features extracted prior to classification, including time and frequency domain features, between eeg channels cross-correlation and graph theoretic features. the evaluation is performed using long-term eeg recordings from the open chb-mit scalp eeg database, suggest that the proposed methodology is able to predict all 185 seizures, providing high rates of seizure prediction sensitivity and low false prediction rates (fpr) of 0.11-0.02 false alarms per hour, depending on the duration of the preictal window. the proposed lstm-based methodology delivers a significant increase in seizure prediction performance compared to both traditional machine learning techniques and convolutional neural networks that have been previously evaluated in the literature.","['term memory deep learning network', 'epileptic seizures using eeg signals', 'long short', 'prediction']"
"the number of gluteal fat augmentation procedures has increased recently and so has the number of complications. because of the increased risk of morbidity and mortality when fat is injected intramuscularly, not knowing where fat is injected is concerning. we sought to identify the planes in which fat is injected during the procedure.","['assisted gluteal fat grafting', 'time ultrasound', 'real']"
"neural circuits typically consist of many different types of neurons, and one faces a challenge in disentangling their individual contributions in measured neural activity. classification of cells into inhibitory and excitatory neurons and localization of neurons on the basis of extracellular recordings are frequently employed procedures. current approaches, however, need a lot of human intervention, which makes them slow, biased, and unreliable. in light of recent advances in deep learning techniques and exploiting the availability of neuron models with quasi-realistic three-dimensional morphology and physiological properties, we present a framework for automatized and objective classification and localization of cells based on the spatiotemporal profiles of the extracellular action potentials recorded by multielectrode arrays. we train convolutional neural networks on simulated signals from a large set of cell models and show that our framework can predict the position of neurons with high accuracy, more precisely than current state-of-the-art methods. our method is also able to classify whether a neuron is excitatory or inhibitory with very high accuracy, substantially improving on commonly used clustering techniques. furthermore, our new method seems to have the potential to separate certain subtypes of excitatory and inhibitory neurons. the possibility of automatically localizing and classifying all neurons recorded with large high-density extracellular electrodes contributes to a more accurate and more reliable mapping of neural circuits. new & noteworthy we propose a novel approach to localize and classify neurons from their extracellularly recorded action potentials with a combination of biophysically detailed neuron models and deep learning techniques. applied to simulated data, this new combination of forward modeling and machine learning yields higher performance compared with state-of-the-art localization and classification methods.","['multielectrode array neuron localization', 'combining biophysical modeling', 'deep learning', 'classification']"
"digital pathology imaging of tumor tissues, which captures histological details in high resolution, is fast becoming a routine clinical procedure. recent developments in deep-learning methods have enabled the identification, characterization, and classification of individual cells from pathology images analysis at a large scale. this creates new opportunities to study the spatial patterns of and interactions among different types of cells. reliable statistical approaches to modeling such spatial patterns and interactions can provide insight into tumor progression and shed light on the biological mechanisms of cancer. in this article, we consider the problem of modeling a pathology image with irregular locations of three different types of cells: lymphocyte, stromal, and tumor cells. we propose a novel bayesian hierarchical model, which incorporates a hidden potts model to project the irregularly distributed cells to a square lattice and a markov random field prior model to identify regions in a heterogeneous pathology image. the model allows us to quantify the interactions between different types of cells, some of which are clinically meaningful. we use markov chain monte carlo sampling techniques, combined with a double metropolis-hastings algorithm, in order to simulate samples approximately from a distribution with an intractable normalizing constant. the proposed model was applied to the pathology images of $205$ lung cancer patients from the national lung screening trial, and the results show that the interaction strength between tumor and stromal cells predicts patient prognosis (p = $0.005$). this statistical methodology provides a new perspective for understanding the role of cell-cell interactions in cancer progression.","['bayesian hidden potts mixture model', 'analyzing lung cancer pathology images']"
勾画危及器官是放射治疗中的重要环节。目前人工勾画的方式依赖于医生的知识和经验，非常耗时且难以保证勾画准确性、一致性和重复性。为此，本研究提出一种深度卷积神经网络，用于头颈部危及器官的自动和精确勾画。研究回顾了 496 例鼻咽癌患者数据，随机选择 376 例用于训练集，60 例用于验证集，60 例作为测试集。使用三维（3d）u-net 深度卷积神经网络结构，结合 dice loss 和 generalized dice loss 两种损失函数训练头颈部危及器官自动勾画深度卷积神经网络模型，评估参数为 dice 相似性系数和 jaccard 距离。19 种危及器官 dice 相似性指数平均达到 0.91，jaccard 距离平均值为 0.15。研究结果显示基于 3d u-net 深度卷积神经网络结合 dice 损失函数可以较好地应用于头颈部危及器官的自动勾画。.,"['net deep convolutional neural network ].', 'risk based', 'neck organs', 'dimensional u', 'automatic segmentation', 'three', 'head']"
"in this paper, we propose a novel neural network architecture for clinical text mining. we formulate this hybrid neural network model (hnn), composed of recurrent neural network and deep residual network, to jointly predict the presence and period assertion values associated with medical events in clinical texts. we evaluate the effectiveness of our model on a corpus of expert-annotated longitudinal electronic health records (ehr) notes from cancer patients. our experiments show that hnn improves the joint assertion classification accuracy as compared to conventional baselines.","['hybrid neural network model', 'period assertions', 'medical events', 'joint prediction', 'clinical notes', 'presence']"
"pathologic diagnosis of nasopharyngeal carcinoma (npc) can be challenging since most cases are nonkeratinizing carcinoma with little differentiation and many admixed lymphocytes. our aim was to evaluate the possibility to identify npc in nasopharyngeal biopsies using deep learning. a total of 726 nasopharyngeal biopsies were included. among them, 100 cases were randomly selected as the testing set, 20 cases as the validation set, and all other 606 cases as the training set. all three datasets had equal numbers of npc cases and benign cases. manual annotation was performed. cropped square image patches of 256 × 256 pixels were used for patch-level training, validation, and testing. the final patch-level algorithm effectively identified npc patches, with an area under the receiver operator characteristic curve (auc) of 0.9900. using gradient-weighted class activation mapping, we demonstrated that the identification of npc patches was based on morphologic features of tumor cells. at the second stage, whole-slide images were sequentially cropped into patches, inferred with the patch-level algorithm, and reconstructed into images with a smaller size for training, validation, and testing. finally, the auc was 0.9848 for slide-level identification of npc. our result shows for the first time that deep learning algorithms can identify npc.","['nasopharyngeal biopsies using deep learning', 'nasopharyngeal carcinoma', 'successful identification']"
"endoscopic piriformis release (epr) is among the available treatments for piriformis syndrome. this procedure typically involves dividing the muscle near the sciatic nerve in the sub-gluteal space, which contains numerous blood vessels and nerves. the objectives of this prospective cadaver study were: 1) to assess the reproducibility and quality of endoscopic piriformis tenotomy near the greater trochanter; 2) to detect iatrogenic injuries to the lateral hip rotators, nerves, and vessels; 3) and to define the surgical safety margins relative to the sciatic nerve and inferior gluteal bundle.","['endoscopic piriformis tenotomy provide safe', 'complete tendon release', 'cadaver study']"
"data-independent acquisition mass spectrometry (dia-ms) is a powerful technique that enables relatively deep proteomic profiling with superior quantification reproducibility. dia data mining predominantly relies on a spectral library of sufficient proteome coverage that, in most cases, is built on data-dependent acquisition-based analysis of the same sample. to expand the proteome coverage for a pre-determined protein family, we report herein on the construction of a hybrid spectral library that supplements a dia experiment-derived library with a protein family-targeted virtual library predicted by deep learning. leveraging this dia hybrid library substantially deepens the coverage of three transmembrane protein families (g protein-coupled receptors, ion channels, and transporters) in mouse brain tissues with increases in protein identification of 37%-87% and peptide identification of 58%-161%. moreover, of the 412 novel gpcr peptides exclusively identified with the dia hybrid library strategy, 53.6% were validated as present in mouse brain tissues based on orthogonal experimental measurement.","['targeted virtual library substantially deepens', 'hybrid spectral library combining dia', 'proteome coverage', 'ms data']"
"prediction of aqueous solubilities or hydration free energies is an extensively studied area in machine learning applications in chemistry since water is the sole solvent in the living system. however, for non-aqueous solutions, few machine learning studies have been undertaken so far despite the fact that the solvation mechanism plays an important role in various chemical reactions. here, we introduce delfos (deep learning model for solvation free energies in generic organic solvents), which is a novel, machine-learning-based qspr method which predicts solvation free energies for various organic solute and solvent systems. a novelty of delfos involves two separate solvent and solute encoder networks that can quantify structural features of given compounds via word embedding and recurrent layers, augmented with the attention mechanism which extracts important substructures from outputs of recurrent neural networks. as a result, the predictor network calculates the solvation free energy of a given solvent-solute pair using features from encoders. with the results obtained from extensive calculations using 2495 solute-solvent pairs, we demonstrate that delfos not only has great potential in showing accuracy comparable to that of the state-of-the-art computational chemistry methods, but also offers information about which substructures play a dominant role in the solvation process.","['solvation free energies', 'generic organic solvents', 'deep learning model', 'prediction', 'delfos']"
"deep learning (dl) algorithms enabled computational models consist of multiple processing layers that represent data with multiple levels of abstraction. in recent years, usage of deep learning is rapidly proliferating in almost every domain, especially in medical image processing, medical image analysis, and bioinformatics. consequently, deep learning has dramatically changed and improved the means of recognition, prediction, and diagnosis effectively in numerous areas of healthcare such as pathology, brain tumor, lung cancer, abdomen, cardiac, and retina. considering the wide range of applications of deep learning, the objective of this article is to review major deep learning concepts pertinent to brain tumor analysis (e.g., segmentation, classification, prediction, evaluation.). a review conducted by summarizing a large number of scientific contributions to the field (i.e., deep learning in brain tumor analysis) is presented in this study. a coherent taxonomy of research landscape from the literature has also been mapped, and the major aspects of this emerging field have been discussed and analyzed. a critical discussion section to show the limitations of deep learning techniques has been included at the end to elaborate open research challenges and directions for future work in this emergent area.","['brain tumor analysis empowered', 'future challenges', 'deep learning', 'taxonomy', 'review']"
"video tracking based biological early warning system achieved a great progress with advanced computer vision and machine learning methods. ability of video tracking of multiple biological organisms has been largely improved in recent years. video based behavioral monitoring has become a common tool for acquiring quantified behavioral data for aquatic risk assessment. investigation of behavioral responses under chemical and environmental stress has been boosted by rapidly developed machine learning and artificial intelligence. in this paper, we introduce the fundamental of video tracking and present the pioneer works in precise tracking of a group of individuals in 2d and 3d space. technical and practical issues suffered in video tracking are explained. subsequently, the toxic analysis based on fish behavioral data is summarized. frequently used computational methods and machine learning are explained with their applications in aquatic toxicity detection and abnormal pattern analysis. finally, advantages of recent developed deep learning approach in toxic prediction are presented.","['monitoring fish behavior using computer vision', 'aquatic toxic analysis', 'recent progress']"
"historically, medical imaging has been a qualitative or semi-quantitative modality. it is difficult to quantify what can be seen in an image, and to turn it into valuable predictive outcomes. as a result of advances in both computational hardware and machine learning algorithms, computers are making great strides in obtaining quantitative information from imaging and correlating it with outcomes. radiomics, in its two forms ""handcrafted and deep,"" is an emerging field that translates medical images into quantitative data to yield biological information and enable radiologic phenotypic profiling for diagnosis, theragnosis, decision support, and monitoring. handcrafted radiomics is a multistage process in which features based on shape, pixel intensities, and texture are extracted from radiographs. within this review, we describe the steps: starting with quantitative imaging data, how it can be extracted, how to correlate it with clinical and biological outcomes, resulting in models that can be used to make predictions, such as survival, or for detection and classification used in diagnostics. the application of deep learning, the second arm of radiomics, and its place in the radiomics workflow is discussed, along with its advantages and disadvantages. to better illustrate the technologies being used, we provide real-world clinical applications of radiomics in oncology, showcasing research on the applications of radiomics, as well as covering its limitations and its future direction.","['quantitative imaging', 'radiomics', 'qualitative']"
"the annotation of three-dimensional (3d) cephalometric landmarks in 3d computerized tomography (ct) has become an essential part of cephalometric analysis, which is used for diagnosis, surgical planning, and treatment evaluation. the automation of 3d landmarking with high-precision remains challenging due to the limited availability of training data and the high computational burden. this paper addresses these challenges by proposing a hierarchical deep-learning method consisting of four stages: 1) a basic landmark annotator for 3d skull pose normalization, 2) a deep-learning-based coarse-to-fine landmark annotator on the midsagittal plane, 3) a low-dimensional representation of the total number of landmarks using variational autoencoder (vae), and 4) a local-to-global landmark annotator. the implementation of the vae allows two-dimensional-image-based 3d morphological feature learning and similarity/dissimilarity representation learning of the concatenated vectors of cephalometric landmarks. the proposed method achieves an average 3d point-to-point error of 3.63 mm for 93 cephalometric landmarks using a small number of training ct datasets. notably, the vae captures variations of craniofacial structural characteristics.","['global landmark annotation', 'automatic 3d cephalometry', 'based local', 'learning']"
to validate concurrent utility of within-scanner encoding and delayed recognition-memory paradigms to ascertain hippocampal activations during task-based memory fmri.,"['mesial temporal lobe epilepsy due', 'delayed recall paradigms using task', 'based memory fmri', 'observational study', 'intramural encoding', 'hippocampal sclerosis', 'hippocampal activations']"
"in recent years, deep learning has been successfully applied to the analysis and processing of ultrasound images. to date, most of this research has focused on segmentation and view recognition. this paper benchmarks different convolutional neural network algorithms for motion estimation in ultrasound imaging. we evaluated and compared several networks derived from flownet2, one of the most efficient architectures in computer vision. the networks were tested with and without transfer learning and the best configuration was compared against the particle-imaging-velocimetry method, a popular state-of-the-art block-matching algorithm. rotations are known to be difficult to track from ultrasound images due to a significant speckle decorrelation. we thus focused on images of rotating disks, that could be tracked through speckle features only. our database consisted of synthetic and in-vitro b-mode images after log-compression, and covered a large range of rotational speeds. one of the flownet2 sub-networks, flownet2sd, produced competitive results with a motion field error smaller than 1 pixel on real data after transfer learning based on simulated data. these errors remains small for a large velocity range without the need for hyper-parameter tuning, which indicates the high potential and adaptability of deep learning solutions to motion estimation in ultrasound imaging.","['convolutional neural networks', 'ultrasound images', 'pilot study', 'motion estimation']"
"人体动作识别（har）是智慧医疗、体育训练、视频监控等众多领域的技术基础，受到社会各界的广泛关注。本文概述了 har 的研究进展及意义，将其归纳为动作捕捉和基于深度学习的动作分类两个过程。首先，详细介绍了基于视频、基于深度相机以及基于惯性传感器的三种主流动作捕捉方式，列举了常用的动作数据集。其次，从特征自动提取及多模态特征融合两方面来描述基于深度学习的 har，并介绍了正骨康复训练中如何通过 har 实现监督锻炼和模拟训练。最后,讨论了 har 的精准动作捕捉、多模态特征融合方法，以及在正骨康复训练应用中的重点和难点。本文通过总结以上内容旨在快速地引导研究人员了解 har 的研究现状及其在正骨康复训练中的应用。.","['modal human motion representation recognition', 'orthopedic rehabilitation training ].', 'review', 'multi', 'application']"
we present a method for computer-generated holography based on deep learning. the inverse process of light propagation is regressed with a number of computationally generated speckle data sets. this method enables noniterative calculation of computer-generated holograms (cghs). the proposed method was experimentally verified with a phase-only cgh.,"['generated holography', 'learning', 'deep']"
"performing patient-specific, pre-operative cochlea ct-based measurements could be helpful to positively affect the outcome of cochlear surgery in terms of intracochlear trauma and loss of residual hearing. therefore, we propose a method to automatically segment and measure the human cochlea in clinical ultra-high-resolution (uhr) ct images, and investigate differences in cochlea size for personalized implant planning.","['scale deep learning framework', 'resolution ct images', 'cochlea localization', 'clinical ultra', 'segmentation', 'multi', 'high', 'analysis']"
the objective of this study is to determine the quality of chest x-ray images using a deep convolutional neural network (dcnn) and a rule base without performing any visual assessment. a method is proposed for determining the minimum diagnosable exposure index (ei) and the target exposure index (eit).,"['target exposure index using', 'deep convolutional neural network', 'rule base', 'calculating']"
to assess the impact on image quality and dose reduction of a new deep learning image reconstruction (dlir) algorithm compared with a hybrid iterative reconstruction (ir) algorithm.,"['deep learning image reconstruction algorithm', 'dose reduction opportunity', 'image quality', 'phantom study', 'ct']"
"we present trafic, a fully automated tool for the labeling and classification of brain fiber tracts. trafic classifies new fibers using a neural network trained using shape features computed from previously traced and manually corrected fiber tracts. it is independent from a dti atlas as it is applied to already traced fibers. this work is motivated by medical applications where the process of extracting fibers from a dti atlas, or classifying fibers manually is time consuming and requires knowledge about brain anatomy. with this new approach we were able to classify traced fiber tracts obtaining encouraging results. in this report we will present in detail the methods used and the results achieved with our approach.","['fiber tract classification using deep learning', 'trafic']"
"t1-weighted image (t1wi) and t2-weighted image (t2wi) are the two routinely acquired magnetic resonance (mr) modalities that can provide complementary information for clinical and research usages. however, the relatively long acquisition time makes the acquired image vulnerable to motion artifacts. to speed up the imaging process, various algorithms have been proposed to reconstruct high-quality images from under-sampled k-space data. however, most of the existing algorithms only rely on mono-modality acquisition for the image reconstruction. in this paper, we propose to combine complementary mr acquisitions (i.e., t1wi and under-sampled t2wi particularly) to reconstruct the high-quality image (i.e., corresponding to the fully-sampled t2wi). to the best of our knowledge, this is the first work to fuse multi-modal mr acquisitions through deep learning to speed up the reconstruction of a certain target image. specifically, we present a novel deep learning approach, namely dense-unet, to accomplish the reconstruction task. the proposed dense-unet requires fewer parameters and less computation, while achieving promising performance. our results have shown that dense-unet can reconstruct a 3d t2wi volume in less than 10 seconds with an under-sampling rate of 8 for the k-space and negligible aliasing artifacts or signal-noise-ratio (snr) loss. experiments also demonstrate excellent transferring capability of dense-unet when applied to the datasets acquired by different mr scanners. the above results imply great potential of our method in many clinical scenarios.","['deep leaning based multi', 'fast mr reconstruction', 'modal fusion']"
"drugs modulate disease states through their actions on targets in the body. determining these targets aids the focused development of new treatments, and helps to better characterize those already employed. one means of accomplishing this is through the deployment of in silico methodologies, harnessing computational analytical and predictive power to produce educated hypotheses for experimental verification. here, we provide an overview of the current state of the art, describe some of the well-established methods in detail, and reflect on how they, and emerging technologies promoting the incorporation of complex and heterogeneous data-sets, can be employed to improve our understanding of (poly)pharmacology.","['silico target prediction', 'small molecules']"
"mesothelin (msln) is a cell surface glycoprotein present in many cancer types. its expression is generally associated with an unfavorable prognosis. this study examined the prognostic significance of msln expression in different areas of individual colorectal cancers (crcs) using tissue microarrays (tmas) by enrolling 314 patients with stage ii (t3-t4, n0, m0) crcs. using formalin-fixed paraffin-embedded tissue blocks from patients, tma blocks were constructed. tissue core specimens were obtained from submucosal invasive front (fr-sm), subserosal invasive front (fr-ss), central area (ce), and rolled edge (ro) of each tumor. using these four-point tma sets, msln expression was immunohistochemically surveyed. the area-specific prognostic significance of msln expression was evaluated. a deep learning convolutional neural network algorithm was used for imaging analysis and evaluating our judgment's objectivity. msln staining ratio was positively correlated between the manual and machine-learning analyses (r\u2009=\u20090.71). the correlation coefficient between ro and ce, ro and fr-sm, and ro and fr-ss was r\u2009=\u20090.63, r\u2009=\u20090.54, and r\u2009=\u20090.61, respectively. disease-specific survival curves for the msln-positive and msln-negative groups in fr-sm, fr-ss, and ro were significantly different (five-year survival rates 88.1% and 95.5% (p\u2009=\u20090.024), 85.0 and 96.2% (p\u2009=\u20090.0087), 87.8 and 95.5% (p\u2009=\u20090.051), and 77.9 and 95.8% (p\u2009=\u20090.046) for fr-sm, fr-ss, ce, and ro, respectively). the analysis performed using area-specific four-point tmas clearly demonstrated that msln expression in stage ii crc was relatively homogeneous within tumors. additionally, high msln expression showed or tended to show unfavorable prognostic significance regardless of the tumor area.","['point tissue microarrays', 'colorectal cancer disclosed', 'specific four', 'prognostic significance', 'mesothelin expression', 'area']"
"pedicle screw fixation is a challenging procedure with a concerning rates of reoperation. after insertion of the screws is completed, the most common intraoperative verification approach is to acquire anterior-posterior and lateral radiographic images, based on which the surgeons try to visually assess the correctness of insertion. given the limited accuracy of the existing verification techniques, we identified the need for an accurate and automated pedicle screw assessment system that can verify the screw insertion intraoperatively. for doing so, this paper offers a framework for automatic segmentation and pose estimation of pedicle screws based on deep learning principles.","['pedicle screw implants based', 'deep learning framework', 'pose estimation', 'arm fluoroscopy', 'segmentation', 'c']"
"the ocean has been investigated for centuries across the world, and planning the travel path for vessels in the ocean has become a hot topic in recent decades as the increasing development of worldwide business trading. planning such suitable paths is often based on big data processing in cybernetics, while not many investigations have been done. we attempt to find the optimal path for vessels in the ocean by proposing an online learning dispatch approach on studying the mission-executing-feedback (mef) model. the proposed approach explores the ocean subdomain (os) to achieve the largest average traveling feedback for different vessels. it balances the ocean path by a deep and wide search, and considers adaptation for these vessels. further, we propose a contextual multiarmed bandit-based algorithm, which provides accurate exploration results with sublinear regret and significantly improves the learning speed. the experimental results show that the proposed mef approach possesses 90% accuracy gain over random exploration and achieves about 25% accuracy improvement over other contextual bandit models on supporting big data online learning pre-eminently.","['massive maritime path planning', 'contextual online learning approach']"
"machine learning, a subset of artificial intelligence, is a set of models and methods that can automatically detect patterns in vast amounts of data, extract information and use it to perform various kinds of decision-making under uncertain conditions. this can assist surgeons in clinical decision-making by identifying patient cohorts that will benefit from surgery prior to treatment. the aim of this review is to evaluate the applications of machine learning in plastic and reconstructive surgery.","['systematic review', 'reconstructive surgery', 'machine learning', 'protocol', 'plastic', 'applications']"
"currently, there are still no early biomarkers to detect infants with risk of autism spectrum disorder (asd), which is mainly diagnosed based on behavioral observations at three or four years of age. since intervention efforts may miss a critical developmental window after 2 years old, it is clinically significant to identify imaging-based biomarkers at an early stage for better intervention, before behavioral diagnostic signs of asd typically arising. previous studies on older children and young adults with asd demonstrate altered developmental trajectories of the amygdala and hippocampus. however, our knowledge on their developmental trajectories in early postnatal stages remains very limited. in this paper, for the first time, we propose a volume-based analysis of the amygdala and hippocampal subfields of the infant subjects with risk of asd at 6, 12, and 24 months of age. to address the challenge of low tissue contrast and small structural size of infant amygdala and hippocampal subfields, we propose a novel deep-learning approach, dilated-dense u-net, to digitally segment the amygdala and hippocampal subfields in a longitudinal dataset, the national database for autism research (ndar). a volume-based analysis is then performed based on the segmentation results. our study shows that the overgrowth of amygdala and cornu ammonis sectors (ca) 1-3 may start from 6 months of age, which may be related to the emergence of autistic spectrum disorder.","['longitudinal mri study', 'hippocampal subfields', 'risk', 'infants', 'autism', 'amygdala']"
measures shown to improve outcomes for patients often fail to be adopted into routine practice in the nhs. the institute for health improvement breakthrough series collaborative (bsc) model is designed to support implementation at scale. this trial aims to assess the effectiveness and cost-effectiveness of quality improvement collaboratives (qics) based on the bsc method for introducing service improvements at scale in the nhs.,"['surgical teams', 'quality improvement', 'scaling', 'qis']"
"wireless networks have been widely deployed with a high demand for wireless data traffic. the ubiquitous availability of wireless signals brings new opportunities for non-intrusive human activity sensing. to enhance a thorough understanding of existing wireless sensing techniques and provide insights for future directions, this survey conducts a review of the existing research on human activity sensing with wireless signals. we review and compare existing research of wireless human activity sensing from seven perspectives, including the types of wireless signals, theoretical models, signal preprocessing techniques, activity segmentation, feature extraction, classification, and application. with the development and deployment of new wireless technology, there will be more sensing opportunities in human activities. based on the analysis of existing research, the survey points out seven challenges on wireless human activity sensing research: robustness, non-coexistence of sensing and communications, privacy, multiple user activity sensing, limited sensing range, complex deep learning, and lack of standard datasets. finally, this survey presents four possible future research trends, including new theoretical models, the coexistence of sensing and communications, awareness of sensing on receivers, and constructing open datasets to enable new wireless sensing opportunities on human activities.","['human activity sensing', 'wireless signals', 'survey']"
"deep brain stimulation (dbs) of the subthalamic nucleus (stn) is a proven and effective therapy for the management of the motor symptoms of parkinson's disease (pd). while accurate positioning of the stimulating electrode is critical for success of this therapy, precise identification of the stn based on imaging can be challenging. we developed a method to accurately visualize the stn on a standard clinical magnetic resonance imaging (mri). the method incorporates a database of 7-tesla (t) mris of pd patients together with machine-learning methods (hereafter 7\u2009t-ml).","['deep brain stimulation surgery', '7t magnetic resonance imaging', 'microelectrode recordings validate', 'nucleus based', 'machine learning', 'clinical visualization', 'subthalamic']"
"researches on the microbiome have been actively conducted worldwide and the results have shown human gut bacterial environment significantly impacts on immune system, psychological conditions, cancers, obesity, and metabolic diseases. thanks to the development of sequencing technology, microbiome studies with large number of samples are eligible on an acceptable cost nowadays. large samples allow analysis of more sophisticated modeling using machine learning approaches to study relationships between microbiome and various traits. this article provides an overview of machine learning methods for non-data scientists interested in the association analysis of microbiomes and host phenotypes. once genomic feature of microbiome is determined, various analysis methods can be used to explore the relationship between microbiome and host phenotypes that include penalized regression, support vector machine (svm), random forest, and artificial neural network (ann). deep neural network methods are also touched. analysis procedure from environment setup to extract analysis results are presented with python programming language.","['machine learning methods', 'microbiome studies']"
"we present a cross-modality generation framework that learns to generate translated modalities from given modalities in mr images. our proposed method performs image modality translation (abbreviated as imt) by means of a deep learning model that leverages conditional generative adversarial networks (cgans). our framework jointly exploits the low-level features (pixel-wise information) and high-level representations (e.g. brain tumors, brain structure like gray matter, etc.) between cross modalities which are important for resolving the challenging complexity in brain structures. our framework can serve as an auxiliary method in medical use and has great application potential. based on our proposed framework, we first propose a method for cross-modality registration by fusing the deformation fields to adopt the cross-modality information from translated modalities. second, we propose an approach for mri segmentation, translated multichannel segmentation (tms), where given modalities, along with translated modalities, are segmented by fully convolutional networks (fcn) in a multichannel manner. both of these two methods successfully adopt the cross-modality information to improve the performance without adding any extra data. experiments demonstrate that our proposed framework advances the state-of-the-art on five brain mri datasets. we also observe encouraging results in cross-modality registration and segmentation on some widely adopted brain datasets. overall, our work can serve as an auxiliary method in medical use and be applied to various tasks in medical fields.","['mri cross', 'modality image', 'image translation']"
"complexcontact (http://raptorx2.uchicago.edu/complexcontact/) is a web server for sequence-based interfacial residue-residue contact prediction of a putative protein complex. interfacial residue-residue contacts are critical for understanding how proteins form complex and interact at residue level. when receiving a pair of protein sequences, complexcontact first searches for their sequence homologs and builds two paired multiple sequence alignments (msa), then it applies co-evolution analysis and a casp-winning deep learning (dl) method to predict interfacial contacts from paired msas and visualizes the prediction as an image. the dl method was originally developed for intra-protein contact prediction and performed the best in casp12. our large-scale experimental test further shows that complexcontact greatly outperforms pure co-evolution methods for inter-protein contact prediction, regardless of the species.","['protein contact prediction using deep learning', 'web server', 'inter', 'complexcontact']"
"large vestibular aqueduct syndrome is one of the common non-syndromic hearing impairment. it is one of the most common inner ear abnormalities that cause hearing loss in children.the main performance is gradual or fluctuant hearing loss, from basic normal to extremely severe. frequently seen in high frequencies hearing loss. the air-bone conduction gaps present in pure tone audiometry test with low frequencies. there were some inducements of intracranial pressure increases before premorbid. some patients could be accompanied by vertigo or instability. so far, there was still no effective way to terminate the patient deafness progress.if there was no effective intervention,the speech developmental delay of children were an inevitable trend,greatly affect their normal social communication learning ability. so, early diagnosis was critical. imaging examination was the golden criterion for the diagnosis of lavs.characteristic audiological performance and gene diagnosis can be the basis of the further diagnosed. because the structure and anatomical location of vestibular aqueduct is small and deep, normal imaging examination is difficult to display its morphology and structure,so,for a long time, it did not work very well. until the advent of high-resolution computed tomography and magnetic resonance imaging, there was a breakthrough and a deeper understanding of the fine structure with inner ear. we reviewed the latest progress of large vestibular aqueduct syndrome imaging studies.","['large vestibular aqueduct syndrome ].', 'research progress', 'imaging']"
"to characterize long non-coding rnas (lncrnas), both identifying and functionally annotating them are essential to be addressed. moreover, a comprehensive construction for lncrna annotation is desired to facilitate the research in the field.","['functional annotation tool based', 'ab initio lncrna identification', 'deep learning', 'lncadeep']"
"the objective of this work is to develop a computer-aided diagnostic system for early diagnosis of prostate cancer. the presented system integrates both clinical biomarkers (prostate-specific antigen) and extracted features from diffusion-weighted magnetic resonance imaging collected at multiple b values. the presented system performs 3 major processing steps. first, prostate delineation using a hybrid approach that combines a level-set model with nonnegative matrix factorization. second, estimation and normalization of diffusion parameters, which are the apparent diffusion coefficients of the delineated prostate volumes at different b values followed by refinement of those apparent diffusion coefficients using a generalized gaussian markov random field model. then, construction of the cumulative distribution functions of the processed apparent diffusion coefficients at multiple b values. in parallel, a k-nearest neighbor classifier is employed to transform the prostate-specific antigen results into diagnostic probabilities. finally, those prostate-specific antigen-based probabilities are integrated with the initial diagnostic probabilities obtained using stacked nonnegativity constraint sparse autoencoders that employ apparent diffusion coefficient-cumulative distribution functions for better diagnostic accuracy. experiments conducted on 18 diffusion-weighted magnetic resonance imaging data sets achieved 94.4% diagnosis accuracy (sensitivity = 88.9% and specificity = 100%), which indicate the promising results of the presented computer-aided diagnostic system.","['deep learning role', 'prostate cancer', 'early diagnosis']"
"retinopathy of prematurity (rop) is a leading cause of childhood blindness worldwide. the decision to treat is primarily based on the presence of plus disease, defined as dilation and tortuosity of retinal vessels. however, clinical diagnosis of plus disease is highly subjective and variable.","['prematurity using deep convolutional neural networks', 'plus disease', 'automated diagnosis', 'retinopathy']"
to investigate the diagnostic performance of deep learning (dl)-based vascular extraction and stenosis detection technology in assessing coronary artery disease (cad).,"['stenosis detection technique', 'coronary artery disease', 'based vascular extraction', 'diagnostic performance', 'deep learning']"
"residue solvent accessibility is closely related to the spatial arrangement and packing of residues. predicting the solvent accessibility of a protein is an important step to understand its structure and function. in this work, we present a deep learning method to predict residue solvent accessibility, which is based on a stacked deep bidirectional recurrent neural network applied to sequence profiles. to capture more long-range sequence information, a merging operator was proposed when bidirectional information from hidden nodes was merged for outputs. three types of merging operators were used in our improved model, with a long short-term memory network performing as a hidden computing node. the trained database was constructed from 7361 proteins extracted from the pisces server using a cut-off of 25% sequence identity. sequence-derived features including position-specific scoring matrix, physical properties, physicochemical characteristics, conservation score and protein coding were used to represent a residue. using this method, predictive values of continuous relative solvent-accessible area were obtained, and then, these values were transformed into binary states with predefined thresholds. our experimental results showed that our deep learning method improved prediction quality relative to current methods, with mean absolute error and pearson's correlation coefficient values of 8.8% and 74.8%, respectively, on the cb502 dataset and 8.2% and 78%, respectively, on the manesh215 dataset.","['stacked deep bidirectional recurrent neural network', 'protein solvent', 'accessibility prediction']"
"electrical stimulation of the human brain is commonly used for eliciting and inhibiting neural activity for clinical diagnostics, modifying abnormal neural circuit function for therapeutics, and interrogating cortical connectivity. however, recording electrical signals with concurrent stimulation results in dominant electrical artifacts that mask the neural signals of interest. here we develop a method to reproducibly and robustly recover neural activity during concurrent stimulation. we concentrate on signal recovery across an array of electrodes without channel-wise fine-tuning of the algorithm. our goal includes signal recovery with trains of stimulation pulses, since repeated, high-frequency pulses are often required to induce desired effects in both therapeutic and research domains. we have made all of our code and data publicly available.","['stimulation artifacts', 'signal recovery', 'intracranial recordings', 'dictionary learning']"
"previous comparisons between single-port laparoscopic appendectomy (spla) and multi-port laparoscopic appendectomy have been conflicting and limited. we compare our single-surgeon, spla experience with multi-port cases performed during the same time.","['port laparoscopic appendectomy', 'retrospective comparison', 'learning curve', 'single', 'multi', 'beyond']"
"the main goal of this study is to explore the use of features representing patient-level electronic health record (ehr) data, generated by the unsupervised deep learning algorithm autoencoder, in predictive modeling. since autoencoder features are unsupervised, this paper focuses on their general lower-dimensional representation of ehr information in a wide variety of predictive tasks.","['predictive models using electronic health records', 'unsupervised deep learning', 'application']"
"left atrium segmentation and visualization serve as a fundamental and crucial role in clinical analysis and understanding of atrial fibrillation. however, most of the existing methods are directly transmitting information, which may cause redundant information to be passed to affect segmentation performance. moreover, they did not further consider atrial visualization after segmentation, which leads to a lack of understanding of the essential atrial anatomy.","['unified deep learning framework', 'left atrium', 'visualization', 'segmentation']"
"to assess the performance of deep learning algorithms for different tasks in retinal fundus images: (1) detection of retinal fundus images versus optical coherence tomography (oct) or other images, (2) evaluation of good quality retinal fundus images, (3) distinction between right eye (od) and left eye (os) retinal fundus images,(4) detection of age-related macular degeneration (amd) and (5) detection of referable glaucomatous optic neuropathy (gon).","['identify retinal fundus images', 'suspected glaucoma', 'quality validation', 'macular degeneration', 'laterality evaluation', 'artificial intelligence']"
"high-density surface electromyography (hd-semg) and deep learning technology are becoming increasingly used in gesture recognition. based on electrode grid data, information can be extracted in the form of images that are generated with instant values of multi-channel semg signals. in previous studies, image-based, two-dimensional convolutional neural networks (2d cnns) have been applied in order to recognize patterns in the electrical activity of muscles from an instantaneous image. however, 2d cnns with 2d kernels are unable to handle a sequence of images that carry information concerning how the instantaneous image evolves with time. this paper presents a 3d cnn with 3d kernels to capture both spatial and temporal structures from sequential semg images and investigates its performance on hd-semg-based gesture recognition in comparison to the 2d cnn. extensive experiments were carried out on two benchmark datasets (i.e., capgmyo db-a and csl-hdemg). the results show that, where the same network architecture is used, 3d cnn can achieve a better performance than 2d cnn, especially for csl-hdemg, which contains the dynamic part of finger movement. for capgmyo db-a, the accuracy of 3d cnn was 1% higher than 2d cnn when the recognition window length was equal to 40 ms, and was 1.5% higher when equal to 150 ms. for csl-hdemg, the accuracies of 3d cnn were 15.3% and 18.6% higher than 2d cnn when the window length was equal to 40 ms and 150 ms, respectively. furthermore, 3d cnn achieves a competitive performance in comparison to the baseline methods.","['based gesture recognition using', '3d convolutional neural network', 'density surface emg', 'high']"
the aim of this 2-year systematic review is to understand how learner assessment and curriculum evaluation of education in palliative care is being undertaken and to examine whether current undergraduate education influences the clinical patient's care.,"['undergraduate palliative care education', 'clinical patient', 'care', 'influence', 'contribution']"
"drug-induced liver injury (dili) has been the single most frequent cause of safety-related drug marketing withdrawals for the past 50 years. recently, deep learning (dl) has been successfully applied in many fields due to its exceptional and automatic learning ability. in this study, dili prediction models were developed using dl architectures, and the best model trained on 475 drugs predicted an external validation set of 198 drugs with an accuracy of 86.9%, sensitivity of 82.5%, specificity of 92.9%, and area under the curve of 0.955, which is better than the performance of previously described dili prediction models. furthermore, with deep analysis, we also identified important molecular features that are related to dili. such dl models could improve the prediction of dili risk in humans. the dl dili prediction models are freely available at http://www.repharma.cn/diliserver/dili_home.php.","['induced liver injury', 'deep learning', 'drug']"
"radiomic features achieve promising results in cancer diagnosis, treatment response prediction, and survival prediction. our goal is to compare the handcrafted (explicitly designed) and deep learning (dl)-based radiomic features extracted from pre-treatment diffusion-weighted magnetic resonance images (dwis) for predicting neoadjuvant chemoradiation treatment (ncrt) response in patients with locally advanced rectal cancer (larc). 43 patients receiving ncrt were included. all patients underwent dwis before ncrt and total mesorectal excision surgery 6-12 weeks after completion of ncrt. gross tumor volume (gtv) contours were drawn by an experienced radiation oncologist on dwis. the patient-cohort was split into the responder group (n = 22) and the non-responder group (n = 21) based on the post-ncrt response assessed by postoperative pathology, mri or colonoscopy. handcrafted and dl-based features were extracted from the apparent diffusion coefficient (adc) map of the dwi using conventional computer-aided diagnosis methods and a pre-trained convolution neural network, respectively. least absolute shrinkage and selection operator (lasso)-logistic regression models were constructed using extracted features for predicting treatment response. the model performance was evaluated with repeated 20 times stratified 4-fold cross-validation using receiver operating characteristic (roc) curves and compared using the corrected paired t-test. the model built with handcrafted features achieved the mean area under the roc curve (auc) of 0.64, while the one built with dl-based features yielded the mean auc of 0.73. the corrected paired t-test on auc showed p-value < 0.05. dl-based features extracted from pre-treatment dwis achieved significantly better classification performance compared with handcrafted features for predicting ncrt response in patients with larc.","['improving neoadjuvant chemoradiation response prediction', 'locally advanced rectal cancer', 'based radiomic features', 'deep learning']"
"video-based human pose recovery is usually conducted by retrieving relevant poses using image features. in the retrieving process, the mapping between 2d images and 3d poses is assumed to be linear in most of the traditional methods. however, their relationships are inherently non-linear, which limits recovery performance of these methods. in this paper, we propose a novel pose recovery method using non-linear mapping with multi-layered deep neural network. it is based on feature extraction with multimodal fusion and back-propagation deep learning. in multimodal fusion, we construct hypergraph laplacian with low-rank representation. in this way, we obtain a unified feature description by standard eigen-decomposition of the hypergraph laplacian matrix. in back-propagation deep learning, we learn a non-linear mapping from 2d images to 3d poses with parameter fine-tuning. the experimental results on three data sets show that the recovery error has been reduced by 20%-25%, which demonstrates the effectiveness of the proposed method.","['multimodal deep autoencoder', 'human pose recovery']"
"deep convolutional neural networks have been widely used in numerous applications, but their demanding storage and computational resource requirements prevent their applications on mobile devices. knowledge distillation aims to optimize a portable student network by taking the knowledge from a well-trained heavy teacher network. traditional teacher-student-based methods used to rely on additional fully connected layers to bridge intermediate layers of teacher and student networks, which brings in a large number of auxiliary parameters. in contrast, this article aims to propagate information from teacher to student without introducing new variables that need to be optimized. we regard the teacher-student paradigm from a new perspective of feature embedding. by introducing the locality preserving loss, the student network is encouraged to generate the low-dimensional features that could inherit intrinsic properties of their corresponding high-dimensional features from the teacher network. the resulting portable network, thus, can naturally maintain the performance as that of the teacher network. theoretical analysis is provided to justify the lower computation complexity of the proposed method. experiments on benchmark data sets and well-trained networks suggest that the proposed algorithm is superior to state-of-the-art teacher-student learning methods in terms of computational and storage complexity.",['learning student networks via feature embedding']
"deep characterization of molecular function of genetic variants in the human genome is becoming increasingly important for understanding genetic associations to disease and for learning to read the regulatory code of the genome. in this paper, i discuss how recent advances in both quantitative genetics and molecular biology have contributed to understanding functional effects of genetic variants, lessons learned from eqtl studies, and future challenges in this field.","['functional genomics bridges', 'quantitative genetics', 'molecular biology', 'gap']"
"measuring the physical size of a cell is valuable in understanding cell growth control. current single-cell volume measurement methods for mammalian cells are labor intensive, inflexible and can cause cell damage. we introduce ctrl: cell topography reconstruction learner, a label-free technique incorporating the deep learning algorithm and the fluorescence exclusion method for reconstructing cell topography and estimating mammalian cell volume from differential interference contrast (dic) microscopy images alone. the method achieves quantitative accuracy, requires minimal sample preparation, and applies to a wide range of biological and experimental conditions. the method can be used to track single-cell volume dynamics over arbitrarily long time periods. for ht1080 fibrosarcoma cells, we observe that the cell size at division is positively correlated with the cell size at birth (sizer), and there is a noticeable reduction in cell size fluctuations at 25% completion of the cell cycle in ht1080 fibrosarcoma cells.","['free artificial intelligence method', 'dynamic measurement', 'cell volume', 'single', 'label', 'ctrl']"
"deep convolutional networks have proven to be very successful in learning task specific features that allow for unprecedented performance on various computer vision tasks. training of such networks follows mostly the supervised learning paradigm, where sufficiently many input-output pairs are required for training. acquisition of large training sets is one of the key challenges, when approaching a new task. in this paper, we aim for generic feature learning and present an approach for training a convolutional network using only unlabeled data. to this end, we train the network to discriminate between a set of surrogate classes. each surrogate class is formed by applying a variety of transformations to a randomly sampled 'seed' image patch. in contrast to supervised network training, the resulting feature representation is not class specific. it rather provides robustness to the transformations that have been applied during training. this generic feature representation allows for classification results that outperform the state of the art for unsupervised learning on several popular datasets (stl-10, cifar-10, caltech-101, caltech-256). while features learned with our approach cannot compete with class specific features from supervised training on a classification task, we show that they are advantageous on geometric matching problems, where they also outperform the sift descriptor.","['exemplar convolutional neural networks', 'discriminative unsupervised feature learning']"
"hashing could significantly accelerate large-scale image search by transforming the high-dimensional features into binary hamming space, where efficient similarity search can be achieved with very fast hamming distance computation and extremely low storage cost. as an important branch of hashing methods, multi-view hashing takes advantages of multiple features from different views for binary hash learning. however, existing multi-view hashing methods are either based on shallow models which fail to fully capture the intrinsic correlations of heterogeneous views, or unsupervised deep models which suffer from insufficient semantics and cannot effectively exploit the complementarity of view features. in this paper, we propose a novel deep collaborative multi-view hashing (dcmvh) method to deeply fuse multi-view features and learn multi-view hash codes collaboratively under a deep architecture. dcmvh is a new deep multi-view hash learning framework. it mainly consists of 1) multiple view-specific networks to extract hidden representations of different views, and 2) a fusion network to learn multi-view fused hash code. dcmvh associates different layers with instance-wise and pair-wise semantic labels respectively. in this way, the discriminative capability of representation layers can be progressively enhanced and meanwhile the complementarity of different view features can be exploited effectively. finally, we develop a fast discrete hash optimization method based on augmented lagrangian multiplier to efficiently solve the binary hash codes. experiments on public multi-view image search datasets demonstrate our approach achieves substantial performance improvement over state-of-the-art methods.","['scale image search', 'deep collaborative multi', 'view hashing', 'large']"
"diabetic retinopathy (dr), which is generally diagnosed by the presence of hemorrhages and hard exudates, is one of the most prevalent causes of visual impairment and blindness. early detection of hard exudates (hes) in color fundus photographs can help in preventing such destructive damage. however, this is a challenging task due to high intra-class diversity and high similarity with other structures in the fundus images. most of the existing methods for detecting hes are based on characterizing hes using hand crafted features (hcfs) only, which can not characterize hes accurately. deep learning methods are scarce in this domain because they require large-scale sample sets for training which are not generally available for most routine medical imaging research.","['hard exudate detection based', 'deep model learned information', 'feature joint representation', 'diabetic retinopathy screening', 'multi']"
"our knowledge of the cerebral bases of decision making has grown considerably in the past decade. the dopamine system is closely involved in many aspects of the decisional process. it is therefore not surprising that the dysfunctions that occur in parkinson's disease (pd) can alter some patients' decisions. put simply, a decision is the final step of a process in which a subject weighs up the potential benefits and costs associated with each of the different options available for a given choice. the option that appears to have the best ratio of benefits to costs is chosen. in some pd patients, dopamine agonists destabilize the balance: the benefits are given an inappropriately high weighting relative to the costs, leading patients to take decisions they would not otherwise have taken. this might be one of the explanations for impulse control disorders observed in some pd patients. dysfunction of the subthalamic nucleus (stn) induced by dopamine replacement or by deep brain stimulation is another mechanism that can alter decision making. the stn plays an active role in the decisional process, especially by slowing down the process when the difference between the options to be considered in a given choice is small (e.g. a win-win choice). deep brain stimulation applied to the stn may interfere with its monitoring role and lead to an impulsive choice. attention disorders and frontal lobe dysfunction, highly prevalent in the course of pd, are other factors that may alter a patient's decision making. patients and caregivers need to be aware of this, since the consequences can sometimes be detrimental.","['disease patients sometimes make wrong decisions', 'parkinson']"
"human pose estimation and action recognition are related tasks since both problems are strongly dependent on the human body representation and analysis. nonetheless, most recent methods in the literature handle the two problems separately. in this work, we propose a multi-task framework for jointly estimating 2d or 3d human poses from monocular color images and classifying human actions from video sequences. we show that a single architecture can be used to solve both problems in an efficient way and still achieves state-of-the-art or comparable results at each task while running with a throughput of more than 100 frames per second. the proposed method benefits from high parameters sharing between the two tasks by unifying still images and video clips processing in a single pipeline, allowing the model to be trained with data from different categories simultaneously and in a seamlessly way. additionally, we provide important insights for end-to-end training the proposed multi-task model by decoupling key prediction parts, which consistently leads to better accuracy on both tasks. the reported results on four datasets (mpii, human3.6m, penn action and ntu rgb+d) demonstrate the effectiveness of our method on the targeted tasks. our source code and trained weights are publicly available at https://github.com/dluvizon/deephar.","['time 3d human pose estimation', 'task deep learning', 'action recognition', 'real', 'multi']"
"spectrum handoff is one of the key techniques in a cognitive radio system. in order to improve the agility and the reliability of spectrum handoffs as well as the system throughput in hybrid cognitive radio networks (hcrns) combing interweave mode with underlay mode, a predictive (or proactive) spectrum handoff scheme based on a deep q-network (dqn) for hcrns is proposed in this paper. in the proposed spectrum handoff approach, spectrum handoff success rate is introduced into an optimal spectrum resource allocation model to ensure the reliability of spectrum handoff, and the closed-form expression for the spectrum handoff success rate is obtained based on the poisson distribution. furthermore, we exploit the transfer learning strategy to further improve the dqn learning process and finally achieve a priority sequence of target available channels for spectrum handoffs, which can maximize the overall hcrns throughput while satisfying constraints on secondary users' interference with primary user, limits on the spectrum handoff success rate, and the secondary users' performance requirements. simulation results show that the proposed spectrum handoff scheme outperforms the state-of-the-art spectrum handoff algorithms based on predictive decision in terms of the convergence rate, the handoff success rate and the system throughput.","['hybrid cognitive radio networks', 'spectrum handoff based', 'dqn predictive decision']"
"the field of medical image reconstruction has seen roughly four types of methods. the first type tended to be analytical methods, such as filtered back-projection (fbp) for x-ray computed tomography (ct) and the inverse fourier transform for magnetic resonance imaging (mri), based on simple mathematical models for the imaging systems. these methods are typically fast, but have suboptimal properties such as poor resolution-noise trade-off for ct. a second type is iterative reconstruction methods based on more complete models for the imaging system physics and, where appropriate, models for the sensor statistics. these iterative methods improved image quality by reducing noise and artifacts. the fda-approved methods among these have been based on relatively simple regularization models. a third type of methods has been designed to accommodate modified data acquisition methods, such as reduced sampling in mri and ct to reduce scan time or radiation dose. these methods typically involve mathematical image models involving assumptions such as sparsity or low-rank. a fourth type of methods replaces mathematically designed models of signals and systems with data-driven or adaptive models inspired by the field of machine learning. this paper focuses on the two most recent trends in medical image reconstruction: methods based on sparsity or low-rank models, and data-driven methods based on machine learning techniques.","['machine learning', 'image reconstruction', 'adaptive methods', 'sparsity', 'data']"
"in precision medicine, next-generation sequencing and novel preclinical reports have led to an increasingly large amount of results, published in the scientific literature. however, identifying novel treatments or predicting a drug response in, for example, cancer patients, from the huge amount of papers available remains a laborious and challenging work. this task can be considered a text mining problem that requires reading a lot of academic documents for identifying a small set of papers describing specific relations between key terms. due to the infeasibility of the manual curation of these relations, computational methods that can automatically identify them from the available literature are urgently needed.","['deep learning approach', 'scientific articles', 'automatic interpretation', 'dl4papers']"
"essential tremor (et) might be a family of diseases unified by the presence of kinetic tremor, but also showing etiological, pathological, and clinical heterogeneity. in this review, we will describe the most significant clinical evidence, which suggests that et is linked to the cerebellum. data for this review were identified by searching pubmed (january 1966 to may 2015) crossing the terms ""essential tremor"" (et) and ""cerebellum,"" which yielded 201 entries, 11 of which included the term ""cerebellum"" in the article title. this was supplemented by articles in the author\'s files that pertained to this topic. the wide spectrum of clinical features of et that suggest that it originates as a cerebellar or cerebellar outflow problem include the presence of intentional tremor, gait and balance abnormalities, subtle features of dysarthria, and oculomotor abnormalities, as well as deficits in eye-hand coordination, motor learning deficits, incoordination during spiral drawing task, abnormalities in motor timing and visual reaction time, impairment of social abilities, improvement in tremor after cerebellar stroke, efficacy of deep brain stimulation (which blocks cerebellar outflow), and cognitive dysfunction. it is unlikely, however, that cerebellar dysfunction, per se, fully explains et-associated dementia, because the cognitive deficits that have been described in patients with cerebellar lesions are generally mild. overall, a variety of clinical findings suggest that in at least a sizable proportion of patients with et, there is an underlying abnormality of the cerebellum and/or its pathways.","['linking essential tremor', 'clinical evidence', 'cerebellum']"
"growing health disparities have a negative impact on young people's educational achievement. community schools that involve deep relationships with partners across multiple domains address these disparities by providing opportunities and services that promote healthy development of young people, and enable them to graduate from high school ready for college, technical school, on-the-job training, career, and citizenship.","['building sustainable health', 'local communities', 'education partnerships', 'stories']"
"accurate segmentation of organs at risk (oars) from head and neck (h&n) ct images is crucial for effective h&n cancer radiotherapy. however, the existing deep learning methods are often not trained in an end-to-end fashion, i.e., they independently predetermine the regions of target organs before organ segmentation, causing limited information sharing between related tasks and thus leading to suboptimal segmentation results. furthermore, when conventional segmentation network is used to segment all the oars simultaneously, the results often favor big oars over small oars. thus, the existing methods often train a specific model for each oar, ignoring the correlation between different segmentation tasks. to address these issues, we propose a new multi-view spatial aggregation framework for joint localization and segmentation of multiple oars using h&n ct images. the core of our framework is a proposed region-of-interest (roi)-based fine-grained representation convolutional neural network (cnn), which is used to generate multi-oar probability maps from each 2d view (i.e., axial, coronal, and sagittal view) of ct images. specifically, our roi-based fine-grained representation cnn (1) unifies the oars localization and segmentation tasks and trains them in an end-to-end fashion, and (2) improves the segmentation results of various-sized oars via a novel roi-based fine-grained representation. our multi-view spatial aggregation framework then spatially aggregates and assembles the generated multi-view multi-oar probability maps to segment all the oars simultaneously. we evaluate our framework using two sets of h&n ct images and achieve competitive and highly robust segmentation performance for oars of various sizes.","['view spatial aggregation framework', 'neck ct images', 'joint localization', 'segmentation', 'risk', 'organs', 'multi', 'head']"
this paper aims to compare the performance of several commonly known machine-learning (ml) models versus a classic autoregression with exogenous inputs (arx) model in the prediction of blood glucose (bg) levels using time-series data of patients with type 1 diabetes (t1d).,"['benchmarking machine learning algorithms', 'type 1 diabetes', 'blood glucose prediction', 'series models', 'classical time', 'comparison']"
"abdominal aortic aneurysm (aaa) is a life-threatening disease, and the only curative treatment relies on open or endovascular repair. the decision to treat relies on the evaluation of the risk of aaa growth and rupture, which can be difficult to assess in practice. artificial intelligence (ai) has revealed new insights into the management of cardiovascular diseases, but its application in aaa has so far been poorly described. the aim of this review was to summarize the current knowledge on the potential applications of ai in patients with aaa.","['abdominal aortic aneurysm', 'artificial intelligence']"
"breast cancer is a collection of multiple tissue pathologies, each with a distinct molecular signature that correlates with patient prognosis and response to therapy. accurately differentiating between breast cancer sub-types is an important part of clinical decision-making. although this problem has been addressed using machine learning methods in the past, there remains unexplained heterogeneity within the established sub-types that cannot be resolved by the commonly used classification algorithms.","['individualised biomarker scores using attention mechanism', 'breast cancer sub', 'types', 'interpretable', 'deeptriage', 'classification']"
"weakly supervised object detection (wsod) is an interesting yet challenging task in the computer vision community. the core is to discover the image regions that contain the complete object instances under the image-level supervision. existing works usually solve this problem via a proposal selection strategy, which selects the most discriminative box regions from the weakly labeled training images. however, these regions usually only contain the discriminative object parts rather than the complete object instances. to address this problem, this article proposes to learn a searching-agent to gradually mine desirable object regions under a region searching paradigm, where we formulate the searching process as a markov decision process and learn the searching-agent under a deep reinforcement learning framework. to learn such a searching-agent under the weak supervision, we extract the pseudo-complete object regions and the corresponding local discriminative object parts and introduce the obtained pseudo-target-part training pairs into the reinforcement learning process of the search-agent. this learning strategy has twofold advantages: 1) it can mimic the searching process to reveal complete object regions from a certain discriminative part of the object under the weak supervision and 2) it will not suffer from the learning difficulty arise from the long-action sequence that happens when searching from the entire image range. comprehensive experiments on benchmark data sets demonstrate that by integrating the learned searching-agent with the existing wsod method, we can achieve better performance than the other state-of-the-art and baseline methods.","['weakly supervised object detection', 'reinforcement searching', 'agent learning', 'discriminant', 'complete']"
"botnets, which consist of remotely controlled compromised machines called bots, provide a distributed platform for several threats against cyber world entities and enterprises. intrusion detection system (ids) provides an efficient countermeasure against botnets. it continually monitors and analyzes network traffic for potential vulnerabilities and possible existence of active attacks. a payload-inspection-based ids (pi-ids) identifies active intrusion attempts by inspecting transmission control protocol and user datagram protocol packet's payload and comparing it with previously seen attacks signatures. however, the pi-ids abilities to detect intrusions might be incapacitated by packet encryption. traffic-based ids (t-ids) alleviates the shortcomings of pi-ids, as it does not inspect packet payload; however, it analyzes packet header to identify intrusions. as the network's traffic grows rapidly, not only the detection-rate is critical, but also the efficiency and the scalability of ids become more significant. in this paper, we propose a state-of-the-art t-ids built on a novel randomized data partitioned learning model (rdplm), relying on a compact network feature set and feature selection techniques, simplified subspacing and a multiple randomized meta-learning technique. the proposed model has achieved 99.984% accuracy and 21.38 s training time on a well-known benchmark botnet dataset. experiment results demonstrate that the proposed methodology outperforms other well-known machine-learning models used in the same detection task, namely, sequential minimal optimization, deep neural network, c4.5, reduced error pruning tree, and randomtree.","['botnet intrusion detection', 'data randomization', 'based partitioning', 'cluster']"
"hashing is an efficient method for nearest neighbor search in large-scale data space by embedding high-dimensional feature descriptors into a similarity preserving hamming space with a low dimension. however, large-scale high-speed retrieval through binary code has a certain degree of reduction in retrieval accuracy compared to traditional retrieval methods. we have noticed that multi-view methods can well preserve the diverse characteristics of data. therefore, we try to introduce the multi-view deep neural network into the hash learning field, and design an efficient and innovative retrieval model, which has achieved a significant improvement in retrieval performance. in this paper, we propose a supervised multi-view hash model which can enhance the multi-view information through neural networks. this is a completely new hash learning method that combines multi-view and deep learning methods. the proposed method utilizes an effective view stability evaluation method to actively explore the relationship among views, which will affect the optimization direction of the entire network. the proposed method is systematically evaluated on the cifar-10, nus-wide and ms-coco datasets, and the results show that our method significantly outperforms the state-of-the-art single-view and multi-view hashing methods.","['view enhancement hashing', 'image retrieval', 'deep multi']"
"the deep convolutional neural network has achieved outstanding performance on neonatal brain mri tissue segmentation. however, it may fail to produce reasonable results on unseen datasets that have different imaging appearance distributions with the training data. the main reason is that deep learning models tend to have a good fitting to the training dataset, but do not lead to a good generalization on the unseen datasets. to address this problem, we propose a multi-task learning method, which simultaneously learns both tissue segmentation and geodesic distance regression to regularize a shared encoder network. furthermore, a dense attention gate is explored to force the network to learn rich contextual information. by using three neonatal brain datasets with different imaging protocols from different scanners, our experimental results demonstrate superior performance of our proposed method over the existing deep learning-based methods on the unseen datasets.","['neonatal brain segmentation using 3d dense', 'dense attention guided', 'task learning', 'geodesic distance', 'unet', 'multi']"
"single-molecule imaging analysis has been applied to study the dynamics and kinetics of molecular behaviors and interactions in living cells. in spite of its high potential as a technique to investigate the molecular mechanisms of cellular phenomena, single-molecule imaging analysis has not been extended to a large scale of molecules in cells due to the low measurement throughput as well as required expertise. to overcome these problems, we have automated the imaging processes by using computer operations, robotics and artificial intelligence (ai). ai is an ideal substitute for expertise to obtain high-quality images for quantitative analysis. our automated in-cell single-molecule imaging system, aisis, could analyze 1600 cells in 1 day, which corresponds to ∼ 100-fold higher efficiency than manual analysis. the large-scale analysis revealed cell-to-cell heterogeneity in the molecular behavior, which had not been recognized in previous studies. an analysis of the receptor behavior and downstream signaling was accomplished within a significantly reduced time frame and revealed the detailed activation scheme of signal transduction, advancing cell biology research. furthermore, by combining the high-throughput analysis with our previous finding that a receptor changes its behavioral dynamics depending on the presence of a ligand/agonist or inhibitor/antagonist, we show that aisis is applicable to comprehensive pharmacological analysis such as drug screening. this ai-aided automation has wide applications for single-molecule analysis.","['molecule imaging aided', 'scale single', 'artificial intelligence', 'large']"
"in contrast to many western nations where family medicine is a cornerstone of the primary care workforce, in japan the specialty is still developing. a number of services within the bailiwick of family medicine have yet to be fully incorporated into japanese family medicine training programs, especially those associated with sexual health. this gap constitutes a lost opportunity for addressing sexual health-related conditions, including cancer prevention, diagnosis, and treatment. in this mixed methods case study we investigated the perceived acceptability and impact of a standardized patient instructor (spi) program that trained japanese family medicine residents in female breast, pelvic, male genital, and prostate examinations.","['standardized patient instructors among japanese family physician trainees', 'mixed methods case study assessing', 'learning sexual health care examinations', 'shizuoka family medicine program', 'cultural context', 'use', 'teaching', 'japan']"
to develop and evaluate a system to prescribe imaging planes for cardiac mri based on deep learning (dl)-based localization of key anatomic landmarks.,"['cardiac mri planes', 'deep learning', 'based prescription']"
"lidar data contain feature information such as the height and shape of the ground target and play an important role for land classification. the effect of convolutional neural network (cnn) for feature extraction on lidar data is very significant, however cnn cannot resolve the spatial relationship of features adequately. the capsule network (capsnet) can identify the spatial variations of features and is widely used in supervised learning. in this article, the capsnet is combined with the residual network (resnet) to design a deep network-rescapnet for improving the accuracy of lidar classification. the capsule network represents the features by vectors, which can account for the direction of the features and the relative position between the features. therefore, more detailed feature information can be extracted. resnet protects the integrity of information by passing input information to the output directly, which can solve the problem of network degradation caused by information loss in the traditional cnn propagation process to a certain extent. two different lidar data sets and several classic machine learning algorithms are used for comparative experiments. the experimental results show that rescapnet proposed in this article `improve the performance of lidar classification.","['novel lidar data classification algorithm combined capsnet', 'resnet']"
"understanding how psychiatry residents learn to prescribe is important for the future of psychiatry. prescribing is a complicated act that involves much more than signing a prescription. during residency, psychiatrists develop seminal attitudes and habits about prescribing. there have been no published studies focusing on psychiatry residents' experience when learning to prescribe.","['qualitative research inquiry', 'psychiatry residents learning', 'prescribe', 'experience']"
"in 7 free-recall experiments, the benefit of creating drawings of to-be-remembered information relative to writing was examined as a mnemonic strategy. in experiments 1 and 2, participants were presented with a list of words and were asked to either draw or write out each. drawn words were better recalled than written. experiments 3-5 showed that the memory boost provided by drawing could not be explained by elaborative encoding (deep level of processing, lop), visual imagery, or picture superiority, respectively. in experiment 6, we explored potential limitations of the drawing effect, by reducing encoding time and increasing list length. drawing, relative to writing, still benefited memory despite these constraints. in experiment 7, the drawing effect was significant even when encoding trial types were compared in pure lists between participants, inconsistent with a distinctiveness account. together these experiments indicate that drawing enhances memory relative to writing, across settings, instructions, and alternate encoding strategies, both within- and between-participants, and that a deep lop, visual imagery, or picture superiority, alone or collectively, are not sufficient to explain the observed effect. we propose that drawing improves memory by encouraging a seamless integration of semantic, visual, and motor aspects of a memory trace.","['robust memory benefits', 'free recall', 'drawing effect', 'reliable', 'evidence']"
"artificial intelligence has found many applications in the last decade due to increased computing power. artificial neural networks are inspired in the brain structure and consist in the interconnection of artificial neurons through artificial synapses in the so-called deep neural networks (dnns). training these systems requires huge amounts of data and, after the network is trained, it can recognize unforeseen data and provide useful information. as far as the training is concerned, we can distinguish between supervised and unsupervised learning. the former requires labelled data and is based on the iterative minimization of the output error using the stochastic gradient descent method followed by the recalculation of the strength of the synaptic connections (weights) with the backpropagation algorithm. on the other hand, unsupervised learning does not require data labeling and it is not based on explicit output error minimization. conventional anns can function with supervised learning algorithms (perceptrons, multi-layer perceptrons, convolutional networks, etc.) but also with unsupervised learning rules (kohonen networks, self-organizing maps, etc.). besides, another type of neural networks are the so-called spiking neural networks (snns) in which learning takes place through the superposition of voltage spikes launched by the neurons. their behavior is much closer to the brain functioning mechanisms they can be used with supervised and unsupervised learning rules. since learning and inference is based on short voltage spikes, energy efficiency improves substantially. up to this moment, all these anns (spiking and conventional) have been implemented as software tools running on conventional computing units based on the von neumann architecture. however, this approach reaches important limits due to the required computing power, physical size and energy consumption. this is particularly true for applications at the edge of the internet. thus, there is an increasing interest in developing ai tools directly implemented in hardware for this type of applications. the first hardware demonstrations have been based on complementary metal-oxide-semiconductor (cmos) circuits and specific communication protocols. however, to further increase training speed andenergy efficiency while reducing the system size, the combination of cmos neuron circuits with memristor synapses is now being explored. it has also been pointed out that the short time non-volatility of some memristors may even allow fabricating purely memristive anns. the memristor is a new device (first demonstrated in solid-state in 2008) which behaves as a resistor with memory and which has been shown to have potentiation and depression properties similar to those of biological synapses. in this special issue, we explore the state of the art of neuromorphic circuits implementing neural networks with memristors for ai applications.","['artificial intelligence applications', 'neuromorphic circuits', 'memristors']"
"we developed a machine learning methodology for automatic sleep stage scoring. our time-frequency analysis-based feature extraction is fine-tuned to capture sleep stage-specific signal features as described in the american academy of sleep medicine manual that the human experts follow. we used ensemble learning with an ensemble of stacked sparse autoencoders for classifying the sleep stages. we used class-balanced random sampling across sleep stages for each model in the ensemble to avoid skewed performance in favor of the most represented sleep stages, and addressed the problem of misclassification errors due to class imbalance while significantly improving worst-stage classification. we used an openly available dataset from 20 healthy young adults for evaluation. we used a single channel of eeg from this dataset, which makes our method a suitable candidate for longitudinal monitoring using wearable eeg in real-world settings. our method has both high overall accuracy (78%, range 75-80%), and high mean [formula: see tex","['84 %, range 82', 'ore', '86']"
"acute lymphoblastic leukemia (all) is the most common childhood cancer. while there are a number of well-recognized prognostic biomarkers at diagnosis, the most powerful independent prognostic factor is the response of the leukemia to induction chemotherapy (campana and pui: blood 129 (2017) 1913-1918). given the potential for machine learning to improve precision medicine, we tested its capacity to monitor disease in children undergoing all treatment. diagnostic and on-treatment bone marrow samples were labeled with an all-discriminating antibody combination and analyzed by imaging flow cytometry. ignoring the fluorescent markers and using only features extracted from bright-field and dark-field cell images, a deep learning model was able to identify all cells at an accuracy of >88%. this antibody-free, single cell method is cheap, quick, and could be adapted to a simple, laser-free cytometer to allow automated, point-of-care testing to detect slow early responders. adaptation to other types of leukemia is feasible, which would revolutionize residual disease monitoring. © 2020 the authors. cytometry part a published by wiley periodicals, inc. on behalf of international society for advancement of cytometry.","['free leukemia monitoring', 'computer vision', 'label']"
"machine learning (ml) is transforming all areas of science. the complex and time-consuming calculations in molecular simulations are particularly suitable for an ml revolution and have already been profoundly affected by the application of existing ml methods. here we review recent ml methods for molecular simulation, with particular focus on (deep) neural networks for the prediction of quantum-mechanical energies and forces, on coarse-grained molecular dynamics, on the extraction of free energy surfaces and kinetics, and on generative network approaches to sample molecular equilibrium structures and compute thermodynamics. to explain these methods and illustrate open methodological problems, we review some important principles of molecular physics and describe how they can be incorporated into ml structures. finally, we identify and describe a list of open challenges for the interface between ml and molecular simulation.","['molecular simulation', 'machine learning']"
"blepharospasm (bl) is characterized by involuntary closures of the eyelids due to spasms of the orbicularis oculi muscle. the gold standard for clinical evaluation of bl involves visual inspection for manual rating scales. this approach is highly subjective and error prone. unfortunately, there are currently no simple quantitative systems for accurate and objective diagnostics of bl. here, we introduce a soft, flexible hybrid bioelectronic system that offers highly conformal, gentle lamination on the skin, while enabling wireless, quantitative detection of electrophysiological signals. computational and experimental studies of soft materials and flexible mechanics provide a set of key fundamental design factors for a low-profile bioelectronic system. the nanomembrane soft electrodes, mounted around the eyes, are capable of accurately measuring clinical symptoms, including the frequency of blinking, the duration of eye closures during spasms, as well as combinations of blinking and spasms. the use of a deep-learning, convolutional neural network, with the bioelectronics offers objective, real-time classification of key pathological features in bl. the wearable bioelectronics outperform the conventional manual clinical rating, as shown by a pilot study with 13 patients. in vivo demonstration of the bioelectronics with these patients indicates the device as an easy-to-use solution for objective quantification of bl.","['soft nanomembrane sensors', 'flexible hybrid bioelectronics', 'wireless quantification', 'blepharospasm']"
there is remarkable heterogeneity in clinical alzheimer's disease (ad) or vascular dementia (vad).,"['vascular dementia neuropsychological syndromes using white', 'gray neuroradiological parameters', 'dissociating statistically', 'determined alzheimer', 'disease']"
"in this paper, we tackle the problem of automatic classification of pulmonary peri-fissural nodules (pfns). the classification problem is formulated as a machine learning approach, where detected nodule candidates are classified as pfns or non-pfns. supervised learning is used, where a classifier is trained to label the detected nodule. the classification of the nodule in 3d is formulated as an ensemble of classifiers trained to recognize pfns based on 2d views of the nodule. in order to describe nodule morphology in 2d views, we use the output of a pre-trained convolutional neural network known as overfeat. we compare our approach with a recently presented descriptor of pulmonary nodule morphology, namely bag of frequencies, and illustrate the advantages offered by the two strategies, achieving performance of auc = 0.868, which is close to the one of human experts.","['convolutional neural network', 'computed tomography using', 'pulmonary peri', 'fissural nodules', 'automatic classification', '2d views', 'ensemble', 'box']"
"we developed a hybrid deep learning model (hdlm) algorithm that quantitatively predicts macular ganglion cell-inner plexiform layer (mgcipl) thickness from red-free retinal nerve fiber layer photographs (rnflps). a total of 789 pairs of rnflps and spectral domain-optical coherence tomography (sd-oct) scans for 431 eyes of 259 participants (183 eyes of 114 healthy controls, 68 eyes of 46 glaucoma suspects, and 180 eyes of 99 glaucoma patients) were enrolled. an hdlm was built by combining a pre-trained deep learning network and support vector machine. the correlation coefficient and mean absolute error (mae) between the predicted and measured mgcipl thicknesses were calculated. the measured (oct-based) and predicted (hdlm-based) average mgcipl thicknesses were 73.96\u2009±\u20098.81\u2009µm and 73.92\u2009±\u20097.36\u2009µm, respectively (p\u2009=\u20090.844). the predicted mgcipl thickness showed a strong correlation and good agreement with the measured mgcipl thickness (correlation coefficient r\u2009=\u20090.739; p\u2009<\u20090.001; mae\u2009=\u20094.76\u2009µm). even when the peripapillary area (diameter: 1.5 disc diameters) was masked, the correlation (r\u2009=\u20090.713; p\u2009<\u20090.001) and agreement (mae\u2009=\u20094.87\u2009µm) were not changed significantly (p\u2009=\u20090.378 and 0.724, respectively). the trained hdlm algorithm showed a great capability for mgcipl thickness prediction from rnflps.","['free fundus photography using hybrid deep learning model', 'inner plexiform layer thickness prediction', 'macular ganglion cell', 'red']"
"brain responses to discrete short sounds have been studied intensively using the event-related potential (erp) method, in which the electroencephalogram (eeg) signal is divided into epochs time-locked to stimuli of interest. here we introduce and apply a novel technique which enables one to isolate erps in human elicited by continuous music. the erps were recorded during listening to a tango nuevo piece, a deep techno track and an acoustic lullaby. acoustic features related to timbre, harmony, and dynamics of the audio signal were computationally extracted from the musical pieces. negative deflation occurring around 100 milliseconds after the stimulus onset (n100) and positive deflation occurring around 200 milliseconds after the stimulus onset (p200) erp responses to peak changes in the acoustic features were distinguishable and were often largest for tango nuevo. in addition to large changes in these musical features, long phases of low values that precede a rapid increase - and that we will call preceding low-feature phases - followed by a rapid increase enhanced the amplitudes of n100 and p200 responses. these erp responses resembled those to simpler sounds, making it possible to utilize the tradition of erp research with naturalistic paradigms.","['related brain responses', 'entire pieces', 'music', 'listening', 'event']"
"medical parasitology education has been facing some difficulties, because it is a course of wide range, lacking clinical cases and concerned specimens of parasites currently. in addition, its relationship with life is not closely enough. all these reasons may impact the effect of class education negatively. therefore, it is important to increase the vitality of parasitology education and diversify the instructional mode by using the resources from internet. in recent years, the discovery channel has uploaded a documentary monsters inside me online. this documentary is high professional and closely linked with parasitology. it maintains numbers of clinical cases about parasitic diseases. each episode is about 3 minutes and shortly enough to be introduced into class teaching. however, this resource has not been fully used in domestic temporally. we found that direct introduction of the documentary into class teaching can enrich teaching forms to attract learning interest of students, and finally improve the teaching effect of class. above that, another popular documentary a bite of china involves many related knowledge points of parasitology. the appropriate usage of the knowledge can build up close linkage between book and life, which is extremely helpful to give students a deep impression of parasitology. in brief, it is our strong recommendation to introduce the documentary monsters inside me into class.","['parasitology class teaching ].', 'parasite', 'experiences', 'documentaries', 'bite', 'application']"
"functional and structural alterations in brain connectivity associated with brain ischemia have been extensively studied. however, the mechanism whereby local ischemia in deep brain region affect brain functions is still unknown. here, we first established a mini-stroke model by infusion of endothelin-1 (et-1) into the dorsal hippocampus or the lateral amygdala, and then investigated how these mini-infarcts affected brain functions associated with these regions. we found that rats with et-1 infusion showed deficit in recall of contextual fear memory, but not in learning process and recall of tone fear memory. in novel object task, et-1 in the hippocampus also eliminated object identity memory. et-1 in the lateral amygdale affected acquisition of fear conditioning and disrupted retention of tone-conditioned fear, but did not impair retention of contextual fear. these findings suggest that et-1-induced mini-infarct in deep brain area leads to functional deficits in learning and memory associated with these regions.","['lateral amygdala results', 'induced mini', 'dorsal hippocampus', 'stroke', 'memory', 'learning', 'endothelin', 'deficits', '1']"
"in this work, the human parsing task, namely decomposing a human image into semantic fashion/body regions, is formulated as an active template regression (atr) problem, where the normalized mask of each fashion/body item is expressed as the linear combination of the learned mask templates, and then morphed to a more precise mask with the active shape parameters, including position, scale and visibility of each semantic region. the mask template coefficients and the active shape parameters together can generate the human parsing results, and are thus called the structure outputs for human parsing. the deep convolutional neural network (cnn) is utilized to build the end-to-end relation between the input human image and the structure outputs for human parsing. more specifically, the structure outputs are predicted by two separate networks. the first cnn network is with max-pooling, and designed to predict the template coefficients for each label mask, while the second cnn network is without max-pooling to preserve sensitivity to label mask position and accurately predict the active shape parameters. for a new image, the structure outputs of the two networks are fused to generate the probability of each label for each pixel, and super-pixel smoothing is finally used to refine the human parsing result. comprehensive evaluations on a large dataset well demonstrate the significant superiority of the atr framework over other state-of-the-arts for human parsing. in particular, the f1-score reaches 64.38 percent by our atr framework, significantly higher than 44.76 percent based on the state-of-the-art algorithm [2","['deep human parsing', 'active template regression']"
"to present the data available and discuss the progress, current advances and challenges of the initiatives, current policies and guidance implemented by the health and education ministries in brazil to target transformation of health teaching in order to improve the health care offered by the brazilian national health system.","['brazilian national health system', 'human resources', 'great challenge', 'health', 'orientation']"
"obesity has become a widespread health problem worldwide. the body mass index (bmi) is a simple and reliable index based on weight and height that is commonly used to identify and classify adults as underweight, normal, overweight (pre-obesity), or obese. in this paper, we propose a hybrid deep neural network for predicting the bmi of smartphone users, based only on the characteristics of body movement captured by the smartphone's built-in motion sensors without any other sensitive data. the proposed deep learning model consists of four major modules: a transformation module for data preprocessing, a convolution module for extracting spatial features, a long short-term memory (lstm) module for exploring temporal dependency, and a fully connected module for regression. we define motion entropy (men), which is a measure of the regularity and complexity of the motion sensor, and propose a novel men-based filtering strategy to select parts of sensor data that met certain thresholds for training the model. we evaluate this model using two public datasets in comparison with baseline conventional feature-based methods using leave-one-subject-out (loso) cross-validation. experimental results show that the proposed model with the men-based filtering strategy outperforms the baseline approaches significantly. the results also show that jogging may be a more suitable activity of daily living (adl) for bmi prediction than walking and walking upstairs. we believe that the conclusions of this study will help to develop a long-term remote health monitoring system.","['body mass index', 'using motion sensors', 'smartphone users', 'motion', 'predict', 'bmi']"
"to carry out the comparative analysis of early and midterm results of no-touch aorta multivessel small thoracotomy coronary artery bypass grafting (mvst cabg), conventional off-pump (opcabg) and on-pump cabg (oncabg).","['touch aorta multivessel small thoracotomy coronary artery bypass grafting', 'propensity score', 'midterm results', 'matched study', 'early']"
"understanding behavior is the first step to truly understanding neural mechanisms in the brain that drive it. traditional behavioral analysis methods often do not capture the richness inherent to the natural behavior. here, we provide detailed step-by-step instructions with visualizations of our recent methodology, deepbehavior. the deepbehavior toolbox uses deep learning frameworks built with convolutional neural networks to rapidly process and analyze behavioral videos. this protocol demonstrates three different frameworks for single object detection, multiple object detection, and three-dimensional (3d) human joint pose tracking. these frameworks return cartesian coordinates of the object of interest for each frame of the behavior video. data collected from the deepbehavior toolbox contain much more detail than traditional behavior analysis methods and provides detailed insights to the behavior dynamics. deepbehavior quantifies behavior tasks in a robust, automated, and precise way. following the identification of behavior, post-processing code is provided to extract information and visualizations from the behavioral videos.","['deep learning toolbox', 'automated behavior analysis', 'step implementation', 'step', 'deepbehavior']"
this study aims to establish a model to analyze clinical experience of tcm veteran doctors. we propose an ensemble learning based framework to analyze clinical records with icd-10 labels information for effective diagnosis and acupoints recommendation.,"['traditional chinese medicine data analysis', 'ensemble learning based framework', '10 labels', 'icd']"
"recent advances in training deep (multi-layer) architectures have inspired a renaissance in neural network use. for example, deep convolutional networks are becoming the default option for difficult tasks on large datasets, such as image and speech recognition. however, here we show that error rates below 1% on the mnist handwritten digit benchmark can be replicated with shallow non-convolutional neural networks. this is achieved by training such networks using the 'extreme learning machine' (elm) approach, which also enables a very rapid training time (∼ 10 minutes). adding distortions, as is common practise for mnist, reduces error rates even further. our methods are also shown to be capable of achieving less than 5.5% error rates on the norb image database. to achieve these results, we introduce several enhancements to the standard elm algorithm, which individually and in combination can significantly improve performance. the main innovation is to ensure each hidden-unit operates only on a randomly sized and positioned patch of each image. this form of random 'receptive field' sampling of the input ensures the input weight matrix is sparse, with about 90% of weights equal to zero. furthermore, combining our methods with a small number of iterations of a single-batch backpropagation method can significantly reduce the number of hidden-units required to achieve a particular performance. our close to state-of-the-art results for mnist and norb suggest that the ease of use and accuracy of the elm algorithm for designing a single-hidden-layer neural network classifier should cause it to be given greater consideration either as a standalone method for simpler problems, or as the final classification stage in deep neural networks applied to more difficult problems.","['training shallow neural network classifiers', 'accurate handwritten digit classification', 'extreme learning machine', 'simple', 'fast', 'algorithm']"
"feature selection is a critical step in deformable image registration. in particular, selecting the most discriminative features that accurately and concisely describe complex morphological patterns in image patches improves correspondence detection, which in turn improves image registration accuracy. furthermore, since more and more imaging modalities are being invented to better identify morphological changes in medical imaging data, the development of deformable image registration method that scales well to new image modalities or new image applications with little to no human intervention would have a significant impact on the medical image analysis community. to address these concerns, a learning-based image registration framework is proposed that uses deep learning to discover compact and highly discriminative features upon observed imaging data. specifically, the proposed feature selection method uses a convolutional stacked autoencoder to identify intrinsic deep feature representations in image patches. since deep learning is an unsupervised learning method, no ground truth label knowledge is required. this makes the proposed feature selection method more flexible to new imaging modalities since feature representations can be directly learned from the observed imaging data in a very short amount of time. using the loni and adni imaging datasets, image registration performance was compared to two existing state-of-the-art deformable image registration methods that use handcrafted features. to demonstrate the scalability of the proposed image registration framework, image registration experiments were conducted on 7.0-t brain mr images. in all experiments, the results showed that the new image registration framework consistently demonstrated more accurate registration results when compared to state of the art.","['unsupervised deep feature representations learning', 'performance image registration framework', 'scalable high']"
"small-angle x-ray scattering (saxs) method is widely used in investigating protein structures in solution, but high-quality 3d model reconstructions are challenging. we present a new algorithm based on a deep learning method for model reconstruction from saxs data. an auto-encoder for protein 3d models was trained to compress 3d shape information into vectors of a 200-dimensional latent space, and the vectors are optimized using genetic algorithms to build 3d models that are consistent with the scattering data. the program has been tested with experimental saxs data, demonstrating the capacity and robustness of accurate model reconstruction. furthermore, the model size information can be optimized using this algorithm, enhancing the automation in model reconstruction directly from saxs data. the program was implemented using python with the tensorflow framework, with source code and webserver available from http://liulab.csrc.ac.cn/decodesaxs.","['ray scattering data using deep learning methods', 'model reconstruction', 'angle x', 'small']"
"high-fidelity simulation-based training is often avoided for early-stage students because of the assumption that while practicing newly learned skills, they are ill suited to processing multiple demands, which can lead to ""cognitive overload"" and poorer learning outcomes. we tested this assumption using a mixed-methods experimental design manipulating psychological immersion.","['methods comparison trial using eye', 'level paramedicine students', 'difficulty rating scales', 'continuous heart rate', 'video observation', 'versus high', 'fidelity simulations', 'cognitive burden', 'tracking', 'performance', 'mixed', 'low', 'interviews', 'entry', 'effects']"
responsive neurostimulation decreases the frequency of disabling seizures when used as an adjunctive therapy in patients with medically refractory partial-onset seizures. the effect of long-term responsive neurostimulation on neuropsychological performance has not yet been established.,"['differential neuropsychological outcomes following targeted responsive neurostimulation', 'onset epilepsy', 'partial']"
"the cerebellum is involved in learning and memory of sensory motor skills. however, the way this process takes place in local microcircuits is still unclear. the initial proposal, casted into the motor learning theory, suggested that learning had to occur at the parallel fiber-purkinje cell synapse under supervision of climbing fibers. however, the uniqueness of this mechanism has been questioned, and multiple forms of long-term plasticity have been revealed at various locations in the cerebellar circuit, including synapses and neurons in the granular layer, molecular layer and deep-cerebellar nuclei. at present, more than 15 forms of plasticity have been reported. there has been a long debate on which plasticity is more relevant to specific aspects of learning, but this question turned out to be hard to answer using physiological analysis alone. recent experiments and models making use of closed-loop robotic simulations are revealing a radically new view: one single form of plasticity is insufficient, while altogether, the different forms of plasticity can explain the multiplicity of properties characterizing cerebellar learning. these include multi-rate acquisition and extinction, reversibility, self-scalability, and generalization. moreover, when the circuit embeds multiple forms of plasticity, it can easily cope with multiple behaviors endowing therefore the cerebellum with the properties needed to operate as an effective generalized forward controller.","['distributed circuit plasticity', 'new clues', 'cerebellar mechanisms', 'learning']"
"automatic segmentation of the prostate on magnetic resonance images (mri) has many applications in prostate cancer diagnosis and therapy. we proposed a deep fully convolutional neural network (cnn) to segment the prostate automatically. our deep cnn model is trained end-to-end in a single learning stage, which uses prostate mri and the corresponding ground truths as inputs. the learned cnn model can be used to make an inference for pixel-wise segmentation. experiments were performed on three data sets, which contain prostate mri of 140 patients. the proposed cnn model of prostate segmentation (psnet) obtained a mean dice similarity coefficient of [formula: see tex","['proposed model could yield satisfactory segmentation', 'manually labeled ground truth', 'experimental results show', 'convolutional neural network', 'prostate segmentation', 'mri based', 'prostate', 'mri', 'psnet', 'compared', ""'],""]"
"recent advances in machine learning, specifically in deep learning with neural networks, has made a profound impact on fields such as natural language processing, image classification, and language modeling; however, feasibility and potential benefits of the approaches to metagenomic data analysis has been largely under-explored. deep learning exploits many layers of learning nonlinear feature representations, typically in an unsupervised fashion, and recent results have shown outstanding generalization performance on previously unseen data. furthermore, some deep learning methods can also represent the structure in a data set. consequently, deep learning and neural networks may prove to be an appropriate approach for metagenomic data. to determine whether such approaches are indeed appropriate for metagenomics, we experiment with two deep learning methods: i) a deep belief network, and ii) a recursive neural network, the latter of which provides a tree representing the structure of the data. we compare these approaches to the standard multi-layer perceptron, which has been well-established in the machine learning community as a powerful prediction algorithm, though its presence is largely missing in metagenomics literature. we find that traditional neural networks can be quite powerful classifiers on metagenomic data compared to baseline methods, such as random forests. on the other hand, while the deep learning approaches did not result in improvements to the classification accuracy, they do provide the ability to learn hierarchical representations of a data set that standard classification methods do not allow. our goal in this effort is not to determine the best algorithm in terms accuracy-as that depends on the specific application-but rather to highlight the benefits and drawbacks of each of the approach we discuss and provide insight on how they can be improved for predictive metagenomic analysis.","['recursive neural networks', 'metagenomic classification', 'multi', 'layer']"
we investigate the clinical effectiveness of a novel deep learning-based noise reduction (nr) approach under noisy conditions with challenging noise types at low signal to noise ratio (snr) levels for mandarin-speaking cochlear implant (ci) recipients.,"['based noise reduction approach', 'improve speech intelligibility', 'cochlear implant recipients', 'deep learning']"
the aim of this implementation study is to describe nurses' experiences of supporting patient learning using the model called 'the challenge to take charge of life with long-term illness'.,"[""term illness ': nurses"", 'take charge', 'supporting patients', 'didactic model', 'long', 'life', 'learning', 'experiences', 'challenge']"
"knowledge of protein-ligand binding residues is important for understanding the functions of proteins and their interaction mechanisms. from experimentally solved protein structures, how to accurately identify its potential binding sites of a specific ligand on the protein is still a challenging problem. compared with structure-alignment-based methods, machine learning algorithms provide an alternative flexible solution which is less dependent on annotated homogeneous protein structures. several factors are important for an efficient protein-ligand prediction model, e.g. discriminative feature representation and effective learning architecture to deal with both the large-scale and severe imbalanced data.","['ligand binding residue prediction enhancement', 'hybrid deep heterogeneous learning', 'structure data', 'sequence', 'protein']"
"most existing approaches for rgb-d indoor scene labeling employ hand-crafted features for each modality independently and combine them in a heuristic manner. there has been some attempt on directly learning features from raw rgb-d data, but the performance is not satisfactory. in this paper, we propose an unsupervised joint feature learning and encoding (jfle) framework for rgb-d scene labeling. the main novelty of our learning framework lies in the joint optimization of feature learning and feature encoding in a coherent way, which significantly boosts the performance. by stacking basic learning structure, higher level features are derived and combined with lower level features for better representing rgb-d data. moreover, to explore the nonlinear intrinsic characteristic of data, we further propose a more general joint deep feature learning and encoding (jdfle) framework that introduces the nonlinear mapping into jfle. the experimental results on the benchmark nyu depth dataset show that our approaches achieve competitive performance, compared with the state-of-the-art methods, while our methods do not need complex feature handcrafting and feature combination and can be easily applied to other data sets.","['unsupervised joint feature learning', 'scene labeling', 'rgb', 'encoding']"
"to assess the value of exosomal mirnas as biomarkers for alzheimer disease (ad), the expression of micrornas was measured in a plasma fraction enriched in exosomes by differential centrifugation, using illumina deep sequencing. samples from 35 persons with a clinical diagnosis of ad dementia were compared to 35 age and sex matched controls. although these samples contained less than 0.1 microgram of total rna, deep sequencing gave reliable and informative results. twenty mirnas showed significant differences in the ad group in initial screening (mir-23b-3p, mir-24-3p, mir-29b-3p, mir-125b-5p, mir-138-5p, mir-139-5p, mir-141-3p, mir-150-5p, mir-152-3p, mir-185-5p, mir-338-3p, mir-342-3p, mir-342-5p, mir-548at-5p, mir-659-5p, mir-3065-5p, mir-3613-3p, mir-3916, mir-4772-3p, mir-5001-3p), many of which satisfied additional biological and statistical criteria, and among which a panel of seven mirnas were highly informative in a machine learning model for predicting ad status of individual samples with 83-89% accuracy. this performance is not due to over-fitting, because a) we used separate samples for training and testing, and b) similar performance was achieved when tested on technical replicate data. perhaps the most interesting single mirna was mir-342-3p, which was a) expressed in the ad group at about 60% of control levels, b) highly correlated with several of the other mirnas that were significantly down-regulated in ad, and c) was also reported to be down-regulated in ad in two previous studies. the findings warrant replication and follow-up with a larger cohort of patients and controls who have been carefully characterized in terms of cognitive and imaging data, other biomarkers (e.g., csf amyloid and tau levels) and risk factors (e.g., apoe4 status), and who are sampled repeatedly over time. integrating mirna expression data with other data is likely to provide informative and robust biomarkers in alzheimer disease.","['without alzheimer disease', 'plasma exosomal mirnas', 'altered expression', 'prospects', 'persons', 'biomarkers']"
"we demonstrate a new deep learning autoencoder network, trained by a nonnegativity constraint algorithm (nonnegativity-constrained autoencoder), that learns features that show part-based representation of data. the learning algorithm is based on constraining negative weights. the performance of the algorithm is assessed based on decomposing data into parts and its prediction performance is tested on three standard image data sets and one text data set. the results indicate that the nonnegativity constraint forces the autoencoder to learn features that amount to a part-based representation of data, while improving sparsity and reconstruction quality in comparison with the traditional sparse autoencoder and nonnegative matrix factorization. it is also shown that this newly acquired representation improves the prediction performance of a deep neural network.","['data using sparse autoencoders', 'nonnegativity constraints', 'deep learning', 'based representation', 'part']"
"mycophilic fungi of anamorphic genus sepedonium (telomorphs in hypomyces, hypocreales, ascomycota) infect and parasitize sporomata of boletes. the obligated hosts such as boletus edulis and allied species (known as ""porcini mushrooms"") are among the most valued and prized edible wild mushrooms in the world. sepedonium infections have a great morphological variability: at the initial state, contaminated mushrooms present a white coating covering tubes and pores; at the final state, sepedonium forms a deep and thick hyphal layer that eventually leads to the total necrosis of the host. up to date, sepedonium infections in porcini mushrooms have been evaluated only through macroscopic and microscopic visual analysis. in this study, in order to implement the infection evaluation as a routine methodology for industrial purposes, the potential application of hyperspectral imaging (hsi) and principal component analysis (pca) for detection of sepedonium presence on sliced and dried b. edulis and allied species was investigated. hyperspectral images were obtained using a pushbroom line-scanning hsi instrument, operating in the wavelength range between 400 and 1000 nm with 5 nm resolution. pca was applied on normal and contaminated samples. to reduce the spectral variability caused by factors unrelated to sepedonium infection, such as scattering effects and differences in sample height, different spectral pre-treatments were applied. a supervised rule was then developed to assign spectra recorded on new test samples to each of the two classes, based on the pc scores. this allowed to visualize directly - within false-color images of test samples - which points of the samples were contaminated. the results achieved may lead to the development of a non-destructive monitoring system for a rapid on-line screening of contaminated mushrooms.","['dried porcini mushrooms', 'based hyperspectral approach', 'mycophilic fungi', 'detect infections', 'boletus edulis', 'allied specie', 'pca']"
"students enter the medical study with different types of motives. given the importance of academic motivation for good academic achievement of the students, the present study was designed to reveal the possible relationship between academic motivation and achievement in medical students.","['nepalese army institute', 'motivational profiles', 'medical students', 'health sciences']"
"we present the first tool of gene prediction, plasgun, for plasmid metagenomic short read data. the tool, developed based on deep learning algorithm of multiple input convolutional neural network, demonstrates much better performance when tested on a benchmark dataset of artificial short reads and presents more reliable results for real plasmid metagenomic data than traditional gene prediction tools designed primarily for chromosome-derived short reads.","['plasmid metagenomic short reads using deep learning', 'gene prediction', 'plasgun']"
"this study categorizes 4 practice change options, including commitment-to-change (ctc) statements using bloom's taxonomy to explore the relationship between a hierarchy of ctc statements and implementation of changes in practice. our hypothesis was that deeper learning would be positively associated with implementation of planned practice changes.","['change statements associated', 'cognitive complexity', 'clinical practice', 'change', 'taxonomy', 'commitment', 'bloom', 'application']"
"coronary computed tomography angiography (ccta) is a reliable and clinically proven method for the evaluation of coronary artery disease. ccta data sets can be used to derive fractional flow reserve (ffr) as ct-ffr. this method has respectable results when compared in previous trials to invasive ffr, with the aim of detecting lesion-specific ischemia. results from previous studies have shown many benefits, including improved therapeutic guidance to efficiently justify the management of patients with suspected coronary artery disease and enhanced outcomes and reduced health care costs. more recently, a technical approach to the calculation of ct-ffr using an artificial intelligence deep machine learning (ml) algorithm has been introduced. ml algorithms provide information in a more objective, reproducible, and rational manner and with improved diagnostic accuracy in comparison to ccta. this review gives an overview of the technical background, clinical validation, and implementation of ml applications in ct-ffr.","['computed tomography fractional flow reserve', 'deep neural networks applications', 'coronary flow assessment', 'machine learning', 'case']"
"to avoid test-driven learning, there have been discussions regarding the use of more formative assessments in health care education to promote students' deep learning. feedback is important in formative assessment, but many students ignore it; therefore, interventions should be introduced which stimulate them to reflect on the new knowledge. the aim for this study was to explore if virtual patient (vp)-based formative assessments, in connection with self-evaluations, had an impact on postgraduate pediatric nursing students' development of clinical reasoning abilities. students' self-evaluations served as the basis for measuring progress. data was analysed using deductive content analysis. the findings showed a clear progression of the clinical reasoning ability of the students. after the first assessment, the students described feelings of uncertainty and that their knowledge gaps were exposed. at the mid-course assessment the awareness of improved clinical reasoning was obvious and the students were more certain of knowing how to solve the vp cases. in the final assessment, self-efficacy was expressed. vp-based assessments, in connection with self-evaluations, early in the education resulted in a gain of students' own identification of the concept of clinical reasoning, awareness of what to focus on during clinical practice and visualised expected clinical competence.","['virtual patients', 'exploratory study', 'clinical reasoning', 'assessing progression']"
"in this paper, we present a deep learning approach to sketch-based shape retrieval that incorporates a few novel techniques to improve the quality of the retrieval results. first, to address the problem of scarcity of training sketch data, we present a sketch augmentation method that more closely mimics human sketches compared to simple image transformation. our method generates more sketches from the existing training data by (i) removing a stroke, (ii) adjusting a stroke, and (iii) rotating the sketch. as such, we generate a large number of sketch samples for training our neural network. second, we obtain the 2d renderings of each 3d model in the shape database by determining the view positions that best depict the 3d shape: i.e., avoiding self-occlusion, showing the most salient features, and following how a human would normally sketch the model. we use a convolutional neural network (cnn) to learn the best viewing positions of each 3d model and generates their 2d images for the next step. third, our method uses a cross-domain learning strategy based on two siamese cnns that pair up sketches and the 2d shape images.","['driven shape retrieval learning framework based', 'convolutional neural networks', 'sketch augmentation']"
to evaluate the performance of deep learning for robust and fully automated quantification of epicardial adipose tissue (eat) from multicenter cardiac ct data.,"['fully automated ct quantification', 'epicardial adipose tissue', 'multicenter study', 'deep learning']"
"collaborative learning, where students work together towards a shared understanding of a concept, is a well-established pedagogy, and one which has great potential for higher education (he). through discussion and challenging each other's ideas, learners gain a richer appreciation for a subject than with solitary study or didactic teaching methods. however, collaborative learning does require some scaffolding by the teacher in order to be successful. collaborative learning can be augmented by the use of web 2.0 collaborative technologies, such as wikis, blogs and social media. this article reviews some of the uses of collaborative learning strategies in microbiology teaching in he. despite the great potential of collaborative learning, evidence of its use in microbiology teaching is, to date, limited. but the potential for collaborative learning approaches to develop self-regulated, deep learners is considerable, and so collaborative learning should be considered strongly as a viable pedagogy for he.","['enhance microbiology teaching', 'e pluribus unum', 'higher education', 'collaborative learning', 'potential']"
"convolutional neural networks (cnns) are commonly used for segmentation of brain tumors. in this work, we assess the effect of cross-institutional training on the performance of cnns.","['institutional training', 'deep learning', 'brain tumors', 'testing', 'segmentation', 'impact', 'cross']"
"automatic sleep stage classification with cardiorespiratory signals has attracted increasing attention. in contrast to the traditional manual scoring based on polysomnography, these signals can be measured using advanced unobtrusive techniques that are currently available, promising the application for personal and continuous home sleep monitoring. this paper describes a methodology for classifying wake, rapid-eye-movement (rem) sleep, and non-rem (nrem) light and deep sleep on a 30 s epoch basis. a total of 142 features were extracted from electrocardiogram and thoracic respiratory effort measured with respiratory inductance plethysmography. to improve the quality of these features, subject-specific z-score normalization and spline smoothing were used to reduce between-subject and within-subject variability. a modified sequential forward selection feature selector procedure was applied, yielding 80 features while preventing the introduction of bias in the estimation of cross-validation performance. psg data from 48 healthy adults were used to validate our methods. using a linear discriminant classifier and a ten-fold cross-validation, we achieved a cohen's kappa coefficient of 0.49 and an accuracy of 69% in the classification of wake, rem, light, and deep sleep. these values increased to kappa = 0.56 and accuracy = 80% when the classification problem was reduced to three classes, wake, rem sleep, and nrem sleep.","['sleep stage classification', 'respiratory effort', 'ecg']"
"computer-aided image analysis of histopathology specimens could potentially provide support for early detection and improved characterization of diseases such as brain tumor, pancreatic neuroendocrine tumor (net), and breast cancer. automated nucleus segmentation is a prerequisite for various quantitative analyses including automatic morphological feature computation. however, it remains to be a challenging problem due to the complex nature of histopathology images. in this paper, we propose a learning-based framework for robust and automatic nucleus segmentation with shape preservation. given a nucleus image, it begins with a deep convolutional neural network (cnn) model to generate a probability map, on which an iterative region merging approach is performed for shape initializations. next, a novel segmentation algorithm is exploited to separate individual nuclei combining a robust selection-based sparse shape model and a local repulsive deformable model. one of the significant benefits of the proposed framework is that it is applicable to different staining histopathology images. due to the feature learning characteristic of the deep cnn and the high level shape prior modeling, the proposed method is general enough to perform well across multiple scenarios. we have tested the proposed algorithm on three large-scale pathology image datasets using a range of different tissue and stain preparations, and the comparative experiments with recent state of the arts demonstrate the superior performance of the proposed approach.","['robust nucleus segmentation', 'based framework', 'automatic learning']"
"lung cancer has a poor prognosis when not diagnosed early and unresectable lesions are present. the management of small lung nodules noted on computed tomography scan is controversial due to uncertain tumor characteristics. a conventional computer-aided diagnosis (cad) scheme requires several image processing and pattern recognition steps to accomplish a quantitative tumor differentiation result. in such an ad hoc image analysis pipeline, every step depends heavily on the performance of the previous step. accordingly, tuning of classification performance in a conventional cad scheme is very complicated and arduous. deep learning techniques, on the other hand, have the intrinsic advantage of an automatic exploitation feature and tuning of performance in a seamless fashion. in this study, we attempted to simplify the image analysis pipeline of conventional cad with deep learning techniques. specifically, we introduced models of a deep belief network and a convolutional neural network in the context of nodule classification in computed tomography images. two baseline methods with feature computing steps were implemented for comparison. the experimental results suggest that deep learning methods could achieve better discriminative results and hold promise in the cad application domain.","['computed tomography images via deep learning technique', 'lung nodules', 'aided classification', 'computer']"
to compare the image quality of low-dose (ld) computed tomography (ct) obtained using a deep learning-based denoising algorithm (dla) with ld ct images reconstructed with a filtered back projection (fbp) and advanced modeled iterative reconstruction (admire).,"['dose abdominal ct using', 'iterative reconstruction algorithm', 'filtered back projection', 'based denoising algorithm', 'ct reconstructed', 'deep learning', 'low', 'comparison']"
image recognition using artificial intelligence with deep learning through convolutional neural networks (cnns) has dramatically improved and been increasingly applied to medical fields for diagnostic imaging. we developed a cnn that can automatically detect gastric cancer in endoscopic images.,"['detecting gastric cancer', 'convolutional neural network', 'artificial intelligence using', 'endoscopic images', 'application']"
"este artigo apresenta detalhes e dicas sobre a técnica de artroscopia seca, baseada em nossa experiência e em suas aplicações clínicas.","['dry arthroscopic exploration', 'wrist arthroscopy', 'basic tips']"
"tinnitus is a common medical condition which interfaces many different disciplines, yet it is not a priority for any individual discipline. a change in its scientific understanding and clinical management requires a shift toward multidisciplinary cooperation, not only in research but also in training. the european school for interdisciplinary tinnitus research (esit) brings together a unique multidisciplinary consortium of clinical practitioners, academic researchers, commercial partners, patient organizations, and public health experts to conduct innovative research and train the next generation of tinnitus researchers. esit supports fundamental science and clinical research projects in order to: (1) advancing new treatment solutions for tinnitus, (2) improving existing treatment paradigms, (3) developing innovative research methods, (4) performing genetic studies on, (5) collecting epidemiological data to create new knowledge about prevalence and risk factors, (6) establishing a pan-european data resource. all research projects involve inter-sectoral partnerships through practical training, quite unlike anything that can be offered by any single university alone. likewise, the postgraduate training curriculum fosters a deep knowledge about tinnitus whilst nurturing transferable competencies in personal qualities and approaches needed to be an effective researcher, knowledge of the standards, requirements and professionalism to do research, and skills to work with others and to ensure the wider impact of research. esit is the seed for future generations of creative, entrepreneurial, and innovative researchers, trained to master the upcoming challenges in the tinnitus field, to implement sustained changes in prevention and clinical management of tinnitus, and to shape doctoral education in tinnitus for the future.","['interdisciplinary tinnitus research', 'european school', 'doctoral training', 'tinnitus', 'research', 'innovations', 'esi']"
"hyperperfusion detected on arterial spin labeling (asl) images acquired after acute stroke onset has been shown to correlate with development of subsequent intracerebral hemorrhage. we present in this study a quantitative hyperperfusion detection model that can provide an objective decision support for the interpretation of asl cerebral blood flow (cbf) maps and rapidly delineate hyperperfusion regions. the detection problem is solved using deep learning such that the model relates asl image patches to the corresponding label (normal or hyperperfused). our method takes into account the regional intensity values of contralateral hemisphere during the labeling of a pixel. each input vector is associated to a label corresponding to the presence of hyperperfusion that was manually established by a clinical researcher in neurology. when compared to the manually established hyperperfusion, the predicted maps reached an accuracy of 97.45 ± 2.49% after crossvalidation. pattern recognition based on deep learning can provide an accurate and objective measure of hyperperfusion on asl cbf images and could therefore improve the detection of hemorrhagic transformation in acute stroke patients.","['arterial spin labeling using deep learning', 'hyperperfusion', 'detection']"
"this paper proposes a spectral-spatial feature learning (ssfl) method to obtain robust features of hyperspectral images (hsis). it combines the spectral feature learning and spatial feature learning in a hierarchical fashion. stacking a set of ssfl units, a deep hierarchical model called the spectral-spatial networks (ssn) is further proposed for hsi classification. ssn can exploit both discriminative spectral and spatial information simultaneously. specifically, ssn learns useful high-level features by alternating between spectral and spatial feature learning operations. then, kernel-based extreme learning machine (kelm), a shallow neural network, is embedded in ssn to classify image pixels. extensive experiments are performed on two benchmark hsi datasets to verify the effectiveness of ssn. compared with state-of-the-art methods, ssn with a deep hierarchical architecture obtains higher classification accuracy in terms of the overall accuracy, average accuracy, and kappa ( κ ) coefficient of agreement, especially when the number of the training samples is small.","['learning hierarchical spectral', 'hyperspectral image classification', 'spatial features']"
correlating electrical activity within the human brain to movement is essential for developing and refining interventions (e.g. deep brain stimulation (dbs)) to treat central nervous system disorders. it also serves as a basis for next generation brain-machine interfaces (bmis). this study highlights a new decoding strategy for capturing movement and its corresponding laterality from deep brain local field potentials (lfps).,"['movement decoding using neural synchronization', 'deep brain local field potentials', 'hemispheric connectivity', 'inter']"
"evidence is accumulating that our brains process incoming information using top-down predictions. if lower level representations are correctly predicted by higher level representations, this enhances processing. however, if they are incorrectly predicted, additional processing is required at higher levels to ""explain away"" prediction errors. here, we explored the potential nature of the models generating such predictions. more specifically, we investigated whether a predictive processing model with a hierarchical structure and causal relations between its levels is able to account for the processing of agent-caused events. in experiment 1, participants watched animated movies of ""experienced"" and ""novice"" bowlers. the results are in line with the idea that prediction errors at a lower level of the hierarchy (i.e., the outcome of how many pins fell down) slow down reporting of information at a higher level (i.e., which agent was throwing the ball). experiments 2 and 3 suggest that this effect is specific to situations in which the predictor is causally related to the outcome. overall, the study supports the idea that a hierarchical predictive processing model can account for the processing of observed action outcomes and that the predictions involved are specific to cases where action outcomes can be predicted based on causal knowledge.","['hierarchical predictive processing', 'two pins', 'expert bowler', 'caused events', 'one', 'hit', 'expect', 'agent']"
"a main research direction in the field of evolutionary machine learning is to develop a scalable classifier system to solve high-dimensional problems. recently work has begun on autonomously reusing learned building blocks of knowledge to scale from low-dimensional problems to high-dimensional ones. an xcs-based classifier system, known as xcscfc, has been shown to be scalable, through the addition of expression tree-like code fragments, to a limit beyond standard learning classifier systems. xcscfc is especially beneficial if the target problem can be divided into a hierarchy of subproblems and each of them is solvable in a bottom-up fashion. however, if the hierarchy of subproblems is too deep, then xcscfc becomes impractical because of the needed computational time and thus eventually hits a limit in problem size. a limitation in this technique is the lack of a cyclic representation, which is inherent in finite state machines (fsms). however, the evolution of fsms is a hard task owing to the combinatorially large number of possible states, connections, and interaction. usually this requires supervised learning to minimize inappropriate fsms, which for high-dimensional problems necessitates subsampling or incremental testing. to avoid these constraints, this work introduces a state-machine-based encoding scheme into xcs for the first time, termed xcssma. the proposed system has been tested on six complex boolean problem domains: multiplexer, majority-on, carry, even-parity, count ones, and digital design verification problems. the proposed approach outperforms xcscfa (an xcs that computes actions) and xcsf (an xcs that computes predictions) in three of the six problem domains, while the performance in others is similar. in addition, xcssma evolved, for the first time, compact and human readable general classifiers (i.e., solving any n-bit problems) for the even-parity and carry problem domains, demonstrating its ability to produce scalable solutions using a cyclic representation.","['complex boolean problems', 'extending xcs', 'cyclic graphs', 'scalability']"
"knee osteoarthritis (oa) is the most common musculoskeletal disorder. oa diagnosis is currently conducted by assessing symptoms and evaluating plain radiographs, but this process suffers from subjectivity. in this study, we present a new transparent computer-aided diagnosis method based on the deep siamese convolutional neural network to automatically score knee oa severity according to the kellgren-lawrence grading scale. we trained our method using the data solely from the multicenter osteoarthritis study and validated it on randomly selected 3,000 subjects (5,960 knees) from osteoarthritis initiative dataset. our method yielded a quadratic kappa coefficient of 0.83 and average multiclass accuracy of 66.71% compared to the annotations given by a committee of clinical experts. here, we also report a radiological oa diagnosis area under the roc curve of 0.93. besides this, we present attention maps highlighting the radiological features affecting the network decision. such information makes the decision process transparent for the practitioner, which builds better trust toward automatic methods. we believe that our model is useful for clinical decision making and for oa research; therefore, we openly release our training codes and the data set created in this study.","['automatic knee osteoarthritis diagnosis', 'plain radiographs', 'deep learning', 'based approach']"
[this corrects the article doi: 10.1371/journal.pone.0179289,"['shared acoustic codes underlie emotional communication', 'deep transfer learning', 'speech', 'music', 'evidence', 'correction']"
"malaria remains a major burden on global health, with roughly 200 million cases worldwide and more than 400,000 deaths per year. besides biomedical research and political efforts, modern information technology is playing a key role in many attempts at fighting the disease. one of the barriers toward a successful mortality reduction has been inadequate malaria diagnosis in particular. to improve diagnosis, image analysis software and machine learning methods have been used to quantify parasitemia in microscopic blood slides. this article gives an overview of these techniques and discusses the current developments in image analysis and machine learning for microscopic malaria diagnosis. we organize the different approaches published in the literature according to the techniques used for imaging, image preprocessing, parasite detection and cell segmentation, feature computation, and automatic cell classification. readers will find the different techniques listed in tables, with the relevant articles cited next to them, for both thin and thick blood smear images. we also discussed the latest developments in sections devoted to deep learning and smartphone technology for future malaria diagnosis.","['machine learning', 'image analysis', 'detecting malaria']"
"an unfavourable yet necessary side-effect of stereotaxic surgery involves the social isolation of post-surgery rats, in order to protect their wound site or skull-mounted implant from damage. social isolation can cause a myriad of behavioural and physiological changes that are detrimental to the well-being of rats, with potential negative implications for a range of experimental paradigms. new method. female sprague dawley rats (n=40) were implanted onto the skull with a novel 3d-printed headstage socket that surrounded an electrode connector. the socket accommodated a removable stainless-steel headcap for the purposes of protecting the implant. rats were pair-housed following surgery, and their behaviour was monitored for up to several weeks under two experimental conditions that involved eeg recording and deep-brain stimulation, as well as behavioural test sessions inside an open-field maze. rat weights were compared between individually- and pair-housed rats at up to 3 weeks post-surgery.","['printed headstage implant', 'versatile 3d', 'group housing', 'rodents']"
"the cystic fibrosis (cf) transmembrane conductance regulator (cftr) protein does not operate in isolation, rather in a dynamic network of interacting components that impact its synthesis, folding, stability, intracellular location and function, referred to herein as the 'cftr functional landscape (cffl)'. for the prominent f508del mutation, many of these interactors are deeply connected to a protein fold management system, the proteostasis network (pn). however, cf encompasses an additional 2000 cftr variants distributed along its entire coding sequence (referred to as cftr2), and each variant contributes a differential liability to pn management of cftr and to a protein 'social network' (sn) that directs the probability of the (patho)physiologic events that impact ion transport in each cell, tissue and patient in health and disease. recognition of the importance of the pn and sn in driving the unique patient cffl leading to disease highlights the importance of precision medicine in therapeutic management of disease progression. we take the view herein that it is not cftr, rather the pn/sn, and their impact on the cffl, that are the key physiologic forces driving onset and clinical progression of cf. we posit that a deep understanding of each patients pn/sn gained by merging genomic, proteomic (mass spectrometry (ms)), and high-content microscopy (hcm) technologies in the context of novel network learning algorithms will lead to a paradigm shift in cf clinical management. this should allow for generation of new classes of patient specific pn/sn directed therapeutics for personalized management of the cffl in the clinic.","['cystic fibrosis functional landscape', 'therapeutic management', 'hallmarks']"
"molecular biomarkers that can predict drug efficacy in cancer patients are crucial components for the advancement of precision medicine. however, identifying these molecular biomarkers remains a laborious and challenging task. next-generation sequencing of patients and preclinical models have increasingly led to the identification of novel gene-mutation-drug relations, and these results have been reported and published in the scientific literature.","['drug relations', 'deep learning', 'mutation', 'literature', 'gene']"
"the discussion about violent video games tends to engender extreme positions, each of which are deserving of deep skepticism. ferguson's (2015, this issue) claim that humans can do something repeatedly with no effect on them should be examined carefully, especially as it violates most established psychological and learning theories. in this commentary, we examine three aspects of ferguson's claim. first, it is a typical rhetorical trick to sow doubt, but it is valuable to examine the doubting claims. second, it is good rhetoric to direct attention in only one direction, but it is valuable to examine that direction within its broader outlook. third, it is good rhetoric to imply bias on the part of one position, but it is valuable to examine the potential biases on all sides. good science definitely requires skeptics. the problem with the violent video game debate is perhaps that we have not been skeptical enough.","['media violence discussion', 'good skeptic', 'skepticism', 'case']"
"cognitive training programs that instruct specific strategies frequently show limited transfer. open-ended approaches can achieve greater transfer, but may fail to benefit many older adults due to age deficits in self-initiated processing. we examined whether a compromise that encourages effort at encoding without an experimenter-prescribed strategy might yield better results. older adults completed memory training under conditions that either (1) mandated a specific strategy to increase deep, associative encoding, (2) attempted to suppress such encoding by mandating rote rehearsal, or (3) encouraged time and effort toward encoding but allowed for strategy choice. the experimenter-enforced associative encoding strategy succeeded in creating integrated representations of studied items, but training-task progress was related to pre-existing ability. independent of condition assignment, self-reported deep encoding was associated with positive training and transfer effects, suggesting that the most beneficial outcomes occur when environmental support guiding effort is provided but participants generate their own strategies.","['driven versus experimenter', 'driven processing strategies', 'memory training', 'way', 'transfer', 'participant', 'go', 'effectiveness']"
"rapid technological advances in non-invasive imaging, coupled with the availability of large data sets and the expansion of computational models and power, have revolutionized the role of imaging in medicine. non-invasive imaging is the pillar of modern cardiovascular diagnostics, with modalities such as cardiac computed tomography (ct) now recognized as first-line options for cardiovascular risk stratification and the assessment of stable or even unstable patients. to date, cardiovascular imaging has lagged behind other fields, such as oncology, in the clinical translational of artificial intelligence (ai)-based approaches. we hereby review the current status of ai in non-invasive cardiovascular imaging, using cardiac ct as a running example of how novel machine learning (ml)-based radiomic approaches can improve clinical care. the integration of ml, deep learning, and radiomic methods has revealed direct links between tissue imaging phenotyping and tissue biology, with important clinical implications. more specifically, we discuss the current evidence, strengths, limitations, and future directions for ai in cardiac imaging and ct, as well as lessons that can be learned from other areas. finally, we propose a scientific framework in order to ensure the clinical and scientific validity of future studies in this novel, yet highly promising field. still in its infancy, ai-based cardiovascular imaging has a lot to offer to both the patients and their doctors as it catalyzes the transition towards a more precise phenotyping of cardiovascular disease.","['radiomic guide', 'precision phenotyping', 'medical imaging', 'cardiovascular disease', 'artificial intelligence']"
"living birds constitute the only vertebrate group whose brain volume relative to body size approaches the uniquely expanded values expressed by mammals. the broad suite of complex behaviors exhibited by crown-group birds, including sociality, vocal learning, parental care, and flying, suggests the origins of their encephalization was likely driven by a mosaic of selective pressures. if true, the historical pattern of brain expansion may be more complex than either a gradual expansion, as proposed by early studies of the avian brain, or a sudden expansion correlating with the appearance of flight. the origins of modern avian neuroanatomy are obscured by the more than 100 million years of evolution along their phylogenetic stem (from the origin of the modern radiation in the middle jurassic to the split from crocodile-line archosaurs). here we use phylogenetic comparative approaches to explore which evolutionary scenarios best explain variation in measured volumes of digitally partitioned endocasts of modern birds and their non-avian ancestors. our analyses suggest that variation in the relative volumes of the endocranium and cerebrum explain most of the structural variation in this lineage. generalized multi-regime ornstein-uhlenbeck (ou) models suggest that powered flight does not appear to be a driver of observed variation, reinforcing the hypothesis that the deep history of the avian brain is complex, with nuances still to be discovered.","['brain modularity across', 'neuroanatomical variation', 'bird transition', 'theropod', 'testing', 'influence', 'flight']"
"reduced graphene oxide (rgo), a carbon-based nanomaterial, has enormous potential in biomedical research, including in\xa0vivo cancer therapeutics. concerns over the toxicity remain outstanding and must be investigated before clinical application. the effect of rgo exposure on animal behaviors, such as learning and memory abilities, has not been clarified. herein, we explored the short- and long-term effects of orally administered rgo on mouse behaviors, including general locomotor activity level, balance and neuromuscular coordination, exploratory and anxiety behaviors, and learning and memory abilities using open-field, rotarod, and morris water maze tests. compared with mice administered buffer-dispersed mouse chow or buffer alone, mice receiving a high dose of small or large rgo nanosheets showed little change in exploratory, anxiety-like, or learning and memory behaviors, although general locomotor activity, balance, and neuromuscular coordination were initially affected, which the mechanisms (e.g. the influence of rgo exposure on the activity of superoxide dismutase in mouse serum) were discussed. the results presented in this work look to provide a deep understanding of the in\xa0vivo toxicity of rgo to animals, especially its effect on learning and memory and other behaviors.","['dose reduced graphene oxide nanosheets', 'orally administered high', 'term effects', 'mouse behaviors', 'short', 'long']"
"artificial intelligence (ai) broadly refers to analytical algorithms that iteratively learn from data, allowing computers to find hidden insights without being explicitly programmed where to look. these include a family of operations encompassing several terms like machine learning, cognitive learning, deep learning and reinforcement learning-based methods that can be used to integrate and interpret complex biomedical and healthcare data in scenarios where traditional statistical methods may not be able to perform. in this review article, we discuss the basics of machine learning algorithms and what potential data sources exist; evaluate the need for machine learning; and examine the potential limitations and challenges of implementing machine in the context of cardiovascular medicine. the most promising avenues for ai in medicine are the development of automated risk prediction algorithms which can be used to guide clinical care; use of unsupervised learning techniques to more precisely phenotype complex disease; and the implementation of reinforcement learning algorithms to intelligently augment healthcare providers. the utility of a machine learning-based predictive model will depend on factors including data heterogeneity, data depth, data breadth, nature of modelling task, choice of machine learning and feature selection algorithms, and orthogonal evidence. a critical understanding of the strength and limitations of various methods and tasks amenable to machine learning is vital. by leveraging the growing corpus of big data in medicine, we detail pathways by which machine learning may facilitate optimal development of patient-specific models for improving diagnoses, intervention and outcome in cardiovascular medicine.","['machine learning', 'cardiovascular medicine', 'yet']"
"in this commentary, we highlight a crucial challenge posed by the proposal of lake et al. to introduce key elements of human cognition into deep neural networks and future artificial-intelligence systems: the need to design effective sophisticated architectures. we propose that looking at the brain is an important means of facing this great challenge.","['require sophisticated architectures', 'brain might guide', 'intelligence systems', 'future artificial', 'architecture challenge', 'knowledge', 'construction']"
"alternative splicing significantly contributes to proteomic diversity and mis-regulation of splicing can cause diseases in human. although both genomic and chromatin features have been shown to associate with splicing, the mechanisms by which various chromatin marks influence splicing is not clear for the most part. moreover, it is not known whether the influence of specific genomic features on splicing is potentially modulated by the chromatin context. here we report a deep neural network (dnn) model for predicting exon inclusion based on comprehensive genomic and chromatin features. our analysis in three cell lines shows that, while both genomic and chromatin features can predict splicing to varying degrees, genomic features are the primary drivers of splicing, and the predictive power of chromatin features can largely be explained by their correlation with genomic features; chromatin features do not yield substantial independent contribution to splicing predictability. however, our model identified specific interactions between chromatin and genomic features suggesting that the effect of genomic elements may be modulated by chromatin context.","['genomic determinants', 'alternative splicing', 'chromatin']"
"automated computer-aided detection (cade) has been an important tool in clinical practice and research. state-of-the-art methods often show high sensitivities at the cost of high false-positives (fp) per patient rates. we design a two-tiered coarse-to-fine cascade framework that first operates a candidate generation system at sensitivities \xa0∼\xa0100% of but at high fp levels. by leveraging existing cade systems, coordinates of regions or volumes of interest (roi or voi) are generated and function as input for a second tier, which is our focus in this study. in this second stage, we generate 2d (two-dimensional) or 2.5d views via sampling through scale transformations, random translations and rotations. these random views are used to train deep convolutional neural network (convnet) classifiers. in testing, the convnets assign class (e.g., lesion, pathology) probabilities for a new set of random views that are then averaged to compute a final per-candidate classification probability. this second tier behaves as a highly selective process to reject difficult false positives while preserving high sensitivities. the methods are evaluated on three data sets: 59 patients for sclerotic metastasis detection, 176 patients for lymph node detection, and 1,186 patients for colonic polyp detection. experimental results show the ability of convnets to generalize well to different medical imaging cade applications and scale elegantly to various data sets. our proposed methods improve performance markedly in all cases. sensitivities improved from 57% to 70%, 43% to 77%, and 58% to 75% at 3 fps per patient for sclerotic metastases, lymph nodes and colonic polyps, respectively.","['aided detection using convolutional neural networks', 'random view aggregation', 'improving computer']"
"recently, many biologically inspired visual computational models have been proposed. the design of these models follows the related biological mechanisms and structures, and these models provide new solutions for visual recognition tasks. in this paper, based on the recent biological evidence, we propose a framework to mimic the active and dynamic learning and recognition process of the primate visual cortex. from principle point of view, the main contributions are that the framework can achieve unsupervised learning of episodic features (including key components and their spatial relations) and semantic features (semantic descriptions of the key components), which support higher level cognition of an object. from performance point of view, the advantages of the framework are as follows: 1) learning episodic features without supervision-for a class of objects without a prior knowledge, the key components, their spatial relations and cover regions can be learned automatically through a deep neural network (dnn); 2) learning semantic features based on episodic features-within the cover regions of the key components, the semantic geometrical values of these components can be computed based on contour detection; 3) forming the general knowledge of a class of objects-the general knowledge of a class of objects can be formed, mainly including the key components, their spatial relations and average semantic values, which is a concise description of the class; and 4) achieving higher level cognition and dynamic updating-for a test image, the model can achieve classification and subclass semantic descriptions. and the test samples with high confidence are selected to dynamically update the whole model. experiments are conducted on face images, and a good performance is achieved in each layer of the dnn and the semantic description learning process. furthermore, the model can be generalized to recognition tasks of other objects with learning ability.","['visual cognition achieving unsupervised episodic', 'semantic feature learning', 'biologically inspired model']"
"rna-binding proteins (rbps) play important roles in the post-transcriptional control of rnas. identifying rbp binding sites and characterizing rbp binding preferences are key steps toward understanding the basic mechanisms of the post-transcriptional gene regulation. though numerous computational methods have been developed for modeling rbp binding preferences, discovering a complete structural representation of the rbp targets by integrating their available structural features in all three dimensions is still a challenging task. in this paper, we develop a general and flexible deep learning framework for modeling structural binding preferences and predicting binding sites of rbps, which takes (predicted) rna tertiary structural information into account for the first time. our framework constructs a unified representation that characterizes the structural specificities of rbp targets in all three dimensions, which can be further used to predict novel candidate binding sites and discover potential binding motifs. through testing on the real clip-seq datasets, we have demonstrated that our deep learning framework can automatically extract effective hidden structural features from the encoded raw sequence and structural profiles, and predict accurate rbp binding sites. in addition, we have conducted the first study to show that integrating the additional rna tertiary structural features can improve the model performance in predicting rbp binding sites, especially for the polypyrimidine tract-binding protein (ptb), which also provides a new evidence to support the view that rbps may own specific tertiary structural binding preferences. in particular, the tests on the internal ribosome entry site (ires) segments yield satisfiable results with experimental support from the literature and further demonstrate the necessity of incorporating rna tertiary structural information into the prediction model. the source code of our approach can be found in https://github.com/thucombio/deepnet-rbp.","['modeling structural features', 'deep learning framework', 'binding protein targets', 'rna']"
