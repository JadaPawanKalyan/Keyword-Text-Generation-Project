{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2m-R-Z3mqjpj"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "erqrmj7Qqxn5"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('documents.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VY7MNj9hrW8_"
   },
   "source": [
    "This data is a collection of research papers from various fields like deep_learning, covid_19, virtual_reality etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 548
    },
    "id": "Tn5u9Ud9ptnd",
    "outputId": "0476b469-62e9-4105-8d59-4714e01c3161"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-b09e88da-42d1-4c14-9e58-2bbb50fced75\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>deep_learning</th>\n",
       "      <th>covid_19</th>\n",
       "      <th>human_connectome</th>\n",
       "      <th>virtual_reality</th>\n",
       "      <th>brain_machine_interfaces</th>\n",
       "      <th>electroactive_polymers</th>\n",
       "      <th>pedot_electrodes</th>\n",
       "      <th>neuroprosthetics</th>\n",
       "      <th>deep_learning_links</th>\n",
       "      <th>covid_19_links</th>\n",
       "      <th>human_connectome_links</th>\n",
       "      <th>virtual_reality_links</th>\n",
       "      <th>brain_machine_interfaces_links</th>\n",
       "      <th>electroactive_polymers_links</th>\n",
       "      <th>pedot_electrodes_links</th>\n",
       "      <th>neuroprosthetics_links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>(['Magnetic resonance spectroscopic imaging (M...</td>\n",
       "      <td>(['As cancer researchers shutter their labs to...</td>\n",
       "      <td>(['For decades, it has been largely unknown to...</td>\n",
       "      <td>(['To evaluate the differences between walking...</td>\n",
       "      <td>(['All neural information systems (NIS) rely o...</td>\n",
       "      <td>(['A mediatorless glucose biosensor was develo...</td>\n",
       "      <td>(['In the growing field of brain-machine inter...</td>\n",
       "      <td>(['The heart continuously and cyclically commu...</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/31352337</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/32234716</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/25420254</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/30653920</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/27669264</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/22967516</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/28266832</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/31051293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>(['Existing deep convolutional neural networks...</td>\n",
       "      <td>(['In December 2019, the outbreak of pneumonia...</td>\n",
       "      <td>(['While resting-state functional magnetic res...</td>\n",
       "      <td>(['Potentially painful invasive procedures are...</td>\n",
       "      <td>(['Independent component analysis (ICA) as a p...</td>\n",
       "      <td>(['Hierarchical structures of hybrid materials...</td>\n",
       "      <td>(['High-performance transparent and flexible t...</td>\n",
       "      <td>(['This study was aimed at investigating the i...</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/31329133</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/32235387</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/25589760</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/30679136</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/27631789</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/23545560</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/28937733</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/30655080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>(['Deep learning techniques have been increasi...</td>\n",
       "      <td>([], 'Treating COVID-19 with Chloroquine.')</td>\n",
       "      <td>(['This paper presents the experimental evalua...</td>\n",
       "      <td>([\"Early exposure to radiological cross-sectio...</td>\n",
       "      <td>([], 'Brain-machine interfaces: assistive, tho...</td>\n",
       "      <td>(['An analytical method was researched for the...</td>\n",
       "      <td>(['In this investigation, we employed a novel ...</td>\n",
       "      <td>(['Low-intensity focused ultrasound stimulatio...</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/31329567</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/32236562</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/25624185</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/30697948</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/27654684</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/22265536</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/28825302</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/30952150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>(['The original article unfortunately containe...</td>\n",
       "      <td>(['18 years ago, in 2002, the world was astoni...</td>\n",
       "      <td>([], \"For Microscopy special issue on 'connect...</td>\n",
       "      <td>(['To investigate the effects of various rehab...</td>\n",
       "      <td>(['While motor-imagery based brain-computer in...</td>\n",
       "      <td>(['The antibacterial properties of a nanocompo...</td>\n",
       "      <td>(['Great progress has been made on the cyclabi...</td>\n",
       "      <td>(['Our brain has developed a specific system t...</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/31350607</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/32235085</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/25652424</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/30686327</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/27578310</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/22091864</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/28306233</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/30685486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>(['The most common applications of artificial ...</td>\n",
       "      <td>([], 'Covid-19: Doctors still at \"considerable...</td>\n",
       "      <td>(['A central feature of theories of spatial na...</td>\n",
       "      <td>(['Virtual reality (VR) is a technology that a...</td>\n",
       "      <td>(['The disorders of consciousness refer to cli...</td>\n",
       "      <td>(['The metal-mediated self-assembly of coordin...</td>\n",
       "      <td>(['With the aim of a reliable biosensing exhib...</td>\n",
       "      <td>([\"Electrophysiological techniques have improv...</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/31348869</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/32234713</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/25601828</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/30668519</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/27590972</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/22624584</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/29201623</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/30564810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b09e88da-42d1-4c14-9e58-2bbb50fced75')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-b09e88da-42d1-4c14-9e58-2bbb50fced75 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-b09e88da-42d1-4c14-9e58-2bbb50fced75');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   Unnamed: 0  ...                        neuroprosthetics_links\n",
       "0           0  ...  https://www.ncbi.nlm.nih.gov/pubmed/31051293\n",
       "1           1  ...  https://www.ncbi.nlm.nih.gov/pubmed/30655080\n",
       "2           2  ...  https://www.ncbi.nlm.nih.gov/pubmed/30952150\n",
       "3           3  ...  https://www.ncbi.nlm.nih.gov/pubmed/30685486\n",
       "4           4  ...  https://www.ncbi.nlm.nih.gov/pubmed/30564810\n",
       "\n",
       "[5 rows x 17 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "l88IRZuMrQDd"
   },
   "outputs": [],
   "source": [
    "# dropping unimportant column \n",
    "\n",
    "df.drop(['Unnamed: 0'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OoR3kqqKrtzo"
   },
   "source": [
    "The format of the data is: first we have the abstract of the paper along with the title of the paper seperated by \",\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "t0zZ6EKGp_hc",
    "outputId": "52d9779d-c667-4530-abdb-c747e9b289c6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"(['As cancer researchers shutter their labs to comply with COVID-19-related work restrictions, some are turning their attention, resources, and technical know-how to the challenge of tackling the deadly coronavirus.'], 'Cancer Labs Pivot to Battle COVID-19.')\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample examples from dataset\n",
    "\n",
    "df['covid_19'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "PyB5nfforLRD",
    "outputId": "75a7e5f2-b660-4071-825e-f7ff2571c6fa"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"(['To assess the use of deep learning (DL) for computer-assisted glaucoma identification, and the impact of training using images selected by an active learning strategy, which minimizes labelling cost. Additionally, this study focuses on the explainability of the glaucoma classifier.'], 'Accurate prediction of glaucoma from colour fundus images with a convolutional neural network that relies on active and transfer learning.')\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample examples from dataset\n",
    "\n",
    "df['deep_learning'][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "id": "x0kIdrp4q0Ny",
    "outputId": "b59b9ef1-2952-43ad-9aa5-08daf37af6e7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"(['Brain-computer interfaces are systems that use signals recorded from the brain to enable communication and control applications for individuals who have impaired function. This technology has developed to the point that it is now being used by individuals who can actually benefit from it. However, there are several outstanding issues that prevent widespread use. These include the ease of obtaining high-quality recordings by home users, the speed, and accuracy of current devices and adapting applications to the needs of the user. In this chapter, we discuss some of these unsolved issues.'], 'BCI in practice.')\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample examples from dataset\n",
    "\n",
    "df['brain_machine_interfaces'][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "MbPGuUkcsXNf"
   },
   "outputs": [],
   "source": [
    "# Parsing the data, to seperate the abstract_texts of the paper and the title of the paper\n",
    "\n",
    "abstract_texts=[]\n",
    "title_names=[]\n",
    "for i in range(df.shape[0]):\n",
    "  p=df['deep_learning'][i]\n",
    "  if(p is np.nan):\n",
    "    continue\n",
    "  a=p.index('[')\n",
    "  b=p.index(']')\n",
    "  k=p[a+2:b-1].lower()\n",
    "  c=p.index(')',b)\n",
    "  k1=p[b+4:c-1].lower()\n",
    "  if(not(k=='' or k1=='')):\n",
    "    abstract_texts.append(k)\n",
    "    title_names.append(k1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "id": "wtYMFaPYqZZt",
    "outputId": "7e1c469f-5302-4970-9a92-249766b637fe"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'magnetic resonance spectroscopic imaging (mrsi) is a powerful molecular imaging modality but has very limited speed, resolution, and snr tradeoffs. construction of a low-dimensional model to effectively reduce the dimensionality of the imaging problem has recently shown great promise in improving these tradeoffs. this paper presents a new approach to model and reconstruct the spectroscopic signals by learning a nonlinear low-dimensional representation of the general mr spectra. specifically, we trained a deep neural network to capture the low-dimensional manifold, where the high-dimensional spectroscopic signals reside. a regularization formulation is proposed to effectively integrate the learned model and physics-based data acquisition model for mrsi reconstruction with the capability to incorporate additional spatiospectral constraints. an efficient numerical algorithm was developed to solve the associated optimization problem involving back-propagating the trained network. simulation and experimental results were obtained to demonstrate the representation power of the learned model and the ability of the proposed formulation in producing snr-enhancing reconstruction from the practical mrsi data.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "pnkrKSOjqboT",
    "outputId": "4c5b59b2-961f-4283-f015-97404e27d99a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'constrained magnetic resonance spectroscopic imaging by learning nonlinear low-dimensional models.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "nw9_ejxnvGMG"
   },
   "outputs": [],
   "source": [
    "# repeating the same with different columns as well\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "  p=df['covid_19'][i]\n",
    "  if(p is np.nan):\n",
    "    continue\n",
    "  a=p.index('[')\n",
    "  b=p.index(']')\n",
    "  k=p[a+2:b-1].lower()\n",
    "  c=p.index(')',b)\n",
    "  k1=p[b+4:c-1].lower()\n",
    "  if(not(k=='' or k1=='')):\n",
    "    abstract_texts.append(k)\n",
    "    title_names.append(k1)\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "  p=df['human_connectome'][i]\n",
    "  if(p is np.nan):\n",
    "    continue\n",
    "  a=p.index('[')\n",
    "  b=p.index(']')\n",
    "  k=p[a+2:b-1].lower()\n",
    "  c=p.index(')',b)\n",
    "  k1=p[b+4:c-1].lower()\n",
    "  if(not(k=='' or k1=='')):\n",
    "    abstract_texts.append(k)\n",
    "    title_names.append(k1)\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "  p=df['virtual_reality'][i]\n",
    "  if(p is np.nan):\n",
    "    continue\n",
    "  a=p.index('[')\n",
    "  b=p.index(']')\n",
    "  k=p[a+2:b-1].lower()\n",
    "  c=p.index(')',b)\n",
    "  k1=p[b+4:c-1].lower()\n",
    "  if(not(k=='' or k1=='')):\n",
    "    abstract_texts.append(k)\n",
    "    title_names.append(k1)\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "  p=df['brain_machine_interfaces'][i]\n",
    "  if(p is np.nan):\n",
    "    continue\n",
    "  a=p.index('[')\n",
    "  b=p.index(']')\n",
    "  k=p[a+2:b-1].lower()\n",
    "  c=p.index(')',b)\n",
    "  k1=p[b+4:c-1].lower()\n",
    "  if(not(k=='' or k1=='')):\n",
    "    abstract_texts.append(k)\n",
    "    title_names.append(k1)\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "  p=df['electroactive_polymers'][i]\n",
    "  if(p is np.nan):\n",
    "    continue\n",
    "  a=p.index('[')\n",
    "  b=p.index(']')\n",
    "  k=p[a+2:b-1].lower()\n",
    "  c=p.index(')',b)\n",
    "  k1=p[b+4:c-1].lower()\n",
    "  if(not(k=='' or k1=='')):\n",
    "    abstract_texts.append(k)\n",
    "    title_names.append(k1)\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "  p=df['pedot_electrodes'][i]\n",
    "  if(p is np.nan):\n",
    "    continue\n",
    "  a=p.index('[')\n",
    "  b=p.index(']')\n",
    "  k=p[a+2:b-1].lower()\n",
    "  c=p.index(')',b)\n",
    "  k1=p[b+4:c-1].lower()\n",
    "  if(not(k=='' or k1=='')):\n",
    "    abstract_texts.append(k)\n",
    "    title_names.append(k1)\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "  p=df['neuroprosthetics'][i]\n",
    "  if(p is np.nan):\n",
    "    continue\n",
    "  a=p.index('[')\n",
    "  b=p.index(']')\n",
    "  k=p[a+2:b-1].lower()\n",
    "  c=p.index(')',b)\n",
    "  k1=p[b+4:c-1].lower()\n",
    "  if(not(k=='' or k1=='')):\n",
    "    abstract_texts.append(k)\n",
    "    title_names.append(k1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e9vV4d7CtZ3R"
   },
   "source": [
    "So we have the title names and the abstracts. Our aim is to extract keywords from the title name of the paper. So I used rake-nltk which extracts keywords in a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4x5_tbQ60CVs"
   },
   "outputs": [],
   "source": [
    "!pip install rake-nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Cq4KQCBtNAM",
    "outputId": "347db9cf-59a2-4600-cec4-9dbc9de08ba2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wGSoX5i0tTGU",
    "outputId": "2939c9d5-f57a-40a8-86d1-a364916f1cb9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "CQmqluRzyFpD"
   },
   "outputs": [],
   "source": [
    "from rake_nltk import Rake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "T1473s3LzTnp"
   },
   "outputs": [],
   "source": [
    "rake_nltk_var = Rake()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "L2ICXuZazYSv"
   },
   "outputs": [],
   "source": [
    "rake_nltk_var.extract_keywords_from_text(title_names[0])\n",
    "keyword_extracted = rake_nltk_var.get_ranked_phrases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SEpO1ZYptWCm",
    "outputId": "d645bb2d-3217-42e5-934c-df41974c4728"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: constrained magnetic resonance spectroscopic imaging by learning nonlinear low-dimensional models.\n",
      "\n",
      "Keywords extracted from text: ['constrained magnetic resonance spectroscopic imaging', 'learning nonlinear low', 'dimensional models']\n"
     ]
    }
   ],
   "source": [
    "# sample keywords extracted from the text\n",
    "\n",
    "print ('Text:',title_names[0])\n",
    "print()\n",
    "print ('Keywords extracted from text:',keyword_extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "HoZb3_4r0leV"
   },
   "outputs": [],
   "source": [
    "# storing keywords for all the texts\n",
    "\n",
    "keywords=[]\n",
    "for i in range(len(title_names)):\n",
    "  rake_nltk_var = Rake()\n",
    "  rake_nltk_var.extract_keywords_from_text(title_names[i])\n",
    "  keyword_extracted = rake_nltk_var.get_ranked_phrases()\n",
    "  keywords.append(keyword_extracted[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "1m1FdJiD13JJ"
   },
   "outputs": [],
   "source": [
    "# creating a dataset with abstract names and the keywords extracted from title\n",
    "\n",
    "df1=pd.DataFrame({\n",
    "    'text':abstract_texts,\n",
    "    'keywords':keywords\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "NzRk6C4kubkP",
    "outputId": "3871141f-9fcc-4285-e542-13e7b028f75c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-afef7cba-9dfa-4cb1-bdae-c287c62b95b9\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38534</th>\n",
       "      <td>neurological disorders disrupt the equilibrium...</td>\n",
       "      <td>[defining ecological strategies, neuroprosthet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38535</th>\n",
       "      <td>the first decade and a half of the twenty-firs...</td>\n",
       "      <td>[natural neural coding, bionic hands, artifici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38536</th>\n",
       "      <td>stimuli from different sensory modalities occu...</td>\n",
       "      <td>[extending peripersonal space representation w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38537</th>\n",
       "      <td>studying body representations in the brain hel...</td>\n",
       "      <td>[somatosensory touch stimuli using 7 tesla fmr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38538</th>\n",
       "      <td>neurofeedback training of motor imagery (mi)-r...</td>\n",
       "      <td>[reinforcement learning, regulated β, motor re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-afef7cba-9dfa-4cb1-bdae-c287c62b95b9')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-afef7cba-9dfa-4cb1-bdae-c287c62b95b9 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-afef7cba-9dfa-4cb1-bdae-c287c62b95b9');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                    text                                           keywords\n",
       "38534  neurological disorders disrupt the equilibrium...  [defining ecological strategies, neuroprosthet...\n",
       "38535  the first decade and a half of the twenty-firs...  [natural neural coding, bionic hands, artifici...\n",
       "38536  stimuli from different sensory modalities occu...  [extending peripersonal space representation w...\n",
       "38537  studying body representations in the brain hel...  [somatosensory touch stimuli using 7 tesla fmr...\n",
       "38538  neurofeedback training of motor imagery (mi)-r...  [reinforcement learning, regulated β, motor re..."
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_t3YnXFXu8QH",
    "outputId": "c58e2ba0-1f83-4211-f1c2-c5bf86701dc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: magnetic resonance spectroscopic imaging (mrsi) is a powerful molecular imaging modality but has very limited speed, resolution, and snr tradeoffs. construction of a low-dimensional model to effectively reduce the dimensionality of the imaging problem has recently shown great promise in improving these tradeoffs. this paper presents a new approach to model and reconstruct the spectroscopic signals by learning a nonlinear low-dimensional representation of the general mr spectra. specifically, we trained a deep neural network to capture the low-dimensional manifold, where the high-dimensional spectroscopic signals reside. a regularization formulation is proposed to effectively integrate the learned model and physics-based data acquisition model for mrsi reconstruction with the capability to incorporate additional spatiospectral constraints. an efficient numerical algorithm was developed to solve the associated optimization problem involving back-propagating the trained network. simulation and experimental results were obtained to demonstrate the representation power of the learned model and the ability of the proposed formulation in producing snr-enhancing reconstruction from the practical mrsi data.\n",
      "\n",
      "Keywords: ['constrained magnetic resonance spectroscopic imaging', 'learning nonlinear low', 'dimensional models']\n"
     ]
    }
   ],
   "source": [
    "# Final dataset example\n",
    "\n",
    "print('Text:', df1['text'][0])\n",
    "print()\n",
    "print('Keywords:', df1['keywords'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GH4BfgnSvLgk"
   },
   "source": [
    "So, in this way we extracted keywords without manually creating them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "rqfgH7OL2Kfl"
   },
   "outputs": [],
   "source": [
    "# Saving the dataset\n",
    "\n",
    "df1.to_csv('data_keywords.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CRrvFFQp2czq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "data keywords extraction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
